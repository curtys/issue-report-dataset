{
    "comments": [
        {
            "author": null,
            "body": "Update to the current svn head.\nI have fixed a DataSender refactoring bug. This means that tomcat 5.5.12 cluster\nsend all messages thread synchronized with only one sender socket. \nOther bug is that the membership message format has changed (s. Bug 37808)\n\nCan you please test with the newest cluster code?\n\nI reference your report now at changelog.\nI am not sure that your szenarion not show another problem!\n\nIs it true, that all your nodes are inside the same cluster replication domain?\n\nSorry for the trouble and thanks for analyse and reporting the bug\nPeter",
            "date": "20051214T08:32:12",
            "id": 0
        },
        {
            "author": null,
            "body": "I'll try to get a copy of the new code, I'm not so sure I can test it though as\nthe circumstances are quite particular in reproducing this problem and I can't\nreally take down our live site to test it. I'll at least read through it to see\nif the blocking scenerio can take place.\n\nAs for the node, yes I think so if I understand your question properly, we only\nhave 1 node name, and 1 domain name, and 1 context which is distributable.",
            "date": "20051214T23:32:22",
            "id": 1
        },
        {
            "author": null,
            "body": "Okay I had a look at the new code and I'm pretty sure the problem will still\nmanifest itself. \n\nThe problem isn't with the code perse but I think it's a problem with the design\nof the replication. Since the replication is in-line with the HTTP request\n(seems like new session requests are inline even in asynch mode), if something\nbad happens to the replication socket which causes it to hang, it will block\nthat thread (presumably until SO_TIMEOUT which is usually 2 minutes).\n\nIf a subsequent request comes in for a new session, it will try to do the same\nthing but it needs to aquire a lock on the DataSender object via sendMessage();\ntherefore, this thread will now block until the previous thread timesout. As a\nresult a lot of threads may backup while waiting for the original socket to timeout.\n\nNote that this could happen even in pooled mode, if all 300 threads had their\nown 300 replicator sockets, and each sat there waiting to timeout for 2 minutes,\nthen there wuld be no more threads available (assuming I'm maxed at 300 threads).\n\nThe only things I can really think of to resolve this is to have the replication\non a separate thread to the http requests. \n\nOf course maybe I'm just mis-reading the code and everything I'm saying might be\nwrong...",
            "date": "20051215T00:25:14",
            "id": 2
        },
        {
            "author": null,
            "body": "Fast async has been designed to be used asynchronously. With such a\nconfiguration, no tcp communication for replication will be done during the\nrequest-response lifecycle. Instead all replication messages will only put into\na local queue. Seperate threads will pick up these messages an send them. The\nqueue will be locked while taking out the messages, but the lock will b freed\nbefore actually trying to send a message.",
            "date": "20051215T01:23:58",
            "id": 3
        },
        {
            "author": null,
            "body": "Hmm,\n\nwhen you don't want update complete to 5.5.15 (svn head) you can\ncompile the cluster module and copy the resulting catalina-cluster.jar inside\n5.5.12 release. \n\nThe default cluster configuration normaly used fastasyncqueue, the problem is\nthat the subclass not implement the right method. Now is fixed and all is\nworking well.\n\nPeter",
            "date": "20051215T08:57:49",
            "id": 4
        }
    ],
    "component": "Catalina:Cluster",
    "description": "If one server fails \"badly\" (I believe resulting in a socket time out error) the\nFastAsyncSocketSender is locked by a thread and causes a backlog on all\nsubsequent http threads causing the entire machine to run out of sockets.\n\nDetails below :\n\nDefault cluster settings : \n<Cluster className=\"org.apache.catalina.cluster.tcp.SimpleTcpCluster\" />\n\nWe have mutlipele web machines (6 of them). Something really bad happened at our\ndata center (not sure what, cable fault, some dweeb tripped on our ethernet,\ndon't quite know yet) causing one of our web servers to die.\n\nThe rest of the machines then back logged trying to replicate to the dead\nmachine, which caused all the web servers to fill up the max threads causing a\nsite outtage.\n\nWe took stack traces at the point in time where we had to restart the tomcat\nprocess, what I believe to be the relavent stack traces are included below. \n\nYou can see one of the http threads (143) is trying to replicate synchronously\n(which I found odd using fastasynch but okay) I believe this thread is stuck on\na 2 minute socket time out and currently holds a lock on FastAsych.\n\nNotice the Cluster-MembershipReceiver thread is waiting for the fastAsynch\nobject and currently holds a lock on ReplicationTransmitter.\n\nNotice Http thread (147) is waiting on ReplicationTransmitter. As a result I\nhave about 298 other Http threads all waiting on ReplicationTransmitter. I had\n300 threads configured.\n\nNow I realised after a \"while\" the socket will time out and it'll all work\nitself out but our site was stuck in this mode for over 10 minutes so I think\nthis is kind of a bug on the basis that 1 machine dying (albiet badly) shouldn't\ncause all other machines to backlog at all.\n\n------------\n\n\"http-80-Processor143\" daemon prio=1 tid=0x084ad748 nid=0x6953 runnable\n[0x7e7bf000..0x7e7bf63c]\n\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:92)\n\tat java.net.SocketOutputStream.write(SocketOutputStream.java:124)\n\tat org.apache.catalina.cluster.tcp.DataSender.writeData(DataSender.java:830)\n\tat org.apache.catalina.cluster.tcp.DataSender.pushMessage(DataSender.java:772)\n\tat org.apache.catalina.cluster.tcp.DataSender.sendMessage(DataSender.java:598)\n\t- locked <0x4e7864f8> (a org.apache.catalina.cluster.tcp.FastAsyncSocketSender)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationTransmitter.sendMessageData(ReplicationTransmitter.java:868)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationTransmitter.sendMessageClusterDomain(ReplicationTransmitter.java:460)\n\tat\norg.apache.catalina.cluster.tcp.SimpleTcpCluster.sendClusterDomain(SimpleTcpCluster.java:1017)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationValve.sendSessionReplicationMessage(ReplicationValve.java:333)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationValve.invoke(ReplicationValve.java:271)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:105)\n\tat\norg.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:107)\n\tat\norg.apache.catalina.valves.FastCommonAccessLogValve.invoke(FastCommonAccessLogValve.java:495)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:148)\n\tat org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:868)\n\tat\norg.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:663)\n\tat\norg.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:527)\n\tat\norg.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:80)\n\tat\norg.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:684)\n\tat java.lang.Thread.run(Thread.java:595)\n\n\n\n\"Cluster-MembershipReceiver\" daemon prio=1 tid=0x78804ad8 nid=0x661c waiting for\nmonitor entry [0x786ff000..0x786ff73c]\n\tat org.apache.catalina.cluster.tcp.DataSender.disconnect(DataSender.java:560)\n\t- waiting to lock <0x4e7864f8> (a\norg.apache.catalina.cluster.tcp.FastAsyncSocketSender)\n\tat\norg.apache.catalina.cluster.tcp.FastAsyncSocketSender.disconnect(FastAsyncSocketSender.java:295)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationTransmitter.remove(ReplicationTransmitter.java:689)\n\t- locked <0x4e7a4e68> (a org.apache.catalina.cluster.tcp.ReplicationTransmitter)\n\tat\norg.apache.catalina.cluster.tcp.SimpleTcpCluster.memberDisappeared(SimpleTcpCluster.java:1124)\n\tat\norg.apache.catalina.cluster.mcast.McastService.memberDisappeared(McastService.java:455)\n\tat\norg.apache.catalina.cluster.mcast.McastServiceImpl.receive(McastServiceImpl.java:221)\n\tat\norg.apache.catalina.cluster.mcast.McastServiceImpl$ReceiverThread.run(McastServiceImpl.java:253)\n\n\n\n\"http-80-Processor147\" daemon prio=1 tid=0x084b1208 nid=0x6957 waiting for\nmonitor entry [0x7e8bf000..0x7e8bf83c]\n\tat\norg.apache.catalina.cluster.tcp.ReplicationTransmitter.addStats(ReplicationTransmitter.java:702)\n\t- waiting to lock <0x4e7a4e68> (a\norg.apache.catalina.cluster.tcp.ReplicationTransmitter)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationTransmitter.sendMessageData(ReplicationTransmitter.java:870)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationTransmitter.sendMessageClusterDomain(ReplicationTransmitter.java:460)\n\tat\norg.apache.catalina.cluster.tcp.SimpleTcpCluster.sendClusterDomain(SimpleTcpCluster.java:1017)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationValve.sendSessionReplicationMessage(ReplicationValve.java:333)\n\tat\norg.apache.catalina.cluster.tcp.ReplicationValve.invoke(ReplicationValve.java:271)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:105)\n\tat\norg.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:107)\n\tat\norg.apache.catalina.valves.FastCommonAccessLogValve.invoke(FastCommonAccessLogValve.java:495)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:148)\n\tat org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:868)\n\tat\norg.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:663)\n\tat\norg.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:527)\n\tat\norg.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:80)\n\tat\norg.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:684)\n\tat java.lang.Thread.run(Thread.java:595)",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "37896",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "P2 normal",
    "product": "Tomcat 5",
    "project": "TOMCAT",
    "summary": "FastAsyncSocketSender blocks all threads on socket error",
    "systemSpecification": true,
    "version": "5.5.12"
}