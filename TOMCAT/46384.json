{
    "comments": [
        {
            "author": null,
            "body": "Created attachment 23501\nPatch to fix this issue\n\nThe attached patch should fix this although I haven't tested it.",
            "date": "20090416T13:49:55",
            "id": 0
        },
        {
            "author": null,
            "body": "Might be an idea to make the field \"memebrshipMutex\" (sic) final, as otherwise the synchronisation is not guaranteed to work.",
            "date": "20090416T15:55:45",
            "id": 1
        },
        {
            "author": null,
            "body": "(In reply to comment #1)\n> Created an attachment (id=23501) [details]\n> Patch to fix this issue\n> \n> The attached patch should fix this although I haven't tested it.\n\nI don't think that patch will fix it. The key problem here is that if the sender thread gets locked up, it will stop broadcast the member itself, and other nodes will deem it gone.\n\nThe only solution here is to not lock up the sender thread ever. The same goes for the receiver thread. \n\nThe code is a bit of a sync spaghetti mess, but Tomcat 6.0 has the fix for this, that will prevent it from locking up these two threads.\n\nTC 6 also has secondary verification mechanism, that are unrelated to this.\n\nYou'd be better off backporting the fix from Tomcat 6 to Tomcat 5",
            "date": "20090416T20:58:18",
            "id": 2
        },
        {
            "author": null,
            "body": "Patch withdrawn based on Filip's comment",
            "date": "20090701T05:31:22",
            "id": 3
        },
        {
            "author": null,
            "body": "Created attachment 24253\nUpdated patch for this issue\n\nI found the time to take another look at this.\n\nWhilst Filip's comment about threads locking up is correct - and Tomcat 6 does have a fix for that - threads locking up is not at the root of this issue. At the root of this issue is there there are two lists of cluster members. One in McastServiceImpl.membership and one in ReplicationTransmitter.map\n\nWhilst checkExpire() does update both lists with the sync on expiredMutex, the receiver thread updates the McastServiceImpl.membership outside of this mutex. That leads to the problem that the OP is describing here.\n\nWhilst Tomcat 6 does contain a fix for this, the code bases have diverged sufficiently that the fix would be invasive. Therefore I am proposing a patch for Tomcat that is similar to my earlier patch but has a slightly wider sync block based on my better understanding of this issue.\n\nI have tested the patch and whilst I can force this issue using a debugger without the patch, I can not force it with the patch in place.",
            "date": "20090913T11:14:42",
            "id": 4
        },
        {
            "author": null,
            "body": "Fixed in trunk. Many thanks.",
            "date": "20091130T16:33:13",
            "id": 5
        },
        {
            "author": null,
            "body": "As said in http://marc.info/?l=tomcat-dev&m=125934902622453&w=2\nit is fixed in 5.5.29.\n(Probably that comment disappeared in the Bugzilla data loss/rollback incident)\n\nThe commit that fixed the issue is r884960.\n\nAs mentioned in comment 5 and comment 3, Tomcat 6 and trunk are not affected by this issue.",
            "date": "20100311T13:58:50",
            "id": 6
        }
    ],
    "component": "Catalina:Cluster",
    "description": "Below there is a \"pseudo-code-extract\" of the McastServiceImpl Recieiver- and Sender-Thread flow.\n\nNow assume the following situation:\n- ServerA,ServerB in a cluster; both had added each other to theire McastMembership \n\nOn ServerA:\nt0: The \"Sender\"-Thread is at position [P0], and found the mm = \"ServerB\". \n    So in the moment \"ServerB\" is not in the McastMembership.map!!\n    \nt1: The \"Receiver\"-Thread receives a packet from \"ServerB\", \n    add this to the McastMembership, \n    calls the SimpleTcpCluster.memberAdded(\"ServerB\") \n    and blocks on [P1]\n    \nt2: The \"Sender\"-Thread continues,\n    calls SimpleTcpCluster.memberDisappeared(\"ServerB\").\n    \n\nThis leads to the following situation:\n- the \"ServerB\" is in the McastMembership.map (and without timeouts, it wont disappear)\n- there is no Sessionreplication to \"ServerB\" \n\n\nThat's it\n\n  \n\nThread: Cluster-MembershipReceiver\n\nMcastServiceImpl.receive\n   added= sync McastMembership.memberAlive(mm) { \n     if (mm not in map) then map+=mm;return true;\n     else (mark mm as new); return false;\n   }\n   if (added) {\n      SimpleTcpCluster.memberAdded(mm)\n        log.info(\"Replication member added:\" + member);\n        sync ReplicationTransmitter.add(mm);\n   }\n     \n  checkExpire\n   ---[P1]---\n   sync on McastServiceImpl(expiredMutex) {\n      mm = sync McastMembership.expire() {\n         if (mm in map to old) then map-=mm;\n         return mm;\n      }\n      SimpleTcpCluster.memberDisappeared(mm);\n        log.info(\"Received member disappeared:\" + member);\n        sync ReplicationTransmitter.remove(mm);\n   }                      \n\n\n\nThread: Cluster-MembershipSender\n\n  McastServiceImpl.send()\n  \n  checkExpire\n   sync on McastServiceImpl(expiredMutex) {\n      mm = sync McastMembership.expire() {\n         if (mm in map to old) then map-=mm;\n         return mm;\n      }\n      ---[P0]---\n      SimpleTcpCluster.memberDisappeared(mm);\n        log.info(\"Received member disappeared:\" + member);\n        sync ReplicationTransmitter.remove(mm);\n   }",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "46384",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "P2 major",
    "product": "Tomcat 5",
    "project": "TOMCAT",
    "summary": "Due to missing synchronization, a member may disappear permanent.",
    "systemSpecification": false,
    "version": "5.5.27"
}