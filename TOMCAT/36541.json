{
    "comments": [
        {
            "author": null,
            "body": "And to prevent the REOPEN ...\n\nSRV.7.7.1 Threading Issues\nMultiple servlets executing request threads may have active access to a single\nsession object at the same time. *The Developer has the responsibility for\nsynchronizing access to session resources as appropriate.*",
            "date": "20050907T13:12:27",
            "id": 0
        },
        {
            "author": null,
            "body": "Sorry, but this means that the develop is responsible for the object he puts in\nsession, not for the session itself.\nTo quote Graig:\nthe underlying spec language (SRV.7.7.1) was originally intended to remind\napplication users that they must make their *own* objects threadsafe if they are\nstored as a session attribute. To use that language as an excuse for the\n*container* not having to make its own collections threadsafe means that the\nlanguage is broken.\nSo, reopen it now?",
            "date": "20050907T15:21:36",
            "id": 1
        },
        {
            "author": null,
            "body": "(In reply to comment #2)\n> Sorry, but this means that the develop is responsible for the object he puts in\n> session, not for the session itself.\n> To quote Graig:\n> the underlying spec language (SRV.7.7.1) was originally intended to remind\n> application users that they must make their *own* objects threadsafe if they are\n> stored as a session attribute. To use that language as an excuse for the\n> *container* not having to make its own collections threadsafe means that the\n> language is broken.\n> So, reopen it now?\n\nDon't bother ;)\n",
            "date": "20050907T15:39:44",
            "id": 2
        },
        {
            "author": null,
            "body": "(In reply to comment #2)\n\nHeheh ... I think you answered the question for yourself ... fix the spec \nfirst, then the container implementations second.",
            "date": "20050907T15:45:16",
            "id": 3
        },
        {
            "author": null,
            "body": "(In reply to comment #4)\n> (In reply to comment #2)\n> \n> Heheh ... I think you answered the question for yourself ... fix the spec \n> first, then the container implementations second.\n\nInteresting, servlet spec 2.3 has exact the same wording of SRV.7.7.1 Threading\nIssues and tomcat 4.1.31, which is the official implementation of the 2.3 spec,\nhas a SYNCHRONIZED session. \n\nSo tomcat 4.x is buggy, or tomcat 5.x is. You say it's the 4.x, I say it's 5.x.",
            "date": "20050907T16:34:41",
            "id": 4
        },
        {
            "author": null,
            "body": "(In reply to comment #5)\n\nActually I'd say neither is buggy, since they both implement the spec as it's \nwritten. If that's not what was intended, then as you quoted Craig saying: \"the\nlanguage is broken\", and the spec needs to be changed.",
            "date": "20050907T16:47:05",
            "id": 5
        },
        {
            "author": null,
            "body": "(In reply to comment #6)\n> (In reply to comment #5)\n> \n> Actually I'd say neither is buggy, since they both implement the spec as it's \n> written. If that's not what was intended, then as you quoted Craig saying: \"the\n> language is broken\", and the spec needs to be changed.\n\nI would agree that neither implementation is buggy -- it is entirely legal for a\nservlet container to avoid letting an application corrupt its interna data\nstructures.  It's too bad that the current Tomcat developers care more about\nperformance than they care about reliability.\n\nIf you aren't going to change it back to the 4.1 implementation (with\nsynchronization locks around the accesses), please take my name out of the\n@author tag for org.apache.catalina.session.StandardSession -- this code does\n*not* represent anything I wish to be associated with.\n",
            "date": "20050907T18:08:30",
            "id": 6
        },
        {
            "author": null,
            "body": "(In reply to comment #7)\n> I would agree that neither implementation is buggy -- it is entirely legal for a\n> servlet container to avoid letting an application corrupt its interna data\n> structures.  It's too bad that the current Tomcat developers care more about\n> performance than they care about reliability.\n\nOf course. Thankfully, you guys have glassfish now for good reliability, so you\ndon't have to deal with these loony Tomcat developers anymore ;)\n\n> If you aren't going to change it back to the 4.1 implementation (with\n> synchronization locks around the accesses), please take my name out of the\n> @author tag for org.apache.catalina.session.StandardSession -- this code does\n> *not* represent anything I wish to be associated with.\n\nSure, I have no problem with that if it's your wish.\n\nThese changes were made as an experiment (the spec allows this to be\nnon-synced), and included in 5.0.19+ and as a consequence in all the most\npopular 5.0.x releases. In the end, it would seem it worked reasonably well.\nHowever, I did get a few reports of corruption a while after this, and I added\nback synchrnozation on write operations to the map in the 5.5 branch. I never\nported this back to 5.0.x given the lack of demand. Apparently, you didn't look\nat it.\n\nAll that got discussed in the past, including the readding of some of the syncs.\n",
            "date": "20050907T18:45:47",
            "id": 7
        },
        {
            "author": null,
            "body": "After we finish clarifying who's is bigger (and mine is best case average), we\ncould return to the bug.\n\n1. The bug isn't invalid, so I reopen it. You can set it to WONTFIX, but not to\nINVALID.\n\n2. Applications working well with tomcat 4, resin or probably any other servlet\ncontainer do not work with tomcat 5.0.x or tomcat 5.5.x. Thus tomcat 5 seems to\nbe not compatible to the servlet spec (or be the only one compatible), if not in\nthe language of the specification itself, but in the intension of it. So tomcat\n5 can be considered BROKEN.\n\n3. The bug applies to tomcat 5.5.x as well, because \n\"... added back synchrnozation on write operations to the map in the 5.5\nbranch... \" doesn't fix anything, since the read operation are the problem and\nMUST be synchronized. \n\n4. The effort to provide a workaround for this problem is enormous compared to\nthe effort to fix the bug. Each and every framework around there now MUST\nprovide two versions, the normal version and the tomcat 5 compatible version.\nYou can't use struts, tapestry, jstl, actually NOTHING existing with tomcat 5.\n\n5. The idea of removing synchronization to gain performance is absurd.\nWho needs the performance? People like us, who have 2000-3000 concurrent users\non each webserver. But people who have 2000-3000 concurrent users, have also\nmany concurrent requests, even from the same user, so instead of gaining\nperformance we are gaining CRASHES. This bug killed 8 (!!!) webservers yesterday. \n\n6. Consider the flurry in the tomcat users community, if the above points + your\n refusal to provide a three LOCs fix gonna make tomcat 5 UNUSEABLE.",
            "date": "20050907T21:29:36",
            "id": 8
        },
        {
            "author": null,
            "body": "Look, the basic problem is that the underlying implementation used to support\nattribute holders is being used in error according to it's documentation\n(java.util.HashMap documentation).  It doesn't just leave the data in an\ninconstistent state, but rather crashes systems.  If the developer has to\nsynchronize access to the session or application or context every where\nattributes are being set then why not change the base application (Tomcat) to do\nthis already....basically the application, context, and session are useless if\nnothing can be stored in them.  So, they have to be synchronized anyways, so\nthis should be done at the Tomcat level.  5.5.x and 5.0.x really need to be\nfixed because it doesn't make sense not to.  Basically I'm getting this from the\nconversation (and anyone else should be).....the spec says it's up to the\ndeveloper to synchronize........the developer has to synchronize every where the\nattributes are set and get.....so what is the difference if Tomcat does it or\nthe developer does it?  Plus, does the spec also say it's up to the developer to\nsynchronize request, context, and session attributes?  It's been a while since I\nhave read the servlet spec, but I have the 2.3 version on disk and will skim\nover it again, but even if the spec says it....it doesn't make sense not to\nsynchronize code that has to be synchronized one way or another anyways.",
            "date": "20050907T21:41:36",
            "id": 9
        },
        {
            "author": null,
            "body": "Something I'm curious about.  If EL is used on in a JSP and a session object\naccessed and manipulated is this synchronized?  What package should I look in\nfor that to check?",
            "date": "20050907T21:58:02",
            "id": 10
        },
        {
            "author": null,
            "body": "So I verified that at least the 5.5.9 code only synchronized the setAttribute\nand not also the getAttribute....why?  ",
            "date": "20050907T22:08:17",
            "id": 11
        },
        {
            "author": null,
            "body": "(In reply to comment #12)\n> So I verified that at least the 5.5.9 code only synchronized the setAttribute\n> and not also the getAttribute....why?  \n\nto quote  Remy Maucherat:\nit was an experiment and he added back synchrnozation on write operations to the\nmap in the 5.5 branch...\n\nActually it doesn't make any sense because you need both get and set to be\nsynchronized, to have the desired effect, so I think we should consider this a\npart of the \"experiment\". ",
            "date": "20050907T22:22:04",
            "id": 12
        },
        {
            "author": null,
            "body": "Well at least ApplicationContext.java and ApplicationRequest.java are\nsynchronizing their attributes in both cases put/get.  So, that is one thing not\nto worry about, but there are other issues, and I'm betting the EL accessing\ncode isn't synchronizing because looking at the code for jasper2 and looking at\nthe runtime file PageContextImpl.java in the scoped getAttribute which calls the\nscoped doGetAttribute it does not synchronize the code either.  So, basically\nwhat that says is if a JSP developer were to use jsp:useBean and creates a\nsession bean then there are going to be problems because as soon as this happens\nan unsynchronized call is taking place.  \n\nThing that makes this debate over whether to change it or not silly is that in\nthe scoped calls the application and request code is already synchronized at the\nclass level so synchronizing only on the session at this point seems weird.  \n\nRegardless....if this tiny three line change doesn't take place then there are\nmore lines in Tomcat that apparently need to be changed, because this bug causes\nother issues.",
            "date": "20050907T22:40:08",
            "id": 13
        },
        {
            "author": null,
            "body": "Why not keep everybody happy, simply make the session management class a\nconfigurable option at both Server and Context level, if the TC developers wish\nto \"experiment\" they can configure the un-synchronized access they so desire.\n",
            "date": "20050907T23:23:11",
            "id": 14
        },
        {
            "author": null,
            "body": "I strongly agree with Craig, et al to error on the side of a more robust implemention by using \nsynchronization on the side of Tomcat. I think doing otherwise would be doing a high-wire act without a \nnet. There are too many places for a developer to miss handling the threading correctly to leave this as is. ",
            "date": "20050907T23:43:25",
            "id": 15
        },
        {
            "author": null,
            "body": "I've been following this with a lot of interest ever since Leon raised the \nissue yesterday, and I discussed it with some folks at work today a bit.\n\nLooking at this strictly from a developers' point of view, I could care less \nwhat the specs says, and I could care less why the Tomcat code is the way it \nis.  The bottom-line is that if I call session.getAttribute() or setAttribute\n() in a servlet or Struts Action or whatnot, I do not expect there to be any \nchance of the internal data structures getting corrupted, or me getting back \ninconsistent data, and I most definitely do not expect there to be any chance \nof a server hang or crash, and I do not expect to have to do anything myself \nto ensure any of this.  Any other answer is, to me and to those I spoke to, \njust plain wrong.\n\nI am in absolute agreement with those saying this needs to be fixed.  I do not \nrecall ever having been bitten by this problem, but it's just subtle enough \nthat I might not have known if I did.\n\nI don't think anyone is looking to place blame here.  I don't care what was \noriginally in the Tomcat code and what is there now or why it was changed.  \nThis simply comes down to a legitimate issue that needs to be resolved.  It's \nnot even a minor issue frankly, it's a pretty substantial one, regardless of \nthe fact that it apparently hasn't caused huge problems for everyone.\n\nIf the spec needs to be fixed, no problem, contact who needs to be contacted \nand let them know.  But that DOES NOT mean you serialize and wait for them to \ndo their thing.  There is a solution here that, to my understanding, isn't \ncontrary to the spec as it exists today anyway, so not following through with \nit is kind of silly.  I'm sure any number of people would be willing to submit \na patch for this if it's an issue of not having time, but to be arguing about \nwhether it should be fixed or not doesn't seem to be reasonable on this one.",
            "date": "20050908T00:36:36",
            "id": 16
        },
        {
            "author": null,
            "body": "(In reply to comment #17)\n\n> I don't think anyone is looking to place blame here.  I don't care what was \n> originally in the Tomcat code and what is there now or why it was changed.  \n> This simply comes down to a legitimate issue that needs to be resolved.  It's \n> not even a minor issue frankly, it's a pretty substantial one, regardless of \n> the fact that it apparently hasn't caused huge problems for everyone.\n\nI'm not even sure if I've been bitten by this either, but I have seen on the\nlist numerous people speaking of running out of Tomcat threads and setting their\nconnections to the max.  If this issue were causing problems they might be\nhaving it and not even realize it.\n\n> If the spec needs to be fixed, no problem, contact who needs to be contacted \n> and let them know.  But that DOES NOT mean you serialize and wait for them to \n> do their thing.  There is a solution here that, to my understanding, isn't \n> contrary to the spec as it exists today anyway, so not following through with \n> it is kind of silly.  I'm sure any number of people would be willing to submit \n> a patch for this if it's an issue of not having time, but to be arguing about \n> whether it should be fixed or not doesn't seem to be reasonable on this one.\n\nI agree....synchronizing these calls isn't going to be contrary to the spec in\nno way at all.\n",
            "date": "20050908T00:42:52",
            "id": 17
        },
        {
            "author": null,
            "body": "I wonder if the new java.util.concurrent classes could be used instead \nof simple HashMap?\n\nhttp://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/ConcurrentHashMap.html\n\nbut that would mean total dependence on j2se 1.5 and that would be a \nproblem for supporting j2se 1.4, though a backport is being worked on here\n\nhttp://www.mathcs.emory.edu/dcl/util/backport-util-concurrent/\n\nother reading here:  \nhttp://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/intro.html\n\nI think that sort of thing would provide a nice solution for speed + \nreliability.  Using this as the underlaying base would/should fix issues with EL\naccess too.",
            "date": "20050908T01:08:17",
            "id": 18
        },
        {
            "author": null,
            "body": "As discussed on tomcat-dev after I reexamined StandardSession code further,\nadequate synchrnoization seems to be in place in the current Tomcat 5.5 code so\nthat the infinite loop situation described in this issue does not occur. Please\ndo not reopen the report.",
            "date": "20050908T04:27:14",
            "id": 19
        },
        {
            "author": null,
            "body": "(In reply to comment #15)\n> Why not keep everybody happy, simply make the session management class a\n> configurable option at both Server and Context level, if the TC developers wish\n> to \"experiment\" they can configure the un-synchronized access they so desire.\n> \n\nActually, the session management code *is* already configurable, albeit not\ntrivially.  You can include a <Manager> element inside your <Context> element\nand create a custom implementation of the Manager interface that returns session\ninstances (probably subclassed from StandardSession) that do the locking for you.\n\nThe key question remains what the default behavior should be, and/or whether\nthere should be an easy boolean setting to turn this particular capability on or\noff.\n",
            "date": "20050908T05:25:01",
            "id": 20
        },
        {
            "author": null,
            "body": "(In reply to comment #8)\n> (In reply to comment #7)\n> > I would agree that neither implementation is buggy -- it is entirely legal for a\n> > servlet container to avoid letting an application corrupt its interna data\n> > structures.  It's too bad that the current Tomcat developers care more about\n> > performance than they care about reliability.\n> \n> Of course. Thankfully, you guys have glassfish now for good reliability, so you\n> don't have to deal with these loony Tomcat developers anymore ;)\n> \n\nApparently it is indeed a good thing :-).  The appropriate patch was just\ncommitted to the Glassfish repository.  If people want an open source\nimplementation of the servlet spec where the developers listen to users on\nissues like this, you might want to browse over to:\n\n    https://glassfish.dev.java.net\n\nand take a look.\n\n> > If you aren't going to change it back to the 4.1 implementation (with\n> > synchronization locks around the accesses), please take my name out of the\n> > @author tag for org.apache.catalina.session.StandardSession -- this code does\n> > *not* represent anything I wish to be associated with.\n> \n> Sure, I have no problem with that if it's your wish.\n> \n\nThis (removing my name from the @author tag on StandardSession), both here and\neverywhere else in the Tomcat code base, would indeed be my wish.\n",
            "date": "20050908T05:32:17",
            "id": 21
        },
        {
            "author": null,
            "body": "(In reply to comment #20)\n> As discussed on tomcat-dev after I reexamined StandardSession code further,\n> adequate synchrnoization seems to be in place in the current Tomcat 5.5 code so\n> that the infinite loop situation described in this issue does not occur. Please\n> do not reopen the report.\n\nRemy, sorry, but you are wrong. The read is the problem, not the write. During\nthe write process the hashmap is in flux, so if a read occurs at this time and\nis not synchronized the thread which reads is killed.\nSo 5.5.x is as broken as 5.0.x is\n",
            "date": "20050908T08:50:57",
            "id": 22
        },
        {
            "author": null,
            "body": "Hmm, I also thing the spec interpretation from the current\nStandardSession inside Tomcat 5.0 and 5.5. is wrong. We had the same problem\nat Cluster DeltaSession for year ago. We now sync also the session attribute \nread operations. Without this fix the Cluster setup is useless for\nproduction servers. \n\nI vote for change the StandardSession implementation to..\n\n   public Object getAttribute(String name) {\n\n        if (!isValid())\n            throw new IllegalStateException(sm\n                    .getString(\"standardSession.getAttribute.ise\"));\n\n        synchronized (attributes) {\n            return (attributes.get(name));\n        }\n\n    }\n\n    public Enumeration getAttributeNames() {\n\n        if (!isValid())\n            throw new IllegalStateException(sm\n                    .getString(\"standardSession.getAttributeNames.ise\"));\n\n        synchronized (attributes) {\n            return (new Enumerator(attributes.keySet(), true));\n        }\n\n    }\n===\n\nPeter",
            "date": "20050908T11:01:31",
            "id": 23
        },
        {
            "author": null,
            "body": "Created attachment 16339\ncompiled fix for 5.0.25\n\na compiled patch for 5.0.19+",
            "date": "20050908T11:35:14",
            "id": 24
        },
        {
            "author": null,
            "body": "Created attachment 16340\npatch for 5.0.19+, source code\n\npatch for 5.0.19+, source code",
            "date": "20050908T11:36:45",
            "id": 25
        },
        {
            "author": null,
            "body": "I submitted a patch for 5.0.19+. To install it:\njar -xf catalina.jar\nreplace StandardSession.class with one attached.\nmake a new jar. \nAlternatively you can rebuild complete tomcat, so i supplied the source code too :-)\n\nIt would be cool to provide a download location for the patched catalina.jar, i\ndon't think submitting a 700K file into bugzilla is the correct behaviour, so\nI'm not doing it.\n\n",
            "date": "20050908T11:42:53",
            "id": 26
        },
        {
            "author": null,
            "body": "(In reply to comment #24)\n> Hmm, I also thing the spec interpretation from the current\n> StandardSession inside Tomcat 5.0 and 5.5. is wrong. We had the same problem\n> at Cluster DeltaSession for year ago. We now sync also the session attribute \n> read operations. Without this fix the Cluster setup is useless for\n> production servers. \n> \n> I vote for change the StandardSession implementation to..\n\nOk. I don't know yet, since the repository is inconclusive, and doesn't match\nwhat you wrote. I see DeltaSession (introduced first along with 5.0.15+) has\nalways had (from revision 1.1) syncs on everything (read/writes), so I don't see\nany conclusive information showing that the current 5.5.x code does produce the\nbug described here. Obviously, if 5.5.x really is still bad for this issue,\nit'll have to be fixed.\n\n(In reply to comment #23)\n> Remy, sorry, but you are wrong. The read is the problem, not the write. During\n> the write process the hashmap is in flux, so if a read occurs at this time and\n> is not synchronized the thread which reads is killed.\n> So 5.5.x is as broken as 5.0.x is\n\nThis means you've tested with 5.5.x, and reproduced an issue ? Or written a\nmicrobenchmark showing a problem with reads ? All I can see is that you're\nsaying \"issue on read, 5.5.x same problem\" like a broken record.\n\n(In reply to comment #22)\n> Apparently it is indeed a good thing :-).  The appropriate patch was just\n> committed to the Glassfish repository.  If people want an open source\n> implementation of the servlet spec where the developers listen to users on\n> issues like this, you might want to browse over to:\n> \n>     https://glassfish.dev.java.net\n> \n> and take a look.\n\nLol, whatever. The web tier of Glassfish is really an ugly behind-the-back fork.\nAll that was required to avoid the ill feelings is a bit of respect, being\ninformed just a little bit, which would have allowed reasonable planning for\ndevelopment resources. I'm glad you're happy about Glassfish, but personally,\nI'll use it in the long run to point out there are problems with large companies\nlike Sun and IBM, their interactions with the ASF, and how they should not be\ntrusted (as in, accept whatever they contribute, but there's no need for being\nthankful for it - and obviously, don't install them as \"despot\" on a project\never, but at the ASF, it's a bit hard to get into this situation).\n\n> This (removing my name from the @author tag on StandardSession), both here and\n> everywhere else in the Tomcat code base, would indeed be my wish.\n\nI wasn't really serious. In the end, it's not really my decision, so you should\nsend a request to the pmc once it is correctly setup.\n",
            "date": "20050908T12:23:46",
            "id": 27
        },
        {
            "author": null,
            "body": "It should be posssible to install such patches by simply place the class file at\nthe correct position.\n\nIn this case it would be\n\njakarta-tomcat-5.0.28/server/classes/org/apache/catalina/session",
            "date": "20050908T12:26:43",
            "id": 28
        },
        {
            "author": null,
            "body": "(In reply to comment #29)\n> It should be posssible to install such patches by simply place the class file at\n> the correct position.\n> \n> In this case it would be\n> \n> jakarta-tomcat-5.0.28/server/classes/org/apache/catalina/session\n\nYes, the classloader setup has been designed to easily allow such patching, but\nthe folder structure can get a bit messy (you got it right, though).",
            "date": "20050908T12:34:37",
            "id": 29
        },
        {
            "author": null,
            "body": "(In reply to comment #28)\n> This means you've tested with 5.5.x, and reproduced an issue ? Or written a\n> microbenchmark showing a problem with reads ? All I can see is that you're\n> saying \"issue on read, 5.5.x same problem\" like a broken record.\n\nNo this means that the statement of the HashMap authors:\n * <p><b>Note that this implementation is not synchronized.</b> If multiple\n * threads access this map concurrently, and at least one of the threads\n * modifies the map structurally, it <i>must</i> be synchronized externally.\nalso applies to x Reader, one Writer, so synchronizing \"writes only\" is a\nmisusage of the HashMap according to the documentation. \n\nOn the other hand, I made some measures and calculated how much performance you\ngain by removing synchronization from get/set methods. \nI compared the performance of synchronized hashmap access against not\nsynchronized (singlethreaded, pIV 2.8 Ghz, HT) and calculated that you gain 230\nmilliseconds on 3,000,000 operations! \nThat is 0.00008 milliseconds per operation. Even you would have 100 accesses to\nthe session from 100 parallel threads, it would cost you additional 8 milliseconds. \nAccording to alexa.com we have an average response time of 0.8 seconds (for the\nuser) and are faster then 80% of the net (google's average is 0.7). I don't know\nhow many sites are faster, lets assume the fastest are at about 0.5 seconds (and\nsites making 100 session accesses in one request surely do not belong in this\ncategory). So if your average request duration is 500 millis, how important is\nit for you to gain 0.00008 milliseconds, or even 0.8 milliseconds?\n",
            "date": "20050908T13:48:06",
            "id": 30
        },
        {
            "author": null,
            "body": "(In reply to comment #31)\n> No this means that the statement of the HashMap authors:\n>  * <p><b>Note that this implementation is not synchronized.</b> If multiple\n>  * threads access this map concurrently, and at least one of the threads\n>  * modifies the map structurally, it <i>must</i> be synchronized externally.\n> also applies to x Reader, one Writer, so synchronizing \"writes only\" is a\n> misusage of the HashMap according to the documentation. \n\nIt's cool, but I have not asked for the nth lecture of this portion of the\njavadoc. How about trying to answer my question ? It doesn't seem that hard.\n\n> On the other hand, I made some measures and calculated how much performance you\n> gain by removing synchronization from get/set methods. \n> I compared the performance of synchronized hashmap access against not\n> synchronized (singlethreaded, pIV 2.8 Ghz, HT) and calculated that you gain 230\n> milliseconds on 3,000,000 operations! \n> That is 0.00008 milliseconds per operation. Even you would have 100 accesses to\n> the session from 100 parallel threads, it would cost you additional 8\nmilliseconds. \n> According to alexa.com we have an average response time of 0.8 seconds (for the\n> user) and are faster then 80% of the net (google's average is 0.7). I don't know\n> how many sites are faster, lets assume the fastest are at about 0.5 seconds (and\n> sites making 100 session accesses in one request surely do not belong in this\n> category). So if your average request duration is 500 millis, how important is\n> it for you to gain 0.00008 milliseconds, or even 0.8 milliseconds?\n\nIn a microbenchmark, the JIT could be playing tricks on you, so I don't know ;)\nObviously, one single read by itself is not going to cost much. Now multiply\nthat by the number of reads you could be making during a single request, and\nalso imagine what it could be if useless syncs were added in plenty other places\ninside the container \"just to be safe\". Syncs should be added wherever needed,\nbut not more than needed.\n\nIf you like microbenchmarks, you could compare (let's say with 1/3 writes, 2/3\nreads): HashMap without sync, HashMap with syncs on writes, Hashtable,\nConcurrentHashMap. I think there could be some more tuning being done for the\nattributes map (like setting a good initial size).\n\nBesides, this is a bit OT, and doesn't answer my question.\n\nI have just looked at two other popular servers source code, and some don't do\nany syncing for this, like Tomcat 5.0.x does. Overall, it means it's not\nportable, and the webapp really should plan on syncing on the session externally\nwherever needed. What I am willing to provide (this is the intent of the code in\n5.5.x right now), by default, is making sure the HashMap cannot get corrupted,\nand that the infinite loop described in this report cannot occur.",
            "date": "20050908T14:08:14",
            "id": 31
        },
        {
            "author": null,
            "body": "> Overall, it means it's not\n> portable, and the webapp really should plan on syncing on the session externally\n> wherever needed.\nIf you use different techniques this might become pain.\nIt might be hard to tell everyone to synchronize against session, and in the end\nyou have the same as synchronize in the base class. Well not really the same as\ntomcat can synchronize against the map, we have to synchronize on a wider\ncontext - the session.\n\n> What I am willing to provide (this is the intent of the code in\n> 5.5.x right now), by default, is making sure the HashMap cannot get corrupted,\n> and that the infinite loop described in this report cannot occur.\nI wonder how this can be done?\nYou might have to introduce your own map implementation, no?\n\nIs it possible to create a thread-safe hash-map without synchronization?\nOk, if two threads put in an element with the same key it might not be\ndeterministic which of both are really set then, but this is not the problem we\nhave to solve.",
            "date": "20050908T14:18:51",
            "id": 32
        },
        {
            "author": null,
            "body": "(In reply to comment #33)\n> > Overall, it means it's not\n> > portable, and the webapp really should plan on syncing on the session externally\n> > wherever needed.\n> If you use different techniques this might become pain.\n> It might be hard to tell everyone to synchronize against session, and in the end\n> you have the same as synchronize in the base class. Well not really the same as\n> tomcat can synchronize against the map, we have to synchronize on a wider\n> context - the session.\n\nYou indeed have to sync on a wider context in many cases.\n\n> > What I am willing to provide (this is the intent of the code in\n> > 5.5.x right now), by default, is making sure the HashMap cannot get corrupted,\n> > and that the infinite loop described in this report cannot occur.\n> I wonder how this can be done?\n> You might have to introduce your own map implementation, no?\n\nNo, because at this point I believe making sure that the HashMap does not get\ncorrupted (using syncs on put and remove) is enough to guarantee that the get\nmethod doesn't enter an infinite loop (by returning null, or the result when\nthere's a problem - it will be unpredictable, but seems to me equivalent to the\nhigher level concurrency issues if you mix and match reads/writes in the webapp\nfor critical data without being careful).\n\nOther than this, it doesn't look that the collection being used with its default\nparameters is that optimal.\n\n> Is it possible to create a thread-safe hash-map without synchronization?\n> Ok, if two threads put in an element with the same key it might not be\n> deterministic which of both are really set then, but this is not the problem we\n> have to solve.\n\nMaybe using a fully array based structure rather than a linked list would make\nit more robust (ie, reads could be bad, writes could be lost, but the structure\nwould remain consistent). There is stuff like ConcurrentHashMap, but it of\ncourse does synchronization of its own.\n\nI did agree previously (hence the current code in the 5.5 branch) that\nrobustness is good, and that the HashMap structure should be protected, as\nthere's no way to restore it, so there are syncs for put and remove.\n\nSince there's a real demand and you guys are quite persistent, I now agree on\nadding an extra configuration parameter on the context allowing to define the\nsweet spot for the collection size, as well as its synchronization policy (the\ndefault being the current 5.5 behavior, unless/until it is shown to still be\nable to cause the inifinite loop originally described in the report).\n",
            "date": "20050908T14:59:26",
            "id": 33
        },
        {
            "author": null,
            "body": "How do we approach the specifications committee for official clarification of\nthis point.\n\nWho is going to take charge to actively do that?\n\nHere is hoping to provoke all vendors to take a look at the issue and report\nback to the committee foir a verdict in the coming months.\n",
            "date": "20050908T15:03:14",
            "id": 34
        },
        {
            "author": null,
            "body": "(In reply to comment #34)\n> No, because at this point I believe making sure that the HashMap does not get\n> corrupted (using syncs on put and remove) is enough to guarantee that the get\n> method doesn't enter an infinite loop (by returning null, or the result when\n> there's a problem - it will be unpredictable, but seems to me equivalent to the\n> higher level concurrency issues if you mix and match reads/writes in the webapp\n> for critical data without being careful).\n\nI understand the point that others are making for all access needing the same\nsychronization.\n\nI don't understand your logic that read/get don't need syncronization.\n\nThe issue with the infinite loop read stems from the fact that two different\nthreads access the map at the same time.  One for read and one for write, while\nthe writer is modifying the map it corrupted the pointers the reader is using to\ntraverse the data structures and thus enters an infinite loop (due to the\nHashMap design, other collection classes can detect some situations and throw an\nexception for ConcurrentAccessException).\n\nThis is because there is no synchrnozation between get/put operations.  Only\nbetween puts.\n\n\n\nAs I pointed out in the TC user mailing list, it would be possible to use a\nReadWriteLock to allow threading of multiple readers to take place.  But while\nthere is one writer working on the Map you need to be sure no reader is using\nthe map too.\n\nIntroducing the ReadWriteLock might introduce an unwanted JDK5 dependancy, I\nthink its a new JDK5 concurrency class ?  It might also be slower than a regular\nsynchronized lock.  But without benchmarks we wont know.\n",
            "date": "20050908T15:14:03",
            "id": 35
        },
        {
            "author": null,
            "body": "(In reply to comment #36)\n>  One for read and one for write, while\n> the writer is modifying the map it corrupted the pointers the reader is using to\n> traverse the data structures and thus enters an infinite loop\n\nSorry to reply to my own post, but my use of the word \"corrupted\" is a bad choice.\n\n\nIn the normal operation of a write modification to the map the internal data\nstructures are altered into a temporary inconsitant state.  This inconsitancy is\npart of the normal working of the write operation.  When the write operation\nreturns to the application the map integrity is always consistant.\n\nThe basic contract is true of all object design, unless otherwise stated to be\nthread safe.  Which we all agree HashMap is not.\n\n\nIf the read operations happens to bump into this moment of temporary\ninconsistacy the infinite loop can occur.\n",
            "date": "20050908T15:20:37",
            "id": 36
        },
        {
            "author": null,
            "body": "(In reply to comment #37)\n> If the read operations happens to bump into this moment of temporary\n> inconsistacy the infinite loop can occur.\n\nAll the entry objects will be mutated. While it may be inconsistent and might\nloop for an instant (although I am not convinced this could really be the case;\nI think the trouble without any sync could only occur if there was more than one\nconcurrent unsynced write, and in particular, two \"remove\"), the pointer value\nwill be corrected and the loop should exit. That's my interpretation looking at\nthe code. I think I'll write a small program to test this.\n",
            "date": "20050908T15:41:16",
            "id": 37
        },
        {
            "author": null,
            "body": "(In reply to comment #38)\n> All the entry objects will be mutated. While it may be inconsistent and might\n> loop for an instant (although I am not convinced this could really be the case;\n> I think the trouble without any sync could only occur if there was more than one\n> concurrent unsynced write, and in particular, two \"remove\"), the pointer value\n> will be corrected and the loop should exit. That's my interpretation looking at\n> the code. I think I'll write a small program to test this.\n> \n\nLet me ask you another question then.  Where is the written specification for\nthe HashMap that states your usage is safe ?  It sounds like you as working on\nthe presumption that all implementation's won't cause an infinite loop (or set\nfire to the computer) but you dont have any API contract to back that\npresumption up.\n\n\n\nI read the specification to state that some put/remove operations (that modify\nthe map structurally are explicitly not threadsafe)\n\n\nYou can't call threadsafe and non-threadsafe calls to an API at the same time. \nThe threadsafe calls are only threadsafe with respect to other threadsafe calls\non the same API.\n\n\nMy understanding of this:\n\nYou can call threadsafe API calls at the same time.\n\nAnytime you want to call a non-threadsafe one you have to serialize it with\nrespect to the API Interface not with respect to itself or other similar\noperations (unless otherwise stated).\n",
            "date": "20050908T15:54:20",
            "id": 38
        },
        {
            "author": null,
            "body": "(In reply to comment #39)\n> Let me ask you another question then.  Where is the written specification for\n> the HashMap that states your usage is safe ?  It sounds like you as working on\n> the presumption that all implementation's won't cause an infinite loop (or set\n> fire to the computer) but you dont have any API contract to back that\n> presumption up.\n> \n> I read the specification to state that some put/remove operations (that modify\n> the map structurally are explicitly not threadsafe)\n> \n> You can't call threadsafe and non-threadsafe calls to an API at the same time. \n> The threadsafe calls are only threadsafe with respect to other threadsafe calls\n> on the same API.\n> \n> My understanding of this:\n> \n> You can call threadsafe API calls at the same time.\n> \n> Anytime you want to call a non-threadsafe one you have to serialize it with\n> respect to the API Interface not with respect to itself or other similar\n> operations (unless otherwise stated).\n\nI guess if it goes back again to lawyerspeak level rather than logic, then\nthere's nothing to talk about. It is all related to reasonable reliability and\nrobustness, and I don't believe the algorithm of a hashmap can become that weird\n(the Sun structure is already not particularly safe). I mean, there could even\nbe bugs in the collection implementation too. \n\nI'd like to remind you once more that this synchronization in the container is\nnot mandatory from what I can see, and at least one other popular container\napparently behaves like Tomcat 5.0. It's the end of this discussion thread as\nfar as I am concerned :)\n\nI'll also add a way to configure size and sync of the collection (assuming I\nconfirm behavior to be acceptable using a test program).",
            "date": "20050908T16:27:45",
            "id": 39
        },
        {
            "author": null,
            "body": "(In reply to comment #38)\n> (In reply to comment #37)\n> > If the read operations happens to bump into this moment of temporary\n> > inconsistacy the infinite loop can occur.\n> \n> All the entry objects will be mutated. While it may be inconsistent and might\n> loop for an instant (although I am not convinced this could really be the case;\n> I think the trouble without any sync could only occur if there was more than one\n> concurrent unsynced write, and in particular, two \"remove\"), the pointer value\n> will be corrected and the loop should exit. That's my interpretation looking at\n> the code. I think I'll write a small program to test this.\n> \nYou can certinaly get null returned when a valid value was added to the Map\npreviosly as well because of the inconsistency.  The hash index used to locate\nthe first Entry is based on the hash and the length of the table (I guess we\nshould say the chosen bucket).  If the value has been added to the map.  Then a\ncall for a get occurs and a call for a write and the write makes a resize and\nthe resize changes the location of the bucket then e could match another Entry\nbesides the one for the correct hash then you start getting into some looping. \nIn a test I had a get interation of 4 times occur when this happened, but\nconsidering all of the possible shifting that can occur I'm not convinced that\nan infinite loop could not occur.  Given the bucket index algorithm and all of\nthe possible values for a hash and a table size I don't think one can safely say\nit's not possible without synchronizing.  If there is a way to determine that\nthe behavior of one search for a bucket with any hash is always going to produce\nthe same result for any size table then I think you can safely not synchronize\nthe code.(In reply to comment #38)\n> (In reply to comment #37)\n> > If the read operations happens to bump into this moment of temporary\n> > inconsistacy the infinite loop can occur.\n> \n> All the entry objects will be mutated. While it may be inconsistent and might\n> loop for an instant (although I am not convinced this could really be the case;\n> I think the trouble without any sync could only occur if there was more than one\n> concurrent unsynced write, and in particular, two \"remove\"), the pointer value\n> will be corrected and the loop should exit. That's my interpretation looking at\n> the code. I think I'll write a small program to test this.\n> \n\nYou can certinaly get null returned when a valid value was added to the Map\npreviosly as well because of the inconsistency.  The hash index used to locate\nthe first Entry is based on the hash and the length of the table (I guess we\nshould say the chosen bucket).  If the value has been added to the map.  Then a\ncall for a get occurs and a call for a write and the write makes a resize and\nthe resize changes the location of the bucket then e could match another Entry\nbesides the one for the correct hash then you start getting into some looping. \nIn a test I had a get interation of 4 times occur when this happened, but\nconsidering all of the possible shifting that can occur I'm not convinced that\nan infinite loop could not occur.  Given the bucket index algorithm and all of\nthe possible values for a hash and a table size I don't think one can safely say\nit's not possible without synchronizing.  If there is a way to determine that\nthe behavior of one search for a bucket with any hash is always going to produce\nthe same result for any size table then I think you can safely not synchronize\nthe code.",
            "date": "20050908T16:43:49",
            "id": 40
        },
        {
            "author": null,
            "body": "(In reply to comment #40)\n> > I read the specification to state that some put/remove operations (that modify\n> > the map structurally are explicitly not threadsafe)\n> > \n> > You can't call threadsafe and non-threadsafe calls to an API at the same time. \n> > The threadsafe calls are only threadsafe with respect to other threadsafe calls\n> > on the same API.\n\n\nThere is nothing weird about anything.  Its basic computer programming design.\n\nIf you write a program what uses another API and you make presumtions about how\nyou can use it then you will come unstuck, not matter what any servlet\nspecification says.\n\nIf however you base it on whats is written into the contract of what the API\npresents to your application then you can legitimatly point the finger at that\nAPI when you find a problem.\n\nMaybe you should write your own Map interface to get the bahaviour you want, I\nthink a generic ReadWriteLock protected Map interface would be a good thing for\nthe wider Java community to have access to.\n\nYour approach for writing a test case to prove the problem is valid, because its\na concurrency rare case, maybe if you sprinckled Thread.sleep() throughout the\nHashMap code to slow it down the you might be able to make the problem 100%\nreproducable.\n\nBut I don't believe Sun's implementation needs to be fixed, as this problem does\nnot seem to contradict the written contract the HashMap API presents.\n\n\n> I'd like to remind you once more that this synchronization in the container is\n> not mandatory from what I can see\n\nAnd I'm not disputing you.  I'm disputing the more fundimental usage problem. \nThere is no way for a wep-app to override the Session object in a portable way\nacross containers.\n\n\n> I'll also add a way to configure size and sync of the collection (assuming I\n> confirm behavior to be acceptable using a test program).\n\nThis would be welcomed by me.\n",
            "date": "20050908T16:56:03",
            "id": 41
        },
        {
            "author": null,
            "body": "(In reply to comment #38)\n> I think the trouble without any sync could only occur if there was more than one\n> concurrent unsynced write, and in particular, two \"remove\"), the pointer value\n> will be corrected and the loop should exit. That's my interpretation looking at\n\nIf I understand this statement correctly -\nYou are saying that syncing the put and remove should be enough to stop the\ninfinite loop, and that this is why it was \"FIXED\" in 5.5.\n\nIf an example could be provided that an unsynced get can lead to an infinite loop,\nwould this change anything concerning the status of this problem?\n\nA second question following on from this:\n\nWhen would anyone want to use a \"threadUnsafe\" session set/getAttribute?\n\nAs we have seen, NOT syncing this causes hangs - so therefore developer\nneeds to do this (if he uses these methods). Wouldn't it make more sense to\njust sync it further down in tomcat, as suggested here, rather than needing\nto sync the whole method every single time you use this in your code?\n",
            "date": "20050908T16:58:58",
            "id": 42
        },
        {
            "author": null,
            "body": "I guess I should add that it seems logical if one web page calls\nSession.setAttribute then it shouldn't be possible later to make a call to\ngetAttribute and it not be available.  i.e. a minute earlier I made a call to\nset then a minute later during my get a resize occurs and I get a null even\nthough I should not get a null.  This could occur because of the bucket\ndistribution on certain hash and table size combinations vary.  I had one hash\nand table combination yield a 9 index.  Later when the resize occured this index\nwas moved to 3, and the resize before that it was moved to 11.  So, start at 9,\nresize, then to 11, resize, then to 3.  So you can imagine what would happen if\nduring the time I get the hash from indexFor and then access the array what I\nmight get....null.  This all in HashMap.get",
            "date": "20050908T17:00:54",
            "id": 43
        },
        {
            "author": null,
            "body": "(In reply to comment #44)\n> I guess I should add that it seems logical if one web page calls\n> Session.setAttribute then it shouldn't be possible later to make a call to\n> getAttribute and it not be available.  i.e. a minute earlier I made a call to\n> set then a minute later during my get a resize occurs and I get a null even\n> though I should not get a null.  This could occur because of the bucket\n> distribution on certain hash and table size combinations vary.  I had one hash\n> and table combination yield a 9 index.  Later when the resize occured this index\n> was moved to 3, and the resize before that it was moved to 11.  So, start at 9,\n> resize, then to 11, resize, then to 3.  So you can imagine what would happen if\n> during the time I get the hash from indexFor and then access the array what I\n> might get....null.  This all in HashMap.get\n\nThis even without speaking of the infinite loop issue.",
            "date": "20050908T17:03:08",
            "id": 44
        },
        {
            "author": null,
            "body": "(In reply to comment #43)\n\n> When would anyone want to use a \"threadUnsafe\" session set/getAttribute?\n> As we have seen, NOT syncing this causes hangs - so therefore developer\n> needs to do this (if he uses these methods). Wouldn't it make more sense to\n> just sync it further down in tomcat, as suggested here, rather than needing\n> to sync the whole method every single time you use this in your code?\n\nOne possible case is for a really simple dumb cache: where you expect the \nresult to be present in the session on every time except the first (eg where \nthe read:write ratio is 10000:1). In such a case, if the get is \nunsynchronized, it's safe to say:\n\n        Object cached = session.get(key);\n        if (cached == null) {\n            synchronized (session) {\n                cached = session.get(key);\n                if (cached == null) {\n                    cached = \"blah\";\n                    session.put(key, cached);\n                }\n            }\n        }\n\nI understand there is potential waste doing two gets (one in and one out of \nsynchronized block), but this only gets executed on the first hit, so \ndecreases in significance as the read:write ratio goes up. \n\nAnyway - that's one case I've found where an un-threadsafe get helps \nperformance wise, especially on lower spec machines short on memory (only \nthrough subjective observations though - don't have any numbers).",
            "date": "20050908T17:51:41",
            "id": 45
        },
        {
            "author": null,
            "body": "I guess the point of the above would be that desired synchronization behaviour \nis usage-dependent, so giving the developer the freedom/responsibility to \ndecide it is not necessarily a bad thing. Personally my reading of the spec \nwas that this was the reason it was left to the developer: because only the \ndeveloper has a good idea what the desired sync behaviour is.\n",
            "date": "20050908T17:56:22",
            "id": 46
        },
        {
            "author": null,
            "body": "(In reply to comment #47)\n> I guess the point of the above would be that desired synchronization behaviour \n> is usage-dependent, so giving the developer the freedom/responsibility to \n> decide it is not necessarily a bad thing. Personally my reading of the spec \n> was that this was the reason it was left to the developer: because only the \n> developer has a good idea what the desired sync behaviour is.\n> \n\nIt would be fine if all the other places in Tomcat were fixed to allow you to do\nthat.  Point in case jsp:useBean with scope=\"session\" can't be synchronized..not\nthat I know of without changing the TC5.0 and 5.5 code.  Also the JSTL\nlibraries, and many other jakarta libraries.",
            "date": "20050908T18:03:23",
            "id": 47
        },
        {
            "author": null,
            "body": "(In reply to comment #46)\n> \n> One possible case is for a really simple dumb cache: where you expect the \n> result to be present in the session on every time except the first (eg where \n> the read:write ratio is 10000:1). In such a case, if the get is \n> unsynchronized, it's safe to say:\n\nI understand, but how can you guarantee that the 'second' request does not\novertake the first put request? Not very likely, agreed - but still possible.\nUsers have a great way at pressing F5 very quickly!\n",
            "date": "20050908T18:05:48",
            "id": 48
        },
        {
            "author": null,
            "body": "(In reply to comment #49)\n> I understand, but how can you guarantee that the 'second' request does not\n> overtake the first put request? Not very likely, agreed - but still possible.\n> Users have a great way at pressing F5 very quickly!\n\nThat was the purpose of the second get check inside the sync block. The second \nrequest will, if the cache is null, block on the sync'd session, and only \nproceed into the sync block after the put. The first thing it does is check \nagain, which returns non null and it continues happily.",
            "date": "20050908T18:10:01",
            "id": 49
        },
        {
            "author": null,
            "body": "(In reply to comment #50)\n> That was the purpose of the second get check inside the sync block. The second \n> request will, if the cache is null, block on the sync'd session, and only \n> proceed into the sync block after the put. The first thing it does is check \n> again, which returns non null and it continues happily.\n\nThe situation can occur IF the second request overtakes the first that\n    Object cached = session.get(key)\nwill simply not come back and return null, because it hangs in the hashmap\ninside the get and so your check for null will never be called",
            "date": "20050908T18:14:01",
            "id": 50
        },
        {
            "author": null,
            "body": "Bear in mind if you are using clustering, you have to put the modified session\nattribute after you have finished modifying the object and wish the new state to\npersist for the next request, as clutering replication only takes place at\nsetAttribute() time.  So the 1000:1 may only be realistic for those users.\n\n\nAlso with the other issue of getting a null back when you expected to see an\nobject.  Session data does not stay around forever, it expires so all web-apps\nmust deal with the no session situation.  So I'd agree that so long as your\nservlet still holds the exact Session object instance you did a setAttribute()\non you can reasonable expect a getAttribute() on it exist.\n\nBut between requests you let go of the instance, and leave it upto the container\nsession manager to hold onto.\n\nIf as comment #44 implies you are talking minutes later, then I read into that\nyou mean across requests.  Well there is no garuntee your session still exists\nso your web-app must deal with that situation.\n\nBut you should not need to deal with seeing an old overwritten value turn up\nagain, that would be a problem.",
            "date": "20050908T18:14:36",
            "id": 51
        },
        {
            "author": null,
            "body": "(In reply to comment #35)\n> How do we approach the specifications committee for official clarification of\n> this point.\n> \n> Who is going to take charge to actively do that?\n> \n> Here is hoping to provoke all vendors to take a look at the issue and report\n> back to the committee foir a verdict in the coming months.\n> \n\nThe formal mechanism to do that is send email to the feedback address listed on\nthe spec (for 2.4, that's <servletapi-feedback AT eng.sun.com>).  I've done\nthat, and corresponded privately with the spec lead for Servlet 2.5 (Greg\nMurray) as well, who will then discuss it with the expert group to see what (if\nany) language changes they might want to do in Servlet 2.5.\n",
            "date": "20050908T18:16:29",
            "id": 52
        },
        {
            "author": null,
            "body": "(In reply to comment #48)\n> (In reply to comment #47)\n> > I guess the point of the above would be that desired synchronization behaviour \n> > is usage-dependent, so giving the developer the freedom/responsibility to \n> > decide it is not necessarily a bad thing. Personally my reading of the spec \n> > was that this was the reason it was left to the developer: because only the \n> > developer has a good idea what the desired sync behaviour is.\n> > \n> \n> It would be fine if all the other places in Tomcat were fixed to allow you to do\n> that.  Point in case jsp:useBean with scope=\"session\" can't be synchronized..not\n> that I know of without changing the TC5.0 and 5.5 code.  Also the JSTL\n> libraries, and many other jakarta libraries.\n\n\nAlso if you access the PageContext in a jsp and use the scoped methods the ones\naccessing APPLICATION and REQUEST scope are already synchronized, yet the\nsession is not.  Also, now you have to synchronize not only session calls, but\nyou also have to synchronize the calls to the PageContext in a JSP.  So, instead\nof some type of a performance gain you end up with double the monitors for those\nobjects and then the one for the session.  \n\nI think these are the points people are making.....there is so much to change\nnow that a patch now and maybe a refactoring could be done and an announcement\nthat the functionality is changing.  But, before TC decides to do that maybe\nthey should see how all of the other servers are handling this.  Because if they\nare handing this with synchronization and others are writing code not worrying\nabout synchronizing........they are not going to rewrite to use Tomcat later and\nwhat about code targeted for a container like Oracle or Sun ONE that someone is\nusing in TC which is not synchronized...point being if the user base gets run\noff whats the point, and who will be left donating to the project.  I really\nthink this is too subtle of a thing to say it's by the spec....at least for the\ntime being, and maybe it should always and forever remain synchronized depending\non what is going on with the real world usage of the spec in other cases.  There\nare other situations where you don't even have access to synchronize the\ncall...again tags, and I'm sure some other API calls directly manipulating the\nsession.  I have found no where in other Tomcat code synchronizing the session\naccess, so there are other issues or fix this one.\n\nI haven't even seen comments on all of the other issues in the TC code accessing\nthe session or the other jakarta projects from anyone but those arguing this\nneeds to be fixed.  So, what's the story?  Is this one thing changing or are all\nof the others changing or is nothing changing (being fixed)?",
            "date": "20050908T18:17:42",
            "id": 53
        },
        {
            "author": null,
            "body": "(In reply to comment #38)\n> All the entry objects will be mutated. While it may be inconsistent and might\n> loop for an instant (although I am not convinced this could really be the case;\n> I think the trouble without any sync could only occur if there was more than one\n> concurrent unsynced write, and in particular, two \"remove\"), the pointer value\n> will be corrected and the loop should exit. That's my interpretation looking at\n> the code. I think I'll write a small program to test this.\n\nOk, I wrote a program which can reproduce the bug even with tomcat 5.5\nconditions, with synchronized put/remove and unsynchronized get. I must correct\nmyself, since it doesn't produce an infinite loop, but just a very LONG LASTING\nFINITE loop, and I am talking about hours or days of execution.\n\nI do following: \nHaving X writer and X reader threads, which modify (set or remove by 50% chance)\nand read 10 mappings concurrently. The abovementioned bug occurs pretty soon\n(500.000 operations), the read thread hangs around for 5-10 seconds and gets\nfixed by the writer thread some time later. \n\nI've measured that a read operation lasts on average 0.01-0.02 milliseconds. So\nif one of the threads detects that last execution lasted longer then 5 seconds\nit is safe to say that this thread was hanging and got fixed by another writer.\n\nSpeaking of that, we could probably reproduce it on the production servers by\nnot restarting them, and leting them run some hours or days instead (maybe as\nlong as the user is still online, I don't know) and hope they will get fixed.\nHowever this is not really a solution.\n\nThe reason I can't reproduce the infinite loop, is that I can't stop the writers\n in time. Performing thousands of writes per second in multiple threads makes it\nhard to stop all writers at the same point, before they unintentionally fix the\nreader.\n\nStill, I assume, I have a good chance that an infinite loop happens on the\nproduction server if the user leaves the server, and no further write operations\nare performed on his session.\n\n",
            "date": "20050908T18:47:59",
            "id": 54
        },
        {
            "author": null,
            "body": "Looks like the problem will hard to reproduce as it requires a situation where a\nwrite to the hashmap causes a table resize/reindex to occur while another thread\nis reading from the hashmap.\n\nI would have thought it would return a null when it couldn't find the value. \nBut there is no guarantee on what happens.\n\nDevelopers could sync on the session everytime they want to read.  But why\nshould they, it is adding to the complexity of writing web apps.  As Wade\nChandler points out it may not even be possible with the JSTL tags.\n\nSome have suggested using ReadWriteLock or some other tricky method of reading,\nchecking if null, and then doing a synced read.  Which is all very good, but\nthere is a simpler solution (for tomcat 5.5) - use ConcurrentHashMap - it says\nthat \"Special-purpose data structures such as the Concurrent hash tables in this\npackage have far less overhead, and typically much better performance than\nplacing ReadWriteLocks around most sequential data structures.\"  Also, the\nConcurrentHashMap already does the second suggestion of doing a sync after a\nnull is returned (if you look at the link at the end of this).\n\nHere you have someone who has done all this hard work of figuring out when you\ncan read/write and deals with locking.  It will give you consistant results, and\ntakes out the opportunity for developers to make mistakes themselves with\ndeciding whether to sync when reading from a session or not.  Plus JSTL and\neverywhere else will benefit in not getting inconsistant results.\n\nNext stop, Application scope...\n\nsome more reading about ConcurrentHashMap internals:\nhttp://www-128.ibm.com/developerworks/java/library/j-jtp08223/",
            "date": "20050908T23:31:29",
            "id": 55
        },
        {
            "author": null,
            "body": "(In reply to comment #56)\n> Looks like the problem will hard to reproduce as it requires a situation where a\n> write to the hashmap causes a table resize/reindex to occur while another thread\n> is reading from the hashmap.\n> \n> I would have thought it would return a null when it couldn't find the value. \n> But there is no guarantee on what happens.\n> \nIt should return a null when you simply look at it the code.  I can't reproduce\nthe infinite loop myself, but Leon says he can reproduce the problem, and if\nit's so then it's a problem (Murphy's Law), and I definitely see that it is\npossible to add an attribute then later while a write is occuring to ... for\ninstance ... be logged in to some application which is relying on session\nvariables and the system think you are not then get kicked out because of\nconcurrency issues in with the HashMap not being synchronized because the system\nthinks a session attribute/variable isn't set when it is.  The original set\ncould have occurred hours before then just when the read is occuring a write\ntakes place which resizes the HashMap, and then an issue arises which makes web\napps unpredictable in Tomcat....you can predict it by knowing the default size\nof the Map and not using more session variables than the Map threshold to size I\nsuppose, but give me a break.  I can't say for certain, myself, whether the\ninfinite loop will occur just syncing the writes or not, but the way the get\nmethod works with the index being calculated for the hash bucket (array index)\nyou can certainly say it's unpredictable and it can definitely cause goofy\nerrors.  So an INVALID resolution seems irresponsible for this issue.",
            "date": "20050909T01:03:44",
            "id": 56
        },
        {
            "author": null,
            "body": "I assume that everyone has read the tomcat mailing list regarding this issue\nand seen and read the link pointing to\n\nhttp://blogs.opensymphony.com/plightbo/archives/000175.html\n\nSo are we still arguing whether or not getAttribute can cause an infinite loop?\nor not?\n\nIf we all agree that getAttribute can cause an infinite loop IF called in a \nmultithreaded environment, we (I assume) all agree that the call to it MUST be\nsynced SOMEWHERE. This also includes the example in comment 46, as it can not\nbe gaurenteed that getAttribute (inside the session.get) in the first line \ndoes not happen in the middle of putAttribute in the middle of session.put.\n\nNow the last question is remaining is who's responsibility is it to sync it?\n\nIf the end developers need to sync it - they will need to sync much more than \njust the 'hashmap' itself\n\n\n",
            "date": "20050909T01:45:28",
            "id": 57
        },
        {
            "author": null,
            "body": "(In reply to comment #58)\n> I assume that everyone has read the tomcat mailing list regarding this issue\n> and seen and read the link pointing to\n> \n> http://blogs.opensymphony.com/plightbo/archives/000175.html\n> \n> So are we still arguing whether or not getAttribute can cause an infinite loop?\n> or not?\n> \n> If we all agree that getAttribute can cause an infinite loop IF called in a \n> multithreaded environment, we (I assume) all agree that the call to it MUST be\n> synced SOMEWHERE. This also includes the example in comment 46, as it can not\n> be gaurenteed that getAttribute (inside the session.get) in the first line \n> does not happen in the middle of putAttribute in the middle of session.put.\n> \n> Now the last question is remaining is who's responsibility is it to sync it?\n> \n> If the end developers need to sync it - they will need to sync much more than \n> just the 'hashmap' itself\n> \n> \n> \n\nAgain though, when you look at all of the places accessing Session.getAttribute\nyou can't synchronize all of them, so the last question that I see is what is\ngoing to be fixed?  Either all of these other places in TC need to be fixed or\nthis one does.  But, I think a real world study should take place before all the\n other places are fixed and this one isn't.  I mean, if all other containers are\nbehaving like TC4.x and synchronizing these calls then it just makes sense for\nTC to follow suit.",
            "date": "20050909T02:10:31",
            "id": 58
        },
        {
            "author": null,
            "body": "(In reply to comment #58)\n> synced SOMEWHERE. This also includes the example in comment 46, as it can not\n> be gaurenteed that getAttribute (inside the session.get) in the first line \n> does not happen in the middle of putAttribute in the middle of session.put.\n\nActually, after looking at this a bit more - I need to correct myself - this \nexample works because the hashmap does not need to be resized on the first and \nonly putAttribute call.\n\nStill - not very pretty though.\n",
            "date": "20050909T02:13:25",
            "id": 59
        },
        {
            "author": null,
            "body": "Too much has said alread, but I also think it is not the only option to simply\nsynchronize.\n\nMost of the time the different webapps/technologies do not utilize the same\ncontent of such a session map. e.g. JSF and your home app mostly wont use the\nsame keys in this hashmap.\nSo why introduce a bottleneck? (and I didnt mean a real performance one, its\nmore  philosophical)\nWhy should one technique influence another one? And there is an impact, in the\nworst case this synchronized map acts like a \"sequencer\".\n\nWhat I would like to say is, its somehow reasonable to not simply synchronize,\nbut to find a hashmap which is able to handle this case.\n\nThis hashmap should be able to insert keys in concurrent. I one insert the same\nkey in parallel the result wont be deterministic, ok - fine.\nAnd for sure, such a map should not lock (and not even wait for some \"free me\"\nevent) on get.\n\nIsnt there a \"cool\" java collection developer here?",
            "date": "20050909T07:35:35",
            "id": 60
        },
        {
            "author": null,
            "body": "(In reply to comment #61)\n\njava.util.ConcurrentHashMap",
            "date": "20050909T10:05:32",
            "id": 61
        },
        {
            "author": null,
            "body": "(In reply to comment #62)\n> (In reply to comment #61)\n> \n> java.util.ConcurrentHashMap\n\nYou meant java.util.concurrent.ConcurrentHashMap, didn't you? \nToo bad it has been introduced in java 5.0\n",
            "date": "20050909T10:14:10",
            "id": 62
        },
        {
            "author": null,
            "body": "Another question:\n\nhttp://java.sun.com/j2se/javadoc/writingdoccomments/index.html\n\nAccording to sun's javadoc principals (above link)\n#  The Java Platform API Specification is a contract between callers and\nimplementations.\n\nThe Specification describes all aspects of the behavior of each method on which\na caller can rely. It does not describe implementation details, such as whether\nthe method is native or synchronized. The specification should describe\n(textually) the thread-safety guarantees provided by a given object. In the\nabsence of explicit indication to the contrary, all objects are assumed to be\n\"thread-safe\" (i.e., it is permissible for multiple threads to access them\nconcurrently). It is recognized that current specifications don't always live up\nto this ideal.\n\nSince the javadoc of the HTTPSession\n(http://java.sun.com/j2ee/1.4/docs/api/index.html) doesn't mention anything\nabout session being not thread-safe, should not the developer be able to rely on\nthe fact that the implementation is thread safe?\n\n\n\n\n\n",
            "date": "20050909T12:26:20",
            "id": 63
        },
        {
            "author": null,
            "body": "(In reply to comment #64)\n> Another question:\n> \n> http://java.sun.com/j2se/javadoc/writingdoccomments/index.html\n> \n> According to sun's javadoc principals (above link)\n> #  The Java Platform API Specification is a contract between callers and\n> implementations.\n\nLeon,\n\nCan you publish your TC+HashMap finding you based your comment #55 ?\n\n\nI've always tried to program for the worst case scenario, assume thread-unsafe\nunless otherwise stated.  Probably my 'C' language background thinking here.  So\nit interests me to hear this stated in reverse for Java (not a bad thing at\nall).  Where within the reference is that implicit thread-safe notion stated ?\n\n\nIs a HashMap really needed for session attributes, exactly how many attributes\ndoes an average application have set ?  Replacing the collection with a bespoke\nTC internal class based on something as silly as a linked list or fixed hash\nbucket redirect into linked list should serve most users well.\n\nThen making the exact collection implementation class a configurable item so\nthose users that would benifit from a safe HashMap for scalabilty of key count\nwould be happy to fix their performance with a config change.\n\n\nIt would please me greatly to see a more proper collection class for the job\nwith a safe write operation whilst allowing simultenous mutiple reads.  But\ntrying to bend the HashMap API into something its not is wrong.\n\nJava Moto #1: \"You program to interfaces\"\n",
            "date": "20050909T12:55:40",
            "id": 64
        },
        {
            "author": null,
            "body": "(In reply to comment #65)\n> all).  Where within the reference is that implicit thread-safe notion stated ?\n\nhttp://java.sun.com/j2se/javadoc/writingapispecs/index.html#top-level\n",
            "date": "20050909T13:10:00",
            "id": 65
        },
        {
            "author": null,
            "body": "(In reply to comment #66)\n> http://java.sun.com/j2se/javadoc/writingapispecs/index.html#top-level\n\nThat reference is invalid in the context of this bug report.  I read it to be a\nhyperthetical example of what to put inside javadoc information.\n\nNothing concrete to under pin all Java programming design.\n\n\nMy comments fallback to what is written (and not written) into the documentation\nfor the HashMap implementation that TC has elected to use for the job.  It does\nnot say you call get() while you are also doing a put() (when the put() may\ncause internal re-arangement), it explicitly warns you of this problem and as we\nhave no way knowing if the put will cause a rearrangment to achieve TCs goal of\nrobustness we have to synchronize our usage.\n",
            "date": "20050909T13:28:29",
            "id": 66
        },
        {
            "author": null,
            "body": "Created attachment 16347\nbug reproduction\n\neclipse ready project. \nto start: \njar -xf synchtest.jar\ncd synchtest\njava -cp classes leon.synch.StartTest",
            "date": "20050909T14:39:16",
            "id": 67
        },
        {
            "author": null,
            "body": "(In reply to comment #65)\n> Leon,\n> \n> Can you publish your TC+HashMap finding you based your comment #55 ?\n\nIt's a simple program, which actually shows the bug (on synchronized put/remove\nand unsychronized get). I am to stupid to program the writers to stop as soon as\nthe loop occurs, so they fix the problem some time after it occurs (thats why a\nlong loop instead of infinite loop). \n\nAfter each execution the reader measures how long the execution lasted. If the\nexecution lasted longer then 5 seconds it cries. The mid time of the execution\nis 0.05 milliseconds. So we can safely assume, that executions which last 5\nseconds or more aren't normal. In fact I had it all night running with 714 \"too\nlong executions\", longest of them being 70 seconds. If I add synchronized(map)\nin the getAttribute method of the Storage class it doesn't occure anymore.\n\n\n\n\n",
            "date": "20050909T14:49:29",
            "id": 68
        },
        {
            "author": null,
            "body": "(In reply to comment #67)\n> (In reply to comment #66)\n> > http://java.sun.com/j2se/javadoc/writingapispecs/index.html#top-level\n> \n> That reference is invalid in the context of this bug report.  I read it to be a\n> hyperthetical example of what to put inside javadoc information.\n> \n> Nothing concrete to under pin all Java programming design.\n\nI think what leon is trying to say is that 'this is what should be done'.\n\nSo either - the documentation for HTTPsession has a problem, that it is missing\nthe information regarding it not being thread safe - or the implementation\nin TC is wrong.\n\nAccording to what I have read here, it has been decided that TC says that HTTPsession\nis NOT threadsafe, meaning that all developers who use HTTPsession will\n- should they call 'put' - need to ensure that they sync the session - otherwise\nnasty things can happen.\n\nThis means that the documentation should definitely be changed to warn developers,\nand that all 3rd party projects fix their code so that it does not crash/ hang tomcat 5.0 .\n\n(I haven't had a proper look to check if the synced puts in 5.5 are enough to stop the\nloops)...\n\nIMHO - Anyone who doesn't care whether or not the data is consistent - really\ndoesn't need the data, and shouldn't bother calling the routine.",
            "date": "20050909T15:12:54",
            "id": 69
        },
        {
            "author": null,
            "body": "Guys please .. Remy already said way back in #40 that he would look into \nallowing this to be configurable :)",
            "date": "20050909T15:16:50",
            "id": 70
        },
        {
            "author": null,
            "body": "(In reply to comment #71)\n> Guys please .. Remy already said way back in #40 that he would look into \n> allowing this to be configurable :)\n\nI don't really see anything that says the real issue will be addressed.  An out\nof the box Tomcat has to be configured not to have a bug?  Plus, he said he\nwould look into it and all this and that and that's fine, but no where does it\nreflect he believes there is an issue, and right now a bug caused by an\nuninformed decision remains.  One, how do you synchronize calls with jsp:useBean\nwith scope of session?  Where else is session accessed in the Tomcat code\nwithout synchronizing that developers should be aware of?  Is JSESSIONID stored\nin the session as well and where is it accessed?  We need to make sure that\naccess is synchronized.  If we are going to talk about specifications and\nresponsibilities lets talk about them, but logically and truthfully.  There is\nmore to this issue than can be addressed by: \"It's the developers\nresponsibility.\".  Do we need to file bugs for all of the other issues if this\nis going to remain invalid?  I say that must be the case if this is to remain\ninvalid.\n\nPersonally I don't like the idea that \"this was done as an experiment\"...\nwritten in one of the comments above... in a system said to be \"production\nquality\" (Tomcat home page).  The point is this: if it were an experiment it\nshould have used an option to turn it on, but should not have been a default by\nany means.  If a system has an apparent flaw that reduces it's stability and\nreliability and  especially when it can be solved with a couple of lines of\ncode.....a patch is a no brainer.  This entire issue makes Tomcat currently\ninvalid as there are sections of standard usage which can not be safe guarded\nagainst concurrency issues.  If I have an issue where customers can get kicked\nout of the site after being logged in and the client asks me to fix it....I\ncan't without changing the entire application, and by that I mean not using\njsp:useBean calls in my JSP pages without wrapping them with other calls, so\nwhat's the point of using the tags in JSP if they can't be safe guarded without\nmore work.  I thought the point of the tags, EL, and other things is to make\ndevelopment quicker and to provide short cuts.\n\nMy opinion:\n\n1) Before a decision was made to change the synchronization of something which\nwas currently synchronized when documentation for the underlying implementation\nexplains there are issues with not synchronizing should not have only been\ndiscussed as to whether it was safe, logical, and correct, but should have been\nproved.\n\n2) If it were to be an experiment, then it should have used an option to turn it\non, and the default been the more correct implementation for the given situation.\n\n3) When a problem is identified in a piece of software being promoted as\nproduction ready it should be handled.  Not shaken off as INVALID.  Where is the\nproof that unsychronized reads don't have issues.  Examine the HashMap source\ncode and write a few tests.  You'll see with the bouncing index that a valid\nvalue can exist in the Map for a given key and that Entry not be located because\nnull is returned.  Thus a program relying on a session variable to be set will\nnot be able to retrieve that session variable and take an entirely different\npath because of this....it's very simple........just read the code:\n    public Object get(Object key) {\n        Object k = maskNull(key);\n        int hash = hash(k);\n        int i = indexFor(hash, table.length);\n        Entry e = table[i]; \n        while (true) {\n            if (e == null)\n                return e;\n            if (e.hash == hash && eq(k, e.key)) \n                return e.value;\n            e = e.next;\n        }\n    }\n\nbetween the time i is set from a call to indexFor if table is resized with all\nvalues null or all items are transfered and the given index for i is null then\nnull is returned as soon as we step into the while loop.  What that means is: If\nbetween the time i is set from indexFor and the HashMap is resized because of a\nwrite then there is a concurrency issue which affects the consistency of the\napplication.\n\nHow can this issue be worked around currently using Tags?  If we need to file\nbugs on all the other places please let us know.  If you would like some help\nwith the other issues I would be willing to help, but my feelings are this\nshould be changed back for the time being and we need a new release based on the\nlatest release with only this change to the source.  In the mean time all the\nother issues can be worked on as all of that will take more time than this\nchange.  Once those issues are dealt with then change it back and make sure the\nissue is documented on the front page of the Tomcat documentation.",
            "date": "20050909T17:37:31",
            "id": 71
        },
        {
            "author": null,
            "body": "Ok, I'm going to *explain* why I'm so upset about this.\n\n\"There is heavily used public API in this heavily multithreaded application that are not thread safe and \nnot documented clearly as such.\"\n\nYou might as well put it on the front page - you've got a page of comments from various ASF people \ntrying to explain to the world how that sentence (which is what it all boils down to) makes a hair of \nsense.\n\nAny other parts of the most commonly used API in the system, those things which are not only used on \nmultithreaded applications but happen to be *heavily* used parts of the API, with a high risk of \nthreading problems, happen to be?  Because I'm looking at your response and wondering WTF you \nexpect of developers - to walk through the spec and GUESS at which things you've decided to willfully \nmisinterpret for the sake of shaving off a few hundred milliseconds that cause my live applications hell?\n\nI've been wondering what's caused this for ages now, and just *happened* to stumble across this.  How \ndare *ANYONE* at the ASF claim a holier-than-thou attitude about a fork when something as simple \nand basic as this gets explained away, marked invalid, and ignored.\n\nYou're experimenting with people's live applications, whom everyone's been encouraging to trust \nsoftware written by authors who think a few hundred milliseconds on Joe's web app is more important \nthan stability.  Plain and simple.  WTF are you doing to Tomcat?  Is there anything more important than \nits reputation as a stable platform?\n\nIf the ASF worked so bloody well, we wouldn't be seeing someone asking us to misread sections of the \nspec.  There is *no* defence for this kind of behaviour in a server like this; there's loads of defence for \nthe existence of the bug, to be sure - but none for this kind of response...  So all the pointless crying \nabout someone forking off looks a lot more, now, like you're getting exactly what you deserve for \ndecisions which quite clearly diverge from the sane by several kilometers.  Even rereading this, I can't \nget over it - a major bug in the support for multithreading, being ignored by its developers for a range \nof differently pointless reasons, resulting in a \"hey, we'll make it configurable\".\n\nConfigurable?  What, now I *want* to selectively cause data corruption?  I didn't realise it was such a \nbeneficial option to have on hand.  Sure, some of our readers get 'teh suck', but hey, it's 8 milliseconds \nfaster for the other guy.\n\nThis is one of those bugs that goes out in e-mail, to just about everyone I know, with a note that says \nmaybe we should be looking at alternative solutions to Tomcat in our live environment - because if this \nis the kind of judgement being used to build the application we're depending on to serve content, you \ncan keep it.  This all works so long as I don't have to question fundamental decisions about whether the \nsoftware is well made, and up until now, I've never even considered the possibility of whether or not I \nshould trust what comes out of the Tomcat dev team.\n\nNow I find out that a major bug that's been affecting our platforms was someone's little 'experiment'.  I \nhaven't got two fingers big enough to stick up at the moron who thought *that* explanation was a good \nidea.\n\nFix it.  Resolved my arse.  And while you're at it, tell me what other areas of the \"spec\" I should be \nmisinterpreting, and working around in my code.  Crying about a fork?  Reading this, you practically \n*deserve* one.",
            "date": "20050914T01:10:24",
            "id": 72
        },
        {
            "author": null,
            "body": "I reopened this ticket because it pretty clearly should not be closed, or at \nleast not with an INVALID resolution.  I would have thought others would have \ndone this (again, it seems it has been closed and reopened already), but so be \nit, I'll do it.\n\n* 18 people voted for this bug, which alone indicates it is not INVALID.\n\n* There continues to be comments made on it which reflect people wanting this \naddressed in some way other than sweeping it under the rug (see the rather \nheated comment right before this one... that is not the first time I have \npersonally heard similar sentiments from someone recently).  Even if all the \ncommitters vehemently disagree with that thinking (and it appears to mainly be \none frankly) it is improper to close this as INVALID because that does not \naccurately reflect reality.\n\n* There continues to be discussion on the mailing lists, and elsewhere, about \nthis.  That too indicates the INVALID resolution is not correct.\n\nIf someone wants to verbally slap me for doing this, go for it.  I for one do \nnot believe this whole situation is being handled properly and this is my act \nof civil disobedience in the matter.  If you want to close it again, at least \nDO NOT do the Tomcat user community the disservice as marking it as INVALID \nbecause that resolution will do more to hurt people than not fixing it (i.e., \nsome may conclude there really is nothing to worry about and get burnt in \nproduction).  Mark it as what it truly is: WONTFIX... which would *still* be \nthe wrong answer IMO, but will at least provide the proper information to \nanyone looking at this ticket after the fact, scratching their head asking \nwhat the hell is going on?!?",
            "date": "20050914T01:32:06",
            "id": 73
        },
        {
            "author": null,
            "body": "(In reply to comment #73)\n\nThe great thing about the ASF is its open source and you can fix it yourself. I \nwould prefer it fixed in Tomcat, but I think your rant, Wade, at a Tomcat \ndeveloper isn't going to make that more likely - this is a volunteer \norganization.\n\nI've created a patch, based on Craig's idea (see comment#21), that can \nbe \"plugged\" in for Tomcat 5.0.x which creates \"thread safe\" sessions - \navailable <a \nhref=\"http://www.niallp.pwp.blueyonder.co.uk/TomcatBug36541.html\">here</a>",
            "date": "20050914T04:09:12",
            "id": 74
        },
        {
            "author": null,
            "body": "Just realize that some of us work for companies that don't allow us to create\nour own patched version--we're required to use the binary, versioned downloads.\n So while a patch may be sufficient for some of the userbase, it's not the\nanswer for everyone. \n\nSo let's just fix it.\n\nJay",
            "date": "20050914T04:28:19",
            "id": 75
        },
        {
            "author": null,
            "body": "(In reply to comment #76)\n\nOK \"patch\" is probably mis-leading - its really a \"plug-in\". You still use the \nTomcat binary download unchanged. Its just a case of dropping in an extra jar \nand configuring Tomcat to use it.\n\n(In reply to comment #75)\n> (In reply to comment #73)\n> would prefer it fixed in Tomcat, but I think your rant, Wade, at a Tomcat \n\nSorry Wade, meant Gregory :-(",
            "date": "20050914T04:35:24",
            "id": 76
        },
        {
            "author": null,
            "body": "Guys, we're in active discussion with the Servlet Spec expert group about\nresolving this.  It's an open issue in the center of everyone's radar and\nhighest on the priority list.  It'll get fixed in the best way possible as soon\nas possible.  Let's try to stay professional about it.",
            "date": "20050914T04:55:06",
            "id": 77
        },
        {
            "author": null,
            "body": "Guys, we're in active discussion with the Servlet Spec expert group about\nresolving this.  It's an open issue in the center of everyone's radar and\nhighest on the priority list.  It'll get fixed in the best way possible as soon\nas possible.  Let's try to stay professional about it.",
            "date": "20050914T04:55:30",
            "id": 78
        },
        {
            "author": null,
            "body": "(In reply to comment #75)\n> (In reply to comment #73)\n> \n> The great thing about the ASF is its open source and you can fix it yourself. I \n> would prefer it fixed in Tomcat, but I think your rant, Wade, at a Tomcat \n> developer isn't going to make that more likely - this is a volunteer \n> organization.\n> \n> I've created a patch, based on Craig's idea (see comment#21), that can \n> be \"plugged\" in for Tomcat 5.0.x which creates \"thread safe\" sessions - \n> available <a \n> href=\"http://www.niallp.pwp.blueyonder.co.uk/TomcatBug36541.html\">here</a>\n\nThat is the great thing about open source software.  Unfortunately I didn't\nwrite comment #73.  It certainly is a volunteer organization.  I have tried to\nhelp and give advice on the Tomcat list for years.  I have even tried to help\nout with a few open source projects with some of my own time: iReport on\nsourceforge.net is one of them.  \n\nWhen I work on any open source project I accept others critism and am conscious\nof the fact that I did not write all of the source code in the project nor am I\nthe only person using and relying on the software.  I am also aware that because\nan issue isn't affecting me directly it doesn't mean it isn't an issue, and\nthese types of problems require being looked into when clear and relevant\nevidence is provided to display a real and valid problem exists.\n\nThe last paragraph is written becuase, I have not been bitten by this specific\nbug as of yet.  I saw the issue come across the Tomcat users list.  I then\nevaluated the situation.  As I was evaluating the situation I noticed that while\nI didn't see how an infinite loop could occur I definitely could see an issue\nbecause not synchronizing the reads can allow incorrect returns from a call to\ngetAttribute (null when the key clearly points to a relevant value) and the\nwhile loop can be entered and iterated over a different number of times before\nreturning.  \n\nI even went as far to take java.util.HashMap, copy it into it's own class so I\ncould access it's internals from code, then wrote tests to validate what I\nthought could happen.  I then noticed areas in the Tomcat source code which are\naccessing the session which are not synchronized which developers can not\ndirectly synchronize.  So, clearly there is a real issue which needs to be\naddressed a the release level.  A patch is fine, and thank you for it, but it\ndoesn't solve the scenario where a new user who doesn't know about this issue,\nthe patch, or anything else associated with it downloads and installs Tomcat. \nSo, when they run into it we'll have this same thing over and over again until\nit's fixed.  I have a feeling it's being worked on though.\n\nAlso, I think some of the more hateful comments could have been avoided had\nthere not been antagonizing language used by certain folks.  If you will notice\nthe comment you are referring to posted by another user, they seem agitated by\nsome of the responses to the issue.  So, yes it's a volunteer organization, and\nASF should be respected by both users and developers alike.  It should be\nconsidered a privilege to be allowed to be a commiter here IMO.  I have always\nfelt that way about anything I have been able to be a part even when I may feel\nlike debating an issue or getting a little heated.\n\nSo, I have written what I just wrote.  I would like to send a sincere thank you\nto all of the Apache developers for their efforts and time: no hard feelings\nfrom me.  Really, I have worked in this business long enough to have been in\nheated debates time and time again with co-workers and fellow developers about\nprogramming issues.  Sorry for the confusion, and I want to reiterate another\nfrustrated individual besides myself wrote comment #73.  I don't want to argue.\n I just want to contribute to software, and make it the best it can be, and\ncertainly as good as it should be.  So, I'll continue to point out things I see\nas issues, and try to grin and bear it when they get pointed out to me.",
            "date": "20050914T05:24:29",
            "id": 79
        },
        {
            "author": null,
            "body": "(In reply to comment #77)\n> (In reply to comment #76)\n> \n> OK \"patch\" is probably mis-leading - its really a \"plug-in\". You still use the \n> Tomcat binary download unchanged. Its just a case of dropping in an extra jar \n> and configuring Tomcat to use it.\n> \n> (In reply to comment #75)\n> > (In reply to comment #73)\n> > would prefer it fixed in Tomcat, but I think your rant, Wade, at a Tomcat \n> \n> Sorry Wade, meant Gregory :-(\n\nThanks for the apology Niall.\n\nWade",
            "date": "20050914T05:30:49",
            "id": 80
        },
        {
            "author": null,
            "body": "just to give a short update on the patch (for those who doubt or/and are interested)\n\nwe installed the patch on friday morning, so it's in the production (live)\nsystem for 5 nearly days now. \nSince that we haven't had a single tomcat crash or hangup. Same period a week\nago it were about 15 servers. We haven't changed anything else, and the system\nhas served about 500.000.000 (real) requests with the patch, so I assume it can\nbe safely said, that the patch works and solves the bug.",
            "date": "20050914T07:54:59",
            "id": 81
        },
        {
            "author": null,
            "body": "(In reply to comment #73)\n> Fix it.  Resolved my arse.  And while you're at it, tell me what other areas\nof the \"spec\" I should be \n> misinterpreting, and working around in my code.  Crying about a fork?  Reading\nthis, you practically \n> *deserve* one.\n\nYes, unfortunately, you need to find yourself a replacement brain really fast so\nyou could actually comprehend the issue. Syncing reads in addition to writes\n(which already prevents data corruption, and is done again in the entire 5.5\nbranch) provides very little, since your reads are going to be dirty anyway\nunless you sync yourself at the application level. Basically, the\nConcurrentHashMap, which uses the same algorithm as the regular HashMap, just\ndoes an additional synced read if the result was null to the initial unsynced read.\n\nThe problem should be solved soon, howver, and you'll be able to stop writing\npointless rants, as the spec wording is going to be heavily changed.\n\nBTW, I am not crying about the Glassfish fork, I am mentionning that the way it\nwas done was, as usual with companies doing forks, innappropriate.\n\n> its reputation as a stable platform\n\nLol, most of the time, people (like you) say it's crap :D",
            "date": "20050914T07:59:26",
            "id": 82
        },
        {
            "author": null,
            "body": "(In reply to comment #78)\n> Guys, we're in active discussion with the Servlet Spec expert group about\n> resolving this.  It's an open issue in the center of everyone's radar and\n> highest on the priority list.  It'll get fixed in the best way possible as soon\n> as possible.  Let's try to stay professional about it.\n\nThanx Yoav, great news! \nI hope this issue will get solved, and we all get our \"I've found a bug in the\nspec and all I got was this lousy t-shirt\" t-shirts, and, most important, stable\nproduction systems soon.\n\nregards\nLeon",
            "date": "20050914T08:04:39",
            "id": 83
        },
        {
            "author": null,
            "body": "1) Take the rant for what it is:  A demand that pointless excuses for why it is marked invalid end.\n2) We'll all feel a lot better now that there's a fix on the cards instead of a lot of excuses.\n3) \"people like me\" quietly use and support Tomcat in our community, and don't show up in forums \nbecause, up until reading this, we didn't even have issues like this *crossing our mind* to bring up.\n\nJust get it fixed.  Don't care how - it's *not* an invalid bug, and there's no excuse for that.",
            "date": "20050914T08:33:35",
            "id": 84
        },
        {
            "author": null,
            "body": "Ok, so completely innocently here (despite what people may happen to think - I'm *still* incensed by \nreading the history on this bug, and still feel well and truly PO'd...)\n\nWhy does the following not represent an issue in DeltaSession 1.35?\nhttp://cvs.apache.org/viewcvs.cgi/jakarta-tomcat-catalina/modules/cluster/src/share/org/apache/\ncatalina/cluster/session/DeltaSession.java?rev=1.35&view=markup\n\nAccess to attributes.put() remains unsynchronized; synchronizing the remainder, especially when other \nmethods are synchronized, strikes me as an oversight - it should cause the exact same problem (albeit \nless often, because reads are being serialized) as a put can still cause the hashmap to resize, and \ntherefore still hit the problem; those puts are also allowed during retrieval of attributes.keyset() and \nother long-running actions as a result of this.  removeAttributeInternal() also fails to synchronize the \nremoval of the attribute from the map, and thus also creates the issue; attribute removal and insert can \nboth cause a right-timed reader to fail.\n\nSo it's not just limited to StandardSession, which...\nhttp://cvs.apache.org/viewcvs.cgi/jakarta-tomcat-catalina/catalina/src/share/org/apache/catalina/\nsession/StandardSession.java?rev=1.60&view=markup\n\nalso fails to synchronize its session data in the current 5.0.11 branch - although it, too, does half the \njob by performing unsynchronized reads, synchronizing writes, failing to synchronize keyset retrieval, \netc.\n\nSo how is this not a 5.5 bug?  StandardSession will definitely exhibit the behavior a lot more often, but \nthe bug is still fundamentally *there* on both.",
            "date": "20050914T10:29:21",
            "id": 85
        },
        {
            "author": null,
            "body": "(In reply to comment #86)\n\nI have fix the unsync write session attribute operation at DeltaSession.\n\nPeter",
            "date": "20050914T14:50:53",
            "id": 86
        },
        {
            "author": null,
            "body": "(In reply to comment #87)\n> (In reply to comment #86)\n> \n> I have fix the unsync write session attribute operation at DeltaSession.\n> \n> Peter\nThere are other places that have this issue I noticed while going through the\nTomcat code such as the StandardSession get/setNote methods which are not\nsynchronized and are used throughout the code without being synchronized.  They\nare used in the authenticators I know and I'm sure they are used in other places\nbecause of their nature.  Should I file a separate bug for each, or is it enough\nto give a generic bug which states there are a lot of cases of unsynchronized\nHashMap in Tomcat so they can be tracked down?  I would work on a patch for it\nas long as I'm not working on it at the same time as anyone else.  Are all\ninstances being looked at as a result of issue 36541?",
            "date": "20050914T16:10:32",
            "id": 87
        },
        {
            "author": null,
            "body": "I am sorry if I am too late to push (the issue is already fixed), but in case\nit's not I have something to say:\n1)SRV 15.1.7 says nothing about HttpSession being not thread-safe. And AFAIR\nthis means the interface should be thread-safe.\n2)SRV 7.7.1 says about synchronizing access to \"session resources\", but it says\nnothing about session object itself. If one thinks session itself was meant in\nit, he should agree that more exact method of synchronizing then \"as\nappropriate\" should be used in the specs: the Developer can choose any way it\nwishes to synchronize access to it's own resources but the method of\nsynchronizing access to a object (HttpSession) that is used by different\nDevelopers (if such a synchronization is needed) MUST be defined.\nIf you read \"session resources\" as \"session\", this means anyone can choose any\nappropriate method of synchronization of session object, that is totally incorrect.\nAs for me, this means that neither 7.7.1 nor any other point of specs does NOT\nsay that session object is unsafe and this means that in any implementation it\nMUST be safe.",
            "date": "20050914T16:45:53",
            "id": 88
        },
        {
            "author": null,
            "body": "Syncing reads in addition to writes\n> (which already prevents data corruption, and is done again in the entire 5.5\n> branch) provides very little, since your reads are going to be dirty anyway\n> unless you sync yourself at the application level. Basically, the\n> ConcurrentHashMap, which uses the same algorithm as the regular HashMap, just\n> does an additional synced read if the result was null to the initial unsynced\nread.\n\nI don't want to flog a dead horse, but I do not think the above is correct. \nNormally \"Dirty Read\" means that you can read an uncommitted transaction.  In\nthis case, it means that you can get an incorrect read when looking at a peice\nof data that no one else is touching.  E.g.  If someone is adding Item X, you\nmay be prevented from seeing Item Y.  This is mostly caused by the resize issue\nalluded to above, and is addressed by ConcurrentHashMap much differently than it\nis addressed in HashMap.\n\nIf you look at the Get code for ConcurrentHashMap:\n     V get(Object key, int hash) {\n           if (count != 0) { // read-volatile\n               HashEntry<K,V> e = getFirst(hash);\n               while (e != null) {\n                   if (e.hash == hash && key.equals(e.key)) {\n                       V v = e.value;\n                       if (v != null)\n                           return v;\n                       return readValueUnderLock(e); // recheck\n                   }\n                   e = e.next;\n               }\n           }\n           return null;\n       }\n\n   HashEntry<K,V> getFirst(int hash) {\n           HashEntry[] tab = table;\n           return (HashEntry<K,V>) tab[hash & (tab.length - 1)];\n       }\n\nThe code in getFirst first sets the table to a local variable, this is probabaly\nmeant to get around the issue brought up by issue#72 where the table can change\nbetween gettting the table length and then accessing an index in that table.\n\nIn addition to this, there are a lot of other differences between\nConcurrentHashMap and Hashmap that address a number of these subtle issues.\nLook at the differences between ConcurrentHashMap$Segment.rehash() and\nHashMap.transfer().  Hashmap.transfer() simply transfers all the entries over to\nthe new list.  ConcurrentHashMap$Segment.rehash() needs to determine which\nentries can be moved over and which need to be copied so that it can keep the\ncurrent table used by the ConcurrentHashMap valid.\n\nThe overall point here is that concurrency issues are subtle, and using data\nstructures that are not meant to be used concurrently in a concurrent manner can\nbe dnagerous.",
            "date": "20050915T16:57:16",
            "id": 89
        },
        {
            "author": null,
            "body": "Actually, for completeness, I thought I would mention some of the other more\nsubtle differences between HashMap and ConcurrentHashMap that make this dangerous.\n\nIn both HashMap and ConcurrentHashMap adding a new entry comes down to a line\nthat looks something like:\n\n  table[bucketIndex] = new Entry<K,V>(hash, key, value, e);\n\nLooks safe, right?  Problem is that Entry<K,V>.next is not final, so it need not\nbe actually flushed to memory by the time table[bucketIndex] is set.  For\nConcurrentHashMap, HashEntry<K,V>.next is declared final, so it must be flushed\nto memory before the constructor is finished.\n\nThis means that for the HashMap case, when doing a get, you can get this\npartially created instance and not look down the rest of the chain, and thus not\nfind your element.  In the ConcurrentHashMap case, this cannot happen because of\nthe above mentioned \"final\" variable.  For more info on this read section 17.5\nof the JVM spec as it is revised for 1.5\n\nhttp://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.5",
            "date": "20050915T23:18:52",
            "id": 90
        },
        {
            "author": null,
            "body": "As mandated in the next Servlet specification (the change seems to be accepted),\nthe session internal maps are now fully synchronized, by using a Hashtable.",
            "date": "20050919T13:47:03",
            "id": 91
        },
        {
            "author": null,
            "body": "could you post a link to the new spec? \nI can't find any changes under:\nhttp://www.jcp.org/aboutJava/communityprocess/maintenance/jsr154/index3.html \n",
            "date": "20050919T14:23:11",
            "id": 92
        },
        {
            "author": null,
            "body": "If session attributes are now going to be synchronized as per spec, what about\nservlet context attributes? They will face the same issue.",
            "date": "20050919T22:56:56",
            "id": 93
        },
        {
            "author": null,
            "body": "(In reply to comment #94)\n> If session attributes are now going to be synchronized as per spec, what about\n> servlet context attributes? They will face the same issue.\n\nThe proposed (and now committed) change protects the attribute collection\n*inside* the HttpSession object, eliminating the opportunity for an application\nto cause that collection to become corrupted.  But the fact that a session\nattribute can be accessed from multiple threads, and therefore might need\ninternal thread safety checks internal to itself, is still the application\ndesigner's issue to solve.  Indeed, it's not anything a container could do\nanything about, even if it wanted to.\n\nThe attribute collection inside Tomcat's ServletContext implementation was\nalready synchronized, and not subject to corruption.  Only the technique used to\nrepresent *session* attributes was in question here.\n",
            "date": "20050920T00:06:46",
            "id": 94
        },
        {
            "author": null,
            "body": "(In reply to comment #95)\n\n> The attribute collection inside Tomcat's ServletContext implementation was\n> already synchronized, and not subject to corruption.\n\nYeah, but what does the spec say (now)? If it is about as unclear as with the\nsession attribute collection, history will repeat itself: Tomcat or some other\ncontainer will implement ServletContext attribute collection unsynchronized\n(because its faster), some people will whine about lockups, spec needs to be\nchanged one more time, container needs to be changed in order to be (new) spec\ncompliant.",
            "date": "20050921T20:44:16",
            "id": 95
        }
    ],
    "component": "Catalina",
    "description": "I'm not quite sure if it's a bug or spec flaw, but I talked to Craig McClanahan\nand he encouraged me to submit it.\nThe session attribute handling methods in 5.0.x aren't thread safe. The\norg.apache.catalina.session.StandardSession and StadardSessionFacade do not\nsynchronize in get/set/remove Attribute. The result is following:\nIf you write and read from the session simultaneously with multiple threads the\ngetter/setter methods corrupt the underlying HashMap. The HashMap's entries got\ncircularly linked, and any thread using a get() on such a HashMap will spin\nforever chasing its tail (quoted from Larry Isaacs). \n\nNow what Josh Bloch and Co. are saying in the javadoc for HashMap:\n * <p><b>Note that this implementation is not synchronized.</b> If multiple\n * threads access this map concurrently, and at least one of the threads\n * modifies the map structurally, it <i>must</i> be synchronized externally.\n * (A structural modification is any operation that adds or deletes one or\n * more mappings; merely changing the value associated with a key that an\n * instance already contains is not a structural modification.)  This is\n * typically accomplished by synchronizing on some object that naturally\n * encapsulates the map.  If no such object exists, the map should be\n * \"wrapped\" using the <tt>Collections.synchronizedMap</tt> method.  This is\n * best done at creation time, to prevent accidental unsynchronized access to\n * the map: <pre> Map m = Collections.synchronizedMap(new HashMap(...));\n * </pre>\n\nThe bug is quite easy to fix, by making the map synchronized (as stated above)\nor explicitely synchronize the places where HashMap.get() or put() is called. \nI could provide a patch if wished.",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "36541",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "P1 critical",
    "product": "Tomcat 5",
    "project": "TOMCAT",
    "summary": "session getAttribute/setAttribute and removeAttribute are NOT Thread safe.",
    "systemSpecification": false,
    "version": "5.0.25"
}