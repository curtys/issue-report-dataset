{
    "comments": [
        {
            "author": "Christoph Kiehl",
            "body": "This is a first patch which uses a FieldCache per index segment. To make this work we had to use our own implementation of FieldCache.StringIndex which does not keep an array of sort indexes for the document, but which keeps an array terms associated which each document. This of course uses more memory and there need to be some performance/scaling tests done.\nWe had to modify SearchIndex.CombinedIndexReader and CachingMultiReader to allow access to the underlying IndexReaders because those IndexReaders are used as cache keys in SharedFieldCache.\nI'm not absolutely satisfied about this solution, because SharedFieldSortComparator has to know that there is a CombinedIndexReader and currently even assumes it.\nPerformance wise we achieved a speed up by factor 5-15 for queries sorting by some field in our current application. In our scenario we have got a lot of write operations and more than 1000000 nodes . For read-only repositories this patch slightly degrades performance by a factor of about 2.",
            "date": "2007-06-19T16:11:45.859+0000",
            "id": 0
        },
        {
            "author": "Marcel Reutegger",
            "body": "Do you have test cases or a description of the queries that you execute?",
            "date": "2007-06-20T11:47:02.452+0000",
            "id": 1
        },
        {
            "author": "Marcel Reutegger",
            "body": "Here's my attempt to keep FieldCaches per index reader.\n\nNot well documented, but it's rather a prototype anyway.\n\nWDYT?",
            "date": "2007-06-20T11:51:05.607+0000",
            "id": 2
        },
        {
            "author": "Marcel Reutegger",
            "body": "btw, both SearchIndex.CombinedIndexReader and CachingMultiReader implement MultiIndexReader which exposes getIndexReaders().",
            "date": "2007-06-20T11:52:16.934+0000",
            "id": 3
        },
        {
            "author": "Christoph Kiehl",
            "body": "The query I'm doing my tests with looks like this:\n\n//element(*, app-mix:document) order by @app:modificationDate\n\nUnfortunately I've got no testcase yet. I'll try to create one.",
            "date": "2007-06-20T11:54:41.767+0000",
            "id": 4
        },
        {
            "author": "Christoph Kiehl",
            "body": "Regarding your ItemStateManagerBasedSortComparator.patch: This patch doesn't work well in our scenario because we've got fairly large resultsets. I think your patch might handle small result sets better than my patch, but for large result sets there are too many documents from different index segments. Using your patch my query takes about 100000ms while using our patch it needs between 200ms and 1000ms.\n\nOne of the other features of my patch is that it creates the caches lazily per index segment. We also played around with a global term cache so if the same term is returned by different index segments the same String object is used for the FieldCache. This minimizes the FieldCache size if one term is contained in multiple index segments. In our case the default FieldCache was about 4MB for a certain field while the patched FieldCache was about 2.5MB.",
            "date": "2007-06-20T12:11:56.040+0000",
            "id": 5
        },
        {
            "author": "Christoph Kiehl",
            "body": "This is a revised version of the first patch. The following changes were applied:\n\n- Using MultiIndexReader interface instead of providing own methods on CombinedIndexReader and CachingMultiReader. This is not only better design but also improves performance a bit.\n- Create caches proactive instead of lazily and use an array to access them. This improves performance a little bit for successive queries.",
            "date": "2007-06-20T16:45:45.460+0000",
            "id": 6
        },
        {
            "author": "Christoph Kiehl",
            "body": "I tried building a test case, but you need a fairly large index to really see the benefitsof my patch. In our production environment the workspace index is 500MB in size and the jcr:system index is about 1200MB (and both of course still growing). With indexes as big as that the effect of the operation systems file system cache is not as big as in small test cases. In my small test case the performance with my patch was a bit worse for repeating queries on an unchanged repository.\nI think we should provide a little tool that takes the wikipedia content an puts it all into a test repository which could then be used for such test cases. What do you think?",
            "date": "2007-06-20T16:54:04.841+0000",
            "id": 7
        },
        {
            "author": "Marcel Reutegger",
            "body": "Thanks a lot for the revised patch. I was just going to write some comments about your previous version and now most of my concerns are already addressed ;)\n\nOne of the concerns I had was regarding lazy loading, because it would have required synchronization on the map (which was missing in the previous patch).\n\nI'm using a fairly simple test case to measure performance. It involves creating 200'000 nodes with a LONG property set to distinct values and then executing the following query:\n\nstuff//*[@foo] order by @foo\n\nOn average the execution time with the current codebase is 2200ms, with your initial patch: 265ms and with the latest patch: 235ms.\n\nCan you please make sure you consistently use space characters instead of tabs in the source code? Thanks.\n\nNow, there's just one thing left. You introduced a cache for the ReadOnlyIndexReaders in AbstractIndex. I'd rather not want to have a cache there because it means that we have to maintain it. In your patch the map is cleaned when the index is invalidated. For older index segments (the bigger ones, which resulted from index merges) this means that the map is only cleaned when the index segment is closed (when it is part of a merge or on shutdown). IMO this is somewhat of a memory leak and should be changed.\n\nI would rather have these three lines at the beginning of the method SharedFieldCache.getStringIndex():\n\n        if (reader instanceof ReadOnlyIndexReader) {\n            reader = ((ReadOnlyIndexReader) reader).getBase();\n        }\n\nIt doesn't win a price for beauty but has the same effect as the cache.\n\nWDYT?",
            "date": "2007-06-22T07:45:01.263+0000",
            "id": 8
        },
        {
            "author": "Christoph Kiehl",
            "body": "Patch3 incorporates changes as suggested. ReadOnlyIndexReaders are no longer cached in AbstractIndex. \n\nThanks for taking the time to review the patches.",
            "date": "2007-06-22T14:37:12.160+0000",
            "id": 9
        },
        {
            "author": "Marcel Reutegger",
            "body": "Committed the latest patch in revision: 550429\n\nChristoph, thanks a lot for your work.",
            "date": "2007-06-25T09:27:02.738+0000",
            "id": 10
        }
    ],
    "component": "jackrabbit-core, query",
    "description": "Jackrabbit uses an IndexSearcher which searches on a single IndexReader which is most likely to be an instance of CachingMultiReader. On every search that does sorting or range queries a FieldCache is populated and associated with this instance of a CachingMultiReader. On successive queries which operate on this CachingMultiReader you will get a tremendous speedup for queries which can reuse  those associated FieldCache instances.\nThe problem is that Jackrabbit creates a new CachingMultiReader _everytime_ one of the underlying indexes are modified. This means if you just change _one_ item in the repository you will need to rebuild all those FieldCaches because the existing FieldCaches are associated with the old instance of CachingMultiReader.\nThis does not only lead to slow search response times for queries which contains range queries or are sorted by a field but also leads to massive memory consumption (depending on the size of your indexes) because there might be multiple instances of CachingMultiReaders in use if you have a scenario where a lot of queries and item modifications are executed concurrently.\nThe goal is to keep those FieldCaches as long as possible.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "JCR-974",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "JACKRABBIT",
    "project": "JACKRABBIT",
    "summary": "Manage Lucene FieldCaches per index segment",
    "systemSpecification": true,
    "version": ""
}