{
    "comments": [
        {
            "author": "Ard Schrijvers",
            "body": "When per-document payloads and unique doc ids are implemented in lucene, we might be able to optimize the hierarchical cache, because we might base it on uid instead of the current doc id (based on uid, we might keep the hierarchical cache intact for ever, even after segment merges and pre-warming / caching will be trivial)\n\nSee dev list lucene mail about the subject:\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-java-dev/200801.mbox/%3c4795CE64.6090206@gmail.com%3e",
            "date": "2008-01-22T20:11:00.069+0000",
            "id": 0
        },
        {
            "author": "Marcel Reutegger",
            "body": "In the meantime we could also initialize the cache when the index reader is created.",
            "date": "2008-01-23T10:26:03.186+0000",
            "id": 1
        },
        {
            "author": "Marcel Reutegger",
            "body": "Proposed patch.",
            "date": "2008-01-23T10:28:17.076+0000",
            "id": 2
        },
        {
            "author": "Ard Schrijvers",
            "body": "That is a quick you patch have there :-) \n\nLooks like a useful optimization, i only have concerns in its current form:\n\nIIUC, merging of 2 indexes also introduces a new CachingIndexReader: if the new formed index is *large*, initializeParents(delegatee) might consume a lot of time and cpu. Therefor a background thread (with low priority) might be better, or would this again impose synchronization problems perhaps?\n\nAlso, since this patch is only pre-warming newly created CachingIndexReaders, and initializes its parents, it does still imply slow uncached queries when 2 large indexes merge and create a new CachingIndexReaders. These two indexes might contains *many parents* of lucene docs residing in other segments, which obviously are not re-warmed (strange non-existing word, but hopefully clear :-) ), so still having not the hierarchical cache up2date.\n\nThink this patch is an improvement, but does not cover the entire pre-warming issue and might lead to hickups for large index merges. \n\nPerhaps a nonstop background thread with low priority from time to time updating the hierarchical cache would be more efficient. OTOH, with low priority threads we are pretty much jvm dependant on how they are handled, isn't? \n\nWDYT?",
            "date": "2008-01-23T10:43:48.802+0000",
            "id": 3
        },
        {
            "author": "Marcel Reutegger",
            "body": "I already had those changes in my checkout ;)\n\nPopulating the cache is quite fast. On my machine I'm able to initialize the cache at a rate of 180k nodes a second. But you are right the tough work still is to resolve DocIds that point to other segments. I'd argue that those DocIds are only a fraction, unless you have an application that heavily modifies existing content.",
            "date": "2008-01-23T13:17:52.061+0000",
            "id": 4
        },
        {
            "author": "Marcel Reutegger",
            "body": "I've added logging information to the CachingIndexReader, which now write the percentage of UUIDDocIds.",
            "date": "2008-01-23T13:19:36.587+0000",
            "id": 5
        },
        {
            "author": "Ard Schrijvers",
            "body": "180k  nodes a sec is really fast, but might also be in your test setup where the parent ids are not scattered around over many different indexes. It might get quite a bit slower then isn't?  Even if  2 large indexes merge, the amount of time needed for pre-warming is small compared to the time taken for merging I suppose? \n\n> I've added logging information to the CachingIndexReader, which now write the percentage of UUIDDocIds\n\nThis is nice info to monitor!\n\n\n\n",
            "date": "2008-01-23T13:32:31.789+0000",
            "id": 6
        },
        {
            "author": "Marcel Reutegger",
            "body": "Reading the parent information is independent of how the ids are distributed. The read is fast because there is no random access involved. The lucene documents can be read sequentially from disk.\n\n> ... pre-warming is small compared to the time taken for merging I suppose?\n\nyes, I think that's correct. On my machine indexes are merged at about 10k nodes per second. Though merging is completely done in the background, while initializing the cache (using the current patch) is done by the first thread that accesses the new index segment after the merge.",
            "date": "2008-01-23T13:48:56.469+0000",
            "id": 7
        },
        {
            "author": "Ard Schrijvers",
            "body": "\"Reading the parent information is independent of how the ids are distributed. The read is fast because there is no random access involved. The lucene documents can be read sequentially from disk. \"\n\nBut if the number of foreignParents becomes larger (through many node updates for example) then looking up parent information and thus pre-warming becomes slower, or am i missing something? If\n\n else if (info.parent != null) {\n               foreignParents++;\n               parents[info.docId] = DocId.create(info.parent);\n           } \n\nneeds to be executed more often I suppose the initializeParents becomes slower. Either I am missing something or my previous comment was unclear.\n\n\"On my machine indexes are merged at about 10k nodes per second. Though merging is completely done in the background, while initializing the cache (using the current patch) is done by the first thread that accesses the new index segment after the merge.\" \n\nMight background pre-warming be an option? ",
            "date": "2008-01-23T13:59:01.565+0000",
            "id": 8
        },
        {
            "author": "Marcel Reutegger",
            "body": "> But if the number of foreignParents becomes larger (through many node updates for example) then looking up parent\n> information and thus pre-warming becomes slower, or am i missing something?\n\nthe only difference between DocId.create(String) and DocId.create(int) is parsing the uuid string. I'm not sure how significant that is. It is certainly slower than the int variant, but it's much less called.",
            "date": "2008-01-23T14:44:29.081+0000",
            "id": 9
        },
        {
            "author": "Marcel Reutegger",
            "body": "> Might background pre-warming be an option?\n\nDone. The index merger thread forces initialization of the CachingIndexReader before the index segments are replaced.",
            "date": "2008-01-23T14:57:53.745+0000",
            "id": 10
        },
        {
            "author": "Ard Schrijvers",
            "body": ">the only difference between DocId.create(String) and DocId.create(int) is parsing the uuid string. I'm not sure how significant that is. It is certainly >slower than the int variant, but it's much less called.\n\nOoow, that is certainly not what i meant (i am certainly not pushing on the difference between parsing a uuid string and just an int!! ): I thought that for building the hierarchy cache in your pre-warming the getDocumentNumber(MultiIndexReader reader) in DocId.UUIDDocId was also executed. I scanned your patch and must have interpreted it incorrectly (also because I assumed it would do some parts regarding looking up parents). I assumed it would call the 'expensive'  getDocumentNumber(MultiIndexReader reader).... I am a little puzzled ATM how it works, and what is pre-warmed. I just need to test your patch because I am clearly off track. Disregard my remarks, I'll try to find some time to take a better look. Sry for any confusion",
            "date": "2008-01-23T14:58:42.427+0000",
            "id": 11
        },
        {
            "author": "Ard Schrijvers",
            "body": ">Done. The index merger thread forces initialization of the CachingIndexReader before the index segments are replaced.\n\nhaving a hard time keep up with you :-)  I'll try your patch tomorrow evening. Curious about the statistics, I'll keep yo posted\n\n\n",
            "date": "2008-01-23T15:03:53.112+0000",
            "id": 12
        },
        {
            "author": "Marcel Reutegger",
            "body": "I'm sorry, that's probably my fault. I didn't describe the patch well enough.\n\nThe UUIDDocIds are not resolved when the cache is filled. The pre-warming is limited to creating the DocId instances. Because most DocIds are PlainDocIds, which do not need to be resolved, the pre-warming is quite effective IMO.",
            "date": "2008-01-25T09:05:28.044+0000",
            "id": 13
        },
        {
            "author": "Ard Schrijvers",
            "body": "\"Because most DocIds are PlainDocIds, which do not need to be resolved, the pre-warming is quite effective IMO\"\n\nYes I already figured this out. It is indeed effective as long as the indexes have not very many deleted/updated nodes (when the number of parent nodes in foreign segment grows).  I agree this is an easy first iteration optimization. Also, when the number of foreign parent might get very high, users good choose to recreate the index by deleting it (if it is an option ofcourse :-) )\n\nI think that when Lucene would have support for uid in the future, we might also be able to pre-warm the parents when they are in different indexes. \n\n+1 for your patch (though i have not yet had time to test performance gain. Still try to find some time for it soon)",
            "date": "2008-01-25T09:13:54.276+0000",
            "id": 14
        },
        {
            "author": "Marcel Reutegger",
            "body": "Applied most recent patch in revision: 615223.\n\nArd, are you OK with setting this issue to fixed? I think once there are more features available in lucene we can create new jira issue.",
            "date": "2008-01-25T13:46:54.852+0000",
            "id": 15
        },
        {
            "author": "Ard Schrijvers",
            "body": "I am ok with it. Not sure either when and how exactly Lucene will add the uid feature. If it makes it to a release,  we can indeed create an issue to make advantage of it\n\nDo you close the issue? ",
            "date": "2008-01-25T14:10:01.265+0000",
            "id": 16
        },
        {
            "author": "Marcel Reutegger",
            "body": "Forgot to commit new class FieldSelectors. Done in revision: 615227.",
            "date": "2008-01-25T14:13:31.572+0000",
            "id": 17
        },
        {
            "author": "Marcel Reutegger",
            "body": "Merged into 1.4 branch together with changes from JCR-1884 in revision: 748135",
            "date": "2009-02-26T13:19:24.567+0000",
            "id": 18
        }
    ],
    "component": "query",
    "description": "The first execution of a query involving DescendantSelfAxisWeight/ChildAxisQuery is slow. Consecutive queries are faster because the hierarchy is cached",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "JCR-1337",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "JACKRABBIT",
    "project": "JACKRABBIT",
    "summary": "Optimize first execution queries for DescendantSelfAxisWeight/ChildAxisQuery",
    "systemSpecification": true,
    "version": "1.4"
}