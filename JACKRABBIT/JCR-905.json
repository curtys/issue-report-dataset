{
    "comments": [
        {
            "author": "Martijn Hendriks",
            "body": "I think that the issue is caused by the fact that a Document for the node is created in two different indices as a result of the pause in scenario 2. Consider the attached log snippets. log1.txt shows scenario 1: everything is written to the volatile index. log2.txt shows what happens after a pause of a few seconds: the volatile index with the entry for node A (that has been generated by the index initialization) is written to disk, after which another Document containing node A is added to a new volatile index (as a result of an event that is generated by the cluster synchronization).\n\n(Please note that I added a custom debug statement to MultiIndex$AddNode).",
            "date": "2007-05-09T14:42:00.493+0000",
            "id": 0
        },
        {
            "author": "Martijn Hendriks",
            "body": "We've found a one-line fix for this issue. The problem is that when the search index receives an event to add a node to the index, it does not take consider the persistent indices. The one-line fix is to first remove the node from the multi-index before adding it again: see attached patch.\n",
            "date": "2007-05-23T13:56:57.672+0000",
            "id": 1
        },
        {
            "author": "Jukka Zitting",
            "body": "Dominique/Marcel, do you see any potential regressions with this patch? I'm not confident enough to apply it in 1.3.1, but it sounds like it definitely should go in trunk before 1.4.",
            "date": "2007-07-09T13:20:38.351+0000",
            "id": 2
        },
        {
            "author": "Marcel Reutegger",
            "body": "This patch adds considerable overhead to the index process because for each added node the index has to first check if the node already exists. In lucene terms this means that lots of index readers and index writers are created and destroyed in a short period of time. The current code relies on the fact that the events passed to the query handler reflect a correct state change on the workspace. E.g. if an event says that a node is added, the index assumes that the node does not exist in the index.\n\nI see two ways to fix this issue:\n\n- The query handler does not automatically re-index the workspace, but rather re-plays the cluster-journal to get a valid index.\n- The query handler needs to associate a journal revision with the current index state. When journal events are processed the query handler will ignore events from the 'past'.\n\nI prefer option 2.",
            "date": "2007-07-10T11:56:53.345+0000",
            "id": 3
        },
        {
            "author": "Martijn Hendriks",
            "body": "I already suspected that the proposed patch would give a significant overhead... Option 2 sounds elegant, but bootstrapping it looks non-trivial to me since the repository and the global revision can change during the re-indexing.",
            "date": "2007-07-11T09:10:36.201+0000",
            "id": 4
        },
        {
            "author": "Marcel Reutegger",
            "body": "Here's an alternative patch, which handles the possible duplicates earlier in the index process, where it is also possible to detect an external update. This avoids the overhead for Jackrabbit instance, which does not operate in a cluster.\n\nCan someone with a cluster installation please test the patch and give feedback. I'll then commit the patch if it fixes the issue.",
            "date": "2007-09-11T10:10:25.468+0000",
            "id": 5
        },
        {
            "author": "Martijn Hendriks",
            "body": "I just tested Marcel's patch and it works fine. It's good to eliminate the overhead for non-clustered installations!\n\nBest wishes,\n\nMartijn",
            "date": "2007-09-17T12:38:25.077+0000",
            "id": 6
        },
        {
            "author": "Marcel Reutegger",
            "body": "Applied patch in revision: 576813\n\nThank you all for testing.",
            "date": "2007-09-18T10:04:43.604+0000",
            "id": 7
        },
        {
            "author": "Jukka Zitting",
            "body": "Merged to the 1.3 branch in revision 577835.",
            "date": "2007-09-20T17:51:48.399+0000",
            "id": 8
        }
    ],
    "component": "clustering",
    "description": "There seems to be a race condition that may cause duplicate search index entries. It is reproducible as follows (Jackrabbit 1.3):\n1) Start clusternode 1 that just adds a single node of node type clustering:test.\n2) Shutdown clusternode 1.\n3) Start clusternode 2 with an empty search index.\n4) Execute the query  //element(*, clustering:test).\n4) Print the result of the query (UUIDs of nodes in the result set).\n\nWhen I just run clusternode 2, then there is one node in the resultset, as expected. However, when I debug clusternode 2 and have a breakpoint (i.e., a pause of a few seconds at line 306 of RepositoryImpl.java - just before the clusternode is started), then the resultset contains two results, both with the same UUID.\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "JCR-905",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "JACKRABBIT",
    "project": "JACKRABBIT",
    "summary": "Clustering: race condition may cause duplicate entries in search index",
    "systemSpecification": true,
    "version": "1.2.1, 1.2.2, 1.2.3, 1.3, 1.3.1"
}