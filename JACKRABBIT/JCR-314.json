{
    "comments": [
        {
            "author": "Michael Neale",
            "body": "anyone for escalating this above a \"minor\" - its kind of a showstopper for some people ?",
            "date": "2007-03-11T05:51:29.875+0000",
            "id": 0
        },
        {
            "author": "Stefan Guggisberg",
            "body": "i agree with michael neale's judgement \n(http://www.mail-archive.com/users@jackrabbit.apache.org/msg02503.html),\nchanging priority to major.",
            "date": "2007-03-11T10:17:51.301+0000",
            "id": 1
        },
        {
            "author": "Oliver Zeigermann",
            "body": "Any idea how this could be achieved?\n\nIf you use blocking locks, it is very hard to avoid deadlocks. Of course you can use an ordered sequence of locks for all requests to avoid deadlocks, but that would mean you need a list of all resources to be locked before you even start doing anything. \n\nAfter my experience with the Slide server I can only recommend non blocking locks. Such locks would make a request fail if it is not able to acquire all locks necessay instead of letting it wait. This would require a notion of a transaction, however.",
            "date": "2007-04-14T22:02:28.113+0000",
            "id": 2
        },
        {
            "author": "Marcel Reutegger",
            "body": "To drive this issue forward I created a patch that replaces the current rather hard coded use of a ReadWriteLock in SharedItemStateManager with an abstraction layer that allows alternative implementations.\n\nThe way locking currently works is implemented in DefaultISMLocking and an initial implementation of a more fine grained locking is available in FineGrainedISMLocking.\n\nFineGrainedISMLocking does not allow concurrent writes but at least allows reads while a long running write takes place and the read does not conflict with the write. I think this is the most common use case (save a big file but still allow other sessions to read, which is currently not possible).\n\nAll tests pass with both the DefaultISMLocking and the FineGrainedISMLocking.\n\nThe first patch only includes the structural changes moving away from the hard coded ReadWriteLock in the SharedItemStateManager to the ISMLocking interface. It does not change the locking semantics that are currently in place. The second patch is the proposal for a more fine grained locking strategy.\n\nComments are welcome.",
            "date": "2007-05-03T12:59:28.107+0000",
            "id": 3
        },
        {
            "author": "Oliver Zeigermann",
            "body": "As far as I can tell the FineGrainedISMLocking  implementation is prone to deadlocks. At least when a DB is used as storage. Such a deadlock can occur distributed between DB and the Jackrabbit locking. The DB can not resolve the deadlock, as internally it looks like there is none. A transaction timeout in the DB is the only way to resolve such a situation. \n\nIn any case there should be a timeout for Jackrabbit locks. For one to to free locks that have never been freed, because some thread forgot to free them. Additionally, to make sure deadlocks between Jackrabbit and DB can be resolved quickly.\n",
            "date": "2007-05-03T13:50:35.951+0000",
            "id": 4
        },
        {
            "author": "Marcel Reutegger",
            "body": "Oliver, thank you for your comment. However I do not see how a deadlock may occur between jackrabbit and the DB used in a persistence manager. Deadlocks always require that locks are acquired in a circular way. That's never the case between Jackrabbit and the DB. A call that returns from the DB will always have released all DB locks. \n\nI'd appreciate if you were a bit more specific, e.g. provide a wait-for graph that shows a deadlock situation.\n\n> In any case there should be a timeout for Jackrabbit locks. For one to to free locks that have\n> never been freed, because some thread forgot to free them.\n\nI disagree. This would clearly be a bug in Jackrabbit and should rather be fixed than worked around with timeouts.",
            "date": "2007-05-04T08:01:51.208+0000",
            "id": 5
        },
        {
            "author": "Jukka Zitting",
            "body": "I briefly reviewed the patches, good work! I like how you've applied the strategy pattern.\n\nMy main concern is that this still doesn't address the concurrency limitations in the current persistence managers. Should that be handled as a separate issue? A more general issue is that this whole ISM core keeps getting more complex, and adding 1+2 new interfaces and all the implementing classes doesn't really help things. I'm not sure what to do about that...\n\nAlso, it would be nice if we had at least a few parallel test cases for excercising such code.",
            "date": "2007-05-14T18:01:04.815+0000",
            "id": 6
        },
        {
            "author": "Marcel Reutegger",
            "body": "Jukka, thanks for your comments.\n\n> My main concern is that this still doesn't address the concurrency limitations in the current\n> persistence managers.\n\nYou are right, the proposed changes will not solve the concurrency limitations completely, but at least they should improve the current situation where no reads are possible through the SISM when a write is taking place. I think truely fine grained locking will not be possible with the current design and thus would require major re-structuring in the jackrabbit core. Something I'd rather like to postpone for a 2.0.\n\n> [...] limitations in the current persistence managers. Should that be handled as a separate issue?\n\nThere are a number of other issues that are related. Even if persistence managers are able to perform concurrent writes, the index will have to support that too otherwise concurrent writes in the PM will be of limited use. And then there's the question how to process (synchronous) events for concurrent writes?\n\n> A more general issue is that this whole ISM core keeps getting more complex, and adding 1+2\n> new interfaces and all the implementing classes doesn't really help things.\n\nI actually didn't want to make it more complex but rather easier to understand. I think the interfaces are of some value because they describe the locking contract independant of the implementation. They also allow to easily try out a different locking implementation / strategy.\n\n> I'm not sure what to do about that...\n\nI'm also not 100% happy with the proposed changes, but at least it solves the most annoying problem with the SISM, that it locks up completely during a large write.\n\nI see the following options:\n- We don't change anything right now and do it better the next time (NGP, jackrabbit 2.0, ...)\n- Redesign the core now to better handle concurrency\n- Accept the patch ISMLocking.patch and discuss a locking implementation/strategy that's better suited than the current one.\n\nI'm obviously in favour of the last option ;) because it gives us the most bang for the buck and is by far less risky than option two.\n\n> Also, it would be nice if we had at least a few parallel test cases for excercising such code.\n\nI agree. I already created some test cases that perform concurrent versioning operations and basic content modifications. So if anyone is interested, feel free to write more of them. The class AbstractConcurrencyTest and its sub classes are a good starting point.",
            "date": "2007-05-15T07:57:40.080+0000",
            "id": 7
        },
        {
            "author": "Jukka Zitting",
            "body": "> I'm obviously in favour of the last option ;) because it gives us the most bang for the buck and is by far less risky than option two.\n\nAgreed.\n\nNote that without solving the concurrency issues in persistence managers (both db and bundle) we're still stuck with fully serialized backend access. But this is one step in the correct direction; the second step would be to start removing the synchronization on the persistence managers.\n",
            "date": "2007-05-15T08:29:36.289+0000",
            "id": 8
        },
        {
            "author": "Stefan Guggisberg",
            "body": "> - Accept the patch ISMLocking.patch and discuss a locking implementation/strategy that's better suited than the current one.\n\n+1\n\nbtw, i did a couple of test runs using ConcurrentReadWriteTest against\n a) current trunk\n b) a) with ISMLocking.patch applied (using DefaultISMLocking)\n c) b) with FineGrainedISMLocking.patch applied (using FineGrainedISMLocking)\n\nenvironment: macbook pro (intel, 2ghz), os-x 10.4.9, jre 1.4.2\n\nresults: \n\na)\n**\n   ~2'300 #writes\n   ~2'300'000 #reads\n\nb)\n**\n   ~2'300 #writes\n   ~2'300'000 #reads\n\nc)\n**\n   ~1'700 #writes\n   ~2'300'000 #reads\n\n=> c) shows a significant decrease in #writes while #reads doesn't seem\nto be affected. i guess that FineGrainedISMLocking still has room for \nimprovement ;)\n\n\n",
            "date": "2007-05-16T14:41:25.239+0000",
            "id": 9
        },
        {
            "author": "Marcel Reutegger",
            "body": "Here's a new version of FineGrainedISMLocking.\n\nThe performance should be better compared to the last version.\n\nI'm not sure the test case is very representative though. Lot of monitor contention happens between the write thread and readers when item states are notified and the cache maps need to be accessed. I think finer grained locking makes this situation even worse because it allows more concurrency on the caches.",
            "date": "2007-05-23T11:02:00.463+0000",
            "id": 10
        },
        {
            "author": "Marcel Reutegger",
            "body": "Applied the patches ISMLocking.patch and FineGrainedISMLocking-v2.patch with one slight change: the SISM used the default implementation for now.\n\nCommitted in revision: 540944\n\nThere are some remaining issues before we can use FineGrainedISMLocking:\n\n- using FineGrainedISMLocking allows for concurrent access to item state caches, which were not possible before. We must ensure that all item state caches are prepared for that.\n- do extensive testing\n- we should check again if the performance is ok",
            "date": "2007-05-23T13:22:30.564+0000",
            "id": 11
        },
        {
            "author": "Marcel Reutegger",
            "body": "The chart shows the writes per second of the writer thread using the\nConcurrentReadWriteTest for DefaultISMLocking and FineGrainedISMLocking.\nThe duration of the test is 120 seconds.",
            "date": "2007-05-23T13:25:09.015+0000",
            "id": 12
        },
        {
            "author": "Jukka Zitting",
            "body": "It seems that saving a single large binary property still (revision 549230) completely blocks read access to other nodes. See my last comment on JCR-926 for more details.",
            "date": "2007-06-20T21:18:10.900+0000",
            "id": 13
        },
        {
            "author": "Jukka Zitting",
            "body": "Forget my last comment, the svn trunk still has DefaultISMLocking as the default.",
            "date": "2007-06-21T08:52:21.293+0000",
            "id": 14
        },
        {
            "author": "Pablo Rios",
            "body": "It seems that during the time a versioning operation is in progress (writer) it is not possible to establish a new session to the repository. This seems to be so because access to the root node of the version histories (/jcr:system/jcr:versionStorage) is required to create a session and this node is included on the active writer changelog. In other words the reader need to access an item (root node of the version storage) that has a dependency on the active writer changelog.\n\nFrom XAVersionManager constructor\n\n        try {\n            state = (NodeState) stateMgr.getItemState(vMgr.getHistoryRootId());\n        } catch (ItemStateException e) {\n            ...\n        }\n\n(An XAVersionManager is instantiated during the instantiation of an XASessionImpl)\n\nNote: I've observed this in an XA environment.\n\nAm I wrong or right ?\n\nWhat may be the consequences of allowing a reader to get a read lock in this situation even if the writer's changelog includes the VERSION_STORAGE_NODE_ID ?\n",
            "date": "2007-09-05T15:46:00.631+0000",
            "id": 15
        },
        {
            "author": "Marcel Reutegger",
            "body": "> What may be the consequences of allowing a reader to get a read lock in this situation even if the writer's changelog includes\n> the VERSION_STORAGE_NODE_ID ?\n\nThat's probably a bad idea. It may happen that a reader sees inconsistent data.\n\nBut anyway, I think a versioning operation will modify only the version storage root node in rare cases. Merely when the version storage is nearly empty. As soon as there are enough versions created the version storage root node has all possible child nodes (named 00, 01, ... ff) and is not modified anymore.",
            "date": "2007-09-14T08:57:49.366+0000",
            "id": 16
        },
        {
            "author": "Thomas Mueller",
            "body": "From http://www.mail-archive.com/users@jackrabbit.apache.org/msg02503.html\n> for people wanting to store large blobs (something that people would look at using JCR for) - this is a showstopper.\n\nIf reading/writing large objects blocks others, it is showstopper.\nBut Data Store should solve this: http://issues.apache.org/jira/browse/JCR-926\nIs it still a problem? \n\nAre there other concurrency problems?\n",
            "date": "2007-09-14T09:18:34.490+0000",
            "id": 17
        },
        {
            "author": "Esteban Franqueiro",
            "body": "This patch adds a lockingStrategy attribute to the Workspace and Versioning element tags. It's possible values are default, fine, and fine+ (this one was a POC we did here).",
            "date": "2007-12-11T14:28:35.312+0000",
            "id": 18
        },
        {
            "author": "Marcel Reutegger",
            "body": "Esteban, thank you for your patch. I've modified it slightly and used a separate configuration element with a class attribute. I didn't include your changes to the FineGrainedISMLocking because I think they may lead to inconsistencies. As described easier in this issue, once the version storage in sufficiently populated, the login will not block anymore when a version operation is in progress.\n\nI have also added a new version of the DTD (1.4) and updated all repository.xml files I found in the sources. Once the changes are committed I will add the DTD to the website.\n\nPlease note that this change is backward compatible. The ISMLocking element is optional and defaults to DefaultISMLocking (the currently hard coded implementation).",
            "date": "2007-12-17T11:21:51.014+0000",
            "id": 19
        },
        {
            "author": "Marcel Reutegger",
            "body": "Committed ConfigurableISMLocking.patch in revision: 605173\n\nPlease note that there are still some open synchronization issues when using FineGrainedISMLocking!",
            "date": "2007-12-18T10:42:53.408+0000",
            "id": 20
        }
    ],
    "component": "jackrabbit-core",
    "description": "The SharedItemStateManager (SISM) currently uses a simple read-write lock to ensure data consistency. Store operations to the PersistenceManager (PM) are effectively serialized.\n\nWe should think about more sophisticated locking to allow concurrent writes on the PM.\n\nOne possible approach:\n\nIf a transaction is currently storing data in a PM a second transaction may check if the set of changes does not intersect with the first transaction. If that is the case it can safely store its data in the PM.\n\nThis fine grained locking must also be respected when reading from the SISM. A read request for an item that is currently being stored must be blocked until the store is finished.",
    "hasPatch": true,
    "hasScreenshot": true,
    "id": "JCR-314",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "JACKRABBIT",
    "project": "JACKRABBIT",
    "summary": "Fine grained locking in SharedItemStateManager",
    "systemSpecification": true,
    "version": "0.9, 1.0, 1.0.1, 1.1, 1.1.1, 1.2.1, 1.2.2, 1.2.3"
}