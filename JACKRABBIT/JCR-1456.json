{
    "comments": [
        {
            "author": "Esteban Franqueiro",
            "body": "Is it possible to have, in those areas, the same problem reported in JCR-1388?\nThe idea is to use a pool package or to build our own?",
            "date": "2008-03-05T18:38:51.979+0000",
            "id": 0
        },
        {
            "author": "Jukka Zitting",
            "body": "> Is it possible to have, in those areas, the same problem reported in JCR-1388?\n\nConnection pools would nicely solve most of our concurrent access issues, as we wouldn't be constrained to a single connection by default and wouldn't need workarounds like the one in JCR-1388.\n\n> The idea is to use a pool package or to build our own?\n\nI'd leverage a pooling DataSource whenever available (JNDI configuration), and use commons-dbcp to pool explicitly configured connections (JDBC Driver configuration).",
            "date": "2008-03-06T08:47:35.227+0000",
            "id": 1
        },
        {
            "author": "Matej Knopp",
            "body": "Any update on this? Is there any estimation or is there a patch expected? :)",
            "date": "2008-07-14T22:03:23.626+0000",
            "id": 2
        },
        {
            "author": "Matej Knopp",
            "body": "Proof of concept patch. \n\n* Abstracts database connection creation to allow pluggable pooling implementation. \n* Not thoroughly tested and also not checked against checkstyle.\n* So far it only covers BundleDbPersistenceManager and it's subclasses. All other components (db journal, db filesystem still use ConnectionRecoveryManager).",
            "date": "2008-07-21T23:19:58.552+0000",
            "id": 3
        },
        {
            "author": "Stefan Guggisberg",
            "body": "thanks for the patch, matej. that's very much appreciated.\n\ni quickly browsed through the diff and noticed the following issue:\n\nit seems like a connection is retrieved from the pool in every \nPersistenceManager method. that's probably fine for \nreading methods but that's not gonna work for writing methods\nsince they need to use the same connection (i.e. transaction).\nall method calls within the store(ChangeLog) scope need\nto use the same connection (with autoCommit set to false),\notherwise you'll end up with inconsistent/brokem repositories.\n\ni am also a bit concerned about the impact of the proposed change\nsince it touches a lot of current code. the patch would have to be\nthoroughly tested with all currently supported backends...\n\n\n",
            "date": "2008-07-23T12:43:13.645+0000",
            "id": 4
        },
        {
            "author": "Matej Knopp",
            "body": "Hi,\n\nThanks a lot for the comment. You're right, there might be a problem with different connections obtained. This could be handled by attaching active connection to current thread, so that the nested calls would always obtain the active connection. Anyway, I will look into it and post a new patch.\n\nI agree that this is a substantial change and will require lot of testing. But i think at some point it will be necessary to bite the bullet and implement connection pooling, whether it will be based on my patch or not. The current situation is rather problematic, keeping opened connection per workspace doesn't scale well at all.",
            "date": "2008-07-23T14:36:44.555+0000",
            "id": 5
        },
        {
            "author": "Matej Knopp",
            "body": "Added ConnectionPooling for DatabaseFileSystem and DbDataStore. \nDatabase connections are thread bound if necessary.\nChecked again checkstyle.\nNot thoroughly tested.",
            "date": "2008-08-10T16:56:25.110+0000",
            "id": 6
        },
        {
            "author": "Thomas Mueller",
            "body": "What about doing that for DbDataStore first? The patch would be much smaller.\n\n> attaching active connection to current thread, so that the nested calls would always obtain the active connection\n\nThat sounds too complicated, too tricky, and too slow for me. For store(ChangeLog), why not simply pass the connection object to the nested calls?\n\n> require lot of testing\n\nJust to make sure: You mean automated tests, right? Manual tests is a maintenance problem.\n",
            "date": "2008-08-18T17:57:24.365+0000",
            "id": 7
        },
        {
            "author": "Matej Knopp",
            "body": "> What about doing that for DbDataStore first? The patch would be much smaller. \n\nWell, the file system is also instantiated per workspace so I believe connection pooling makes sense there. But it can be excluded from the patch, that shouldn't be a big issue.\nSame goes for DataStore. But while you can live without Db file system, DbDateStore is more or less necessary for clustered environments and the lack of connection pooling can be a serious issue there.\n\n> That sounds too complicated, too tricky, and too slow for me. For store(ChangeLog), why not simply pass the connection object to the nested calls? \n\nBecause the nested calls are invoked from BundleDbPersistenceManager which doesn't know about database connection. \n \nIt's really not complicated at all. There is one class (ThreadLocalConnectionProviderAdapter) that makes sure that getConnection() returns same connection for \"nested\" calls. \nAlso, could you please be more specific about what exactly sounds too slow about this?\n\n> Just to make sure: You mean automated tests, right? Manual tests is a maintenance problem. \nWell, all unit tests that work with \"vanilla\" jackrabbit also work after the patch is applied. However the patch hasn't been heavily tested in \"real world\" environment or with different database backends.",
            "date": "2008-08-18T20:33:07.672+0000",
            "id": 8
        },
        {
            "author": "Matej Knopp",
            "body": "Patch for current trunk (rev 672286)",
            "date": "2008-08-26T19:28:24.137+0000",
            "id": 9
        },
        {
            "author": "Thomas Mueller",
            "body": "Thanks for the patch!\n\n> It's really not complicated at all. There is one class (ThreadLocalConnectionProviderAdapter...\n\nThis class does look complicated to me. To avoid ThreadLocal, what about:\n\nBundleDbPersistenceManager {\n  Connection currentConnection\n  synchronized store(..) {\n    try {\n       currentConnection = ...\n       super.store(..)\n    } finally {\n       currentConnection = null\n    }\n  }\n\n> the patch hasn't been heavily tested in \"real world\" \n\nI have already said, manual tests and real world tests are a maintenance problem. If there is no automated test, each change is big risk. Maintaining and improving the code is very hard in this case.\n\n",
            "date": "2008-08-28T00:08:56.756+0000",
            "id": 10
        },
        {
            "author": "Dave Brosius",
            "body": "I like the idea of this patch, but i think the ConnectionProperties is too specific. It should just be\n\n\nprivate String url;\nprivate String driver;\nprivate Properties connectionProperties.\n\nfor instance, i would like to add\n\nproperties.put(\"oracle.net.ssl_cipher_suites\", \"(SSL_DH_anon_WITH_3DES_EDE_CBC_SHA, SSL_DH_anon_WITH_RC4_128_MD5, SSL_DH_anon_WITH_DES_CBC_SHA)\";\n\nso that i can connect to the jackrabbit database over SSL.\n\nAnd of course a similar implication for the repository.xml, to include arbitrary connection properties.",
            "date": "2008-09-02T17:19:09.860+0000",
            "id": 11
        },
        {
            "author": "Thomas Mueller",
            "body": "Hi Dave,\n\nThe connection properties you described are unrelated to \"Database connection pooling\", right?\nIf yes then I suggest to open another issue.\n\nRegards,\nThomas",
            "date": "2008-09-09T08:55:02.784+0000",
            "id": 12
        },
        {
            "author": "Jukka Zitting",
            "body": "Let's postpone this to 1.6.",
            "date": "2008-10-12T21:58:46.810+0000",
            "id": 13
        },
        {
            "author": "Sunil D",
            "body": "Just wanted to ask what the status of this ticket is. I see it's unassigned and there's no fix version right now; is it still planned for 1.6?",
            "date": "2009-03-04T05:46:58.262+0000",
            "id": 14
        },
        {
            "author": "Jukka Zitting",
            "body": "As far as I know, nobody is actively working on this. We'll include this in 1.6 if someone comes up with a patch that everyone agrees on by that time.",
            "date": "2009-03-05T09:12:13.068+0000",
            "id": 15
        },
        {
            "author": "Brian Topping",
            "body": "There's been two separate revisions of the original patch and it was never applied.  What guarantee does the community or a contributor have that this patch would be applied if it were reworked to be current?",
            "date": "2009-04-15T18:14:42.916+0000",
            "id": 16
        },
        {
            "author": "Matej Knopp",
            "body": "What are the requirements for the patch? I'm willing to provide one against current trunk but I have to know upfront what's expected of it so that it doesn't end like the previous attempt.",
            "date": "2009-05-14T18:03:56.082+0000",
            "id": 17
        },
        {
            "author": "Jukka Zitting",
            "body": "I think the main concerns raised above are:\n\n* The entire store(ChangeLog) operation needs to happen atomically\n\n* Using ThreadLocal for the connection seems unnecessarily complex (from the perspective of someone new trying to understand the code), it's better to pass the connection around as a method argument or encapsulate it as a member variable of an object that performs the database operations\n\nI also have some extra concerns:\n\n* Could you implement this without introducing new configuration entries? We may consider adding that later, but it would be clearer if we first implemented connection pooling with the access configuration that we currently have.\n\n* We should leverage something like Commons DBCP instead of implementing our own connection pooling logic. Commons DBCP is much better than anything that we could come up with.\n\n* Related to the above, we should use the standard DataSource interface interface instead of a custom ConnectionManager class. This would nicely abstract away all the pooling logic and make the code much more familiar to people who already know JDBC. All top-level methods would look like something like this:\n\n    public void doSomething() throws SQLException {\n        Connection connection = dataSource.getConnection();\n        try {\n            // do something with the connection\n        } finally {\n            connection.close();\n        }\n    }\n\nThe above are of course just individual opinions. Feel free to argue otherwise if you have a better solution.\n\nPS. The Jackrabbit sandbox is nowadays open to all Apache committers, so if you may want to create a development branch of Jackrabbit trunk (or the 1.x branch) in the sandbox for this work. The changes here are so extensive that it may be easier for us to work incrementally through svn.\n\nPPS. Alternatively, if you know Git, you may want to clone git://git.apache.org/jackrabbit.git and publish your changes for example on Github.\n\n",
            "date": "2009-05-14T18:34:21.813+0000",
            "id": 18
        },
        {
            "author": "Matej Knopp",
            "body": ">Using ThreadLocal for the connection seems unnecessarily complex (from the perspective of someone new trying to understand the code), it's better to pass the connection around as a method argument or encapsulate it as a member variable of an object that performs the database operations \n\nThe problem here is that BundleDbPersistenceManager superclass is connection agnostic so passing the database connection as argument doesn't seem to be an option. Storing that as member variable is, but it requires additional locking. To reduce unnecessary locking I decided to use thread locals. Since it's perceived to be too complicated there won't be any in next patch.\n\n> Could you implement this without introducing new configuration entries? We may consider adding that later, but it would be clearer if we first implemented connection pooling with the access configuration that we currently have. \n\nAs far as I can remember all introduced configuration entities were completely optional with sane default making the change pretty much transparent for user.\n\n> We should leverage something like Commons DBCP instead of implementing our own connection pooling logic. Commons DBCP is much better than anything that we could come up with. \n\nWhat's the point of hardwiring concrete connection pool? In my previous patch I didn't attempt to do any connection pooling. I just had a connection source which could be easily implemented to get the connection from *any* connection pool or JNDI. If you insist though on using commons dbcp I can live with that though.\n\n> Related to the above, we should use the standard DataSource interface interface instead of a custom ConnectionManager class. This would nicely abstract away all the pooling logic and make the code much more familiar to people who already know JDBC. All top-level methods would look like something like this\n\nThe connection manager in patch didn't create database connections. It delegated that to a connection provider. The purpose of ConnectionManager were some convenience methods and prepared statements caching. The connection provider was simple DataSource like interface. The reason why I chose not to use DataSource is because DataSource has no means to pass connection properties (url, driver, etc). That normally isn't a problem, in jackrabbit however it is, because the database properties are specified on components level (persistence manager, file system, journal, etc). \n\nIf PersistenceManager is supposed to have connection properties (which you seem to insist on in order not to change configuration) then it needs a way to pass these information to code that manages database connections. And DataSource doesn't provide any means for it.\n\nThe custom sandbox could work for me. \n\nThanks for your input, it's very appreciated.",
            "date": "2009-05-14T19:29:40.697+0000",
            "id": 19
        },
        {
            "author": "Jukka Zitting",
            "body": "> The problem here is that BundleDbPersistenceManager superclass is connection\n> agnostic so passing the database connection as argument doesn't seem to be an option.\n\nWe can always change the superclass.\n\n> Storing that as member variable is, but it requires additional locking.\n\nNot if it's a member of an extra object that's instantiated per each top level method call.\n\n> As far as I can remember all introduced configuration entities were completely optional\n> with sane default making the change pretty much transparent for user. \n\nFor now I'm mostly worried about  the patch being more complex than it needs to be. We can add config entries once the basic functionality is in place.\n\n> What's the point of hardwiring concrete connection pool?\n\nSo we don't need to implement one. Note that the solution should work with existing Jackrabbit configurations that do not specify a connection pool. There's no need for DBCP when a JNDI DataSource is configured, but it makes things a lot easier for non-JNDI configurations.\n\n> In my previous patch I didn't attempt to do any connection pooling.\n\nWhat's SimplePoolingConnectionProvider for then?\n\n> The reason why I chose not to use DataSource is because DataSource has no means to\n> pass connection properties (url, driver, etc).\n\nThat's what we'd use Commons DBCP for (in cases when a JNDI DataSource has not already been configured).\n\n> The custom sandbox could work for me.\n\nOK, good. I created such a development branch in https://svn.apache.org/repos/asf/jackrabbit/sandbox/JCR-1456.\n\n",
            "date": "2009-05-14T20:36:34.210+0000",
            "id": 20
        },
        {
            "author": "Matej Knopp",
            "body": "> We can always change the superclass.\n\nWell, the superclass methods could pass a context object around that the subclass could use to store connection.\n\n> Not if it's a member of an extra object that's instantiated per each top level method call.\n\nYes, but then the superclass needs to pass this object as method argument. Which is probably okay.\n\n> For now I'm mostly worried about the patch being more complex than it needs to be. We can add config entries once the basic functionality is in place.\n\nThe problem here is that right now every component (persistence manager, fs, journal, ...) in jackrabbit is responsible for creating the database connection thus the connection properties are specified as configuration option for the component. But connection pooling essentially takes this responsibility from component. So how should the database properties be handled? Where should the connection pool be configured?\n\nMy previous patch solved this in way that allowed propagation of connection properties from components to connection pool and didn't require any changes to configuration files but that came at cost of readability and complexity.  Current way of configuring database connections in jackrabbit assumes the connection is created by the component but this is really not compatible with connection pools.\n\nThe cleanest solution would be to add section in configuration to define data sources and then way to assign a data source to each component that needs database connection.  This obviously requires changing the configuration scheme though.\n\nIf you have an idea how to configure connection pools and configure the components to use those pools while preserving current configuration scheme I'd love to know about it. The approach I tried worked but it resulted in code apparently too complicated to be committed.\n\nThere is one way I can imagine connection pooling working without change to configuration syntax. While parsing the configuration jackrabbit would create datasource (with default connection pool i.e. dbcp) for each distinct connection properties and then pass this datasource to the component to which the connection properties belong.\n\nThis would make the configuration parsing code bit more complicated but wouldn't require any change to configuration files.\n\n> So we don't need to implement one. Note that the solution should work with existing Jackrabbit configurations that do not specify a connection pool. There's no need for DBCP when a JNDI DataSource is configured, but it makes things a lot easier for non-JNDI configurations.\n\nI agree that jackrabbit should have connection pooling configured by default but that should be overridable in configuration file. \n\n> What's SimplePoolingConnectionProvider for then?\n\nThat's just a simple connection pool i used for development. It was meant to be kind of \"Default\" connection provider and the connection pooling logic should be replaced with DBCP should people have agried with the approach i taked with the patch.\n\n",
            "date": "2009-05-14T21:23:44.978+0000",
            "id": 21
        },
        {
            "author": "Jukka Zitting",
            "body": "> The problem here is that right now every component (persistence manager, fs,\n> journal, ...) in jackrabbit is responsible for creating the database connection\n> thus the connection properties are specified as configuration option for the\n> component. But connection pooling essentially takes this responsibility from\n> component. So how should the database properties be handled? Where\n> should the connection pool be configured?\n\nRight where we currently configure the single database connection per component.\n\n> If you have an idea how to configure connection pools and configure the\n> components to use those pools while preserving current configuration\n> scheme I'd love to know about it.\n\nSee the attached patch (dbcp.patch) for a simple change that makes all the connections we currently create to come from connection pools. This change obviously doesn't solve the main issue, but should illustrate how I envision us to handle existing database configurations.\n\n> There is one way I can imagine connection pooling working without change\n> to configuration syntax. While parsing the configuration jackrabbit would create\n> datasource (with default connection pool i.e. dbcp) for each distinct connection\n> properties and then pass this datasource to the component to which the\n> connection properties belong.\n\nExactly!\n",
            "date": "2009-05-15T11:15:42.715+0000",
            "id": 22
        },
        {
            "author": "Jukka Zitting",
            "body": "Minor update (protect against a null driver class) to dbcp.patch.",
            "date": "2009-05-15T11:19:09.455+0000",
            "id": 23
        },
        {
            "author": "Jukka Zitting",
            "body": "What do you think about my dbcp.patch? Should I commit it to the feature branch as a starting point?",
            "date": "2009-05-22T12:10:46.924+0000",
            "id": 24
        },
        {
            "author": "Matej Knopp",
            "body": "I like it. I think it's a good way to start. ",
            "date": "2009-05-22T12:54:37.147+0000",
            "id": 25
        },
        {
            "author": "Jukka Zitting",
            "body": "OK, thanks. I applied the patch in revision 778741. As a next step I think we should change the ConnectionFactory to return the configured DataSource instead of a Connection object. This way we can push the DataSource reference all the way up to the PersistenceManager implementations and use it to get Connections only on demand.",
            "date": "2009-05-26T15:18:37.307+0000",
            "id": 26
        },
        {
            "author": "Matej Knopp",
            "body": "There is one problem with your patch that I overlooked. You create new BasicDataSource every time getDriverDataSource() is called. I think there should only be one datasource instance per driverclass/url combo. Otherwise it just keeps creating pools.\n\nI can fix this easily but it will take some time. Right now I'm in process of getting BundleDbPersistenceManager and subclasses used to borrowing connections instead of relying on one shared always being available.",
            "date": "2009-05-26T16:44:18.630+0000",
            "id": 27
        },
        {
            "author": "Jukka Zitting",
            "body": "> You create new BasicDataSource every time getDriverDataSource() is called.\n\nThat's by design. As noted in my previous comment, I think we should replace ConnectionFactory.getConnection() with ConnectionFactory.getDataSource() and store a reference to the returned DataSource in the persistence manager.\n\n> I think there should only be one datasource instance per driverclass/url combo. \n\nEventually yes. There the extra configuration parts that you proposed earlier will come in handy. However I think it's more straightforward if we start with one DataSource per persistence manager for now. Doing it this way we can keep the changes nicely localized within a single persistence manager. We can change the configuration mechanism or introduce some repository-local DataSource registry later on once the basic pooling functionality is there.",
            "date": "2009-05-26T18:10:21.799+0000",
            "id": 28
        },
        {
            "author": "Matej Knopp",
            "body": "Initial version of new patch. Probably lacks lot of polish. Would be nice if someone reviewed the patch and provided feedback.",
            "date": "2009-05-28T19:42:22.184+0000",
            "id": 29
        },
        {
            "author": "Jukka Zitting",
            "body": "Reviewing a 2000+ line patch isn't too easy. Could you split it to smaller pieces? Also, feel free to commit the incremental changes directly to the branch in the sandbox. That way we can better label, comment and discuss each step separately instead of syncing up only on aggregate patches.\n\nOn the proposed changes: Good stuff, thanks! We're definitely seeing good progress here.\n\nThe main concern I have is about the Context concept you're introducing. I see where you're coming, but I think there's a better way to do this. The \"context\" of a method call is the object on which the method is called. How about, instead of passing the Context objects around, we actually moved the recipient methods *into* the Context class?\n\nThe Context class would then become something like a generic DatabaseOperation base class that encapsulates the database Connection being used for that operation. Subclasses like LoadBundleOperation, SaveChangesOperation or CheckSchemaOperation could extend this base class with specific functionality that we currently have inside the PersistenceManager (and other) classes. Database-specific extensions can be handled as yet another subclasses like OracleCheckSchemaOperation and the PersistenceManager classes would simply act as factories of these Operation instances instead of actually implementing the database functionality.\n\nWDYT?",
            "date": "2009-05-29T12:22:32.354+0000",
            "id": 30
        },
        {
            "author": "Matej Knopp",
            "body": "Thanks for the feedback.\n\nUnfortunately most of the patch is one big change - it modifies AbstractBundlePersistenceManager so it requires all it's subclasses to be adapted. \n\nThe context class was IMHO probably the easiest way to introduce connection pooling without requiring complete refactor/rewrite of persistence managers. Yet the patch is quite big. \n\nI like the idea of operations. This would however be far bigger change that what I did. I thought the idea was to introduce connection pooling with minimal fuzz. Looks like I was wrong. I will look into this. I agree that if done properly this would be much cleaner solution than passing context object around.",
            "date": "2009-05-29T14:47:58.436+0000",
            "id": 31
        },
        {
            "author": "Jukka Zitting",
            "body": "My concerns about too many changes were mostly about having the modifications go too much beyond the o.a.j.core.persistence package (and other database-related packages). What we do inside those packages is open for discussion, and I'd personally prefer to reach a clean design that's built with connection pooling in mind than to patch the current design to work with pooled connections.\n\nAnyway, I think the Context class is a good starting point, and we can continue by refactoring until the design is better.\n\nFair point about the one big change. If you like you can commit the full patch as-is and we can work from there in svn.",
            "date": "2009-05-30T07:56:42.073+0000",
            "id": 32
        },
        {
            "author": "Thomas Mueller",
            "body": "To reduce the risk of problems, what about creating new classes instead of patching the existing classes? Like that you could concentrate on one database type first. It's just an idea... ",
            "date": "2009-05-30T08:31:29.386+0000",
            "id": 33
        },
        {
            "author": "Jukka Zitting",
            "body": "We're already working on a branch, so I'm not that worried about changing things. Let's see what we come up with and then consider whether the result should be merged back as-is or perhaps copied into a new package in trunk.  We should probably also set up some extra integration tests that exercise all the database types that we can easily set up.",
            "date": "2009-05-30T09:12:25.220+0000",
            "id": 34
        },
        {
            "author": "Jukka Zitting",
            "body": "I updated the sandbox branch to match the trunk and applied the latest patch.\n\nBTW, the branch now only compiles on Java 5 as the DataSource wrapper class doesn't work with Java 6.",
            "date": "2009-07-08T14:40:58.454+0000",
            "id": 35
        },
        {
            "author": "Matej Knopp",
            "body": "I'm not sure what to do about the missing methods from DataSource. We can add dummy implementation to make it compile but that doesn't really solve the problem (if the real datasource implements methods from Wrapper interface). ",
            "date": "2009-07-08T16:14:59.854+0000",
            "id": 36
        },
        {
            "author": "Martijn Hendriks",
            "body": "In order to make testing on other databases than Derby easier, I've created a new profile in jackrabbit-core and new configuration files in src/test/repository-filtered.\nThe profile copies the test configuration files from src/test/repository-filtered and filters them against properties specified in the pom. The core tests can then be run, e.g., against a configuration which puts all data in a MySQL database.\n\nI think that this makes testing the core against other than the Derby backend easier. Shall I commit this to the sandbox branch which has been created for this issue?",
            "date": "2009-07-30T13:29:24.808+0000",
            "id": 37
        },
        {
            "author": "Stefan Guggisberg",
            "body": "> Shall I commit this to the sandbox branch which has been created for this issue?\n\n+1 \n\ngreat, thanks!",
            "date": "2009-07-31T12:16:51.309+0000",
            "id": 38
        },
        {
            "author": "Martijn Hendriks",
            "body": "Committed in revision 800118. Using a different DB backend for testing can be done as follows:\n* Edit the relevant properties in the pom of the jackrabbit-core's use-descriptor-overlay profile.\n* Make sure you have the appropriate DB driver on the classpath (a MySQL driver is already there)\n* Run mvn clean integration-test -Puse-descriptor-overlay\n\nNote that the profile drops and recreates the test database in the clean phase.\n\nI recently have been looking at refactoring the database classes a bit to remove duplication in e.g., all these bean properties (username, password, schema object prefix, etc) and, more importantly, methods like checkSchema. The idea was to have a base class, say DbSupport, with all these common properties and methods and and with a method to get a sort of JDBC helper class which encapsulates the Connection and operations on it (something like the ConnectionRecoveryManager). I had various subclasses of the JDBC helper in mind for the various DB types (Oracle9, Derby). This works quite nicely for the core.fs.db package and connection pooling can then be located inside that JDBC helper class. I was wondering if that could help us here. What if the Operations that are mentioned above use such as JDBC helper class?",
            "date": "2009-08-02T18:18:12.738+0000",
            "id": 39
        },
        {
            "author": "Martijn Hendriks",
            "body": "I've taken the liberty to take the next step: see revision 801659. I've replaced the DataSource field with a ConnectionHelper field, removed the Context from the method signatures and basically put the Context's state in the ConnectionHelper. I've also moved checkSchema and prepareSchemaObjectPrefix to the ConnectionHelper class. Database specific code is now contained in the ConnectionHelper class hierarchy and this hierarchy can be reused in other database dependent packages. The BundleDbPM's init method now calls a \"createConnectionHelper\" method which subclasses can override to use a specialized ConnectionHelper.\n\nAt least the following builds succeed:\n* mvn clean integration-test  (Derby and local FS backend)\n* mvn clean test -Puse-descriptor-overlay,mysql  (MySQL backend, ignoring GCTest failure)\n* mvn clean test -Puse-descriptor-overlay,mssql  (MSSQL backend, ignoring GCTest failure)\n\nKnown open issues:\n* The H2, Oracle and Postgres PMs are broken (I've made it compile by commenting code out)\n* Make the pooling smarter (ConnectionFactory)\n* Add pooling to other DB based packages: db fs, db journal, db datastore, regular db pms.\n* blockOnConnectionLoss feature and retrying on failure strategy must be checked.",
            "date": "2009-08-06T14:29:42.418+0000",
            "id": 40
        },
        {
            "author": "Martijn Hendriks",
            "body": "I think that it is a good point to ask some feedback about the direction that the work on the sandbox branch is taking.\n\nWhat has been done:\n* A getDataSource method has been added to the ConnectionFactory which creates and returns a pooled datasource (commons-dbcp).\n* Maven profiles and some infrastructure have been added which make running the automated tests against different DB backends easier.\n* A DB uitility packages has been added: o.a.j.c.util.db. Classes from o.a.j.c.persistence.bundle.util have been moved there, and most importantly, it contains the ConnectionHelper class hierarchy. This hierarchy uses a DataSource provided by the Connectionfactory and provides a means to execute SQL and has specializations for several DB types. Most notably, the Oracle10R1ConnectionHelper implements special blob handling. It also contains a CheckSchemaOperation class which encapsulates the logic to check and create DB schemas (using a ConnectionHelper).\n* The bundle PMs and the DB Filesystem classes have been refactored to use the ConnectionHelper and CheckSchemaOperation classes. The PM and FS classes serve as factories for ConnectionHelper and CheckSchemaOperation instances.\n\nWhat must still be done:\n* Refactor remaining db based packages to use the ConnectionHelper and CheckSchemaOperation. (journal, datastore, and maybe the non-bundle pms).\n* Improve the implementation of Connectionfactory.getDataSource (now it creates a new DataSource for each invocation with default properties....)\n* ....\n* A lot of integration testing\n\nSo what do you think about the current direction?",
            "date": "2009-09-02T10:31:19.142+0000",
            "id": 41
        },
        {
            "author": "Martijn Hendriks",
            "body": "I think this should be fixed in 2.0.0.",
            "date": "2009-09-03T09:35:47.752+0000",
            "id": 42
        },
        {
            "author": "Jukka Zitting",
            "body": "I gave a quick look at the current state in the sandbox branch, and I'm pretty happy with how this has turned out!\n\nAgreed about targeting this for Jackrabbit 2.0. We should start looking at merging the changes back to trunk so they'll go out in the 2.0 betas for more testing before the final 2.0 release.",
            "date": "2009-10-21T08:42:48.926+0000",
            "id": 43
        },
        {
            "author": "Jukka Zitting",
            "body": "Attached a patch showing the full set of changes between the JCR-1456 sandbox branch and the latest trunk.\n\nAnyone opposed to merging these changes to trunk? There's obviously still some work to be done, but I think the current state is already good enough to be included in the 2.0 beta releases.",
            "date": "2009-10-21T12:17:07.081+0000",
            "id": 44
        },
        {
            "author": "Thomas Mueller",
            "body": "Is the 20% slowdown problem solved? I think that should be solved before merging to trunk (disabling validation or doing validation on idle).\n\nP.S. JCR-1456.patch looks like a 'reverse patch'.",
            "date": "2009-10-21T12:52:31.081+0000",
            "id": 45
        },
        {
            "author": "Stefan Guggisberg",
            "body": "> Is the 20% slowdown problem solved? I think that should be solved before merging to trunk (disabling validation or doing validation on idle). \n\ni agree with thomas. i'd be okay to merging these changes to trunk if the performance issue has been resolved.",
            "date": "2009-10-21T13:01:49.667+0000",
            "id": 46
        },
        {
            "author": "Martijn Hendriks",
            "body": "I think that the \"testWhileIdle\" approach for the DataSources managed by Jackrabbit resolves the performance issue (this is already present in the sandbox branch). I will try to get some more test results tomorrow. What I intend to do is measure the time that it takes to build the jackrabbit-core up to the integration-test phase on MySQL, MSSQL, H2 and Oracle backends. I compare the sandbox branch with a close revision in the trunk. I hope that these build-times are approximately the same. Is that enough, or should we do some more measurements?\n",
            "date": "2009-10-21T13:15:39.311+0000",
            "id": 47
        },
        {
            "author": "Stefan Guggisberg",
            "body": "> [...] Is that enough, or should we do some more measurements? \n\nthat would be fine with me, thanks.\n",
            "date": "2009-10-21T13:47:34.622+0000",
            "id": 48
        },
        {
            "author": "Thomas Mueller",
            "body": "> Is that enough\n\nThat's enough, thanks.\n\nCould you post the test code / setup or describe what you tested? So that we can reproduce the results if needed. Just to protect from those who say \"The new version *feels* slower...\"",
            "date": "2009-10-21T13:56:24.712+0000",
            "id": 49
        },
        {
            "author": "Martijn Hendriks",
            "body": "Sure, I'll describe what I did as precisely as possible. All thanks for your feedback.",
            "date": "2009-10-21T14:04:17.814+0000",
            "id": 50
        },
        {
            "author": "Martijn Hendriks",
            "body": "I attached the results of the performance test and also a patch against the trunk which I applied to setup the tests. There seems to be some overhead as a result of the patch. One case, however, shows quite dramatic performance loss (50%). I want to find out what causes this.",
            "date": "2009-10-23T06:45:27.680+0000",
            "id": 51
        },
        {
            "author": "Stefan Guggisberg",
            "body": "thanks for sharing the results. they do look very promising.\ni am pretty sure thomas has an idea how to explain/address\nto +50% on h2.",
            "date": "2009-10-23T09:21:49.811+0000",
            "id": 52
        },
        {
            "author": "Thomas Mueller",
            "body": "Strange is that Connection.getAutoCommit() is called so much (maybe 50% of all JDBC method calls). Sometimes it is called 4 times in a row, without any other JDBC calls in between. It's not a problem for most databases (specially embedded), but I wonder why it is called so much and if this could be avoided. \n\nI just tested H2 embedded. I don't know why H2 got slower in your case, maybe because you set the trace level to the maximum, or because you have used the server mode (I used embedded and disabled the trace output).\n\n127 seconds with trunk \n131 seconds with JCR-1456\nMaven 2.0.9, 1.5.0_20, Mac OS 10.5.8\n\nUnrelated to JCR-1456: I had to disable the H2 shutdown hook because one of tests doesn't seem to close the repository correctly, so that Jackrabbit executes database statements in a shutdown hook. This only happens in the trunk, not in JCR-1456.",
            "date": "2009-10-26T14:15:32.231+0000",
            "id": 53
        },
        {
            "author": "Jukka Zitting",
            "body": "The AutoCommit stuff shouldn't be needed with connection pooling anymore, the AutoCommit mode should simply always be off.\n\nWe use the AutoCommit mode to avoid having to add explicit commit() calls even after read-only operations. It's being switched on an off depending whether the repository is performing a read or a write operation. Now with the connection pool a connection is simply closed (or reclaimed to the pool) after a read operation ends, so no pending transaction state starts to accumulate on the database side.",
            "date": "2009-10-26T14:31:18.401+0000",
            "id": 54
        },
        {
            "author": "Martijn Hendriks",
            "body": "(Sorry for the late reply...)\n\n> Strange is that Connection.getAutoCommit() is called so much (maybe 50% of all JDBC method calls). Sometimes it is called 4 times in a row\n\nThe commons-dbcp pool calls getAutoCommit on each borrow and on each return and ConnectionHelper.getConnection also calls it. That's three. I agree that the number of calls to getAutoCommit is very large: 28756 vs 759 on the trunk for the tests.\n\n> I just tested H2 embedded. I don't know why H2 got slower in your case\n\nI see the same: H2 embedded is just a couple of seconds slower. Using H2 in server mode over TCP (localhost), however, (using tracing or not) is significantly slower. This might have something to do with the large number of getAutoCommit calls....?\n\n> The AutoCommit stuff shouldn't be needed with connection pooling anymore, the AutoCommit mode should simply always be off. \n\nI don't think that changing the default for autoCommit changes the number of calls to getAutoCommit. Can we just keep this default or is there another reason to make the default \"false\"?\n",
            "date": "2009-11-12T12:39:57.277+0000",
            "id": 55
        },
        {
            "author": "Jukka Zitting",
            "body": "Any objections to merging this work to Jackrabbit trunk? The branch looks pretty good to me now, and I think any remaining issues are best solved in trunk where it's easier for more people to try out and look at the code.\n",
            "date": "2009-11-27T09:32:47.047+0000",
            "id": 56
        },
        {
            "author": "Thomas Mueller",
            "body": "+1 merge",
            "date": "2009-11-27T09:38:40.815+0000",
            "id": 57
        },
        {
            "author": "Stefan Guggisberg",
            "body": "> Any objections to merging this work to Jackrabbit trunk? The branch looks pretty good to me now, and I think any remaining issues are best solved in trunk where it's easier for more people to try out and look at the code. \n\nare there any known issues?\n\nwould merging to trunk mean changing the current pm implementions or would the connection pooling be an optional feature?",
            "date": "2009-11-27T09:42:10.970+0000",
            "id": 58
        },
        {
            "author": "Thomas Mueller",
            "body": "It would mean changing the current pm implementations. So pooling wouldn't be optional.",
            "date": "2009-11-27T09:47:08.926+0000",
            "id": 59
        },
        {
            "author": "Stefan Guggisberg",
            "body": "> It would mean changing the current pm implementations. So pooling wouldn't be optional.\n\nok, assuming that there are no known issues at this time:\n\n-0 for merging it to trunk \n\n+1 for merging it to trunk if pooling would be an optional feature \n \n \n\n",
            "date": "2009-11-27T10:11:31.231+0000",
            "id": 60
        },
        {
            "author": "Jukka Zitting",
            "body": "> +1 for merging it to trunk if pooling would be an optional feature\n\nWould you be fine with an option that made the connection pool contain just a single persistent connection (which would essentially match current functionality), or would you rather keep the current code as is and introduce the pool-enabled code in separate packages (see my earlier comment from 30/May/09)?\n",
            "date": "2009-11-27T10:46:31.925+0000",
            "id": 61
        },
        {
            "author": "Stefan Guggisberg",
            "body": "> Would you be fine with an option that made the connection pool contain just a single persistent connection (which would essentially match current functionality), or would you rather keep the current code as is and introduce the pool-enabled code in separate packages (see my earlier comment from 30/May/09)? \n\npersonally i'd prefer the latter.",
            "date": "2009-11-27T17:17:23.353+0000",
            "id": 62
        },
        {
            "author": "Martijn Hendriks",
            "body": "> are there any known issues? \n\nBesides the minor performance degradation there are none.\n",
            "date": "2009-11-30T11:58:59.811+0000",
            "id": 63
        },
        {
            "author": "Jukka Zitting",
            "body": "OK, let's go with the separate package. Should we do this just for the persistence managers, or all of the affected pieces (fs, data store, journal)? I'd keep the non-pooled stuff around just for persistence managers since they're the most critical part of the system.",
            "date": "2009-11-30T14:45:29.428+0000",
            "id": 64
        },
        {
            "author": "Stefan Guggisberg",
            "body": ">  I'd keep the non-pooled stuff around just for persistence managers since they're the most critical part of the system.\n\nthat's ok with me.",
            "date": "2009-11-30T14:54:02.061+0000",
            "id": 65
        },
        {
            "author": "Jukka Zitting",
            "body": "The pooled bundle persistence managers are now in o.a.j.core.persistence.pool and the original bundle PMs in o.a.j.core.persistence.bundle as before.\n\nWith that change in place I've now merged all the changes from the JCR-1456 sandbox branch back to trunk. Further work on this issue should happen in trunk.",
            "date": "2009-12-02T16:33:59.299+0000",
            "id": 66
        },
        {
            "author": "Jukka Zitting",
            "body": "Resolving this as Fixed for 2.0-beta4 since all the basic work is now in trunk and we should record this changes as having occurred in time for 2.0-beta4. Let's use separate issues for any remaining issues or improvements related to database connection pooling.",
            "date": "2009-12-04T10:41:04.538+0000",
            "id": 67
        }
    ],
    "component": "jackrabbit-core",
    "description": "Jackrabbit should use database connection pools instead of a single connection per persistence manager, cluster journal, or database data store.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "JCR-1456",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "JACKRABBIT",
    "project": "JACKRABBIT",
    "summary": "Database connection pooling",
    "systemSpecification": true,
    "version": ""
}