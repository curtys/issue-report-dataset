{
    "comments": [
        {
            "author": "Shai Erera",
            "body": "IndexReader and IndexSearcher already offer a doc/document method which takes StoredFieldVisitor, so why adding another version to them?\n\nAlso, I don't think that DocumentStoredFieldVisitor should change. I find it very intuitive that I need to specify that fields that I want to load, rather than the fields that I don't want to. I.e., in my apps, there are many fields that are stored, but not loaded for results display.\n\nHowever, I do see the convenience of specifying just 1-2 fields that you don't want to load, rather than 20 that you do. So how about you create a new StoredFieldVisitor, which takes the list of fields 'not to load'? It can extend DocumentStoredFieldVisitor by overriding needsField?",
            "date": "2011-12-11T15:40:39.855+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nHowever, I do see the convenience of specifying just 1-2 fields that you don't want to load, rather than 20 that you do. So how about you create a new StoredFieldVisitor, which takes the list of fields 'not to load'? It can extend DocumentStoredFieldVisitor by overriding needsField?\n{quote}\n\nDocumentStoredFieldsVisitor already supports this in its ctors.\n\nSo i would recommend we consider adding some sugar to indexreader:\n\n{noformat}\npublic final Document document(int docID, Set<String> fields) {\n  return document(docid, new DocumentStoredFieldsVisitor(fields));\n}\n{noformat}\n\nsure there are cases where you want more complicated logic like to return STOP after certain fields, for that write your own logic.\nBut this is probably pretty common.",
            "date": "2011-12-11T15:47:24.988+0000",
            "id": 1
        },
        {
            "author": "Uwe Schindler",
            "body": "I think the issue is more about something else:\n\nbq. when generating digest for some documents with huge fields, it should be unnecessary to load the field but just interesting part of the field with the offset information. but indexreader always return the whole field content. afterward, the customized storedfieldsreader will got a repeated loading\n\nHe wants to specify an offset/length into a very large field and only retrieve the subslice.",
            "date": "2011-12-11T15:48:46.839+0000",
            "id": 2
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. So i would recommend we consider adding some sugar to indexreader:\n\nThats unrelated, BUT: yes please! And you already noted in the signature, one is very important: This method must be FINAL in IR!",
            "date": "2011-12-11T15:50:35.800+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nHe wants to specify an offset/length into a very large field and only retrieve the subslice.\n{quote}\n\nI really think the solution here is just to put the interesting part in its own field...\n\nOtherwise we have to add lots of complexity to the codec apis to support this (for instance what are the offsets/lengths? bytes? utf-16?)\n",
            "date": "2011-12-11T15:53:21.502+0000",
            "id": 4
        },
        {
            "author": "Shai Erera",
            "body": "bq. He wants to specify an offset/length into a very large field and only retrieve the subslice.\n\nThat's indeed what the issue's description says, but there's no evidence to it in the patch. And I agree with Robert that in that case, one should store the interesting part in a special field.\n\nbq. DocumentStoredFieldsVisitor already supports this in its ctors.\n\nWhere? What am I missing? DSFV only takes a list of fieldsToAdd, not fieldsToFilter. If you have 20 fields in your index, and you want to load all but 2 fields, it may be more convenient to specify these two, and I proposed that it can be done in a DSFV extension.\n\nbq. So i would recommend we consider adding some sugar to indexreader:\n\nI think this method is redundant, because one can easily call new DSFV(fields) and use the SFV document version. And why do we favor Set<String> over String...? :)",
            "date": "2011-12-11T16:05:16.199+0000",
            "id": 5
        },
        {
            "author": "peter chang",
            "body": "1. i agree with robert, fieldsToAdd, fieldsToFilter something like this can be added for IR and IS.doc\n2. yes, the offset info is specified topic related. it can be process in app level when process multi-bytes encoded languages such as Zh_CN. in this situation, the offset is just an estimation. ",
            "date": "2011-12-11T16:08:54.672+0000",
            "id": 6
        },
        {
            "author": "peter chang",
            "body": "3. i do not think i can store only the interesting part because i do not know which is interesting part at index time. For example, the digest part of the search results is generated according to the query of somebody's.",
            "date": "2011-12-11T16:23:57.755+0000",
            "id": 7
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. I think this method is redundant, because one can easily call new DSFV(fields) and use the SFV document version. And why do we favor Set<String> over String...? \n\nAhm this would favour veeeery slow code. We would need to create a Set<String> on every call :-)\n\nBut I agree here with Robert we should add the sugar method (final please and without maxDoc checks, that's up to the abstract impl) for easier use.",
            "date": "2011-12-11T16:25:00.370+0000",
            "id": 8
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. 3. i do not think i can store only the interesting part because i do not know which is interesting part at index time. For example, the digest part of the search results is generated according to the query of somebody's.\n\nDigest is the wrong word, this confused here lots of people. The use case you talk about is \"highlighting\". I agree for very large fields this is expensive.\n\nIn fact your patch does not handle this case and I agree with the others as it's to heavy to implement and adds back the crazy complexity we had with lazy fields & co.",
            "date": "2011-12-11T16:27:59.397+0000",
            "id": 9
        },
        {
            "author": "peter chang",
            "body": "yes, i mean hightlighting or sth. else dynamic generated at search time. Thnaks for Uwe's reminding.",
            "date": "2011-12-11T16:36:45.871+0000",
            "id": 10
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nWhere? What am I missing? DSFV only takes a list of fieldsToAdd, not fieldsToFilter. If you have 20 fields in your index, and you want to load all but 2 fields, it may be more convenient to specify these two, and I proposed that it can be done in a DSFV extension.\n{quote}\n\nWell, you certainly *can* do this in a DSFV extension. The only question is do we need to provide one that does this? I think in general\neach app will be different and having this visitor interface is \"enough\" rather than us supplying tons of concrete implementations for various\nuse cases.\n\n{quote}\nI think this method is redundant, because one can easily call new DSFV(fields) and use the SFV document version.\n{quote}\n\nYes its definitely redundant. But I think this is probably very common? Doesn't matter to me either way though.\n\n\n",
            "date": "2011-12-11T16:54:19.181+0000",
            "id": 11
        },
        {
            "author": "Shai Erera",
            "body": "bq. The only question is do we need to provide one that does this?\n\nOh, I did not propose that we do it in Lucene, but rather that Peter do it himself (I wrote \"how about *you* ...\"). I agree we should not cater for all use cases out there.\n\nbq. Yes its definitely redundant. But I think this is probably very common? Doesn't matter to me either way though.\n\nI don't mind much either. It's just that this sugar method suggests that you have to create a Set<String> on every call, while if we point people to DSFV, people will fins that they can pass String... too.\n\nI anyway think that for most apps, this object is probably constructed just once, because usually the list of fields does not change between queries, or at least you will have a handful of those, one per query type. Perhaps if we omit the sugar method, people will think that way, and indeed create the object just once. Dunno, it's your call.\n\nIf someone ends up committing that method in the context of this issue, I suggest that its subject is renamed accordingly. Otherwise, just close it.",
            "date": "2011-12-11T17:51:01.856+0000",
            "id": 12
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nI don't mind much either. It's just that this sugar method suggests that you have to create a Set<String> on every call, while if we point people to DSFV, people will fins that they can pass String... too.\n{quote}\n\nTrue, but thats just because DSFV creates the hashset on the fly :)\n\n{quote}\nPerhaps if we omit the sugar method, people will think that way, and indeed create the object just once. Dunno, it's your call.\n{quote}\n\nThats true too, because if you reuse the DSFV then the String... method is not harmful since you are only doing it once.\nSo I think the String... method is ok on DSFV for this reason.\n\nHowever on indexreader, i think its also ok to have a sugar method with Set, because it just creates a DSFV around that hashset,\nso its hardly wasteful. \n\nIn other words: Create a Set<String> and reuse your own Set via the proposed sugar method, and I think its fine, \nand a lot friendlier. Its not hashing anything. Sure its creating a DSFV each time, but like using a DSFV in any way, \nits also creating a Document object each time. If you are really worried about this stuff, implement your own visitor \nand don't use Document at all :) Don't forget we are talking about stored fields too!\n\nAnd I say keep the String... on DSFV only, but don't add to IR, so we don't encourage lots of wasteful rehashing.\n",
            "date": "2011-12-11T18:01:13.984+0000",
            "id": 13
        },
        {
            "author": "Shai Erera",
            "body": "Ok. One last comment (b/c I really don't mind if it's added or not) -- I meant that if we'll put a Set method on IR, users might falsely create a Set on every document() call, b/c it's there and it's convenient. Maybe javadocs can warn people against doing this ...",
            "date": "2011-12-11T18:12:59.508+0000",
            "id": 14
        },
        {
            "author": "Michael McCandless",
            "body": "+1 to adding simple sugar method to IR to only load the specified fields (Set<String>) of the document.\n\nIt's just sugar to forward to DSFV.",
            "date": "2011-12-11T21:22:54.049+0000",
            "id": 15
        },
        {
            "author": "peter chang",
            "body": "i upload this patch just for convenience\n{code:title=IndexSearcher.java|borderStyle=solid}\n  /* Sugar for <code>.getIndexReader().document(docID)</code> */\n  /** see {@link IndexReader#document(int, Set, Set)} for detail*/\n  public Document doc(int docID, Set<String> fieldsToAdd, Set<String> fieldsToFilter) throws CorruptIndexException, IOException {\n\treturn reader.document(docID, fieldsToAdd, fieldsToFilter);\n  }\n{code}\nhere, you see the IS also has the access to document fetch. so in this case, IS will look like powerless if IR can not supply such method or interface to the external.\n",
            "date": "2011-12-12T03:36:34.866+0000",
            "id": 16
        },
        {
            "author": "Michael McCandless",
            "body": "I was thinking just simple sugar, like the attached patch...",
            "date": "2011-12-12T19:55:39.309+0000",
            "id": 17
        },
        {
            "author": "Michael McCandless",
            "body": "Thanks Peter!",
            "date": "2011-12-14T20:28:29.858+0000",
            "id": 18
        }
    ],
    "component": "core/index, core/search",
    "description": "when generating digest for some documents with huge fields, it should be unnecessary to load the field but just interesting part of the field with the offset information. but indexreader always return the whole field content. afterward, the customized storedfieldsreader will got a repeated loading",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3638",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "IndexReader.document always return a doc with all the stored fields loaded. And this can be slow for the indexed document contain huge fields",
    "systemSpecification": true,
    "version": "4.0-ALPHA"
}