{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "Prototype patch just for testing...\n\nAs a quick test for viability here... I hacked\nFieldCacheImpl.DocTermsIndexImpl, to build an FST to map term <-> ord,\nand changed the lookup method to use the new Util.getByOutput method.\n\nThen I tested perf on 10M docs from Wikipedia:\n\n{noformat}\n                Task    QPS base StdDev base   QPS fstfcStdDev fstfc      Pct diff\n         TermGroup1M       47.75        1.59       25.75        0.36  -48% -  -43%\n        TermBGroup1M       17.10        0.58       14.20        0.37  -21% -  -11%\n            PKLookup      158.73        6.07      155.84        3.00   -7% -    4%\n       TermTitleSort       43.49        2.54       42.73        1.84  -11% -    8%\n             Respell       81.13        3.24       80.67        3.83   -8% -    8%\n                Term      106.13        3.59      106.03        1.28   -4% -    4%\n      TermBGroup1M1P       25.31        0.44       25.37        0.54   -3% -    4%\n              Fuzzy2       55.32        1.21       55.76        2.55   -5% -    7%\n              Fuzzy1       74.06        1.21       74.88        2.80   -4% -    6%\n        SloppyPhrase        9.82        0.61        9.95        0.42   -8% -   12%\n            SpanNear        3.39        0.16        3.47        0.15   -6% -   12%\n              Phrase        9.29        0.69        9.66        0.69  -10% -   20%\n            Wildcard       20.15        0.66       21.23        0.46    0% -   11%\n         AndHighHigh       13.43        0.55       14.24        0.70   -3% -   15%\n             Prefix3       10.05        0.53       10.70        0.19    0% -   14%\n          AndHighMed       56.62        3.36       60.54        4.28   -6% -   21%\n           OrHighMed       25.78        0.98       27.75        1.51   -1% -   17%\n          OrHighHigh       10.97        0.41       11.82        0.63   -1% -   17%\n              IntNRQ        9.74        0.81       10.83        0.26    0% -   24%\n{noformat}\n\nTwo-pass grouping took a big hit... and single-pass grouping a moderate\nhit... but TermTitleSort was a minor slowdown, which is good news.\n\nThe net RAM required across all segs for the title field FST was 30.2\nMB, vs 46.5 MB for the current FieldCache terms storage (PagedBytes +\nPackedInts), which is ~35% less.\n\nThe FST for the group-by fields was quite a bit larger (~60%) RAM\nusage than PagedBytes + PackedInts, because these fields are actually\nrandomly generated unicode strings...\n\nI didn't make the change to use the FST for term -> ord lookup (have\nto fix the binarySearchLookup method), but we really should do this\n\"for real\" because it's doing an unnecessary binary search (repeated\nord -> term lookup) now.  Ie, perf should be better than\nabove... grouping is a heavier user of binarySearchLookup than sorting\nso it should help recover some of that slowdown.\n\nAlso, Util.getByOutput currently doesn't optimize for array'd\narcs... so if we fix that we should get some small perf gain.\n\nTo do this \"for real\" I think we should do it only with DocValues,\nbecause the FST build time is relatively costly.\n",
            "date": "2012-01-29T18:02:21.337+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "Updated patch to use FST for term -> ord lookup during 2 pass grouping... much better results:\n\n{noformat}\n                Task    QPS base StdDev base   QPS fstfcStdDev fstfc      Pct diff\n         TermGroup1M       45.69        1.25       43.43        0.90   -9% -    0%\n            PKLookup      164.02        9.00      157.12        6.23  -12% -    5%\n             Respell       64.28        2.75       61.96        2.48  -11% -    4%\n        SloppyPhrase        5.99        0.26        5.79        0.35  -13% -    7%\n              Fuzzy2       54.07        2.47       52.56        1.83  -10% -    5%\n              Phrase       14.97        0.16       14.61        0.44   -6% -    1%\n       TermTitleSort       39.53        0.56       38.71        1.93   -8% -    4%\n           OrHighMed       32.91        1.33       32.27        1.48  -10% -    6%\n          OrHighHigh       15.10        0.62       14.83        0.68   -9% -    7%\n          AndHighMed       53.49        0.56       52.53        2.02   -6% -    3%\n            SpanNear       14.28        0.21       14.04        0.28   -5% -    1%\n              Fuzzy1       60.37        1.25       59.39        1.65   -6% -    3%\n         AndHighHigh        9.15        0.12        9.01        0.25   -5% -    2%\n        TermBGroup1M       33.53        0.61       33.07        0.77   -5% -    2%\n              IntNRQ       10.16        0.47       10.04        0.90  -14% -   12%\n             Prefix3       40.44        0.59       40.44        1.99   -6% -    6%\n            Wildcard       35.38        0.63       35.55        1.49   -5% -    6%\n      TermBGroup1M1P       16.54        0.34       16.78        0.54   -3% -    6%\n                Term      100.39        2.64      103.13        3.69   -3% -    9%\n{noformat}\n",
            "date": "2012-01-29T18:27:49.694+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "Interesting that it hurts sort and grouping so little... some questions:\n\n* don't you think this should be 4.0's default sorted bytes implementation?\n* alternatively, since this test hurts sort so little, maybe we could try \n  every n'th (e.g. 128) term going into the FST? So this would just be a\n  'sort index' like the terms index, augmenting the existing sorted bytes \n  (you could still load em all up in ram for other purposes, like merging). \n  But we could avoid this (mostly) for sort and hopefully resolve most\n  comparisons with the fst \"index\", maybe only rarely going to the DirectSource...\n",
            "date": "2012-01-30T19:09:24.414+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "New patch, still just prototyping on FC, but now all tests pass.\n\nI enabled packing and the wikipedia title data is now ~43.8% smaller than what FC does today (PagedBytes + PackedInts).\n\nResults are about the same as before:\n{noformat}\n            PKLookup      127.87        2.68      115.22        5.37  -15% -   -3%\n       TermTitleSort       69.77        4.32       64.91        2.62  -15% -    3%\n        TermBGroup1M       35.85        1.03       34.49        0.92   -8% -    1%\n         TermGroup1M       26.58        0.72       26.13        0.38   -5% -    2%\n             Respell       75.04        2.63       74.28        1.33   -6% -    4%\n              Fuzzy1       86.35        1.93       86.27        1.34   -3% -    3%\n              Phrase       18.92        0.57       18.94        0.57   -5% -    6%\n            SpanNear        1.46        0.02        1.46        0.05   -4% -    5%\n        SloppyPhrase       15.85        0.69       15.93        0.69   -7% -    9%\n              Fuzzy2       31.37        0.61       31.65        0.53   -2% -    4%\n      TermBGroup1M1P       44.99        1.32       45.47        0.74   -3% -    5%\n          AndHighMed       40.22        1.00       41.43        0.32    0% -    6%\n            Wildcard       26.11        1.15       27.15        0.21   -1% -    9%\n          OrHighHigh        6.14        0.42        6.40        0.34   -7% -   17%\n           OrHighMed       10.65        0.72       11.10        0.60   -7% -   17%\n         AndHighHigh        9.16        0.33        9.56        0.04    0% -    8%\n             Prefix3       43.07        2.32       45.34        0.55   -1% -   12%\n                Term       34.11        1.60       36.09        1.19   -2% -   14%\n              IntNRQ        7.66        0.64        8.22        0.57   -7% -   25%\n{noformat}",
            "date": "2012-02-01T17:28:22.562+0000",
            "id": 3
        },
        {
            "author": "Simon Willnauer",
            "body": "here is a first cut at using FST to hold terms in sorted DocValues. This patch holds all data in an FST and currently doesn't support a direct source ie all FSTs are loaded into memory even during merging. All test (except BWcompat -- wich is good!) pass. I think we can have this as a first step but not being the default? ",
            "date": "2012-06-14T20:08:21.745+0000",
            "id": 4
        },
        {
            "author": "Simon Willnauer",
            "body": "next iteration...\n\n- using FSTEnum to do getOrdByValue\n- opened up FSTEnum to subclass in different package\n- FSTEnum#seekCeil/Floor now returns a SeekStatus to prevent comparisons \n- fixed some tests to not rely on a \"default\" values that is a general test problem in docvalues not related to this issue\n\nI still have some nocommits in there. The current impl of getOrdByValue creates a new FSTEnum for each lookup which is costly we should be able to share it somehow but I really don't like using a ThreadLocal maybe we need a Lookup object or something like that but I am not sure yet.\n",
            "date": "2012-06-15T22:29:42.576+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "Very cool!\n\nWhy did you need a custom subclass of FSTEnum (instead of\nBytesRefFSTEnum)?  Is it for getOutput?  Couldn't you\ngetCurrent().output instead?\n\nWe could probably make a static Util.getCeil (like Util.get, but\nfinds ceiling term if there is no exact match) ... would likely be\nfaster than re-using an FSTEnum ... but sorta hairy to write.\n\nI'm curious how DV sort perf compares ... hopefully it's little loss\n(going on my previous tests here...).\n\nAwesome to fix seekCeil to return enum result ... maybe factor out the\nsame enum from TermsEnum so we can share it?  And you can remove the\ntwo TODOs from FSTEnum.java...\n\nCan ToFSTBytesRefConsumer be moved to FSTSortedBytesImpl.java?\n",
            "date": "2012-06-18T17:03:46.970+0000",
            "id": 6
        },
        {
            "author": "David Smiley",
            "body": "See LUCENE-4562 which should improve sorting performance across segments.\n\nI also wonder if the ord's might be accessible to the higher level APIs so that those APIs could work off of ord's (int) instead of terms (byteref).  Maybe this is too radical, or I'm out of my league on understanding this stuff and I'm making no sense.",
            "date": "2012-11-18T20:17:05.509+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "bq. I also wonder if the ord's might be accessible to the higher level APIs so that those APIs could work off of ord's (int) instead of terms (byteref).\n\nThe challenge is the ords are not \"global\" (ie not a total order): they are only ordered for the terms within one segment, unless your index is single segment, or you're working with a top-level reader.\n",
            "date": "2012-11-19T00:25:16.315+0000",
            "id": 8
        },
        {
            "author": "Uwe Schindler",
            "body": "Closed after release.",
            "date": "2013-05-10T10:33:37.989+0000",
            "id": 9
        }
    ],
    "component": "",
    "description": null,
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3729",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Allow using FST to hold terms data in DocValues.BYTES_*_SORTED",
    "systemSpecification": true,
    "version": ""
}