{
    "comments": [
        {
            "author": "Yonik Seeley",
            "body": "For solr users, this is easy to see in the example data.\n\nThe following query has a coord of 1/2 for the solr document (since apple appears in a different doc).  Press CTRL-U to see the explain properly formatted:\n\nhttp://localhost:8983/solr/select?q=solr%20apple&debugQuery=true\n\nThe following query has no coord since zzz does not appear in the example corpus:\n\nhttp://localhost:8983/solr/select?q=solr%20zzz&debugQuery=true",
            "date": "2010-08-24T01:45:38.197+0000",
            "id": 0
        },
        {
            "author": "Yonik Seeley",
            "body": "This happens because of short circuiting during scorer creation - if the term doesn't exist in the index, then TermWeight.scorer() returns null.  In the higher level BooleanWeight.scorer(), the clause is completely disregarded (unless it is mandatory).",
            "date": "2010-08-24T01:49:32.240+0000",
            "id": 1
        },
        {
            "author": "Yonik Seeley",
            "body": "OK, the fix should be easy - just keep track of maxcoord in the weights and pass it into the scorer instead of having the scorers add it up.  I'll get to it tomorrow.",
            "date": "2010-08-24T01:55:15.266+0000",
            "id": 2
        },
        {
            "author": "Yonik Seeley",
            "body": "Here's an unfinished (and untested) draft patch.\n",
            "date": "2010-08-24T04:35:02.197+0000",
            "id": 3
        },
        {
            "author": "Paul Elschot",
            "body": "Wouldn't it be easier to use a non matching Scorer instead of null?",
            "date": "2010-08-24T06:01:54.877+0000",
            "id": 4
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. Wouldn't it be easier to use a non matching Scorer instead of null?\n\nThat was my bias, but people decided against that in LUCENE-1754\n\n",
            "date": "2010-08-24T13:27:52.299+0000",
            "id": 5
        },
        {
            "author": "Yonik Seeley",
            "body": "OK, this bug does manifest in 3.1 also - just not with term queries.  A phrase query of non-existing terms can tickle it:\nhttp://localhost:8983/solr/select?q=solr+\"zzz+zzz\"&debugQuery=true\n\nThis does still work on Solr 1.4/lLucene 2.9.  Anyone know if null is actually ever returned from Weight.scorer() in 2.9?",
            "date": "2010-08-24T13:42:43.679+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "Are we sure that non-existent terms/phrases should contribute to coord?  I have no idea which way is \"right\" ;)  I'm just asking...\n\nbq. Anyone know if null is actually ever returned from Weight.scorer() in 2.9?\n\nHmm LUCENE-1754 was fixed in 2.9?  Didn't in bring allowed null return from Weight.scorer()?",
            "date": "2010-08-24T13:50:47.668+0000",
            "id": 7
        },
        {
            "author": "Marvin Humphrey",
            "body": "> Anyone know if null is actually ever returned from Weight.scorer() in 2.9?\n\nThis behavior goes back a long time -- at least back as far as svn trunk just\nprior to 1.9, which is what I worked off of when I was porting.",
            "date": "2010-08-24T13:58:46.697+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "Amazingly, I just hit a random test failure (seed = 5148889059941714836L reproduces it):\n\n{noformat}\n    [junit] Testsuite: org.apache.lucene.search.TestMultiSearcherRanking\n    [junit] Testcase: testTwoTermQuery(org.apache.lucene.search.TestMultiSearcherRanking):\tFAILED\n    [junit] expected:<0.48314467> but was:<0.60746753>\n    [junit] junit.framework.AssertionFailedError: expected:<0.48314467> but was:<0.60746753>\n    [junit] \tat org.apache.lucene.search.TestMultiSearcherRanking.checkQuery(TestMultiSearcherRanking.java:102)\n    [junit] \tat org.apache.lucene.search.TestMultiSearcherRanking.testTwoTermQuery(TestMultiSearcherRanking.java:47)\n    [junit] \tat org.apache.lucene.util.LuceneTestCase.runBare(LuceneTestCase.java:380)\n    [junit] \tat org.apache.lucene.util.LuceneTestCase.run(LuceneTestCase.java:372)\n{noformat}\n\nThe failure is in fact caused by this issue!  (The patch fixes it).  The RandomIndexWriter in this test w/ the above seed creates a multi-segment index, and then tests on a 2-term BQ.  Some segments did/didn't have both of the terms and this causes the score difference.\n\nSo...  I think we really should fix this, for consistency.  Otherwise, how your docs fall into segments can alter your scores, which is awful.",
            "date": "2010-08-24T14:17:16.622+0000",
            "id": 9
        },
        {
            "author": "Robert Muir",
            "body": "bq. So... I think we really should fix this, for consistency. Otherwise, how your docs fall into segments can alter your scores, which is awful.\n\n+1",
            "date": "2010-08-24T14:21:30.480+0000",
            "id": 10
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. Are we sure that non-existent terms/phrases should contribute to coord?\n\nYep :-)\n\nAdding an unrelated document and having scores radically change on other docs isn't a good thing.\nIt also makes testing and relevancy tuning hard (hoss & I were really scratching our heads last night trying to figure out why coord wasn't being applied).  idf is currently the only similarity factor that varies with index size + content... adding coord to that list wouldn't be good.\n\nActually, I just thought of something potentially *much* worse.  With per-segment searching, doesn't this make coord vary per-segment?  That means we're adding up scores that aren't comparable... and all of a sudden this is looking like a much worse bug.  A match in a very small segment is likely to contribute much more to a score than a match in a large segment.",
            "date": "2010-08-24T14:24:50.524+0000",
            "id": 11
        },
        {
            "author": "Yonik Seeley",
            "body": "All tests pass for me: I'll commit shortly to trunk and then backport to 3.1",
            "date": "2010-08-24T14:40:50.084+0000",
            "id": 12
        },
        {
            "author": "Yonik Seeley",
            "body": "I backported the test to the 3.0 branch, and everything looks good.\nBoth 2.9 and 3.0 remove null scorers w/o accounting for them in coord, but I don't believe we actually ever return any null scorers in those versions.",
            "date": "2010-08-27T16:31:53.009+0000",
            "id": 13
        },
        {
            "author": "Grant Ingersoll",
            "body": "Bulk close for 3.1",
            "date": "2011-03-30T15:49:54.755+0000",
            "id": 14
        }
    ],
    "component": "",
    "description": "Missing terms in a boolean query \"disappear\" (i.e. they don't even affect the coord factor).",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2617",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "coord should still apply to missing terms/clauses",
    "systemSpecification": true,
    "version": "3.1, 4.0-ALPHA"
}