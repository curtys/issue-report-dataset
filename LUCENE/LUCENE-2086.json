{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "Attached patch.",
            "date": "2009-11-20T17:11:47.611+0000",
            "id": 0
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. for better locality for the disk heads\n\nIt's not just the disk heads, right? \nI assumed the majority of the benefit was due to the cached TermEnum scan (instead of a seek) in TermInfosReader.get()\n\n\n",
            "date": "2009-11-20T17:39:13.012+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "Ahh, you're right, so long as your deletes are within the same index block (128 terms in length), we avoid the binary search through the terms index and simply scan within the block.  Though, you need relatively high density of deletions to see that.  Also, no matter what when you cross an indexed term, the binary search will be done.  I'll genericize the language in the CHANGES entry.\n\nAnd actually this reminds to go make sure the flex branch is doing this optimization too...",
            "date": "2009-11-20T18:02:54.681+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "OK I changed changes entry to:\n\n* LUCENE-2086: When resolving deleted terms, do so in term sort order\n  for better performance (Bogdan Ghidireac via Mike McCandless)\n\n",
            "date": "2009-11-20T18:07:48.217+0000",
            "id": 3
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. Though, you need relatively high density of deletions to see that.\n\nYep, but re-indexing a whole bunch of documents is a common case - and that will give a very high density (often consecutive terms).\nAlso, it may be a complete index build / rebuild, where all the terms will be consecutive.  Solr, for instance, can't tell if there are any duplicates when building an index from scratch, so it must use update().  There is a way to tell Solr not to enforce duplicate overwriting (overwrite=false param) but I doubt many people do that, and it risks user error (using it when there are dups in the docs being added, or already in the index).\n",
            "date": "2009-11-20T18:13:17.910+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "Excellent, so this is an important optimization!  I'll commit shortly...",
            "date": "2009-11-20T18:23:50.954+0000",
            "id": 5
        },
        {
            "author": "Tim Smith",
            "body": "any chance this can go into 3.0.0 or a 3.0.1?\n",
            "date": "2009-11-20T18:30:39.715+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "bq. any chance this can go into 3.0.0 or a 3.0.1?\n\nI don't think it should be backported (it's an optimization).  Generally we [should] only back port bug fixes.",
            "date": "2009-11-20T18:33:48.259+0000",
            "id": 7
        },
        {
            "author": "Tim Smith",
            "body": "i've seen the deletes dominating commit time quite often, so obviously it would be very useful to be able to absorb this optimization sooner than later (whats the timeframe for 3.1?)\n\notherwise i'll have to override the classes involved and pull in this patch (never like this approach myself)",
            "date": "2009-11-20T18:36:26.101+0000",
            "id": 8
        },
        {
            "author": "Jason Rutherglen",
            "body": "bq. I don't think it should be backported (it's an optimization). Generally we [should] only back port bug fixes.\n\nIt doesn't break backwards compatibility and it's well under the hood so it seems like something that go into a sub decimal release?",
            "date": "2009-11-20T18:40:07.536+0000",
            "id": 9
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. i've seen the deletes dominating commit time quite often, so obviously it would be very useful to be able to absorb this optimization sooner than later (whats the timeframe for 3.1?)\n\nI'm not sure how much gain you can expect from this patch (there are\nmany factors involved) -- maybe try it & report back?\n\nNot sure what the timeframe is for 3.1 at this point...\n\nbq. otherwise i'll have to override the classes involved and pull in this patch (never like this approach myself)\n\nI understand... you could run with trunk (and report back!) ;)\n\nbq. It doesn't break backwards compatibility and it's well under the hood so it seems like something that go into a sub decimal release?\n\nI know it's tempting to do so, but I think it's important to hold the\nline on only back-porting important bug fixes... as innocent as this\nchange looks, it's always possible I screwed something up, and so\nwhy risk a point release with that?  Point releases are supposed to\nbe as stable as we can possibly make them.\n\nThis way the change has plenty of time to \"bake\" on trunk and if\nsomething is amiss we'll have much more time/attention to catch it.\n\nI'd rather see us release a 3.1 sooner rather than later, instead.\n",
            "date": "2009-11-20T18:48:59.869+0000",
            "id": 10
        },
        {
            "author": "Tim Smith",
            "body": "bq. maybe try it & report back?\n\ni'll see if i can find some cycles to try this against the most painful use case i have\n\nbq. I'd rather see us release a 3.1 sooner rather than later, instead.\n\nyes please.\nI would definitely like to see a more accelerated release cycle (even if less functionality gets into each minor release)",
            "date": "2009-11-20T18:51:55.407+0000",
            "id": 11
        },
        {
            "author": "Tim Smith",
            "body": "Got some performance numbers:\n\nDescription of test (NOTE: this is representative of actions that may occur in a running system (not a contrived test)):\n* feed 4 million operations (3/4 are deletes, 1/4 are updates (single field))\n* commit\n* feed 1 million updates (about 1/3 are updates, 2/3/ deletes (randomly selected))\n* commit\n\nNumbers:\n|| Desc || Old || New ||\n| feed 4 million | 56914ms | 15698ms |\n| commit 4 million | 9072ms | 14291ms |\n| total (4 million) | 65986ms | 29989ms | \n| update 1 million | 46096ms | 11340ms |\n| commit 1 million | 13501ms | 9273ms | \n| total (1 million) | 59597ms | 20613ms |\n\nThis shows significant improvements with new patched data (1/3 the time for 1 million, about 1/2 the time for initial 4 million feed)\n\nThis means i'm gonna definitely need to incorporate this patch while i'm still on 3.0 (will upgrade to 3.0 as soon as its out, then apply this fix) \nIdeally, a 3.0.1 would be forthcoming in the next month or so with this fix so i wouldn't have to maintain this patched overlay of code\n\n\n\n\n",
            "date": "2009-11-23T20:56:43.610+0000",
            "id": 12
        },
        {
            "author": "Michael McCandless",
            "body": "Hmm these really are sizable gains!  Thanks for testing.\n\nI guess since the change is so minor and the gains so sizable we should back port for 3.0.1.  If nobody objects I'll do so in a day or two...",
            "date": "2009-11-23T22:14:11.771+0000",
            "id": 13
        },
        {
            "author": "Uwe Schindler",
            "body": "No problem, you can commit to 3.0 branch as soon as the 3 votes for the release are there and I can release the current artifacts.",
            "date": "2009-11-23T22:20:44.543+0000",
            "id": 14
        },
        {
            "author": "Mark Miller",
            "body": "No objection, but its an awkward precedent - you can see any bleeding edge user always wanting the latest optimization in the next bug fix release (considering how long you'll likely have to wait for x.n).\n\nBut as I'm one that was somewhat pro this for 2.9 (due to some being stuck on 1.4), I won't try and stop it here. I'm a big fan of case by case in general anyway. I agree with your previous comment about trying to keep a bug fix release as stable as possible - and this being a minor change, that would seemt to go along with it - but code is a funny beast, even when dealing with the simple ...",
            "date": "2009-11-23T22:23:56.645+0000",
            "id": 15
        },
        {
            "author": "Michael McCandless",
            "body": "Yeah there's an exception to every rule ;)  Fast forward a month or two, if we find out I somehow broke 3.0.1 by back-porting this fix, I'll be real grumpy!",
            "date": "2009-11-23T22:36:40.729+0000",
            "id": 16
        },
        {
            "author": "Michael McCandless",
            "body": "bq. No problem, you can commit to 3.0 branch as soon as the 3 votes for the release are there and I can release the current artifacts.\n\nBTW can't/won't you cut the tag back on the right revision, anyway?  Ie why freeze the 3.0 branch from any backports?",
            "date": "2009-11-23T22:56:15.847+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "Just commit it. It is so simple, so if I respin, it can be in 3.0.0.\n\nI did'nt want to have commits in 3.0, because if I respin a release, I would not be able to only take *some* of the fixes into 3.0.0. That was the reason.\n\nCan you put this also in 2.9.2 if you remove the generics?",
            "date": "2009-11-24T07:16:12.997+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nI did'nt want to have commits in 3.0, because if I respin a release, I would not be able to only take some of the fixes into 3.0.0. That was the reason.\n\nCan you put this also in 2.9.2 if you remove the generics?\n{quote}\nOK I'll backport...",
            "date": "2009-11-24T09:39:36.010+0000",
            "id": 19
        },
        {
            "author": "Michael McCandless",
            "body": "Backported to 3.0.x...\n\n2.9.x next.",
            "date": "2009-11-24T13:40:25.645+0000",
            "id": 20
        },
        {
            "author": "Michael McCandless",
            "body": "OK backported to 2.9.x.",
            "date": "2009-11-24T13:48:58.075+0000",
            "id": 21
        }
    ],
    "component": "core/index",
    "description": "See java-dev thread \"IndexWriter.updateDocument performance improvement\".",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2086",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "When resolving deletes, IW should resolve in term sort order",
    "systemSpecification": true,
    "version": ""
}