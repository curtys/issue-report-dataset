{
    "comments": [
        {
            "author": "Fernando Martins",
            "body": "I'm also having memory leaking when doing simple Searches using lucene CVS checkout from 2006-01-10\nI'm using jrockit-jdk1.5.0_03.\n\nI've tried with this patch, and my simple search test STOPPED leaking.\nMaybe it does depend on the JVM version.\nI'll try on our application this patch to see if it stops leaking.\n\n",
            "date": "2006-01-11T07:28:38.000+0000",
            "id": 0
        },
        {
            "author": "Nicholaus Shupe",
            "body": "I will be trying this patch on Lucene 1.9.1 to see if it fixes my production memory leak with Tomcat 5.5.15 / Redhat / Java 1.5.0_06.",
            "date": "2006-05-01T23:15:34.000+0000",
            "id": 1
        },
        {
            "author": "robert engels",
            "body": "The bug is invalid, as was pointed out on the lucene-dev list.\n\nWhen the thread dies, all thread locals will be cleaned-up.\n\nIf the thread does not die, the thread-locals are still cleaned-up PERIODICALLY. And the value is always cleaned up - since it is held in a WeakReference, the only things that \"hangs around\" is the key - which consumes VERYL LITTLE memory.\n\nThe submitter should be able to provide a testcase that demonstrate the ThreadLocal bug. The one provided with bug 529 is invalid (as was pointed out on the dev email thread).\n\nIMHO, there is NO BUG HERE. The users are ding something else that is causing a OOM.\n\nThis bug should be closed as invalid.",
            "date": "2006-05-01T23:37:29.000+0000",
            "id": 2
        },
        {
            "author": "robert engels",
            "body": "The finalize() method should be removed from the Segment/Term readers.\n\nIn most cases this will actually make things worse, as the objects will need to stay around until the finalizer thread can run.",
            "date": "2006-05-01T23:39:35.000+0000",
            "id": 3
        },
        {
            "author": "kieran",
            "body": "I have created a test that exhibits the above-discussed problem.\nPlease note, I don't think it should necessarily be called a \"Lucene\" bug, as the lucene source is written in a way that /should/ work. It's more likely to be a JVM bug, I think.\nPlease note, I have seen this bug in SUN Hotspot JVM 1.4.2 on Linux. I will shortly be trying some other JVMs and platforms, but - for the time being - this test should only be run against such an environment.\nWhile developing this test, it also became apparent that the bug only exhibits itself when using a RAMDirectory as the source for an IndexSearcher.\nI will shortly attach the test to this issue.\n",
            "date": "2006-05-02T18:55:53.000+0000",
            "id": 4
        },
        {
            "author": "kieran",
            "body": "test case for recreating this issue on (at least) sun jvm hotspot 1.4.2 on linux",
            "date": "2006-05-02T18:58:02.000+0000",
            "id": 5
        },
        {
            "author": "Nicholaus Shupe",
            "body": "I agree with robert engels about the finalize method being taken out of the class.  In fact, the finalize method is run by the finalizer thread, and by setting the value to null in that thread, it effectively creates one more entry in the Thread threadLocals map.  This can only hurt the class and performance.  I'm still investigating to why the memory leak occurs though.",
            "date": "2006-05-04T01:24:17.000+0000",
            "id": 6
        },
        {
            "author": "robert engels",
            "body": "fwiw, we have done EXTENSIVE memory profiling of the low-level Lucene (and JVM) routines.\n\nIt is my opinion that there are no memory leaks in either.\n\nIn every case that we \"found\" a memory leak, it always ended up tied back to something we were doing wrong on our client code.",
            "date": "2006-05-04T01:34:03.000+0000",
            "id": 7
        },
        {
            "author": "Nicholaus Shupe",
            "body": "robert engels is *incorrect* in that there isn't a memory leak with Lucene.  The test case made by kieran demonstrates the memory leak quite well on my machine for the following setup:\n\nLucene 1.9.1\nSun JDK 1.5.0_06\nJVM Args: -Xmx4M (low memory to get the unit test to fail faster)\nWindows XP Pro\n\nThe test case will fail on my machine with i = 2006 and useRamDirectory set to true (as indicated by kieran, this point is important).\n\nFurthermore, by changing the enumerators declaration to:\n\n  private Map enumerators = Collections.synchronizedMap(new WeakHashMap());\n\nand the getEnum method to:\n\n  private SegmentTermEnum getEnum() {\n    Thread currentThread = Thread.currentThread();\n    SegmentTermEnum termEnum = (SegmentTermEnum)enumerators.get(currentThread);\n    if (termEnum == null) {\n      termEnum = terms();\n      enumerators.put(currentThread, termEnum);\n    }\n    return termEnum;\n  }\n\n(note that I'm not suggesting that my changes be used for the official patch)\n\nThe problem dissapears, and the unit test completes.  I vote that this bug be bumped to critical in priority and a fix be included for the Lucene 1.9.2 release and perhaps a patch be made for the 1.4.3 release for those who need it.\n\nFor further reading on the perils of ThreadLocal I suggest the following reading:\n\nhttp://www.me.umn.edu/~shivane/blogs/cafefeed/2004/06/of-non-static-threadlocals-and-memory.html\nhttp://www.szegedi.org/articles/memleak.html\nhttp://crazybob.org/2006/02/threadlocal-memory-leak.html\nhttp://opensource.atlassian.com/confluence/spring/pages/viewpage.action?pageId=2669",
            "date": "2006-05-04T03:32:38.000+0000",
            "id": 8
        },
        {
            "author": "robert engels",
            "body": "I agree that the test case does fail, so I was wrong. There is \"something\" broken in Lucene or the JDK.\n\nWhat is the JDK bug that was fixed that allows it to work under 1.5? The proposed patch is nearly exactly the implementation of ThreadLocal, so I am not sure how it would fix the problem?\n\nWhen I ran it under the profiler, it seems to work correctly. I still it may have something to do with finalizers preventing GC when it needs it.\n",
            "date": "2006-05-04T03:51:48.000+0000",
            "id": 9
        },
        {
            "author": "Nicholaus Shupe",
            "body": "The problem is apparent on my machine with JDK 1.5, so basically this bug shows up, regardless of JDK version.\n\nI've looked at the source for ThreadLocal, and there's a custom implementation of a map being used which is a bit scarry.  However, you'd figure they tested the hell out of it, including instance count verification with the garbage collector.\n\nIf we assume the code for ThreadLocal is correct, then the only idea I have is that the value, a SegmentTermEnum has a reference chain back to the ThreadLocal in someway, which would prevent the ThreadLocal key in the inner map from being collected.  However, I can't seem to show that being true.  I've even tried not using the .clone method thinking there might be something fishy with that, but nothing came out of that.",
            "date": "2006-05-04T03:59:50.000+0000",
            "id": 10
        },
        {
            "author": "Nicholaus Shupe",
            "body": "This type of ThreadLocal (anti?)pattern also seems to be present in SegmentReader.",
            "date": "2006-05-04T04:13:53.000+0000",
            "id": 11
        },
        {
            "author": "robert engels",
            "body": "It works fine for me under 1.5.0_06.\n\nI have determined the problem with the ThreadLocal code in 1.4.2. The entries in the ThreadLocalMap extend WeakReference (holding a weak ref to the key which is the ThreadLocal), but also contain a HARD reference to the value (the thread local value - which in this case can be quite large).\n\nIn JDK 1.4.2, the entries are only cleaned-up if a hit occurs and the ThreadLocalMap determines that the entry is stale (the key has been reclaimed), and at this point the entry is reused for the new ThreadLocal. If no hits ever occur (or it keeps hiiting the same entry), the number of entries in the table will become unbounded.\n\nIn JDK 1.5, the ThreadLocal code periodically clean-ups SOME stale ThreadLocals during each invocation - using cleanSomeSlots().\n\nThis is why using the proposed patch works - it uses a standard WeakHashMap which expunges ALL stale entries on nearly every operation.\n\nI will look into creating a derived ThreadLocal that works properly. Or we can just package the proposed patch into a FixedThreadLocal. I don't know what the Lucene dev policies are on \"fixing\" JDK problems. Seems to me a FixedThreadLocal is the best solution.\n",
            "date": "2006-05-04T04:45:56.000+0000",
            "id": 12
        },
        {
            "author": "robert engels",
            "body": "ThreadLocal replacement that avoids memory leak",
            "date": "2006-05-04T10:27:21.000+0000",
            "id": 13
        },
        {
            "author": "robert engels",
            "body": "I posted FixedThreadLocal.java. Changed Lucene to use this class instead of ThreadLocal. Test case runs fine under 1.4.\n\nThe performance difference appears almost non existent. I think this is because in typical Lucene usage the number of invocations is quite small.\n\nA better multi-threaded version is also possible, using a WeakHashMap for each thread, containing the FixedThreadLocals for that thread. This would minimize the length of the synchronization required.\n\nIn either case, the finalize methods should be removed. This contributes greatly to the problems with the current code. In fact, it does nothing, since if the object was finalizable, then its reference would have already been reclaimed from the ThreadLocalMap, so having the finalize method actually slows this process. (I removed the finalized methods from Lucene - test case runs fine).\n\nBUT, this problem is not as severe as it appears.\n\nThe main reason that this becomes an issue with JDK 1.4 and the testcase, is that the size of the objects being put into the ThreadLocal, since the RAMDirectory has a complete copy of the index. In most uses this will not be the case, and the objects will be reclaimed eventually, as the ThreadLocalMap size stabalizes. The bug in ThreadLocal allows a certain number of stale entries, once the index size gets to 300k, a max of 30 entries can be stale without running out of memory.\n",
            "date": "2006-05-04T10:40:21.000+0000",
            "id": 14
        },
        {
            "author": "robert engels",
            "body": "demonstrate thread local memory leak",
            "date": "2006-05-04T10:53:23.000+0000",
            "id": 15
        },
        {
            "author": "robert engels",
            "body": "I posted ThreadLocalTest.java that clearly demonstrates the \"problem\" with JDK 1.4.\n\nBUT, it also demonstrates the problem with the test case.\n\nIf you run the test with -Xmx4m it will fail quickly under JDK 1.4.2.\nIf you run the test as is under JDK 1.5 with the same memory constraints it will run forever.\n\nWith the same memory constraints, if you change the test to use FixedThreadLocal it will run forever.\n\nBUT, if you run the test with -Xmx64m under JDK 1.4.2 it will run forever! This is because the ThreadLocalMap size stablizes.\n\nThus, unless you are creating and accessing large RAMDirectories you will never experience the problem.\n\nI think this bug should be closed as invalid. BUT, the finalizer() methods should be removed from the Lucene code since it does no good, and actually slows the system by delaying the GC.\n\nHopefully this ends the issue, and we can move on to other things.",
            "date": "2006-05-04T11:00:23.000+0000",
            "id": 16
        },
        {
            "author": "robert engels",
            "body": "Just for my own \"pat on the back\", it goes back to what I said in the earliest comment.\n\nThere is NOT a memory leak in Lucene or JDK 1.4.2 or Lucene.\n\nJDK 1.4.2 made a performance vs. memory size decision that works in most cases.\n\nIn the submitters case their deisgn decision does not work so well (combination of size of ThreadLocal values and maximum heap size).\n\nWith JDK 1.5, they chose an alternative implementation that is SLOWER, but the memory requirements in the general case are smaller, and deterministic.\n\nThere will ALWAYS be design decisions like this in ALL software development.\n",
            "date": "2006-05-04T11:06:01.000+0000",
            "id": 17
        },
        {
            "author": "Andy Hind",
            "body": "I agree this is not strictly an issue with lucene....but .....\n\nLucene has an unusual use pattern for thread locals (instance vs static member variables).\nThere are issues with ThreadLocal, discussed here and elsewhere, including potential instability.\nYou should expect others to use thread locals - maybe in the same way.\n\nI fixed the issue reported in LUCENE-529 with memory sensitive caching using SoftReferences to the values held as ThreadLocals.\nBefore an out of memory error, the values are cleared and hard refs to the soft reference wrapper class remain.\nThis pattern is used by some classes in the JVM.\nThis limits the memory overhead with thread local use. \nThere will always be some overhead.\n\nI am happy with the alternative fix using WeakHashMap\nNote: stale entries are always scanned and removed (each call to put, get, size) in contrast to thread locals. \nThis is what I want - it must be stable!\n \nI spent as much time as I could trying to come up with a clear, simple test case that applied regardless of memory constraints.\nA clear failure case must be possible, but I did not have time to investigate the criteria for ThreadLocal instability.\nIn any case, I would send this to Sun.\n\nA test case is one thing, knowning, understanding and fixing/working around an issue is another.\nIn all the simple cases I tried I got stability but with higher memory use and gc activity than with the \"fixed\" version.\nHowever, I did also remove the pointless finalize() method, which could very well explain the growth of the thread local table.\n\nWe have had problems with 1.5.0_06. The issue is caused by the pattern of thread local use and garbage collection producing instability in the size of the thread local table. Your single test case does not imply that the issue does not exist for other JVMs and use cases.  I have had the issue without using RAMDirectory - it seems it is just more likely with it.\n\nBy the way, cause and effect is sufficient for me. I have a problem with using the 1.4.3 code, this change fixes it.\n\nRegards\n\nAndy",
            "date": "2006-05-04T17:40:28.000+0000",
            "id": 18
        },
        {
            "author": "robert engels",
            "body": "To restate:\n\nIt is NOT a bug. It is a design decision in the JDK between performance and memory use. This decisions changed a bit in 1.5. 1.5 still does not clear the entire ThreadLocal table - it uses hueristics to clear MOST of the entries - a balance between memory and speed. The WeakHashMap clears ALL entries on every invocation. It is slower than a ThreadLocal, BUT, it's memory use is more deterministic.\n\nLucene will work FINE in all cases except when loading large directories into a RAMDirectory, and closing and reopening said directories multiple times.\n\nSince this may be a common use case for Lucene, I suggest using the FixedThreadLocal class - trading performance for deterministic memory use.\n\nIn all cases, the current finalize() methods that \"clear the ThreadLocal value\" should be removed. It is incorrect, and causes performance problems. Since the finalize() is for the ThreadLocal value, it will never be finalized until the ThreadLocal has already cleared the entry - which is based on the key (the ThreadLocal), since the ThreadLocal entry maintains a hard ref to the value.",
            "date": "2006-05-04T22:00:59.000+0000",
            "id": 19
        },
        {
            "author": "robert engels",
            "body": "Oops. Last comment was not quite correct.\n\nThe reason the finalize() methods are worthless for clearing the ThreadLocal entries, is that they are clearing the ThreadLocal entry for the \"finalize\" thread !\n\nSo they do nothing but slow down finalization/GC.\n",
            "date": "2006-05-04T22:31:36.000+0000",
            "id": 20
        },
        {
            "author": "robert engels",
            "body": "The best solution is this,\n\nmove the \n\n    enumerators.set(null);\n\nto the TermInfosReader close(), and remove the finalize().\n\nEverything will work fine.",
            "date": "2006-05-04T22:40:38.000+0000",
            "id": 21
        },
        {
            "author": "robert engels",
            "body": "Actually, the last simple \"fix\" only works well for single threaded applications, so it is not much of a \"fix\".\n\nUse FixedthreadLocal - works best.",
            "date": "2006-05-04T23:56:52.000+0000",
            "id": 22
        },
        {
            "author": "Nicholaus Shupe",
            "body": "However, this problem is classified is eventually irrelevant to me.  Bug in the JDK, bug in Lucene, not a bug, it's all the same.  What is relevant is that I have a production app using Lucene 1.9.1 that will produce an OutOfMemoryError within 2 weeks of use with a huge 128MB of heap.  The configuration is Sun's JDK 1.5.0_06 on Linux / Tomcat 5.5.15.  With a patch, I am NOT getting the memory link, and my customers are NOT being denied service because of LUCENE-436.\n\nFor what it's worth, the use case for my app is opening up one IndexReader and one IndexSearcher, and using the IndexSearcher in an multi-threaded environment.  If this isn't a primary use case for Lucene, it should be.",
            "date": "2006-05-05T00:40:23.000+0000",
            "id": 23
        },
        {
            "author": "robert engels",
            "body": "Are you always loading your indexes using RAMDirectories?\n\nI use multi-hundred megabytes indexes, with 196 max heap, and it runs for months.\n\nI can guarentee that if your index grows to 100+ megabytes you will get an OOM no matter what you do (loading into a RAMDirectory with a 128 max heap), SO, THE ISSUE IS COMPLETELY DEPENDENT on YOUR configuration.\n\nYou may find that using a 256 max heap allows your index to run forever with NO code CHANGES.\n\nI am not saying this issue should not be addressed, but it is not  BUG. It is a performance vs. memory consumption design tradeoff. If you knew anything about software, you would understand this.\n\nIt may be the common case that Lucene should favor lower memory consumption vs. performance, but it is not a ABSOLUTE.\n\nThere are conceivably many users of Lucene where the change does not make sense, the performance degradation is not worth it (because they have plenty of memory available based on index size, and/or do not load the indexes into memory).\n\n\n",
            "date": "2006-05-05T00:55:46.000+0000",
            "id": 24
        },
        {
            "author": "robert engels",
            "body": "better version of TermInfos reader that avoid multiple ThreadLocal.get() calls",
            "date": "2006-05-05T00:57:03.000+0000",
            "id": 25
        },
        {
            "author": "robert engels",
            "body": "I attached a better version of TermInfosReader that avoids multiple ThreadLocal.get() during get(Term r) which can be expensive.\n\nThis is especially important if ThreadLocal is changed to FixedThreadLocal due to the lower performance of get().\n\nI also removed some unused package level methods.\n",
            "date": "2006-05-05T01:01:02.000+0000",
            "id": 26
        },
        {
            "author": "Nicholaus Shupe",
            "body": "I am not using a RAMDirectory.  I never indicated as such.  Here's the the way I load my index:\n\nreader = IndexReader.open(dictionaryIndexDirectory);\n\ndictionaryIndexDirectory is a java.io.File.\n\nMy index is 30 megabytes.  This configuration should be perfectly fine in 128 MB of heap, even 64 sounds reasonable.  I can't simply add a 128 MB heap to my configuration without additional cost.  I can't just throw hardware at the problem.  Also, any performance arguments are irrelevant unless proven with real numbers.  If you knew anything about software, you would understand this as well.",
            "date": "2006-05-05T01:20:29.000+0000",
            "id": 27
        },
        {
            "author": "robert engels",
            "body": "Then you have some other problem.\n\nThe ONLY way the ThreadLocal issue is an ISSUE is if VERY LARGE objects are referenced by the ThreadLocal. Since your indexes are not being held in ram, there is some other problem. You even provided that test case that DEMONSTRATES the \"memory leak\" issue is not a problem unless a RAMDirectory is used.\n\nAs for what is a valid heap size - this depends completely on the other code loaded into the JVM, and what memory it uses.\n\nI use a max heap of 196 with 400mb index and it works fine.\n\n",
            "date": "2006-05-05T01:33:04.000+0000",
            "id": 28
        },
        {
            "author": "kieran",
            "body": "Robert Engels description of the ThreadLocal issue in JDK 1.4.2 provides a very plausible explanation for why this is not a bug, either in Lucene, or in the JDK.\n\nIt's not a memory \"leak\", in the traditional sense (i.e. an unbounded increase in heap memory usage); however, it can - in certain circumstances - lead to a lot more memory being assigned than is necessary, which (and this is pivotal) isn't necessarily considered for GC-ing once it's no longer (hard-)referenced.\n\nPersonally, now this behaviour of ThreadLocal has been pointed out, I find it very difficult to envisage circumstances in which I'll even consider using it - until it is altered. (I won't say never, because, as Robert points out, there IS a performance gain to this behaviour).\n\nMy personal experience is that this \"memory leak\" / \"larger than necessary memory footprint\" can cause extreme problems in production apps. We've been running out of memory even with 700MB assigned to each JRE. My patch has resolved the issue, and so we will apply it to each future release of Lucene, before we use it. Maybe ours is an unusual setup: we periodically close our IndexSearcher, reload an index from the filesystem into a RAMDirectory, and create a new IndexSearcher from it. These indexes are only a few MB in size.\n\nThe reason I posted this patch and test case was to help developers who might be in a similar situation to me, and save them from the having to perform the days of investigation that I did - not because I wanted to force an unwanted change into the Lucene source code. It would be very useful to me if a variant of this patch WAS incorporated into Lucene but I recognize that other users may well have different priorities vis-a-vis performance vs memory ueage.\n\n(btw, Robert, I think you might have mistakenly ascribed the test case to Nicholaus! It was me who suggested that it was dependent on using RAMDirectories.)\n\nKind regards.",
            "date": "2006-05-05T05:29:39.000+0000",
            "id": 29
        },
        {
            "author": "Erik Hatcher",
            "body": "Please, everyone, let's keep this discussion technical and factual and avoid making degrading statements to one another.  It doesn't help the situation to have such negative tones being used. The discussion aspect of this should be moved to java-dev anyway, and leave JIRA comments for details on patches attached and other technical details related directly towards resolving this issue.",
            "date": "2006-05-05T08:46:59.000+0000",
            "id": 30
        },
        {
            "author": "Fernando Padilla",
            "body": "Here are our facts.  It looks like this bug is also affecting us!!\n\n\nWe are also running into memory issues on our production servers and running out of memory.\n\nTomcat 5, Lucene1.9.1, JDK 1.5, RHEL, RAMDirectory\n\nWe are constantly updating the index ( 2400 documents smoothly reindexed every 30 hour ).\n\nIndex size of about 5M.\n\nWe are doing ordered searches against the index.\n\nWe are constantly creating new IndexReader/Writer/Searcher and closing as needed.\n\nIn QA we have Xmx500M, in production we have Xmx1500M.\n",
            "date": "2006-05-11T07:07:10.000+0000",
            "id": 31
        },
        {
            "author": "Fernando Padilla",
            "body": "So I went ahead and made our own version of lucene-1.9.1 from the sources along with the proposed patch.  And yes it does help our memory leak.  If you refer to the previous comment, you can see what our environment looks like.  I will go ahead and attach our version of the patch now.",
            "date": "2006-05-12T05:07:26.000+0000",
            "id": 32
        },
        {
            "author": "Fernando Padilla",
            "body": "alright then.  Attached is the patch that I just created.  I couldn't resist modifying the FixedThreadLocal to suit my tastes. :)\n\nand it goes against the \"1.9.1\" src that I downloaded off of their website. (though it was marked as version \"1.9.2-dev\", which then I re-christened \"1.9.2-protrade\" ).\n\nAnd yes it seems to have helped with the memory leak.\n\nthank you all.\n",
            "date": "2006-05-12T05:08:13.000+0000",
            "id": 33
        },
        {
            "author": "Antony Scerri",
            "body": "Would it not be easier to simply make the objects stored in the ThreadLocal a WeakReference. So in the case of TermInfosReader store the SegmentTermEnum within the WeakReference, and then place that into the enumerators varaible. This will maintain the cloned term enumerator object for the lifetime of the thread using it, but also allow the objects to be cleaned up by the GC when the index owning the TermInfosReader is no longer referenced (at which point no thread should be using the index). \n",
            "date": "2006-08-21T13:45:19.000+0000",
            "id": 34
        },
        {
            "author": "Antony Scerri",
            "body": "Lets forget that last comment I made, I was testing out a simple setup and forgot there wasn't going to be a hard reference to the cloned term enum object anywhere, so the weak reference would get cleared away immediately upon GC. A SoftReference could be used instead, but would be subject to GC if free memory was low, which under heavy load could mean it would again get cleared away by GC before the thread had finished.",
            "date": "2006-08-21T16:46:16.000+0000",
            "id": 35
        },
        {
            "author": "Otis Gospodnetic",
            "body": "4 months later, I think I see the same problem here.\nI'm using JDK 1.6 (I saw the same problem under 1.5.0_0(8,9,10)) and Lucene from HEAD (2.1-dev).\nI'm running out of 2GB heap in under 1 day on a production system that searches tens of thousands of indexes, where a few hundred of them have IndexSearchers open to them at any one time, with unused IndexSearchers getting closed after some period of inactivity.\n\nI'm periodically dumping the heap with jconsole and noticing the continuously increasing number of:\n\n org.apache.lucene.index.TermInfo\n org.apache.lucene.index.CompoundFileReader$CSIndexInput\n org.apache.lucene.index.Term\n org.apache.lucene.index.SegmentTermEnum\n...\n\nThere was a LOT of back and forth here.\n\nWhat is the final solution?  I see a complete new copy of TermInfosReader, but there are a lot of formatting changes in there, it's hard to tell what was actually changed, even with diff -bB --expand-tabs.\n\nI also see FixedThreadLocal, but I see no references to it from TermInfosReader...?\n",
            "date": "2006-12-13T21:17:08.000+0000",
            "id": 36
        },
        {
            "author": "robert engels",
            "body": "I would doubt the ThreadLocal \"issue\" that was in 1.4, changed in 1.5, would be reintroduced in 1.6.\n\nI do not use Lucene 2.1 so I can't say for certain that a new memory bug hasn't been introduced.\n\nI suggest attaching a good profiler (like JProfiler) and figure our the cause of the memory leak (the root references).\n\nI use 1.9 based Lucene and can say unequivocally there are no inherent memory issues (especially when running under 1.5+).\n\nThere may also be new issues introduced in JDK 6 - we have not tested with it, only 1.4 and 1.5.",
            "date": "2006-12-13T22:32:08.000+0000",
            "id": 37
        },
        {
            "author": "Otis Gospodnetic",
            "body": "My leak ended up being caused by the patch in LUCENE-651 and is fixed by LUCENE-754.\n\nThe only thing left to do in this case is:\n1) remove finalize() calls in SegmentReader and TermInfosReader\n2) call enumerators.remove() in TermInfosReader's close()\n\nI'll do that in the next few days.\n",
            "date": "2006-12-19T22:33:49.000+0000",
            "id": 38
        },
        {
            "author": "Yonik Seeley",
            "body": "The more finalizers we can get rid of, the better.  They are too hard to use correctly and cause performance problems.\nhttp://devresource.hp.com/drc/resources/jmemmodel/index.jsp",
            "date": "2006-12-20T03:27:09.000+0000",
            "id": 39
        },
        {
            "author": "Otis Gospodnetic",
            "body": "This patch removes finalize() in TermInfosReader and SegmentReader, and it adds the enumerators.remove() call in TermInfosReader close() method.",
            "date": "2006-12-20T03:43:41.000+0000",
            "id": 40
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Applied and committed the LUCENE-436.patch (is JIRA smart enough not to hyperlink this?) - all unit tests still pass.",
            "date": "2006-12-20T20:28:16.000+0000",
            "id": 41
        }
    ],
    "component": "core/index",
    "description": "We've been experiencing terrible memory problems on our production search server, running lucene (1.4.3).\n\nOur live app regularly opens new indexes and, in doing so, releases old IndexReaders for garbage collection.\n\nBut...there appears to be a memory leak in org.apache.lucene.index.TermInfosReader.java.\nUnder certain conditions (possibly related to JVM version, although I've personally observed it under both linux JVM 1.4.2_06, and 1.5.0_03, and SUNOS JVM 1.4.1) the ThreadLocal member variable, \"enumerators\" doesn't get garbage-collected when the TermInfosReader object is gc-ed.\n\nLooking at the code in TermInfosReader.java, there's no reason why it _shouldn't_ be gc-ed, so I can only presume (and I've seen this suggested elsewhere) that there could be a bug in the garbage collector of some JVMs.\n\nI've seen this problem briefly discussed; in particular at the following URL:\n  http://java2.5341.com/msg/85821.html\nThe patch that Doug recommended, which is included in lucene-1.4.3 doesn't work in our particular circumstances. Doug's patch only clears the ThreadLocal variable for the thread running the finalizer (my knowledge of java breaks down here - I'm not sure which thread actually runs the finalizer). In our situation, the TermInfosReader is (potentially) used by more than one thread, meaning that Doug's patch _doesn't_ allow the affected JVMs to correctly collect garbage.\n\nSo...I've devised a simple patch which, from my observations on linux JVMs 1.4.2_06, and 1.5.0_03, fixes this problem.\n\nKieran\nPS Thanks to daniel naber for pointing me to jira/lucene\n\n@@ -19,6 +19,7 @@\n import java.io.IOException;\n\n import org.apache.lucene.store.Directory;\n+import java.util.Hashtable;\n\n /** This stores a monotonically increasing set of <Term, TermInfo> pairs in a\n  * Directory.  Pairs are accessed either by Term or by ordinal position the\n@@ -29,7 +30,7 @@\n   private String segment;\n   private FieldInfos fieldInfos;\n\n-  private ThreadLocal enumerators = new ThreadLocal();\n+  private final Hashtable enumeratorsByThread = new Hashtable();\n   private SegmentTermEnum origEnum;\n   private long size;\n\n@@ -60,10 +61,10 @@\n   }\n\n   private SegmentTermEnum getEnum() {\n-    SegmentTermEnum termEnum = (SegmentTermEnum)enumerators.get();\n+    SegmentTermEnum termEnum = (SegmentTermEnum)enumeratorsByThread.get(Thread.currentThread());\n     if (termEnum == null) {\n       termEnum = terms();\n-      enumerators.set(termEnum);\n+      enumeratorsByThread.put(Thread.currentThread(), termEnum);\n     }\n     return termEnum;\n   }\n@@ -195,5 +196,15 @@\n   public SegmentTermEnum terms(Term term) throws IOException {\n     get(term);\n     return (SegmentTermEnum)getEnum().clone();\n+  }\n+\n+  /* some jvms might have trouble gc-ing enumeratorsByThread */\n+  protected void finalize() throws Throwable {\n+    try {\n+        // make sure gc can clear up.\n+        enumeratorsByThread.clear();\n+    } finally {\n+        super.finalize();\n+    }\n   }\n }\n\n\n\nTermInfosReader.java, full source:\n======================================\npackage org.apache.lucene.index;\n\n/**\n * Copyright 2004 The Apache Software Foundation\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport java.io.IOException;\n\nimport org.apache.lucene.store.Directory;\nimport java.util.Hashtable;\n\n/** This stores a monotonically increasing set of <Term, TermInfo> pairs in a\n * Directory.  Pairs are accessed either by Term or by ordinal position the\n * set.  */\n\nfinal class TermInfosReader {\n  private Directory directory;\n  private String segment;\n  private FieldInfos fieldInfos;\n\n  private final Hashtable enumeratorsByThread = new Hashtable();\n  private SegmentTermEnum origEnum;\n  private long size;\n\n  TermInfosReader(Directory dir, String seg, FieldInfos fis)\n       throws IOException {\n    directory = dir;\n    segment = seg;\n    fieldInfos = fis;\n\n    origEnum = new SegmentTermEnum(directory.openFile(segment + \".tis\"),\n                                   fieldInfos, false);\n    size = origEnum.size;\n    readIndex();\n  }\n\n  public int getSkipInterval() {\n    return origEnum.skipInterval;\n  }\n\n  final void close() throws IOException {\n    if (origEnum != null)\n      origEnum.close();\n  }\n\n  /** Returns the number of term/value pairs in the set. */\n  final long size() {\n    return size;\n  }\n\n  private SegmentTermEnum getEnum() {\n    SegmentTermEnum termEnum = (SegmentTermEnum)enumeratorsByThread.get(Thread.currentThread());\n    if (termEnum == null) {\n      termEnum = terms();\n      enumeratorsByThread.put(Thread.currentThread(), termEnum);\n    }\n    return termEnum;\n  }\n\n  Term[] indexTerms = null;\n  TermInfo[] indexInfos;\n  long[] indexPointers;\n\n  private final void readIndex() throws IOException {\n    SegmentTermEnum indexEnum =\n      new SegmentTermEnum(directory.openFile(segment + \".tii\"),\n\t\t\t  fieldInfos, true);\n    try {\n      int indexSize = (int)indexEnum.size;\n\n      indexTerms = new Term[indexSize];\n      indexInfos = new TermInfo[indexSize];\n      indexPointers = new long[indexSize];\n\n      for (int i = 0; indexEnum.next(); i++) {\n\tindexTerms[i] = indexEnum.term();\n\tindexInfos[i] = indexEnum.termInfo();\n\tindexPointers[i] = indexEnum.indexPointer;\n      }\n    } finally {\n      indexEnum.close();\n    }\n  }\n\n  /** Returns the offset of the greatest index entry which is less than or equal to term.*/\n  private final int getIndexOffset(Term term) throws IOException {\n    int lo = 0;\t\t\t\t\t  // binary search indexTerms[]\n    int hi = indexTerms.length - 1;\n\n    while (hi >= lo) {\n      int mid = (lo + hi) >> 1;\n      int delta = term.compareTo(indexTerms[mid]);\n      if (delta < 0)\n\thi = mid - 1;\n      else if (delta > 0)\n\tlo = mid + 1;\n      else\n\treturn mid;\n    }\n    return hi;\n  }\n\n  private final void seekEnum(int indexOffset) throws IOException {\n    getEnum().seek(indexPointers[indexOffset],\n\t      (indexOffset * getEnum().indexInterval) - 1,\n\t      indexTerms[indexOffset], indexInfos[indexOffset]);\n  }\n\n  /** Returns the TermInfo for a Term in the set, or null. */\n  TermInfo get(Term term) throws IOException {\n    if (size == 0) return null;\n\n    // optimize sequential access: first try scanning cached enum w/o seeking\n    SegmentTermEnum enumerator = getEnum();\n    if (enumerator.term() != null                 // term is at or past current\n\t&& ((enumerator.prev != null && term.compareTo(enumerator.prev) > 0)\n\t    || term.compareTo(enumerator.term()) >= 0)) {\n      int enumOffset = (int)(enumerator.position/enumerator.indexInterval)+1;\n      if (indexTerms.length == enumOffset\t  // but before end of block\n\t  || term.compareTo(indexTerms[enumOffset]) < 0)\n\treturn scanEnum(term);\t\t\t  // no need to seek\n    }\n\n    // random-access: must seek\n    seekEnum(getIndexOffset(term));\n    return scanEnum(term);\n  }\n\n  /** Scans within block for matching term. */\n  private final TermInfo scanEnum(Term term) throws IOException {\n    SegmentTermEnum enumerator = getEnum();\n    while (term.compareTo(enumerator.term()) > 0 && enumerator.next()) {}\n    if (enumerator.term() != null && term.compareTo(enumerator.term()) == 0)\n      return enumerator.termInfo();\n    else\n      return null;\n  }\n\n  /** Returns the nth term in the set. */\n  final Term get(int position) throws IOException {\n    if (size == 0) return null;\n\n    SegmentTermEnum enumerator = getEnum();\n    if (enumerator != null && enumerator.term() != null &&\n        position >= enumerator.position &&\n\tposition < (enumerator.position + enumerator.indexInterval))\n      return scanEnum(position);\t\t  // can avoid seek\n\n    seekEnum(position / enumerator.indexInterval); // must seek\n    return scanEnum(position);\n  }\n\n  private final Term scanEnum(int position) throws IOException {\n    SegmentTermEnum enumerator = getEnum();\n    while(enumerator.position < position)\n      if (!enumerator.next())\n\treturn null;\n\n    return enumerator.term();\n  }\n\n  /** Returns the position of a Term in the set or -1. */\n  final long getPosition(Term term) throws IOException {\n    if (size == 0) return -1;\n\n    int indexOffset = getIndexOffset(term);\n    seekEnum(indexOffset);\n\n    SegmentTermEnum enumerator = getEnum();\n    while(term.compareTo(enumerator.term()) > 0 && enumerator.next()) {}\n\n    if (term.compareTo(enumerator.term()) == 0)\n      return enumerator.position;\n    else\n      return -1;\n  }\n\n  /** Returns an enumeration of all the Terms and TermInfos in the set. */\n  public SegmentTermEnum terms() {\n    return (SegmentTermEnum)origEnum.clone();\n  }\n\n  /** Returns an enumeration of terms starting at or after the named term. */\n  public SegmentTermEnum terms(Term term) throws IOException {\n    get(term);\n    return (SegmentTermEnum)getEnum().clone();\n  }\n\n  /* some jvms might have trouble gc-ing enumeratorsByThread */ \n  protected void finalize() throws Throwable {\n    try {\n        // make sure gc can clear up.\n        enumeratorsByThread.clear();\n    } finally {\n        super.finalize();\n    }\n  }\n}\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-436",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "[PATCH] TermInfosReader, SegmentTermEnum Out Of Memory Exception",
    "systemSpecification": true,
    "version": "1.4"
}