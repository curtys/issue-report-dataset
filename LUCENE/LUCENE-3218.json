{
    "comments": [
        {
            "author": "Simon Willnauer",
            "body": "first sketch still some nocommits - this patch includes the latest patch from LUCENE-3201 which made the CFS part of directory. This patch adds write support to the CompoundFileDirectory. The CFWriter tries to write files directly to the CFS if possible like when no other file is currently open for writing it opens a stream directly on the CFS. Yet, this change also adds a new file to the CFS (.cfe) which only holds the entry table which makes all seeks unneeded (plays better with AppendingCodec).\n\nI currently don't use it during indexing since we decided after flush if we use CFS or not. Yet this might change with this optimization but I will leave this to another issue.\n\n",
            "date": "2011-06-20T18:50:45.162+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks cool!\n\nSo the CFW will take the first output opened against it and let it write\ndirectly into the \"actual\" CFS file, and then if another file is\nopened while that first one is still open, the 2nd file will write to\nseparate file and then will copy in on close.  We may want to delegate\nthe separate files too?  So that on close they copy themselves into\nthe CFS and remove the original?  This way IW won't have to separately\ncreate CFS in the end.\n\nSomehow we need IW to add the biggest sub-file first...\n\ns/compund/compound\n\nCFW.close should assert currentOutput != null (and, if we delegate sep\nentries, that they are also all closed)?\n\nYou might need to sync the CompoundFileWriter.this.currentOutput test\n/ setting to null?  Though... Lucene is always single threaded in\nwriting files for the same segment, today anyway.\n\nCan we make a separate createCompoundOutput?  (Ie, instaed of passing\nOpenMode to openCompoundInput).  And: I'm assuming a given compound\noutput can only be opened once, appended to / separate files copied\ninto, closed and then never opened again for writing?  (Ie, still\n\"write once\" at the file level).\n",
            "date": "2011-06-20T21:07:58.235+0000",
            "id": 1
        },
        {
            "author": "Simon Willnauer",
            "body": "next iteration - seems close. \n\n* moved CFW to o.a.l.store and made package private.\n* added createCompoundOutput to Directory instead of passing OpenMode\n* added write support to CompundFileDirectory\n* Separately written file are appended during close if possible (no other file is currently written directly to the CF). If files is locked append happens once that file is closed.\n* IW uses Directory methods only, addFile has been converted to Directory#copy\n\n\nonce thing which still bugs me is the setAbortCheck on CFDirectory.. I wonder if we can solve that differently, ideas?\n",
            "date": "2011-06-21T10:46:14.977+0000",
            "id": 2
        },
        {
            "author": "Simon Willnauer",
            "body": "updated patch NOW containing all files :)\n\nsorry for the missing files in the last patch",
            "date": "2011-06-21T14:23:22.309+0000",
            "id": 3
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks great!\n\nCan we name it createCompoundOutput?  Emphasizes that we are\nwrite-once (this file shouldn't exist), and matches createOutput.\n\nOn checkAbort... we could not send that to the CFW and instead call\ncheckAbort in the outer loops?  (Ie, where we .copy the files in).\nThe existing CFW already only checks once-per-file anyway...\n\nMaybe instead of asserts for the mis-use of the CFD API (eg no\nentries, something is still open), we should make these real\nexceptions (ie, thrown even when assertions are off)?\n\nThis comment looks stale (in CFW.java)?:\n{noformat}\n      // Close the output stream. Set the os to null before trying to\n      // close so that if an exception occurs during the close, the\n      // finally clause below will not attempt to close the stream\n      // the second time.\n{noformat}\n\nopenCompoundOutput needs javadoc.\n\nCFD.createOutput's jdoc says Not Implememented but it is.\n\nThe new test cases in TestCompoundFile names its file d.csf ;) Column\nstride fields lives on!!  Too many tlas...\n",
            "date": "2011-06-21T14:46:12.926+0000",
            "id": 4
        },
        {
            "author": "Simon Willnauer",
            "body": "final patch. \n* fixed javadocs + several javadoc warnings\n* renamed openCompoundOutput to createCompoundOutput\n* fixed file extensions in test CSF LOL!!\n* copyFileEntry now deletes files that are separately written once copied into the CFS.\n* converted asserts to exceptions in CFW\n\nI plan to commit this today if nobody objects.",
            "date": "2011-06-21T15:16:53.166+0000",
            "id": 5
        },
        {
            "author": "Simon Willnauer",
            "body": "Committed in revision 1138063.\nI will try to backport this to 3.x if possible",
            "date": "2011-06-21T15:54:23.769+0000",
            "id": 6
        },
        {
            "author": "Simon Willnauer",
            "body": "here is a patch against 3.x. I had to change one test in lucene/backwards and remove some tests from there which used the CFW / CFR.\n\nA review would be good here!",
            "date": "2011-06-22T09:16:26.754+0000",
            "id": 7
        },
        {
            "author": "Robert Muir",
            "body": "Hi Simon, currently this attached patch fails... not sure why yet.\n\nBut I think we should resolve this tests issue before backporting",
            "date": "2011-06-22T10:26:12.845+0000",
            "id": 8
        },
        {
            "author": "Simon Willnauer",
            "body": "thank you robert, while this has actually been tested since its in the base class though its now cleaner. The test failure came from RAMDirectory simply overriding existing files. I added an explicit check for it.",
            "date": "2011-06-22T10:53:45.963+0000",
            "id": 9
        },
        {
            "author": "Robert Muir",
            "body": "Thanks Simon, I feel better now that we get our open-files-for-write tracking back.",
            "date": "2011-06-22T11:09:32.179+0000",
            "id": 10
        },
        {
            "author": "Simon Willnauer",
            "body": "backported to 3.x - thanks guys",
            "date": "2011-06-22T13:14:19.069+0000",
            "id": 11
        },
        {
            "author": "Robert Muir",
            "body": "See LUCENE-3374, LUCENE-3380.\n\nThere are some serious traps here with how the CFE files are created for \"delegator\"-like Directory impls such as FileSwitchDirectory and NRTCachingDirectory.\n\nWith such dirs that might have policies the writer is \"backdooring\" their decision about where files should go since it only has a reference to the \"sub\" directory.\n\nI think this is non-intuitive and we should do something to try to prevent surprises.",
            "date": "2011-08-18T08:22:05.673+0000",
            "id": 12
        },
        {
            "author": "Robert Muir",
            "body": "Can CFS reading/writing not take a parent directory, instead of:\n\nCompoundFileDirectory(Directory parent, ....)\n\nI think it should be\nCompoundFileDirectory(IndexInput cfs, IndexInput cfe)\n\nAnd directory.createOutput etc should take *both* filenames, this would remove this backdooring completely.",
            "date": "2011-08-18T08:55:03.621+0000",
            "id": 13
        },
        {
            "author": "Michael McCandless",
            "body": "Maybe we can avoid making a separate _X.cfe file?\n\nWe did this because previously the CFS stored the header in the front of the file (I think)?\n\nCould we, instead, put the header at the end of the file, but place a long pointer at the start of the file saying where the header is located (I'd rather not rely on file.length())?  Then we could have a single (_X.cfs) file again and we can not use the Dir impl for delegation?",
            "date": "2011-08-19T13:20:01.211+0000",
            "id": 14
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. We did this because previously the CFS stored the header in the front of the file (I think)?\nis this really the problem here? I mean this problem is in FileSwitch / NRT Directory. The CFS uses a directory to write files, I would expect that if we use for instance NRT directory it gets the NRT directory instead of either of of its sub directories. its not really a CFS problem IMO and we should rather fix the actual directory rather than reverting the small optimization having the header in a separate file. i think we should prevent the seek if not absolutely necessary.",
            "date": "2011-08-19T13:30:40.667+0000",
            "id": 15
        },
        {
            "author": "Marvin Humphrey",
            "body": "I don't fully grok Robert's concern, but with regards to Mike's suggestion of\ninlining the metadata: Why not put that file pointer at the very end of the\nfile?  So that the read-time sequence of actions is: seek to 8 bytes before the\nend, read the file pointer, seek back to beginning of metadata.\n\nThat way you don't need to seek backwards during writing, which IIRC used to\nbe an issue for Hadoop.\n",
            "date": "2011-08-19T13:34:38.502+0000",
            "id": 16
        },
        {
            "author": "Robert Muir",
            "body": "This is definitely not a bug in the directory, and its a serious issue (i think a blocker for release myself).\n\nI'll try to explain the issue again a little better than I did on https://issues.apache.org/jira/browse/LUCENE-3380?focusedCommentId=13086872&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13086872\n\nThis is just an example of the API problem, with FileSwitchDirectory.\n\nIn Lucene we have FileSwitchDirectory which is a Directory that lets you \"switch\" between 2 different directory implementations based on file extension.\nSo conceptually it looks like this:\n\n{code}\nFileSwitchDirectory extends Directory {\n  Directory a;\n  Directory b;\n  Set extensions; // these are the file extensions that go to \"a\", all other ones are handled by \"b\"\n}\n{code}\n\nImagine you configure this directory to put all \"*.cfs\" in \"a\", and everything else in \"b\".\n\nSo when FileSwitchDirectory is asked where to put \"1.cfs\", it forwards the request to \"a\".\n\nBut the \"1.cfe\" file is actually wrongly created in \"a\" also, causing FileNotFoundExceptions later when the file is to be read, because its in the wrong directory. This is because of how the compound file mechanism works now, it calls a.createOutput(\"1.cfe\") instead of fileswitchdirectory.createOutput(\"1.cfe\").\n\nSo this is a serious problem for any Directories that delegate responsibility like this, not just the ones in Lucene.\n",
            "date": "2011-08-19T13:48:02.172+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "Thanks Robert for explaining this again, I agree 100% with you, the current cfe/cfs discussion is really serious and the current impl is heavy broken.",
            "date": "2011-08-19T13:51:46.730+0000",
            "id": 18
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nMaybe we can avoid making a separate _X.cfe file?\n{quote}\n\n+1, this sounds great (however it can be done, ideally with Marvin's idea to support appendable-only filesystems also), and would end the confusion here.",
            "date": "2011-08-19T13:52:53.464+0000",
            "id": 19
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. i think we should prevent the seek if not absolutely necessary.\n\nYou have a very small optimization here that only affects opening the CFS.\n\nBut because we need to fix the wrong behaviour in FileSwitch (and also NRTCaching dir, which is in my opinion more serious!!!!), FileSwitch and NRTCachingDir now use the default CompoundFileImpl. If you wrap MMapDir by FileSwitch or NRTCaching, the whole custom impl of the compound file in MMap that speeds up even further is obsolete, as not used (you can use the compound file with really no slowdown at all as we can map parts of the CFS file into memeory and need no offset calculations and can also save mapping costs).\n\nThis is gone now, just because a one-time seek at opening time is prevented.",
            "date": "2011-08-19T13:58:00.806+0000",
            "id": 20
        },
        {
            "author": "Robert Muir",
            "body": "Right, the fix I applied is really a hack, but I didnt want to leave our codebase broken while we figure this out.\n\nIts not just a problem from a performance perspective, I think its just bad to make assumptions about how the inner directory works.\nIn this case with fileswitchdirectory etc, it really should be fully delegating this stuff down, and be clueless about how its implemented by the underlying sub directory.",
            "date": "2011-08-19T14:01:46.654+0000",
            "id": 21
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nWhy not put that file pointer at the very end of the\nfile? So that the read-time sequence of actions is: seek to 8 bytes before the\nend, read the file pointer, seek back to beginning of metadata.\n{quote}\n\nI would rather not rely on metadata (file length) when reading, only the contents of the file.\n\nI think append-only filesystems (eg HDFS) can make their own impl that uses the file length instead (like AppendingCodecc).",
            "date": "2011-08-19T15:27:06.996+0000",
            "id": 22
        },
        {
            "author": "Robert Muir",
            "body": "Anyone have opinions on 3.x? \n\nI think it might be wise to think about pulling these CFS changes (LUCENE-3201, too) back from 3.x and instead\ngive things some time to settle in trunk?\n\nWe could always then backport at a later release, but we got lucky here that we still haven't released anything.\n",
            "date": "2011-08-19T15:42:24.750+0000",
            "id": 23
        },
        {
            "author": "Andrzej Bialecki ",
            "body": "bq. I think append-only filesystems (eg HDFS) can make their own impl that uses the file length instead (like AppendingCodecc).\n\nAppendingCodec solves only one issue, that of postings and SegmentInfos. I'm worried that adding seek+rewrite tricks in other places that are not under the control of Codec or under any other configurable implementation (such as CFS) will ultimately prevent the efficient use of Lucene on Hadoop. Unless we put those places under the control of a Codec (or some other configurable interface).",
            "date": "2011-08-19T20:54:19.643+0000",
            "id": 24
        },
        {
            "author": "Uwe Schindler",
            "body": "The trick with the latest updates to compound files is that the CompoundFileWriter/Reader is returned by the directory implementation - and this is broken and the discussion is about this.\nSo this would be the place, where you theoretically could completely make another CFS on-disk format or e.g. write the stuff to a ZIP file :-)\n\nSee here: [https://builds.apache.org/job/Lucene-3.x/javadoc/core/org/apache/lucene/store/Directory.html#createCompoundOutput(java.lang.String)]",
            "date": "2011-08-19T21:04:31.062+0000",
            "id": 25
        },
        {
            "author": "Simon Willnauer",
            "body": "personally I think we should try to be append only on general. So eventually this is about creating the cfe and cfs file from the \"right\" directory. What we could do to use the parent ie. FileSwitchDir etc. is add a protected method that allows passing the parent dir to the createCompoundOutput / openCompoundInput which is then in turn used to create the actual files. We can call this method from the public createCompoundOutput / openCompoundInput versions with \"this\" as the directory to create files. How does that sound? Lemme know if I miss something...",
            "date": "2011-08-19T21:28:54.658+0000",
            "id": 26
        },
        {
            "author": "Robert Muir",
            "body": "I disagree, we don't need to compensate for hadoop's problems.\n",
            "date": "2011-08-19T21:34:51.502+0000",
            "id": 27
        },
        {
            "author": "Uwe Schindler",
            "body": "If we want append only, we should also remove seek methods from IndexOutput... I DISAGREE, too!",
            "date": "2011-08-19T21:39:13.984+0000",
            "id": 28
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nSo eventually this is about creating the cfe and cfs file from the \"right\" directory.\n{quote}\n\nThat's not the only issue: while that is the primary reason I reopened this issue I also have concerns about the API being complicated and non-intuitive.\n\nMaking the API even more complicated because Filesystem X can only write WingDings or cannot seek doesn't seem to be a good solution to me.",
            "date": "2011-08-19T21:48:52.863+0000",
            "id": 29
        },
        {
            "author": "Uwe Schindler",
            "body": "When looking into the CompoundFileDirectory code I also found a small bug in version handling.\nreadEntries() reads the first VInt and uses it for version checking (if negative). This check has 2 problems:\n- if the VInt is smaller then FORMAT_CURRENT it should throw IndexTooNewException\n- the comparison should not be against FORMAT_CURRENT itsself (this constant should only be used for writing CFS files), it should compare against real version numbers. This would otherwise break on later additions of new formats.",
            "date": "2011-08-19T23:30:10.451+0000",
            "id": 30
        },
        {
            "author": "Robert Muir",
            "body": "I think the situation here is too complicated already, we are discussing all kinds of complicated stuff and I dont think \"appendable\" CFS is worth any of this.\n\nI think we should back out these CFS changes for now.",
            "date": "2011-08-20T09:05:17.495+0000",
            "id": 31
        },
        {
            "author": "Michael McCandless",
            "body": "bq. I think we should back out these CFS changes for now.\n\n+1\n\nGenerally if we add a cool optimization and it turns out that optimization risks even just apparent index corruption and/or adds scary traps / confusing complexity to the API I think we should pull the change and iterate on the issue / branch until these problems are addressed?\n\nWe had a similar experience with copyBytes, but that time it was real corruption.\n\nOptimizations aren't worth such risks I think, especially if it's only an index-time opto?",
            "date": "2011-08-20T16:06:12.022+0000",
            "id": 32
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. I think we should back out these CFS changes for now.\n\n-1 \n\nI think we are over reacting here, especially robert gets too crazy about this. Honestly I think CFS should be detached from directory and we should make it a delegating directory if at all. That way we would always operate on the right directory, can safely create two files and keep Directory itself clean. We can still add the ability to partially map a certain file (offset, length) into memory like we do now in the specialized CFS Dirs. This entire think is not a problem of appending at all IMO. \n\nhow does that sound? I think this would solve all the problems we are having and keeps it appendable.\n\nsimon",
            "date": "2011-08-21T06:13:12.404+0000",
            "id": 33
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi when thinking about the whole stuff one more time again, I may have a solution to again decouple CFS from the parent directory, so one can create any CFS using one single class (but perhaps the factory in directory is still an idea to make it customizable). There are several solutions, but most of them have customization problems:\n- The current approach was discussed already, nothing more to say\n- A possibility to make it possible for MMap to map certain parts of the file is to move the getIndexInputSlice up to the abstract Directory base class and make the default implementation the current CFIndexInput from the default CFS impl. This would be even backwards compatible. So the CFS impl can simply ask the parent directory it warps for a slice. The problem here is easy: Current CFS impl opens the CFS file exactly one time and consumes exactly one file handle. The slices work on the same file handle. If we move the slice handling up to the directory, the \"state\" is gone, so handling the all-the-time open CFS file cannot be managed anymore. When using a new file handle for each slice, we gain nothing (CFS is to reduce file handles).\n- Last night I had one idea that might fix this issue. Lets move the slice handling into the abstract IndexInput base class, again the default impl would simply use the current CFIndexInput to return a slice. In the case of MMapIndexInput it would simply return a remapped slice on the current file handle. The only thing that would change is that the RAF would kept open the wohle time (like MMapCFDirectory does), in contrast to curren, where th RAF is closed directly after mapping. This approach would allow it for the CFS impl to simply ask it parant directory for an IndexInput to handle the SFC file itsself and for each sub-slice ask this IndexInput for this.\n\nThe last approach seems reasonable, but we need some more checks how to implement that. The last approach keeps both \"features\" of CFS:\n- One OS file handle\n- possibility for certain directory implementations to return sliced IndexInputs in an optimal way. The current IndexInput have a clone method, in this case we would need a similar method, where you can give offset and length.\n\nOn the other hand, we can remove the \"factory\" for CFS files from directory, we can go back to a simple new CFSDirectory(parentDirectory, cfsName).\n\nDoes this sound reasonable?",
            "date": "2011-08-21T10:19:08.571+0000",
            "id": 34
        },
        {
            "author": "Robert Muir",
            "body": "None of this is reasonable.\n\nWhen something goes wrong with an optimization, and multiple people ask for you to back it out, back it out.\n\nthen later we can discuss how to re-implement it.\n\n",
            "date": "2011-08-21T10:30:17.866+0000",
            "id": 35
        },
        {
            "author": "Uwe Schindler",
            "body": "But we can still consider this as solutions to solve the issue later? I just dont want to make suggestions with lots of brainwork and sleepless nights involved, if it's not considered and just be backed out with \"None of this is reasonable.\".",
            "date": "2011-08-21T10:47:27.899+0000",
            "id": 36
        },
        {
            "author": "Michael McCandless",
            "body": "I think both Simon's and Uwe's ideas are good and should be explored!  With all these ideas we will find a clean way to get CFS reading/writing integrated into Directory.\n\nBut I think that exploration should just be outside of trunk and 3.x, eg on a branch.  Once we iterate to a good point again we can commit it back to trunk, let it bake/age, then merge back to 3.x if it seems stable.",
            "date": "2011-08-21T13:09:31.169+0000",
            "id": 37
        },
        {
            "author": "Mark Miller",
            "body": "+1 on backing out of 3.x at least - this is our stable branch...I can't imagine this optimization belongs in our stable branch given all of this discussion...",
            "date": "2011-08-21T14:40:41.266+0000",
            "id": 38
        },
        {
            "author": "Simon Willnauer",
            "body": "its all yours do whatever you think needs to be done. have fun ;)",
            "date": "2011-08-21T15:43:08.777+0000",
            "id": 39
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. None of this is reasonable.\nyour unreasonable comments here are totally counter productive IMO. Just my $0.05 ",
            "date": "2011-08-21T15:45:39.599+0000",
            "id": 40
        },
        {
            "author": "Mark Miller",
            "body": "Isn't there a lot of middle ground here? Why don't we just back out of 3.x for now and keep pushing towards a consensus implementation on trunk?",
            "date": "2011-08-21T17:37:16.372+0000",
            "id": 41
        },
        {
            "author": "Simon Willnauer",
            "body": "FYI - I backed out the changes from 3.x ",
            "date": "2011-08-22T12:11:05.548+0000",
            "id": 42
        },
        {
            "author": "Uwe Schindler",
            "body": "Showuld we send an email to java-user as the index format in the stable branch changed by this (indexes with new CFS files can no longer be read)?",
            "date": "2011-08-22T14:33:34.378+0000",
            "id": 43
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Showuld we send an email to java-user as the index format in the stable branch changed by this (indexes with new CFS files can no longer be read)?\nI will do",
            "date": "2011-08-22T16:17:48.564+0000",
            "id": 44
        },
        {
            "author": "Simon Willnauer",
            "body": "here is a rough patch against trunk that detaches CFDirectory from other dir impls but still extends Directory. all optimizations still remain while always the top-level directory is used to create / open the CFS. \nI didn't follow uwes last approach since I could figure out when to close the RAF reference since like in the MMap case we want to forcefully unmap the file and therefor would also need to close the RAF reference in the base stream. I use a helper construct (IndexInputHandle - yes need to find a better name) that can only be pulled from another directory (protected). So this is private to the directory impls but solves our cases here nicely I think.\n\nstill rough but its a start.",
            "date": "2011-08-22T16:21:58.352+0000",
            "id": 45
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Simon,\n\nthanks for taking care. This looks really nice and easier to understand. I agree, the problem with the RAF open file is hard to manage (especially when to close it).\n\nOne small suggestion: Currently the CFS file is opened twice: One time to read the contents and a second time to read the actual files using the handle (and for new format to read the CFE file, but thats unavoidable - once we nuke old index support in Lucene 5, we can always open the cfe first and read the contents, but until then we need to do both). Why not open the IndexInputHandle at the beginning and then simply request a full slice for the directory initialization (or ideally only that part that contains the directory)? The slice can then be closed afterwards as before.\n\nSo very cool work!\nGreetings from Berkeley!",
            "date": "2011-08-22T17:12:47.602+0000",
            "id": 46
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nThis looks really nice and easier to understand.\n{quote}\n\nI agree! At a glance, it seems this design looks much better to and avoids the sneaky delegation problems.\n\nOnly one minor thing glancing at the patch: in MockDirectoryWrapper, can we track that the handle is actually closed?",
            "date": "2011-08-22T17:39:07.714+0000",
            "id": 47
        },
        {
            "author": "Simon Willnauer",
            "body": "next iteration\n\n* removed 3.4 support for the current format (cfe file) in SI\n* regenerated the BW test indices (not in the patch) \n* add javadoc for IndexInputHandle\n* added IndexInputHandle#openFullSlice to get a slice spanning the entire file.\n* Track indexInputHandle instances in MockDirectoryWrapper to ensure they are closed.\n* Use the IndexInputHandle ie. the underlying file handle to create all streams in CFS (uwes suggestion - thanks for that)\n\nI didn't include the generated indices for bw tests in the patch for size / readability. Yet, if you want to run the tests you need to generate them otherwise TestBackwardsCompatibility will fail.\n\nthis seems close, the question is if we want to backport this to 3.x too?",
            "date": "2011-08-23T08:21:55.882+0000",
            "id": 48
        },
        {
            "author": "Michael McCandless",
            "body": "This approach looks nice!  Maybe rename IndexInputHandle to\nIndexInputProvider?  IndexInputSlicer?  SliceCreator?\n\nMaybe rename CSIndexInput -> SlicedIndexInput?\n\nIn SimpleFSDir we may as well move that static Descriptor class out?\nRather than having to import it to itself.\n",
            "date": "2011-08-23T18:12:14.461+0000",
            "id": 49
        },
        {
            "author": "Mark Miller",
            "body": "bq. this seems close, the question is if we want to backport this to 3.x too?\n\nWhy don't we get it committed to trunk and let it chill for a while, let it hit random testing for a while, get used by adventurous users, and then make the decision?",
            "date": "2011-08-23T18:19:37.934+0000",
            "id": 50
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Why don't we get it committed to trunk and let it chill for a while, let it hit random testing for a while, get used by adventurous users, and then make the decision?\n+1",
            "date": "2011-08-23T18:33:25.691+0000",
            "id": 51
        },
        {
            "author": "Simon Willnauer",
            "body": "I don't really like the name IndexInputHandle what about\n * IndexInputFactory\n * IndexInputProducer\n * IndexInputSlicer\n \nmore ideas?",
            "date": "2011-08-23T18:34:16.344+0000",
            "id": 52
        },
        {
            "author": "Uwe Schindler",
            "body": "I would also rename CFIndexInput to SliceIndexInput, it's private so does not matter, but wozuld be nice to have.\n\nOtherwise I agree with committing to trunk. As far as I see, the format did not change in trunk, so once we get this back into 3.x we are at the state pre-revert?",
            "date": "2011-08-24T06:21:43.531+0000",
            "id": 53
        },
        {
            "author": "Simon Willnauer",
            "body": "new patch, I renamed IndexInputHandle to IndexInputSlicer and made the createSlicer method public otherwise Directory impls outside of o.a.l.store can not delegate to it.\n\nbq.I would also rename CFIndexInput to SliceIndexInput, it's private so does not matter, but wozuld be nice to have.\n\ndone\n\nbq. Otherwise I agree with committing to trunk. As far as I see, the format did not change in trunk, so once we get this back into 3.x we are at the state pre-revert?\n\nyes that's true.\n\nI think is ready to commit, if nobody objects I am going to commit this later today.",
            "date": "2011-08-24T08:28:20.473+0000",
            "id": 54
        },
        {
            "author": "Simon Willnauer",
            "body": "I committed this to trunk. I will leave this issue open until we decide to backport to 3.x.\n\nsimon",
            "date": "2011-08-24T16:05:53.410+0000",
            "id": 55
        },
        {
            "author": "Robert Muir",
            "body": "not a blocker, it was pulled from 3.x (and fixed in trunk)",
            "date": "2011-10-07T19:33:25.812+0000",
            "id": 56
        },
        {
            "author": "Simon Willnauer",
            "body": "I am closing this - we are not backporting this to 3.x and its committed & stable on trunk",
            "date": "2011-11-04T22:07:06.700+0000",
            "id": 57
        }
    ],
    "component": "core/index",
    "description": "Currently CFS is created once all files are written during a flush / merge. Once on disk the files are copied into the CFS format which is basically a unnecessary for some of the files. We can at any time write at least one file directly into the CFS which can save a reasonable amount of IO. For instance stored fields could be written directly during indexing and during a Codec Flush one of the written files can be appended directly. This optimization is a nice sideeffect for lucene indexing itself but more important for DocValues and LUCENE-3216 we could transparently pack per field files into a single file only for docvalues without changing any code once LUCENE-3216 is resolved.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3218",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Make CFS appendable  ",
    "systemSpecification": true,
    "version": "3.4, 4.0-ALPHA"
}