{
    "comments": [
        {
            "author": "Steve Rowe",
            "body": "RangeFilter should also take in a Locale, to perform the same sort of comparisons.\n\nQueryParser already takes in a Locale, though it was originally intended to be used for date comparisons.  It could forward this Locale, through ConstantScoreRangeQuery, to RangeFilter.",
            "date": "2008-05-02T17:17:25.453+0000",
            "id": 0
        },
        {
            "author": "Yonik Seeley",
            "body": "How do you suggest actually retrieving all of the documents between two endpoints based on non-index ordering?",
            "date": "2008-05-02T19:31:16.783+0000",
            "id": 1
        },
        {
            "author": "Steve Rowe",
            "body": "(Wild guess): iterate over all terms instead of iterating over terms between the lower and upper term.  Hmm, this is going to be slow.\n\nThe implementation could default to the current behavior if no/null Locale is supplied.",
            "date": "2008-05-02T20:01:24.437+0000",
            "id": 2
        },
        {
            "author": "Steve Rowe",
            "body": "Attaching a patch containing class CollatingRangeQuery, which extends RangeQuery, overriding the rewrite() method.  A test class is also supplied.  This is targetted at contrib/.\n\nBecause *all* index terms in the Field of the lower and upper terms of the range have to be examined, since index term ordering (Unicode code point order) is not necessarily the same as the collation in the given Locale, CollatingRangeQuery's will be significantly slower than the RangeQuery's.\n\nOne of the tests uses some of the Farsi information Esra supplied in the original post.  Note that neither Java 1.4.2 nor 1.5.0 contains collation information for Farsi.  Instead, the test uses the Arabic Locale, which appears to contain the proper letter ordering for the non-Arabic Farsi letters.",
            "date": "2008-05-05T04:38:56.522+0000",
            "id": 3
        },
        {
            "author": "Hoss Man",
            "body": "a few random thoughts:\n\n1) you should be able to at least start the enumerator by skiping to a term consisting of the lowerTermField and the termText of \"\" ... even if the Collation of the term text is random, you still know which field you want.\n\n2) why can a collator only be specified by a Locale, why not just let people specify the Collator they want directly?\n\n3) instead of adding a new public CollatingRangeQuery, would it make more sense to add an optional Collator to RangeQuery (and RangeFilter) which triggers a different code path when non null?  (from a performance standpoint it would basically be one conditional check at the begining of the rewrite method.)\n\n4) when i first saw the thread that spawned this issue, my first reaction was to wonder if it would make sense to start allowing a Collator to be specified when indexing, and to use the raw bytes from the CollationKey as the indexed value -- I haven't thought it through very hard, but i wonder if that would be feasible (it seems like it would certainly faster at query time, since it would allow more traditional term skipping.",
            "date": "2008-05-06T04:37:19.075+0000",
            "id": 4
        },
        {
            "author": "Steve Rowe",
            "body": "bq. 1) you should be able to at least start the enumerator by skiping to a term consisting of the lowerTermField and the termText of \"\" ... even if the Collation of the term text is random, you still know which field you want.\n\nI thought I did that - from the patch:\n\n{code:java}\n    TermEnum enumerator = reader.terms(new Term(getField(), \"\"));\n    ...\n  public String getField() {\n    return (lowerTerm != null ? lowerTerm.field() : upperTerm.field());\n  }\n{code}\n\nbq. 2) why can a collator only be specified by a Locale, why not just let people specify the Collator they want directly?\n\nIn the java-user thread that spawned this issue, I mentioned that this would be necessary for custom Collators.  I used Locale because it's simpler to specify, but you're right, directly specifying a Collator makes more sense.\n\nbq. 3) instead of adding a new public CollatingRangeQuery, would it make more sense to add an optional Collator to RangeQuery (and RangeFilter) which triggers a different code path when non null? (from a performance standpoint it would basically be one conditional check at the begining of the rewrite method.)\n\nThis was my original thought, but since the performance impact could be large compared to a standard RangeQuery, I thought it made more sense to put it where it couldn't be used accidentally :).  I can redo it to integrate with the existing classes, though.\n\nbq. 4) when i first saw the thread that spawned this issue, my first reaction was to wonder if it would make sense to start allowing a Collator to be specified when indexing, and to use the raw bytes from the CollationKey as the indexed value - I haven't thought it through very hard, but i wonder if that would be feasible (it seems like it would certainly faster at query time, since it would allow more traditional term skipping.\n\nI thought of something similar, but wow, this would be large.  It would require that the exact Collator used to generate the index terms also be used to generate CollationKeys for RangeQuery's/Filter's -- the Collator's rules would have to be stored in the index.  Also, how would binary CollationKey (de-)serialization fit into the String (de-)serialization currently in place for index terms?\n\nMy guess is that the functionality provided here is most useful for fields with a small number of terms -- especially in the case of RangeQuery's, where the BooleanQuery clause limit is not guarded against.  Given this IMHO most likely scenario, the performance optimization you're talking about (and the attendant code complexification) probably isn't warranted.\n",
            "date": "2008-05-06T13:09:12.642+0000",
            "id": 5
        },
        {
            "author": "Hoss Man",
            "body": "bq. I thought I did that \n\nmy bad.  i missread.\n\nbq. since the performance impact could be large compared to a standard RangeQuery, I thought it made more sense to put it where it couldn't be used accidentally\n\nHmmm...  excellent point.  you convinced me.\n\nBTW: if hooks for CollatingRangeQuery are added to QueryParser, it shouldn't use this class just because a Locale is specified -- that would cause some unexpected results for people who have been specifying a Locale for date reasons. a new \"setter\" would need to indicate when to pay attention to Collation.",
            "date": "2008-05-08T22:30:57.647+0000",
            "id": 6
        },
        {
            "author": "Steve Rowe",
            "body": "bq. Hmmm... excellent point. you convinced me.\n\nOkay. :)  At your (previous) suggestion, I have redone the patch (will attach shortly), moving the collating stuff into RangeQuery and RangeFilter, with enabling bits in QueryParser and ConstantScoreRangeQuery.  I put WARNING text in the javadoc for each method that invokes the expensive index Term iteration, so hopefully that will give pause to those who might otherwise unwittingly slow things down.\n\nbq. BTW: if hooks for CollatingRangeQuery are added to QueryParser, it shouldn't use this class just because a Locale is specified - that would cause some unexpected results for people who have been specifying a Locale for date reasons. a new \"setter\" would need to indicate when to pay attention to Collation.\n\nI added a new setter to QueryParser for this purpose: {{setRangeCollator(Collator)}}.",
            "date": "2008-05-09T05:03:10.580+0000",
            "id": 7
        },
        {
            "author": "Steve Rowe",
            "body": "Rewritten patch, with the collating range functionality now added to existing classes RangeQuery and RangeFilter.\n\nAll tests pass.",
            "date": "2008-05-09T05:05:03.044+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "Grant, what's the game plan on this one?",
            "date": "2008-09-08T11:29:50.816+0000",
            "id": 9
        },
        {
            "author": "Grant Ingersoll",
            "body": "Steve, can you update this for trunk (assuming SVN is working)?",
            "date": "2008-09-12T13:09:56.347+0000",
            "id": 10
        },
        {
            "author": "Steve Rowe",
            "body": "Updated to current trunk revision (694771).  Mostly this consisted of switching away from deprecated Hits in tests.\n\nAlso, I used JavaCC 4.1 to regenerate QueryParser.java et al., and it looks like all of the files in the o.a.l.queryParser package have been changed - apparently the last time they were generated, JavaCC 4.0 was used.\n\nAll tests pass for me (except TestIndexReaderReopen.testThreadSafety(), which I just posted to java-dev about, and which should be completely unrelated to this issue).",
            "date": "2008-09-12T18:41:02.840+0000",
            "id": 11
        },
        {
            "author": "Grant Ingersoll",
            "body": "{quote}\nMostly this consisted of switching away from deprecated Hits in tests. \n{quote}\n\nSeems like the new tests in TestRangeFilter still uses Hits.\n\nAlso, from the Collator javadocs:\n{quote}\nWhen sorting a list of Strings however, it is generally necessary to compare each String multiple times. In this case, CollationKeys provide better performance. The CollationKey class converts a String to a series of bits that can be compared bitwise against other CollationKeys. A CollationKey is created by a Collator object for a given String. \n{quote}\n\nI don't think we need to implement this now, but I wonder if there is a performance difference if we created the CollationKey for comparison.  The big question is whether the construction of that for each term outweighs the savings by repeated comparisons to lower and upper.  \n\nOne more question, and it probably shows my lack of knowledge here, but would it be possible to enumerate the various codepoints where there are problems and just handle these separately, somehow?  Basically, how pervasive is the problem?  Would we perhaps be better off having a check to see if one of these bad codepoints falls in the range of lower/upper and then handle it separately?  Or, perhaps, some reasoning  would allow us to better narrow in on the lowerTerm/upper instead of having to check the whole field.  Just thinking out loud...\n\nOtherwise, looks pretty good.",
            "date": "2008-09-13T13:46:52.654+0000",
            "id": 12
        },
        {
            "author": "Steve Rowe",
            "body": "bq. Seems like the new tests in TestRangeFilter still uses Hits.\n\nThanks, I missed those - this new patch removes Hits usages; also, switched a few deprecated Field.Index.UN_TOKENIZED usages to NOT_ANALYZED.\n\nAll tests pass.",
            "date": "2008-09-13T17:17:33.906+0000",
            "id": 13
        },
        {
            "author": "Steve Rowe",
            "body": "{quote}\nfrom the Collator javadocs:\nbq. When sorting a list of Strings however, it is generally necessary to compare each String multiple times. In this case, CollationKeys provide better performance. The CollationKey class converts a String to a series of bits that can be compared bitwise against other CollationKeys. A CollationKey is created by a Collator object for a given String. \n\nI don't think we need to implement this now, but I wonder if there is a performance difference if we created the CollationKey for comparison. The big question is whether the construction of that for each term outweighs the savings by repeated comparisons to lower and upper.\n{quote}\n\nI think the problem is that every single index term has to be converted to a CollationKey for every single (range) search.  In an earlier comment on this issue, Hoss said:\n\nbq. 4) when i first saw the thread that spawned this issue, my first reaction was to wonder if it would make sense to start allowing a Collator to be specified when indexing, and to use the raw bytes from the CollationKey as the indexed value - I haven't thought it through very hard, but i wonder if that would be feasible (it seems like it would certainly faster at query time, since it would allow more traditional term skipping.\n\nI'm working on a utility class to store arbitrary binary in sortable, indexable Strings, so that CollationKeys can be stored in the index.  IMHO, though, this issue should still go forward.\n\nbq. One more question, and it probably shows my lack of knowledge here, but would it be possible to enumerate the various codepoints where there are problems and just handle these separately, somehow? Basically, how pervasive is the problem? Would we perhaps be better off having a check to see if one of these bad codepoints falls in the range of lower/upper and then handle it separately?\n\nLanguages, in some cases using the same character repertoire, define different orderings.  Also, I believe some orderings are context dependent - you can't always compare character by character.   So adding this stuff to Lucene would be to duplicate a lot of the stuff that's already done in the Collator.",
            "date": "2008-09-13T17:45:47.303+0000",
            "id": 14
        },
        {
            "author": "Grant Ingersoll",
            "body": "{quote}\nI think the problem is that every single index term has to be converted to a CollationKey for every single (range) search. \n{quote}\n\nYes, agreed.  The question mainly is would that be faster than the String comparisons.  Basically, is a construction plus a bitwise compare faster than a string compare?  \n\n\n{quote}\nLanguages, in some cases using the same character repertoire, define different orderings. Also, I believe some orderings are context dependent - you can't always compare character by character. So adding this stuff to Lucene would be to duplicate a lot of the stuff that's already done in the Collator.\n{quote}\n\nMakes sense, was just wondering if there were some shortcuts to be had since we have a very particular case and I was thinking maybe it would allow us to narrow down the range to search.\n\nFor instance, hypothetically speaking, say your field had a full range of words starting with A up to Z, but that you knew the ordering problem only occurred between L and P and that your lower and upper terms K and Q, then you could feel confident that you could skip to K and stop at Q w/o any ramifications.  I realize this is repeating what is in the Collator, but it would be nice if the collator exposed the info.  However, perhaps, if using a RuleBasedCollator, the getRules() method could be used to optimize.  Again, just thinking out loud, I haven't explored it.\n\nI agree, this should still go forward, even as is.\n",
            "date": "2008-09-14T16:20:15.847+0000",
            "id": 15
        },
        {
            "author": "Grant Ingersoll",
            "body": "Committed revision 696056.",
            "date": "2008-09-16T21:03:44.912+0000",
            "id": 16
        },
        {
            "author": "Steve Rowe",
            "body": "Hoss wrote:\n\nbq. 4) when i first saw the thread that spawned this issue, my first reaction was to wonder if it would make sense to start allowing a Collator to be specified when indexing, and to use the raw bytes from the CollationKey as the indexed value - I haven't thought it through very hard, but i wonder if that would be feasible (it seems like it would certainly faster at query time, since it would allow more traditional term skipping.\n\nSee LUCENE-1435, which is an implementation of this idea.",
            "date": "2008-11-01T05:01:58.917+0000",
            "id": 17
        }
    ],
    "component": "core/search",
    "description": "See [this java-user discussion|http://www.nabble.com/lucene-farsi-problem-td16977096.html] of problems caused by Unicode code-point comparison, instead of collation, in RangeQuery.\n\nRangeQuery could take in a Locale via a setter, which could be used with a java.text.Collator and/or CollationKey's, to handle ranges for languages which have alphabet orderings different from those in Unicode.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1279",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "RangeQuery and RangeFilter should use collation to check for range inclusion",
    "systemSpecification": true,
    "version": "2.3.1"
}