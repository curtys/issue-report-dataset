{
    "comments": [
        {
            "author": "Grant Ingersoll",
            "body": "This seems generally useful and could go in contrib/analysis I suppose.  Any thoughts on it, Mark, in hindsight?  Do you still use it from time to time or do you now think there are better ways of doing it?",
            "date": "2008-01-10T20:33:21.283+0000",
            "id": 0
        },
        {
            "author": "Grant Ingersoll",
            "body": "I think it makes sense to add this in after the 2.3 release.",
            "date": "2008-01-12T23:11:26.098+0000",
            "id": 1
        },
        {
            "author": "Mark Harwood",
            "body": "I personally don't use this but others may. It was easier to solve my particular problem by adding stop words to my XSL query templates (I added support to the XMLQueryParser for the \"FuzzyLikeThisQuery\" tag to take stop words). This was more about ease of configuration in my particular app.\n\nI know Nutch has something similar implemented elsewhere - maybe in the query parser.\n\nI also had the notion that wrapping IndexReader to auto-cache TermDocs for super-popular terms using a BitSet would be a good way to avoid the IO overhead. This Bitset wouldn't help resolve positional queries e.g. phrase/span queries which need a TermPositions implementation but would work for straight TermQueries.\n\n",
            "date": "2008-01-14T23:54:37.185+0000",
            "id": 2
        },
        {
            "author": "Grant Ingersoll",
            "body": "Committed, thanks Mark!",
            "date": "2008-02-07T14:13:52.422+0000",
            "id": 3
        }
    ],
    "component": "modules/analysis",
    "description": "An analyzer used primarily at query time to wrap another analyzer and provide a layer of protection\nwhich prevents very common words from being passed into queries. For very large indexes the cost\nof reading TermDocs for a very common word can be  high. This analyzer was created after experience with\na 38 million doc index which had a term in around 50% of docs and was causing TermQueries for \nthis term to take 2 seconds.\n\nUse the various \"addStopWords\" methods in this class to automate the identification and addition of \nstop words found in an already existing index.",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-494",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Analyzer for preventing overload of search service by queries with common terms in large indexes",
    "systemSpecification": true,
    "version": "2.4"
}