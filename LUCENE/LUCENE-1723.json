{
    "comments": [
        {
            "author": "Robert Muir",
            "body": "Dima, have you tried your test against the latest lucene trunk?\n\nI got these results:\n{noformat}\norg.apache.lucene.analysis.standard.StandardAnalyzer passed, value highlighted: <b>thetext</b>\norg.apache.lucene.analysis.SimpleAnalyzer passed, value highlighted: <b>thetext</b>\norg.apache.lucene.analysis.StopAnalyzer passed, value highlighted: <b>thetext</b>\norg.apache.lucene.analysis.WhitespaceAnalyzer passed, value highlighted: <b>thetext</b>\norg.apache.lucene.analysis.NewKeywordAnalyzer passed, value highlighted: <b>thetext</b>\norg.apache.lucene.analysis.KeywordAnalyzer passed, value highlighted: <b>thetext</b>\n{noformat}\n\nmaybe you can verify the same?",
            "date": "2009-06-30T03:03:45.151+0000",
            "id": 0
        },
        {
            "author": "Dima May",
            "body": "Verified! You are absolutely correct, the bug has been fixed on the latest trunk. The next method in the KeywordTokenizer now sets the start and end offsets:\n\n   reusableToken.setStartOffset(input.correctOffset(0))\n   reusableToken.setEndOffset(input.correctOffset(upto));\n\nI will resolve and close the ticket. Sorry for the trouble and thank you for the prompt attention. \n",
            "date": "2009-06-30T03:57:46.965+0000",
            "id": 1
        }
    ],
    "component": "modules/analysis",
    "description": "KeywordTokenizer sets the Token's term length attribute but appears to omit the end offset. The issue was discovered while using a highlighter with the KeywordAnalyzer. KeywordAnalyzer delegates to KeywordTokenizer propagating the bug. \n\nBelow is a JUnit test (source is also attached) that exercises various analyzers via a Highlighter instance. Every analyzer but the KeywordAnazlyzer successfully wraps the text with the highlight tags, such as \"<b>thetext</b>\". When using KeywordAnalyzer the tags appear before the text, for example: \"<b></b>thetext\". \n\nPlease note NewKeywordAnalyzer and NewKeywordTokenizer classes below. When using NewKeywordAnalyzer the tags are properly placed around the text. The NewKeywordTokenizer overrides the next method of the KeywordTokenizer setting the end offset for the returned Token. NewKeywordAnalyzer utilizes KeywordTokenizer to produce proper token.\n\nUnless there is an objection I will gladly post a patch in the very near future . \n\n-----------------------------\npackage lucene;\n\nimport java.io.IOException;\nimport java.io.Reader;\n\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.KeywordAnalyzer;\nimport org.apache.lucene.analysis.KeywordTokenizer;\nimport org.apache.lucene.analysis.SimpleAnalyzer;\nimport org.apache.lucene.analysis.StopAnalyzer;\nimport org.apache.lucene.analysis.Token;\nimport org.apache.lucene.analysis.TokenStream;\nimport org.apache.lucene.analysis.Tokenizer;\nimport org.apache.lucene.analysis.WhitespaceAnalyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.search.highlight.Highlighter;\nimport org.apache.lucene.search.highlight.QueryScorer;\nimport org.apache.lucene.search.highlight.SimpleHTMLFormatter;\nimport org.apache.lucene.search.highlight.WeightedTerm;\nimport org.junit.Test;\nimport static org.junit.Assert.*;\n\npublic class AnalyzerBug {\n\n\t@Test\n\tpublic void testWithHighlighting() throws IOException {\n\t\tString text = \"thetext\";\n\t\tWeightedTerm[] terms = { new WeightedTerm(1.0f, text) };\n\n\t\tHighlighter highlighter = new Highlighter(new SimpleHTMLFormatter(\n\t\t\t\t\"<b>\", \"</b>\"), new QueryScorer(terms));\n\n\t\tAnalyzer[] analazers = { new StandardAnalyzer(), new SimpleAnalyzer(),\n\t\t\t\tnew StopAnalyzer(), new WhitespaceAnalyzer(),\n\t\t\t\tnew NewKeywordAnalyzer(), new KeywordAnalyzer() };\n\n\t\t// Analyzers pass except KeywordAnalyzer\n\t\tfor (Analyzer analazer : analazers) {\n\t\t\tString highighted = highlighter.getBestFragment(analazer,\n\t\t\t\t\t\"CONTENT\", text);\n\t\t\tassertEquals(\"Failed for \" + analazer.getClass().getName(), \"<b>\"\n\t\t\t\t\t+ text + \"</b>\", highighted);\n\t\t\tSystem.out.println(analazer.getClass().getName()\n\t\t\t\t\t+ \" passed, value highlighted: \" + highighted);\n\t\t}\n\t}\n}\n\nclass NewKeywordAnalyzer extends KeywordAnalyzer {\n\n\t@Override\n\tpublic TokenStream reusableTokenStream(String fieldName, Reader reader)\n\t\t\tthrows IOException {\n\t\tTokenizer tokenizer = (Tokenizer) getPreviousTokenStream();\n\t\tif (tokenizer == null) {\n\t\t\ttokenizer = new NewKeywordTokenizer(reader);\n\t\t\tsetPreviousTokenStream(tokenizer);\n\t\t} else\n\t\t\ttokenizer.reset(reader);\n\t\treturn tokenizer;\n\t}\n\n\t@Override\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\n\t\treturn new NewKeywordTokenizer(reader);\n\t}\n}\n\nclass NewKeywordTokenizer extends KeywordTokenizer {\n\tpublic NewKeywordTokenizer(Reader input) {\n\t\tsuper(input);\n\t}\n\n\t@Override\n\tpublic Token next(Token t) throws IOException {\n\t\tToken result = super.next(t);\n\t\tif (result != null) {\n\t\t\tresult.setEndOffset(result.termLength());\n\t\t}\n\t\treturn result;\n\t}\n}\n",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-1723",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "KeywordTokenizer does not properly set the end offset",
    "systemSpecification": true,
    "version": "2.4.1"
}