{
    "comments": [
        {
            "author": "Grant Ingersoll",
            "body": "Patch shortly.  This will be all new code, other than minor changes to include javadocs.  I am going to create contrib/wikipedia, as there are probably other things that can go in here once the seed is started.",
            "date": "2008-01-02T16:12:08.270+0000",
            "id": 0
        },
        {
            "author": "Grant Ingersoll",
            "body": "Adds contrib/wikipedia.  Updates the javadocs build and the site docs.\n\nWill commit Friday, pending feedback.\n\nCurrent issues:\nDoesn't assign multiple types to tokens that have more than one possible type, i.e. something like '''[[link]]''' (a bold link).  In this case, I assign the more important type: the link.",
            "date": "2008-01-02T16:44:17.759+0000",
            "id": 1
        },
        {
            "author": "Grant Ingersoll",
            "body": "Should now handle external links with non link text, i.e. [http://foo.com/junk Foo Junk] and spit out 3 tokens: http://foo.com/junk, Foo, Junk",
            "date": "2008-01-02T19:32:11.398+0000",
            "id": 2
        },
        {
            "author": "Grant Ingersoll",
            "body": "More URL testing and fixes.",
            "date": "2008-01-02T19:46:47.018+0000",
            "id": 3
        },
        {
            "author": "Grant Ingersoll",
            "body": "More legible unit test.  Also now skips HTML tags from within the text.  Fixed issue with heading.  Added support for <ref> tag in addition to the brace-based citation {{",
            "date": "2008-01-02T22:45:21.562+0000",
            "id": 4
        },
        {
            "author": "Doug Cutting",
            "body": "Should the position increment be zero for link urls, so that phrase searches work correctly with anchors?  One might even index URLs in a separate field...",
            "date": "2008-01-03T19:22:23.403+0000",
            "id": 5
        },
        {
            "author": "Grant Ingersoll",
            "body": "{quote}\nShould the position increment be zero for link urls, so that phrase searches work correctly with anchors? \n{quote}\n\nGood point.  I will look into it.\n\n{quote}\nOne might even index URLs in a separate field...\n{quote}\n\nYep, there are all kinds of fun things you can do with the various pieces, and the TeeTokenFilter/SinkTokenizer is really handy for this stuff. ",
            "date": "2008-01-03T20:41:28.694+0000",
            "id": 6
        },
        {
            "author": "Grant Ingersoll",
            "body": "The first alphanum in internal and external link gets a positionIncrement of 0, so phrases can still work.",
            "date": "2008-01-03T22:09:40.310+0000",
            "id": 7
        },
        {
            "author": "Grant Ingersoll",
            "body": "Handle anchors in links and check for various link conditions",
            "date": "2008-01-04T02:36:26.702+0000",
            "id": 8
        },
        {
            "author": "Grant Ingersoll",
            "body": "Adds in EXTERNAL_LINK_URL type to distinguish the first token of an external link from the other tokens.\n\nAlso adds in a POM template, so this project can be mavenized.\n\nAre we there yet?",
            "date": "2008-01-04T03:10:05.557+0000",
            "id": 9
        },
        {
            "author": "Grant Ingersoll",
            "body": "Committed.",
            "date": "2008-01-04T14:29:52.361+0000",
            "id": 10
        },
        {
            "author": "Grant Ingersoll",
            "body": "I updated the link slightly to increment the first token of a link (i.e. the URL or the Wiki link) and then not increment the next token in the link, such that the link and the first display token will be at the same position instead of the first way I had it which put the link token at the same position as the previous token.\n\nI also modified the EXTERNAL link state to recognize https",
            "date": "2008-01-04T20:17:10.278+0000",
            "id": 11
        }
    ],
    "component": "modules/analysis",
    "description": "I have extended StandardTokenizer to recognize Wikipedia syntax and mark tokens with certain attributes.  It isn't necessarily complete, but it does a good enough job for it to be consumed and improved by others.\n\nIt sets the Token.type() value depending on the Wikipedia syntax (links, internal links, bold, italics, etc.) based on my pass at http://en.wikipedia.org/wiki/Wikipedia:Tutorial\n\nI have only tested it with the benchmarking EnwikiDocMaker wikipedia stuff and it seems to do a decent job.\n\nCaveats:  I am not sure how to best handle testing, since the content is licensed under GNU Free Doc License, I believe I can't copy and paste a whole document into the unit test.  I have hand coded one doc and have another one that just generally runs over the benchmark Wikipedia download.\n\nOne more question is where to put it.  It could go in analysis, but the tests at least will have a dependency on Benchmark.  I am thinking of adding a new contrib/wikipedia where this could grow to have other wikipedia things (perhaps we would move EnwikiDocMaker there????) and reverse the dependency on Benchmark.\n\nI will post a patch over the next few days.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1103",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "WikipediaTokenizer",
    "systemSpecification": true,
    "version": ""
}