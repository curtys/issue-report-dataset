{
    "comments": [
        {
            "author": "Yonik Seeley",
            "body": "Attaching patch.\n\nChanges:\n\n- Only open a single IndexInput for the .nrm file and reuse it for all\nnorms sharing that file in the segment.  No clone is needed since\nonly a single norm is read at any time.\n\n- close norms when no longer needed (idea from Michael)\n\n- removed extra IndexInput clone() when reading the norms... why was this there originally?\n",
            "date": "2007-03-03T18:43:48.285+0000",
            "id": 0
        },
        {
            "author": "Yonik Seeley",
            "body": "> - removed extra IndexInput clone() when reading the norms... why was this there originally? \n\nGoing back to the original SegmentReader implementation (2001), getNorms() wasn't synchronized, hence the clone of IndexInput was needed.",
            "date": "2007-03-03T20:06:38.954+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "Whoa, you beat me to it: this was the next bug I was about to open!\n\nAnd I had worked through a patch, even setting in = null in the newly\nadded Norm.close method :)\n\nAnd then also re-discovering that TestMultiSearcher closes its\nsearcher and then keeps using it...\n\nYour patch looks perfect to me.  +1\n\nI like the removal of the .clone() since norms(...) is synchronized.\n\nThe one thing I was still trying to work out is if we could somehow\nclose the singleNormStream once all Norm instances that share it had\ncached.  It seems like a nice to have, but, since norms(...) is\nalready synchronized we could have a simple refcount to track how many\nNorm instances still required it and then close the stream when that\nhits 0?  This way we can free up 1 more file descriptor in certain\ncases.",
            "date": "2007-03-03T23:24:00.079+0000",
            "id": 2
        },
        {
            "author": "Yonik Seeley",
            "body": "Yeah, I considered refcounting the input, but I'm not sure that it's worth it.\nThe reason is predictability... since you don't know what queries are coming, you don't know when that descriptor will be closed, and hence need to plan for the upper bound on descriptor usage anyway.",
            "date": "2007-03-04T03:04:17.151+0000",
            "id": 3
        },
        {
            "author": "Yonik Seeley",
            "body": "committed.  Thanks for the review Mike.",
            "date": "2007-03-04T03:23:53.148+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "> The reason is predictability... since you don't know what queries are coming, you don't know when that descriptor will be closed, and hence need to plan for the upper bound on descriptor usage anyway.\n\nAgreed, the upper bound is what counts here, so it's not much help to reduce by one at some random later time.",
            "date": "2007-03-04T08:01:28.770+0000",
            "id": 5
        },
        {
            "author": "Doron Cohen",
            "body": "wow..  I totally missed this point in 756.  Fix here seems perfect to me too. Thanks for catching and fixing this Yonik.",
            "date": "2007-03-04T08:21:48.758+0000",
            "id": 6
        }
    ],
    "component": "",
    "description": "The new index file format with a single .nrm file for all norms does not decrease file descriptor usage.\nThe .nrm file is opened once for each field with norms in the index segment.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-821",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "single norm file still uses up descriptors",
    "systemSpecification": true,
    "version": ""
}