{
    "comments": [
        {
            "author": "Hoss Man",
            "body": "The one worry i have about an approach like this comes from the fine print of the CollationKey docs...\n\nbq. You can only compare CollationKeys generated from the same Collator object.\n\n\"same\" tends to have a very specific meaning in Java documentation, .. it's usually used to indicate refrence equality (ie \"==\" not .equals) ...\n\nbq. The equals method for class Object implements the most discriminating possible equivalence relation on objects; that is, for any non-null reference values x and y, this method returns true if and only if x and y refer to the same object (x == y has the value true).\n\nso the question becomes: did they reall mean \"same Collator\" or did they mean \"a Collator with the same rules\" ? \n\nis it safe to persist a CollationKey from a Collator A and then compare it with a CollationKey from another Collator B where A.equals(B) but A != B (because A and B are from different JVM instances?)",
            "date": "2008-11-01T18:22:44.887+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "at least in ICU, its not completely safe.  If the different JVM instances are \"different\" in version (upgrade, etc) then it would be a shame to find your sorts all busted. \n\nWhen comparing keys, it is important to know that both keys were generated by the same algorithms and weightings. Otherwise, identical strings with keys generated on two different dates, for example, might compare as unequal. Sort keys can be affected by new versions of ICU or its data tables, new sort key formats, or changes to the Collator.\n\nhttp://www.icu-project.org/userguide/Collate_ServiceArchitecture.html",
            "date": "2008-11-01T21:48:43.974+0000",
            "id": 1
        },
        {
            "author": "Steve Rowe",
            "body": "Three problems I can think of off the top of my head with attempting an automatically managed solution to the problem of CollationKey comparability:\n\n# There doesn't seem to be any way of ascertaining the RuleBasedCollator version, so one would have to store exact JVM version and Locale used to genenerate the Collator, and the strength used, and then fail any range or sort operations if the indexed CollationKeys were produced with ones different from the current ones.\n# Lucene doesn't have an index-level per-field place to store arbitrary information.\n# Other implementations of java.text.Collator, besides RuleBasedCollator, are certainly possible.\n\nSo, it seems to me, either the user of this functionality has to manage the versioning external to the Lucene index, or they can't use the functionality :).\n\nWould strong warnings in the javadocs be enough to allow people to take appropriate precautions?",
            "date": "2008-11-02T17:16:43.397+0000",
            "id": 2
        },
        {
            "author": "Robert Muir",
            "body": "One alternative is that the ICU implementation has versioning specifically for this purpose.\n\nThe version information of Collator is a 32-bit integer. If a new version of ICU has changes affecting the content of collation elements, the version information will be changed. In that case, to use the new version of ICU collator will require regenerating any saved or stored sort keys. However, since ICU 1.8.1. it is possible to build your program so that it uses more than one version of ICU. Therefore, you could use the current version for the features you need and use the older version for collation.",
            "date": "2008-11-02T18:32:52.631+0000",
            "id": 3
        },
        {
            "author": "Hoss Man",
            "body": "bq. So, it seems to me, either the user of this functionality has to manage the versioning external to the Lucene index, or they can't use the functionality .\n\nbq. Would strong warnings in the javadocs be enough to allow people to take appropriate precautions?\n\nI agree with you on both points ... this is really just an extension of warning people to use compatible analyzers when indexing/querying. \n\n(I only brought it up in my first comment because i know very little about the internals of *any* Collator Implementations out there, and i wasn't sure if *all* Implementations produces keys that were only comparable between \"same\" instances .. as long as there are *some* implementations of Collator that products keys which can be compared between \"equivalent\" instances, then this feature certainly seems useful.",
            "date": "2008-11-03T18:20:04.710+0000",
            "id": 4
        },
        {
            "author": "Steve Rowe",
            "body": "Robert Muir wrote:\n\nbq. One alternative is that the ICU implementation has versioning specifically for this purpose. \n\nI'll look into using RegexQuery as a model here (it enables use of either java.util.regex or Jakarta Regexp, defaulting to java.util.regex), and try to add CollatorCapable/CollatorCapabilities, so that ICU's Collator implementation will be usable.",
            "date": "2008-11-03T18:59:06.626+0000",
            "id": 5
        },
        {
            "author": "Steve Rowe",
            "body": "Hoss wrote:\n\n{quote}\nbq. So, it seems to me, either the user of this functionality has to manage the versioning external to the Lucene index, or they can't use the functionality .\n\nbq. Would strong warnings in the javadocs be enough to allow people to take appropriate precautions?\n\nI agree with you on both points ... this is really just an extension of warning people to use compatible analyzers when indexing/querying. \n{quote}\n\nI will add warnings about this issue to the javadocs.",
            "date": "2008-11-03T19:01:43.903+0000",
            "id": 6
        },
        {
            "author": "Steve Rowe",
            "body": "Modifications in this patch:\n\n# Added dependency on ICU4J 4.0\n# Introduced ICUCollationKeyFilter, which uses ICU collation to produce the collation keys\n# Added Analyzer versions of the Filters, creating IndexableBinaryStringTools-encoded collation keys from the single token produced by KeywordTokenizer.\n# Centralized testing to a base class, which the four test classes extend, to avoid duplication\n# Moved from contrib/analyzers/o/a/l/analysis/miscellaneous/ to a new contrib package: contrib/collation, because it doesn't make sense to add a dependency to the entire contrib/analyzers package just for ICUCollationKeyFilter/Analyzer\n\nThe external ICU4J dependency, which should be checked into contrib/collation/lib/, can be downloaded here: [http://download.icu-project.org/files/icu4j/4.0/icu4j-4_0.jar].  The license for this jar is included in the patch at contrib/collation/lib/ICU-LICENSE.txt.\n",
            "date": "2008-11-11T05:03:05.805+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "Could we, alternatively, push this change into DocumentsWriter, such that on writing a segment it uses a per-field Collator (FieldInfo would be extended to record this) to sort the terms dict?\n\nI haven't fully thought through the tradeoffs... but it seems like this'd be simpler to use?  Ie rather than putting a CollationKeyFilter in your analyzer chain, and then doing the reverse of this for all searches at search time, you simply set the Collator on the fields (at indexing & searching time, since I agree we should for now not try to serialize into the index which field has which Collator)?\n\nI guess there is a performance cost to using the Collator to do live binary search (during searching) and sorting (during indexing) vs doing unicode String comparisions but in practice at search time this is probably a tiny part of the net cost of searching?",
            "date": "2008-11-11T10:58:10.032+0000",
            "id": 8
        },
        {
            "author": "Steve Rowe",
            "body": "Hi Mike,\n\nbq.Could we, alternatively, push this change into DocumentsWriter, such that on writing a segment it uses a per-field Collator (FieldInfo would be extended to record this) to sort the terms dict?\n\nAre you suggesting to not store collation keys in the index?\n\nbq. I haven't fully thought through the tradeoffs... but it seems like this'd be simpler to use? Ie rather than putting a CollationKeyFilter in your analyzer chain, and then doing the reverse of this for all searches at search time, you simply set the Collator on the fields (at indexing & searching time, since I agree we should for now not try to serialize into the index which field has which Collator)?\n\nThe query-time process in this patch is not the reverse - it is exactly the same.  The String-encoded collation keys stored in the index are compared directly with those from query terms.  Neither the String-encoding nor the CollationKey needs to be reversed.\n\nbq. I guess there is a performance cost to using the Collator to do live binary search (during searching) and sorting (during indexing) vs doing unicode String comparisions but in practice at search time this is probably a tiny part of the net cost of searching?\n\nIn the current code base, for range searching on a collated field, every single term has to be collated with the search term.  This patch allows skipTo to function when using collation, potentially providing a significant speedup.",
            "date": "2008-11-11T18:29:15.307+0000",
            "id": 9
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. Are you suggesting to not store collation keys in the index?\n\nRight, I'm proposing storing the original Strings, but sorted\naccording Collator.compare (for that one field), in the Terms dict.\n\nbq. The query-time process in this patch is not the reverse - it is exactly the same.\n\nOK got it.  Where/how would you implement the query time conversion of\nterms?\n\nAnd wouldn't there be times when you also want to reverse the\nencoding?  EG if you enum all terms for presentation (maybe as part of\nfaceted search for example)?\n\nbq. In the current code base, for range searching on a collated field, every single term has to be collated with the search term. This patch allows skipTo to function when using collation, potentially providing a significant speedup.\n\nBoth the original proposed approach (external-to-indexing) and this\ninternal-to-indexing approach would solve this, right?  Ie, in both\ncases the terms have been sorted according to the Collator, but in the\ninternal-to-indexing case it's the original String term stored in the\nterms dict.\n\nHere are some pros of internal-to-indexing:\n\n  - You don't have to convert every single term visited during\n    analysis first to a CollationKey then ByteBuffer then encoded\n    binary string.  Indexing throughput should be faster?  (Though,\n    when writing the segment you do need to sort using\n    Collator.compare, which I guess could be slow).\n\n  - Real terms are stored in the index -- tools like Luke can look at\n    the index and see normal looking terms.  Though... I don't have a\n    sense of what the encoded term would look like -- maybe it's not\n    that different from the original in practice?\n\n  - Querying would just work without term conversion\n\nAnd some cons:\n\n  - It's obviously a more invasive change to Lucene (and probably\n    should go after the flex-indexing changes).  The\n    external-to-indexing approach is nicely externalized.\n\n  - Performance -- the binary search of the terms index would be\n    slower using Collator.compare instead of String.compareTo (though\n    I would expect this to be minimal in practice).\n\nI'm sure there are many pros/cons I'm missing...\n",
            "date": "2008-11-11T21:18:25.151+0000",
            "id": 10
        },
        {
            "author": "Steve Rowe",
            "body": "bq. And wouldn't there be times when you also want to reverse the encoding? EG if you enum all terms for presentation (maybe as part of faceted search for example)?\n\nAFAIK, CollationKey generation is a one-way operation.  If the original terms are required for presentation, they can be stored, right?\n\n{quote}\nHere are some pros of internal-to-indexing:\n      [...]\n    - Real terms are stored in the index - tools like Luke can look at\n      the index and see normal looking terms. Though... I don't have a\n      sense of what the encoded term would look like - maybe it's not\n      that different from the original in practice?\n{quote}\n\nIndexableBinaryStringTools (LUCENE-1434) implements a base-8000h encoding: the lower 15 bits of each character have 1-7/8 bytes packed into them.  It's radically different from the original byte array, at least in terms of looking at it with a text viewer like Luke.  And I don't think CollationKeys themselves are intended for human consumption.\n\n{quote}\nbq. In the current code base, for range searching on a collated field, every single term has to be collated with the search term. This patch allows skipTo to function when using collation, potentially providing a significant speedup.\n\nBoth the original proposed approach (external-to-indexing) and this\ninternal-to-indexing approach would solve this, right? Ie, in both\ncases the terms have been sorted according to the Collator, but in the\ninternal-to-indexing case it's the original String term stored in the\nterms dict.\n{quote}\n\nPerhaps I'm missing something, but o.a.l.index.TermEnum.skipTo(Term) compares the target term using String.compareTo(), so regardless of the index term dictionary ordering, skipTo() won't necessarily stop at the correct location, right?  From TermEnum.java:\n\n{code:java}\n  public boolean skipTo(Term target) throws IOException {\n     do {\n        if (!next())\n  \t        return false;\n     } while (target.compareTo(term()) > 0);\n     return true;\n  }\n{code}\n\nand here's o.a.l.index.Term.compareTo(Term):\n\n{code:java}\n  public final int compareTo(Term other) {\n    if (field == other.field)\t\t\t  // fields are interned\n      return text.compareTo(other.text);\n    else\n      return field.compareTo(other.field);\n  }\n{code}\n",
            "date": "2008-11-11T21:51:47.415+0000",
            "id": 11
        },
        {
            "author": "Michael McCandless",
            "body": "bq. IndexableBinaryStringTools (LUCENE-1434) implements a base-8000h encoding: the lower 15 bits of each character have 1-7/8 bytes packed into them. It's radically different from the original byte array, at least in terms of looking at it with a text viewer like Luke. And I don't think CollationKeys themselves are intended for human consumption.\n\nOh OK.  So having done this term conversion, you can't really look at / use the resulting terms in the index for human consumption (you'd have to store stuff yourself).\n\nbq. Perhaps I'm missing something, but o.a.l.index.TermEnum.skipTo(Term) compares the target term using String.compareTo(),\n\nBut we could just fix that to pay attention to the Collator for that field, if it has one, right?  (Or with flexible indexing I think the impl really should own this method, ie, it should be abstract in TermEnum).\n\nI think the external approach is fine for starters... I just think long-term it may make sense to have core Lucene respect the Collator, but it really is an invasive change.  We should wait until we make progress on flexible indexing at which point such a change should be far less costly.",
            "date": "2008-11-11T22:31:33.639+0000",
            "id": 12
        },
        {
            "author": "Steve Rowe",
            "body": "{quote}\nbq. Perhaps I'm missing something, but o.a.l.index.TermEnum.skipTo(Term) compares the target term using String.compareTo(),\n\nBut we could just fix that to pay attention to the Collator for that field, if it has one, right? (Or with flexible indexing I think the impl really should own this method, ie, it should be abstract in TermEnum).\n{quote}\n\nUm, yes.  :) \n\nbq. I think the external approach is fine for starters... I just think long-term it may make sense to have core Lucene respect the Collator, but it really is an invasive change. We should wait until we make progress on flexible indexing at which point such a change should be far less costly.\n\nNow that I understand it, I too think the internal-to-indexing approach is cleaner/easier to use/better long-term.  This patch is an attempt to improve on the performance of the range collation facilities introduced in LUCENE-1279.  So I guess the question is whether it's worth putting in another less-than-optimal workaround.",
            "date": "2008-11-11T23:04:50.910+0000",
            "id": 13
        },
        {
            "author": "Michael McCandless",
            "body": "Another use-case for allowing per-field custom sorting of Terms would be simpler numeric RangeQuery.  Ie, right now you have to zero-pad numbers to trick Lucene into sorting them numerically (which causes challenges for BigDecimal, being discussed now on java-user).  But if you could have Lucene sort by the number then numeric range queries would be straightforward.",
            "date": "2008-11-22T19:03:27.110+0000",
            "id": 14
        },
        {
            "author": "Steve Rowe",
            "body": "Removed accidentally included IndexableBinaryString and its test from the patch (see LUCENE-1434 for these).",
            "date": "2008-12-09T00:07:42.481+0000",
            "id": 15
        },
        {
            "author": "Michael McCandless",
            "body": "I think we should commit this to contrib/collation as an \"external\" way to get faster range filters on fields that require custom Collator; at some future point we can consider allowing a given field to sort its terms in some custom way.\n\nMarvin: does KS/Lucy give control over sort order of the terms in a field?",
            "date": "2009-03-18T20:31:06.033+0000",
            "id": 16
        },
        {
            "author": "Michael McCandless",
            "body": "Steven, I'm hitting compilation errors, eg:\n\n{code}\n    [javac] /tango/mike/src/lucene.collation/contrib/collation/src/test/org/apache/lucene/collation/CollationTestBase.java:42: package org.apache.lucene.queryParser.analyzing does not exist\n    [javac] import org.apache.lucene.queryParser.analyzing.AnalyzingQueryParser;\n    [javac]                                               ^\n    [javac] /tango/mike/src/lucene.collation/contrib/collation/src/test/org/apache/lucene/collation/CollationTestBase.java:89: cannot find symbol\n{code}\n\nWhat is AnalyzingQueryParser?",
            "date": "2009-03-18T20:57:59.081+0000",
            "id": 17
        },
        {
            "author": "Steve Rowe",
            "body": "It's in contrib/miscellaneous/\n\nI used AnalyzingQueryParser in the tests to allow CollationKeyFilter to be applied to the terms in the range query - the standard QueryParser doesn't analyze range terms.\n\nFrom:\n\nhttp://lucene.apache.org/java/2_4_1/api/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser.html\n\nbq. Overrides Lucene's default QueryParser so that Fuzzy-, Prefix-, Range-, and WildcardQuerys are also passed through the given analyzer, but wild card characters (like *) don't get removed from the search terms. \n\nThis is a (test-only) cross-contrib dependency.  I'm not sure why I didn't have trouble with compilation - I haven't looked at this in months.  I'll take a look later on tonight.",
            "date": "2009-03-18T21:13:13.146+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "OK, thanks for the pointer -- I learn something new every day!",
            "date": "2009-03-18T21:39:20.585+0000",
            "id": 19
        },
        {
            "author": "Steve Rowe",
            "body": "New patch that compiles.\n\nI'm not sure how this ever worked previously - I must somehow have had lucene-misc-X.jar on the classpath or something.\n\nAnyway, the build.xml in this patch, cribbing from contrib/benchmark/build.xml, first builds contrib/miscellaneous, then adds build/contrib/miscellaneous/classes/java/ to the classpath, so that AnalyzingQueryParser can be linked against.\n\nEverything now compiles, and all contrib tests pass.",
            "date": "2009-03-19T06:33:35.964+0000",
            "id": 20
        },
        {
            "author": "Michael McCandless",
            "body": "Super, thanks Steven.  I plan to commit soon.",
            "date": "2009-03-19T09:40:16.140+0000",
            "id": 21
        },
        {
            "author": "Michael McCandless",
            "body": "Thanks Steven!",
            "date": "2009-03-19T10:52:04.905+0000",
            "id": 22
        }
    ],
    "component": "",
    "description": "Converts each token into its CollationKey using the provided collator, and then encodes the CollationKey with IndexableBinaryStringTools, to allow it to be stored as an index term.\n\nThis will allow for efficient range searches and Sorts over fields that need collation for proper ordering.\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1435",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "CollationKeyFilter: convert tokens into CollationKeys encoded using IndexableBinaryStringTools",
    "systemSpecification": true,
    "version": "2.4"
}