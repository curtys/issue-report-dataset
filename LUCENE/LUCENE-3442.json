{
    "comments": [
        {
            "author": "Uwe Schindler",
            "body": "The issue lies in the fact that an optimization in TermQuery prevents it's Weight.scorer() method to behave correctly when no atomic reader is passed in. This is no longer supported in Lucene trunk, but in 3.x the weight should still be able to work on composite readers. The sample code provided does this exactly: It calls QWF.getDocIdSet on a non-atomic IndexReader. QWF calls TermWeight.scorer() and this one returns null, because the composite reader is not in its DF cache.\n\nThe fix is easy: Don't early exit in scorer() if the reader passed in is not atomic.",
            "date": "2011-09-20T18:53:11.954+0000",
            "id": 0
        },
        {
            "author": "Uwe Schindler",
            "body": "Patch that fixes the issue. It also contains the testcase provided by Dan C.\n\nWill commit soon.",
            "date": "2011-09-20T18:57:17.259+0000",
            "id": 1
        },
        {
            "author": "Uwe Schindler",
            "body": "The issue is caused by LUCENE-2829, committed January and exists since Lucene 3.1.",
            "date": "2011-09-20T19:03:01.714+0000",
            "id": 2
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed 3.x branch revision: 1173311",
            "date": "2011-09-20T19:16:25.020+0000",
            "id": 3
        },
        {
            "author": "Uwe Schindler",
            "body": "Bulk close after release of 3.5",
            "date": "2011-11-27T12:29:25.784+0000",
            "id": 4
        }
    ],
    "component": "core/search",
    "description": "If you try to get the iterator for the DocIdSet returned by a QueryWrapperFilter which wraps a TermQuery you get null instead of an iterator that returns the same documents as the search on the TermQuery.\n\nCode demonstrating the issue:\n\n{code:java}\nimport java.io.IOException;\nimport org.apache.lucene.analysis.WhitespaceAnalyzer;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.lucene.document.Field.Index;\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.index.IndexReader;\nimport org.apache.lucene.index.IndexWriter;\nimport org.apache.lucene.index.IndexWriterConfig;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.store.RAMDirectory;\nimport org.apache.lucene.util.Version;\nimport org.apache.lucene.search.DocIdSet;\nimport org.apache.lucene.search.DocIdSetIterator;\nimport org.apache.lucene.search.Filter;\nimport org.apache.lucene.search.IndexSearcher;\nimport org.apache.lucene.search.QueryWrapperFilter;\nimport org.apache.lucene.search.TermQuery;\nimport org.apache.lucene.search.TopDocs;\n\npublic class TestQueryWrapperFilterIterator {\n   public static void main(String[] args) {\n\t\ttry {\n\t\t\tIndexWriterConfig iwconfig = new IndexWriterConfig(Version.LUCENE_34, new WhitespaceAnalyzer(Version.LUCENE_34));\n\t\t\tiwconfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\t\t\tRAMDirectory dir = new RAMDirectory();\n\t\t\n\t\t\tIndexWriter writer = new IndexWriter(dir, iwconfig);\n\t\t\tDocument d = new Document();\n\t\t\td.add(new Field(\"id\", \"1001\", Store.YES, Index.NOT_ANALYZED));\n\t\t\td.add(new Field(\"text\", \"headline one group one\", Store.YES, Index.ANALYZED));\n\t\t\td.add(new Field(\"group\", \"grp1\", Store.YES, Index.NOT_ANALYZED));\n\t\t    writer.addDocument(d);\n\t\t\twriter.commit();\n\t\t\twriter.close();\n\t\t\t\n\t\t\tIndexReader rdr = IndexReader.open(dir);\n\t\t\tIndexSearcher searcher = new IndexSearcher(rdr);\n\t\t\t\n\t\t\tTermQuery tq = new TermQuery(new Term(\"text\", \"headline\"));\n\t\t\t\n\t\t\tTopDocs results = searcher.search(tq, 5);\n\t\t\tSystem.out.println(\"Number of search results: \" + results.totalHits);\n\t\t\t\n\t\t\tFilter f = new QueryWrapperFilter(tq);\n\t\t\t\n\t\t\tDocIdSet dis = f.getDocIdSet(rdr);\n\t\t\t\n\t\t\tDocIdSetIterator it = dis.iterator();\n\t\t\tif (it != null) {\n\t\t\t\tint docId = it.nextDoc();\n\t\t\t\twhile (docId != DocIdSetIterator.NO_MORE_DOCS) {\n\t\t\t\t\tDocument doc = rdr.document(docId);\n\t\t\t\t\tSystem.out.println(\"Iterator doc: \" + doc.get(\"id\"));\n\t\t\t\t\tdocId = it.nextDoc();\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tSystem.out.println(\"Iterator was null: \");\n\t\t\t}\n\t\t\t\n\t\t\tsearcher.close();\n\t\t\trdr.close();\n\t\t} catch (IOException ioe) {\n\t\t\tioe.printStackTrace();\n\t\t}\n\n\t}\n}\n{code}",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3442",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "QueryWrapperFilter gets null DocIdSetIterator when wrapping TermQuery",
    "systemSpecification": true,
    "version": "3.1, 3.2, 3.3, 3.4"
}