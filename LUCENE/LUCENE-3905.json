{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "Patch.\n\nI also fixed end() offset bug in the ngram tokenizers...",
            "date": "2012-03-23T12:45:40.952+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "+1, we know the ngramtokenizers truncate to the first 1024 chars, but that \ndoesn't mean they can't implement end() correctly so that at least\nhighlighting on multivalued fields etc works.",
            "date": "2012-03-23T12:50:23.416+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "oh one thing: i think we should blast the filter versions of these the same way?\n\ne.g. if i have mocktokenizer + (edge)ngramfilter, are they ok?",
            "date": "2012-03-23T12:53:26.762+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "The ngram filters are unfortunately not OK: they use up tons of RAM when you send random/big tokens through them, because they don't have the same 1024 character limit... I think we should open a new issue for them... in fact I think repairing them could make a good GSoC!",
            "date": "2012-03-23T17:26:35.619+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "I see... well +1 for this commit, its an improvement!",
            "date": "2012-03-23T17:30:01.161+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "OK I opened LUCENE-3907 for ngram love...",
            "date": "2012-03-23T17:33:29.958+0000",
            "id": 5
        }
    ],
    "component": "",
    "description": "We already have LineFileDocs, that pulls content generated from europarl or wikipedia... I think sometimes BTSTC should test the analyzers on that as well.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3905",
    "issuetypeClassified": "OTHER",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "BaseTokenStreamTestCase should test analyzers on real-ish content",
    "systemSpecification": true,
    "version": ""
}