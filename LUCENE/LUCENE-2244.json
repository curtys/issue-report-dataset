{
    "comments": [
        {
            "author": "Andi Vajda",
            "body": "A patch expanding the understanding of the single-quote character to the characters that ASCIIFoldingFilter turns into \"'\".",
            "date": "2010-01-30T23:36:30.943+0000",
            "id": 0
        },
        {
            "author": "Steve Rowe",
            "body": "bq. Maybe a better approach would be to make it possible to have an ASCIIFoldingFilter-like reader as a character filter that could be in inserted in front of StandardTokenizer ?\n\nSOLR-2013 placed an ASCIIFoldingFilter char filter configuration file in Solr's {{example/solr/conf/}} directory.",
            "date": "2010-09-29T06:04:13.371+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "Andi, now that LUCENE-2167 is resolved, i think we should revisit this one.\n\nThere are two issues:\n* does the tokenization work the way it should for these quotes (I think LUCENE-2167 will do the right thing)?\n* does the 's-stripping (analysis.en.EnglishPossessiveFilter) work the way you want?\n\nFor the latter: it could be extended itself to include more apostrophes, maybe from this list: http://unicode.org/cldr/utility/confusables.jsp?a='&r=None\n\nOr someone could put ASCIIFoldingFilter before the EnglishPossessiveFilter.\n",
            "date": "2010-09-29T06:12:56.877+0000",
            "id": 2
        },
        {
            "author": "Uwe Schindler",
            "body": "Since Lucene 3.1 StandardTokenizer was replaced by a new one doing [Unicode Standard Annex #29|http://unicode.org/reports/tr29/] segmentation. This should solve this issue.",
            "date": "2011-01-26T12:09:21.388+0000",
            "id": 3
        }
    ],
    "component": "modules/analysis",
    "description": "In the vein of LUCENE-1126 and LUCENE-1390, StandardTokenizerImpl.jflex should do a better job at understanding non-ASCII punctuation characters.\n\nFor example, its understanding of the single-quote character \"'\" is currently limited to that character only. It will set a token's type to APOSTROPHE only if the \"'\" was used.\nIn the patch attached, I added all the characters that ASCIIFoldingFilter would change into \"'\".\n\nI'm not sure that this is the right approach so I didn't write a complete patch for all the other hardcoded characters used in jflex rules such as \".\", \"-\" which have some variants in ASCIIFoldingFilter that could be used as well.\n\nMaybe a better approach would be to make it possible to have an ASCIIFoldingFilter-like reader as a character filter that could be in inserted in front of StandardTokenizer ?",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-2244",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Improve StandardTokenizer's understanding of non ASCII punctuation and quotes",
    "systemSpecification": true,
    "version": "3.0"
}