{
    "comments": [
        {
            "author": "Uwe Schindler",
            "body": "CharTermAtttribute is also in 3.1.",
            "date": "2010-05-21T21:29:14.039+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "What are your thoughts here Uwe?\n\nShould we fix for 3.1 or leave till 3.2?\n\nIt does seem good if we could possibly fix for 3.1 due to the fact toString() was the only\nreal introspection we had before?\n\nBut at the same time, Solr's analysis.jsp etc doesn't introspect attributes outside of the\noriginal 6 in Token anyway, so maybe we could delay?\n\n\n",
            "date": "2011-01-16T16:43:31.650+0000",
            "id": 1
        },
        {
            "author": "Uwe Schindler",
            "body": "Oh, I forgot about that one! Wanted to fix this. I am currently away from my computer, can we discuss tomorrow?\n\nI really wanted to fix this, sorry.",
            "date": "2011-01-16T16:56:16.803+0000",
            "id": 2
        },
        {
            "author": "Uwe Schindler",
            "body": "I will work tomorrow on a patch with sophisticated backwards for 3.x and merge to trunk without sophisticated things *g*.\n\nI changed my mind a little bit: I would simplify the whole thing: AttributeSource and AttributeImpl should have a simple method:\n{code}\nvoid addToMap(Map<String,?>)\n{code}\n\nThe default code would simply look like AttributeImpl.toString() now and add all non-static fields to the impl - special attributes like CharTermAttribute would have special handling. The default toString() [if not overridden] would simply call this method, too and pass a Fake-Map to the addToMap() method to populate a StringBuilder in Map.put() [to not automatically create a real Map always).\n\nCode in analysis.jsp would simply pass a map (e.g. a LinkedHashMap to preserve order) and then print it out. The values in the map are native types / or CharSequence for (Char)TermAttribute.\n\nThe only problem with this aproach would be that the attribute keys must be unique - an idea would be to prefix them with the attribute name.\n\nI will also remove the abstract equals() and hashCode() in AttributeImpl - the attribute API does not rely on them to be implemented - this simplyfies implementation of attributes, because equals/hashCode are never used. In 4.0 I would remove this from all custom attributes.\n\nWhat do you think?",
            "date": "2011-01-16T23:41:08.165+0000",
            "id": 3
        },
        {
            "author": "Earwin Burrfoot",
            "body": "Nice. Except maybe introduce a simple interface instead of the Map<String, ?> ?\n\n{code}\ninterface AttributeReflector { // Name is crap, should be changed\n  void reflect(String key, Object value);\n}\n\nvoid reflectWith(AttributeReflector reflector);\n{code}\n\nYou have no need for fake maps then, both in toString(), and in user code.\n",
            "date": "2011-01-17T00:15:23.846+0000",
            "id": 4
        },
        {
            "author": "Uwe Schindler",
            "body": "I had the same idea and I am coding it currently.",
            "date": "2011-01-17T00:17:51.846+0000",
            "id": 5
        },
        {
            "author": "Earwin Burrfoot",
            "body": "Another step in the same direction then. Instead of\nbq. The only problem with this aproach would be that the attribute keys must be unique - an idea would be to prefix them with the attribute name.\nLet us define interface as - void reflect(Class<?> attributeClass, String key, Object value) ?\nIf the client code then wants to call toString() on attributeClass and concat with key - it's free to do so. If it wants to be more creative - it can.",
            "date": "2011-01-17T00:36:12.723+0000",
            "id": 6
        },
        {
            "author": "Uwe Schindler",
            "body": "Here a first patch with the proposed API (thanks Earwin).\n\nThe patch is for 3.x, as it contains already the sophisticated(TM) backwards compatibility layer (see javadocs).\n\nStill missing:\n- Remove obsolete toString in contrib/queryparser\n- Test for sophisticated bw\n- Tests for API in general\n- an AttributeChecker test class that checks basic Attribute features and its implementation (copyTo, reflectAsString,...)\n- Solr changes to make use of this API in analysis.jsp and the other TokenStream component\n\nWhat do you think?",
            "date": "2011-01-17T15:44:00.577+0000",
            "id": 7
        },
        {
            "author": "Uwe Schindler",
            "body": "New patch with analysis.jsp fixed (also SOLR-2315):\n- highlighting works again\n- only attributes are shown that exist at the step of analysis\n- attribute names changed a little bit, because it uses the ones from reflection api\n- Attribute class name shown in mouse hover\n- start/endOffset now in two different lines (no chance to do it other without another special case)\n- payloads are no longer printed as text, because it used default platform encoding (new String(byte[]))!\n\nI also added some example screenshots!",
            "date": "2011-01-17T23:43:43.238+0000",
            "id": 8
        },
        {
            "author": "Robert Muir",
            "body": "+1, this looks great.\n\ni think its really important to show all the attributes in analysis.jsp, e.g. KeywordAttribute.\n",
            "date": "2011-01-17T23:50:14.364+0000",
            "id": 9
        },
        {
            "author": "Simon Willnauer",
            "body": "nice work uwe!! +1 ;)",
            "date": "2011-01-18T00:11:42.273+0000",
            "id": 10
        },
        {
            "author": "Uwe Schindler",
            "body": "Next patch - Converted deprecated AnalysisRequestHandler and (Field|Document)AnalysisRequestHandler:\n- Token are now correctly ordered by position not endOffset (this is identical to analysis.jsp)\n- Moved over to AttributeSource\n- support for custom attributes\n- fixed payloads to display as hex like in analysis.jsp (maybe this should be fixed in future to support Payload instances directly in ResponseWriter)\n\nI will now concentrate on contrib/queryparser, Lucene reflection tests and javadocs in Lucene core",
            "date": "2011-01-18T13:58:59.562+0000",
            "id": 11
        },
        {
            "author": "Uwe Schindler",
            "body": "In my opinion, there is lots of code duplication in unmainainable analysis.jsp. I think we should open a new issue to remove it and replace by an XSL or alternatively make its internal functionality backed by FieldAnalysisReuqestHandler.",
            "date": "2011-01-18T14:01:04.886+0000",
            "id": 12
        },
        {
            "author": "Mark Miller",
            "body": "Agreed Uwe.",
            "date": "2011-01-18T15:20:02.182+0000",
            "id": 13
        },
        {
            "author": "Uwe Schindler",
            "body": "Final patch for 3.x:\n- Added some tests for reflection API\n- Added test for sophisticated backwards layer\n\nI will commit this tomorrow and forward-port to trunk.\n\nContrib/queryparsers attributes are not yet compatible with reflection, as the toString() there has wrong format (throws UOE). I will open a separate issue to fix that, this is not a serious problem at the moment, as attribute reflection is not needed there.",
            "date": "2011-01-18T23:14:11.124+0000",
            "id": 14
        },
        {
            "author": "Uwe Schindler",
            "body": "Also converted contrib/queryparser. The problematic thing was that these attributes use an xml-like toString() and so the backwards layer is enabled. So I simply added the reflectWith() method to not use reflection like for toString. But for consistence, in trunk, we should remove toString() and reflectWith().\n\nWill commit tomorrow, as said before.",
            "date": "2011-01-18T23:44:10.760+0000",
            "id": 15
        },
        {
            "author": "Uwe Schindler",
            "body": "Minor upgrades in backwards compatibility layer and javadocs.\nWill commit this now.",
            "date": "2011-01-19T12:03:18.095+0000",
            "id": 16
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed 3.x revision: 1060784\n\nWill now port to trunk without backwards layer.",
            "date": "2011-01-19T12:27:48.671+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "First preview of trunk patch:\n\n- Removed useless equals() and hashCode() from internal attributes\n- Removed backwards layer from previous patch / contrib-qp needs no special handling anymore\n\nSolr:\n\n- Removed deprecated AnalysisRequestHandler instead of fixing it - still test need to be cleaned up\n- (Field|Document)AnalysisRequestHandler now works primarily on BytesRef, especially for highlighting\n- Using BytesRef to wrap Payloads to easy print them as hex using BytesRef.toString()\n- There is still one analysis test failing: as NumericTermAttribute does not support cloning, analysis does not work and test fails. I will now open another issue to fix this (make NumericTermAttribute decoupled from outer TokenStream).\n",
            "date": "2011-01-19T16:28:17.901+0000",
            "id": 18
        },
        {
            "author": "Uwe Schindler",
            "body": "Further TODOs:\n- User TermsHash to collect the match set in AnalysisRequestHandlerBase",
            "date": "2011-01-19T16:42:03.139+0000",
            "id": 19
        },
        {
            "author": "Uwe Schindler",
            "body": "Hopefully final patch:\n- minor changes for resolved NumericTermAttribute clone issue (LUCENE-2875)\n- removed leftover AnalysisRequestHandler in clustering tests\n\nI will commit this tomorrow if no-one objects!",
            "date": "2011-01-19T19:57:15.917+0000",
            "id": 20
        },
        {
            "author": "Uwe Schindler",
            "body": "Final trunk patch, will commit now.",
            "date": "2011-01-19T22:37:58.780+0000",
            "id": 21
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed trunk revision: 1061039",
            "date": "2011-01-19T22:41:41.887+0000",
            "id": 22
        },
        {
            "author": "Grant Ingersoll",
            "body": "Bulk close for 3.1",
            "date": "2011-03-30T15:50:26.737+0000",
            "id": 23
        }
    ],
    "component": "modules/analysis",
    "description": "AttributeSource/TokenStream inspection in Solr needs to have some insight into the contents of AttributeImpls. As LUCENE-2302 has some problems with toString() [which is not structured and conflicts with CharSequence's definition for CharTermAttribute], I propose an simple API that get a default implementation in AttributeImpl (just like toString() current):\n\n- Iterator<Map.Entry<String,?>> AttributeImpl.contentsIterator() returns an iterator (for most attributes its a singleton) of a key-value pair, e.g. \"term\"->\"foobar\",\"startOffset\"->Integer.valueOf(0),...\n- AttributeSource gets the same method, it just concat the iterators of each getAttributeImplsIterator() AttributeImpl\n\nNo backwards problems occur, as the default toString() method will work like before (it just gets iterator and lists), but we simply remove the documentation for the format. (Char)TermAttribute gets a special impl fo toString() according to CharSequence and a corresponding iterator.\n\nI also want to remove the abstract hashCode() and equals() methods from AttributeImpl, as they are not needed and just create work for the implementor.",
    "hasPatch": true,
    "hasScreenshot": true,
    "id": "LUCENE-2374",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Add reflection API to AttributeSource/AttributeImpl",
    "systemSpecification": true,
    "version": ""
}