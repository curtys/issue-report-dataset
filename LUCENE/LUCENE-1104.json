{
    "comments": [
        {
            "author": "Grant Ingersoll",
            "body": "I think the remaining 3 issues are reasonable to keep open",
            "date": "2008-01-12T23:14:23.366+0000",
            "id": 0
        }
    ],
    "component": "modules/analysis",
    "description": "A list of all JIRA issues in component \"Analysis\" that haven't been updated in 2007:\n\n   *\t LUCENE-760  \t Spellchecker could/should use n-gram tokenizers instead of rolling its own n-gramming   \n   *\tLUCENE-677 \tItalian Analyzer \n   *\tLUCENE-571 \tStandardTokenizer parses decimal number as <HOST> \n   *\tLUCENE-566 \tEsperanto Analyzer \n   *\tLUCENE-559 \tTurkish Analyzer for Lucene \n   *\tLUCENE-494 \tAnalyzer for preventing overload of search service by queries with common terms in large indexes \n   *\tLUCENE-424 \t[PATCH] Submissiom form simple Romanian Analyzer \n   *\tLUCENE-417 \tStandardTokenizer has problems with comma-separated values \n   *\tLUCENE-400 \tNGramFilter -- construct n-grams from a TokenStream \n   *\tLUCENE-396 \t[PATCH] Add position increment back into StopFilter \n   *\tLUCENE-387 \tContrib: Main memory based SynonymMap and SynonymTokenFilter \n   *\tLUCENE-321 \t[PATCH] Submissiom of my Tswana Analyzer \n   *\tLUCENE-233 \t[PATCH] analyzer refactoring based on CVS HEAD from 6/21/2004 \n   *\tLUCENE-210 \t[PATCH] Never write an Analyzer again \n   *\tLUCENE-205 \t[PATCH] Patches for RussianAnalyzer \n   *\tLUCENE-185 \t[PATCH] Thai Analysis Enhancement \n   *\tLUCENE-152 \t[PATCH] KStem for Lucene \n   *\tLUCENE-82 \t[PATCH] HTMLParser: IOException: Pipe closed \n\n",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-1104",
    "issuetypeClassified": "OTHER",
    "issuetypeTracker": "OTHER",
    "priority": "Trivial",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Clean up old JIRA issues in component \"Analysis\"",
    "systemSpecification": true,
    "version": ""
}