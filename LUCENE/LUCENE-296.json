{
    "comments": [
        {
            "author": "Daniel Naber",
            "body": "The \"synchronized\" for the similarity() method should no be necessary, should \nit? \n \nI tried modifying the value of TYPICAL_LONGEST_WORD_IN_INDEX (e.g. to 1 or to \n100) and I didn't see any real difference. Are you sure this particular \noptimization is useful? \n \nAs I mentioned, the speedup of all changes together is 20-40% in my short \ntests, so I'm sure this patch will be committed sooner or later. \n ",
            "date": "2004-10-27T04:57:33.000+0000",
            "id": 0
        },
        {
            "author": "Jonathan Hager",
            "body": "The \"synchronized\" was added to the similarity() because it uses the d[][]\nacross calls to it.  If similarity() was called on the SAME FuzzyTermEnum object\nby two different threads, the results could not be guaranteed.  How lucene uses\nFuzzyTermEnum, this will never happen.  Currently, Lucene creates it and let's\nit be garbage collected within a single method.  This is more defensive\nprogramming than anything else.\n\nThe TYPICAL_LONGEST_WORD_IN_INDEX is used in two different context.  The first\ncontext is to initializing the d[][] to something smarter than [x][1].  It\nshould save very little time as d[][] will quickly grow to the appropriate size.\n The second context is to create a lookup table for the max distance, so that it\ndoes not have to recalculate what the max distance is for every word.  The max\ndistance is a constant for every word of the same length.  I also only saw\nmarginal gain from this change.  \n\nI went back to estimate the acutal amount of time saved from this change in\nisolation.  On a modern machine, it is less than 200ms for 10 million words (see\ntest below).  \n\npublic class Scratch\n{\n  private static final int TYPICAL_LONGEST_WORD_IN_INDEX = 19;\n  private static final float[] TYPICAL_WORD_LENGTH_DISTRIBUTION = {\n   0, 0.01f, 0.015f, 0.025f, 0.05f, 0.10f, 0.125f, 0.15f, 0.155f, 0.12f, 0.10f,\n0.07f, 0.04f, 0.015f, 0.010f, 0.005f, 0.005f, 0.005f\n  };\n\n  private final int[] maxDistances = new int[TYPICAL_LONGEST_WORD_IN_INDEX];\n\n  public Scratch()\n  {\n    for (int i = 0; i < maxDistances.length; i++)\n    {\n      maxDistances[i] = calculateMaxDistance(i);\n    }\n  }\n\n  private final int getMaxDistance(int m){\n    return (m < maxDistances.length) ? maxDistances[m] : calculateMaxDistance(m);\n  }\n\n  private int calculateMaxDistance(int m){\n    return (int) ((1-0.5) * (Math.min(7, m) + 0));\n  }\n\n  public static void main(String[] args)\n  {    \n    long start = System.currentTimeMillis();\n    Scratch s = new Scratch();\n    final int totalNumberOfRuns = 10000000;\n    for (int i = 0; i < TYPICAL_WORD_LENGTH_DISTRIBUTION.length; i++)\n    {\n      float v = TYPICAL_WORD_LENGTH_DISTRIBUTION[i];\n      final int runsForASingleLength = (int) (v * totalNumberOfRuns);\n      //System.out.println(runsForASingleLength);\n      for (int j=0; j < runsForASingleLength; j++) {\n        s.getMaxDistance(i);\n      }\n    }\n\n    long total = System.currentTimeMillis() - start;\n\n    System.out.println(\"Time to lookup the records (in ms): \" + total);\n\n    long start2 = System.currentTimeMillis();\n\n    for (int i = 0; i < TYPICAL_WORD_LENGTH_DISTRIBUTION.length; i++)\n    {\n      float v = TYPICAL_WORD_LENGTH_DISTRIBUTION[i];\n      final int runsForASingleLength = (int) (v * totalNumberOfRuns);\n      for (int j=0; j < runsForASingleLength; j++) {\n        s.calculateMaxDistance(i);\n      }\n    }\n\n     long total2 = System.currentTimeMillis() - start2;\n\n    System.out.println(\"Time to recalculate the records (in ms): \" + total2);\n  }\n\n}",
            "date": "2004-10-27T05:58:20.000+0000",
            "id": 1
        },
        {
            "author": "Christoph Goller",
            "body": "The following observation should not get lost:\n\nIn his original mail Jonathan also mentioned that currently similarity\nmay be below 0.0f. A possible fix, if this should be fixed, would be to relate\nthe Levenstein distance to the maximum of the two length values instead of the\nminimum.",
            "date": "2004-10-28T23:21:32.000+0000",
            "id": 2
        },
        {
            "author": "Daniel Naber",
            "body": "Thanks, your patch has now been applied. I didn't do anything about that \n\"similarity can be less than 0\" issue. If anybody considers that a problem, \nplease let us know and open a separate issue. ",
            "date": "2004-11-08T07:39:53.000+0000",
            "id": 3
        }
    ],
    "component": "core/search",
    "description": "I took a look at it to see if it could be improved.  I saw speed improvements of\n20% - 40% by making a couple changes.  \n\nThe patch is here: http://www.hagerfamily.com/patches/FuzzyTermEnumOptimizePatch.txt\n\nThe Patch is based on the HEAD of the CVS tree as of Oct 22, 2004.\n\nWhat Changed?\n\nSince the word was discarded if the edit distance for the word was\nabove a certain threshold, I updated the distance algorithm to abort\nif at any time during the calculation it is determined that the best\npossible outcome of the edit distance algorithm is above this\nthreshold.  The source code has a great explanation.\n\nI also reduced the amount of floating point math, reduced the amount\nof potential space the array takes in its first dimension, removed the\npotential divide by 0 error when one term is an empty string, and\nfixed a bug where an IllegalArgumentException was thrown if the class\nwas somehow initialized wrong, instead of looking at the arguments.\n\nThe behavior is almost identical.  The exception is that similarity is\nset to 0.0 when it is guaranteed to be below the minimum similarity.\n\nResults\n\nI saw the biggest improvement from longer words, which makes a sense.\nMy long word was \"bridgetown\" and I saw a 60% improvement on this.\nThe biggest improvement are for words that are farthest away from the\nmedian length of the words in the index.  Short words (1-3 characters)\nsaw a 30% improvement.  Medium words saw a 10% improvement (5-7\ncharacters).  These improvements are with the prefix set to 0.",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-296",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "[PATCH] FuzzyTermEnum optimization and refactor",
    "systemSpecification": false,
    "version": ""
}