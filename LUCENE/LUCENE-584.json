{
    "comments": [
        {
            "author": "Eks Dev",
            "body": "Peter, \n\nthere is some advanced things you are probably interested in.\n\nsee:\n\"some utilities for a compact sparse filter\" LUCENE-328\n\nAlso interesting:\n[#SOLR-15] OpenBitSet - ASF JIRA\n\ncomplete solr solution for Filters is one cool thing! a bit awkward bridge to lucene due to BitSet in Filter, but this is due to be resolved... ",
            "date": "2006-05-31T19:48:34.000+0000",
            "id": 0
        },
        {
            "author": "Peter Sch\u00e4fer",
            "body": "thanks, this looks interesting.\n\nRegards,\nPeter",
            "date": "2006-06-01T19:11:35.000+0000",
            "id": 1
        },
        {
            "author": "Paul Elschot",
            "body": "As the title of this issue is as accurate as it gets, I'm attaching a  series of patches and additions here  that make Scorer a subclass of Matcher, while Matcher takes the current role of the BitSet in Filter.\nAll patches against trunk revision 417299.",
            "date": "2006-06-27T04:42:23.000+0000",
            "id": 2
        },
        {
            "author": "Paul Elschot",
            "body": "javadocs of HitCollector.java to use 'matching' instead of 'non-zero score'.\nThis is actually independent of the Matcher/Scorer change.",
            "date": "2006-06-27T04:47:19.000+0000",
            "id": 3
        },
        {
            "author": "Paul Elschot",
            "body": "javadocs of Searcher.java to use 'matching' instead of 'non-zero score',\nand to describe the Filter effect more accurately.\nThis is independent of the Matcher/Scorer change.",
            "date": "2006-06-27T04:49:40.000+0000",
            "id": 4
        },
        {
            "author": "Paul Elschot",
            "body": "MatchCollector.java with collect(int) method for org.apache.lucene.search.\n",
            "date": "2006-06-27T04:52:04.000+0000",
            "id": 5
        },
        {
            "author": "Paul Elschot",
            "body": "Matcher.java, including a match(MatchCollector) method, for org.apache.lucene.search.",
            "date": "2006-06-27T04:53:49.000+0000",
            "id": 6
        },
        {
            "author": "Paul Elschot",
            "body": "patch to Scorer.java to subclass Matcher.",
            "date": "2006-06-27T04:55:06.000+0000",
            "id": 7
        },
        {
            "author": "Paul Elschot",
            "body": "patch to Filter to add getMatcher() and to deprecate getBits() in favour of getMatcher().\nIncludes commented test code to test IndexSearcher using BitsMatcher.",
            "date": "2006-06-27T04:58:23.000+0000",
            "id": 8
        },
        {
            "author": "Paul Elschot",
            "body": "Patch to IndexSearcher.java to prefer getMatcher() over getBits() on Filter.\nAlso add method IndexSearcher.match(Query, MatchCollector).\n",
            "date": "2006-06-27T05:00:26.000+0000",
            "id": 9
        },
        {
            "author": "Paul Elschot",
            "body": "A Matcher constructed from a BitSet for org.apache.lucene.util.",
            "date": "2006-06-27T05:02:44.000+0000",
            "id": 10
        },
        {
            "author": "Paul Elschot",
            "body": "SortedVIntList.java for org.apache.lucene.util superseding the one in LUCENE-328. Has a getMatcher() method.",
            "date": "2006-06-27T05:05:25.000+0000",
            "id": 11
        },
        {
            "author": "Paul Elschot",
            "body": "TestSortedVIntList.java, superseding the one in LUCENE-328 testing the Matcher provided by a SortedVIntList.\n",
            "date": "2006-06-27T05:07:18.000+0000",
            "id": 12
        },
        {
            "author": "Paul Elschot",
            "body": "LUCENE-328 is superseded by this issue.",
            "date": "2006-06-27T05:09:06.000+0000",
            "id": 13
        },
        {
            "author": "Paul Elschot",
            "body": "I hope I got all the attachments right, please holler in case something does not patch or compile cleanly.\n\nSome questions/remarks:\n\n- When IndexSearcher gets a BitSet from a Filter, it will not use skipTo() on the Scorer\nof the Query being filtered.\nThis still allows to use the 1.4 BooleanScorer until Filter.getBits() is removed.\n\n- Ok. not to add match() method(s) to Searcher/Searchable ?\n\n- BitSetIterator of SOLR-15 could implement a Matcher, and perhaps to be added to org.apache.lucene.util ?\n\n- Matcher as superclass of Scorer opens possibility to add BooleanQuery.add(Filter) method.\nThis also needs the addition of required Matchers to ConjunctionScorer and the addition of prohibited Matchers at ReqExclScorer/DisjunctionScorer.\nDoing this filtering in ConjunctionScorer/ReqExclScorer will probably reduce the number of method calls for filtering.\nOnce such an addition is done to BooleanQuery, the filtering methods in IndexSearcher could be deprecated in favour of BooleanQuery.add(Filter).\n\nRegards,\nPaul Elschot\n",
            "date": "2006-06-27T05:22:26.000+0000",
            "id": 14
        },
        {
            "author": "Paul Elschot",
            "body": "I've started to improve the javadocs of almost all code posted here, so it's probably not worthwhile to commit this as it is now.\nI don't expect changes to the java code in the short term.\n\nRegards,\nPaul Elschot\n\n",
            "date": "2006-06-28T05:46:59.000+0000",
            "id": 15
        },
        {
            "author": "Eks Dev",
            "body": "Any toughts on adding OpenBitSet from solr here? ",
            "date": "2006-06-28T12:47:30.000+0000",
            "id": 16
        },
        {
            "author": "Paul Elschot",
            "body": "Patches against trunk revision 417683, current.\nCompared to previous patches/files, there are only javadoc updates,\nand the javadocs of Searchable are also patched.\n\n",
            "date": "2006-06-28T14:19:18.000+0000",
            "id": 17
        },
        {
            "author": "Paul Elschot",
            "body": "Added some javadocs to BitsMatcher.\nAdded Matcher constructor to SortedVIntList, and extended the test for this.\n",
            "date": "2006-06-29T04:08:02.000+0000",
            "id": 18
        },
        {
            "author": "Paul Elschot",
            "body": "Perhaps the BitsMatcher class is better implemented as a static method in a new class MatcherUtils.createMatcher(BitSet).\nSimilar methods could be added for OpenBitSet, SortedVIntList, int[] and whatever data structure comes around for implementing Filter.getMatcher(IndexReader).\nWhen Matcher is a superclass of Scorer, TermScorer already implements a Matcher for TermDocs.\n",
            "date": "2006-07-02T17:53:39.000+0000",
            "id": 19
        },
        {
            "author": "Paul Elschot",
            "body": "As requested on java-dev, Matcher20060830.patch is the whole thing as a single patch, relative to srv/java/org/apache/lucene in the trunk, revision 438598 of 30 August 2006.\n\nThis does not contain the FIXME the earlier posted Filter-20060628.patch .\nThis FIXME code can be used to test that IndexSearcher works correctly with a BitsMatcher filter instead of with the current BitSet filter.\n\nRegards,\nPaul Elschot",
            "date": "2006-08-30T19:31:00.000+0000",
            "id": 20
        },
        {
            "author": "Yonik Seeley",
            "body": "Thanks Paul,\nI like the Matcher/Scorer relation.\n\nIt looks like no Filters currently return a matcher, so the current patch just lays the groundwork, right?\n\nWhen some filters do start to return a matcher, it looks like support for the 1.4 BooleanScorer needs to be removed, or a check done in IndexSearcher.search() to disable skipping on the scorer if it's in use.\n\nI wonder what the performance impact is... for a dense search with a dense bitset filter, it looks like quite a bit of overhead is added (two calls in order to get the next doc, use of nextSetBit() instead of get(), checking \"exhausted\" each time and checking for -1 to set exhausted).  I suppose one can always drop back to using a HitCollector for special cases though.",
            "date": "2006-08-30T20:47:37.000+0000",
            "id": 21
        },
        {
            "author": "Paul Elschot",
            "body": "Matcher20060830b.patch corrects 2 mistakes in Matcher20060830.patch:\nSearchable.java was present twice, and TestSortedVIntList was not present.\nThanks eks for pointing out the mistake.\n\nThis patch was generated from the trunk directory.\n\nRegards,\nPaul Elschot",
            "date": "2006-08-30T20:52:05.000+0000",
            "id": 22
        },
        {
            "author": "Paul Elschot",
            "body": "Yonik, as to you questions:\n\n> It looks like no Filters currently return a matcher, so the current patch just lays the groundwork, right?\n\nRight. Only the previous Filter-20060628.patch contains some commented FIXME code to actually introduce a BitsMatcher in each case where a BitSet is used.\n\n>When some filters do start to return a matcher, it looks like support for the 1.4 BooleanScorer needs\n> to be removed, or a check done in IndexSearcher.search() to disable skipping on the scorer if it's in use.\n\nIirc the patch still supports the 1.4 BooleanScorer when a BitSet is returned by Filter. I'd have to have a look at the patched IndexSearcher to be sure though.\nA BitSet is randomly addressable, so it can work to filter the 1.4 BooleanScorer which can score documents out of order.  This case can be deprecated completely by also deprecating the possibility to use the 1.4 boolean scorer, but that is not in the patch. The patch only deprecates the Filter.bits() method.\n\n\n> I wonder what the performance impact is... for a dense search with a dense bitset\n> filter, it looks like quite a bit of overhead is added (two calls in order to get the next \n> doc, use of nextSetBit() instead of get(), checking \"exhausted\" each time and \n> checking for -1 to set exhausted). I suppose one can always drop back to using\n> a HitCollector for special cases though.\n\nBitsMatcher could also work without the \"exhausted\" flag, but then an infinite loop\nmight occur when trying to continue after the first time next() or skipTo() returned false.\nContinuing after false was returned in these cases is a bug, however an infinite loop\ncan be difficult to debug. I'd rather be on the safe side of that with the exhausted flag and wait for an actual profile to show the performance problem.\n\nRegards,\nPaul Elschot\n",
            "date": "2006-08-30T21:18:03.000+0000",
            "id": 23
        },
        {
            "author": "Eks Dev",
            "body": "using the latest Matcher20060830.patch \n\nant said \"BUILD SUCCESSFUL\" ;)\n\nI will see how it works on some real life cases using our 50Mio collection and report back what our standard app level tests  have to say (we have standardized collection /requsts/hits so bad things should pop -up quickly). Need a day or two for this.\n\nthanks for this work. \ne. \n",
            "date": "2006-08-30T21:26:10.000+0000",
            "id": 24
        },
        {
            "author": "Eks Dev",
            "body": "Hi Paul,\nfor me, this patch did not cause any incompatibility issues. All our tests passed without noticing any difference to the previous trunk version. No performance changes as well ( we use HitCollector only, so Yoniks comment does not apply here).\nTests are application level, and make index hot (6hrs searches with test batch of requests with known responses), 50Mio not artificial docs, real requests...\n\nEarly this week we will try to implement our first Matchers and see how they behave\n ",
            "date": "2006-09-03T20:35:02.000+0000",
            "id": 25
        },
        {
            "author": "Paul Elschot",
            "body": "> No performance changes as well.\n\nIt's good to hear that. As mentioned earlier, this is groundwork only.\nOnce an actual Matcher is used I expect some some performance differences to show up.\n\nWhich comment of Yonik related to HitCollector do you mean?\n\n> Early this week we will try to implement our first Matchers and see how they behave \n\nBitsMatcher and SortedVIntList could start that.\nAlso I'd like to see one on Solr's OpenBitSet...\n\n",
            "date": "2006-09-04T06:46:42.000+0000",
            "id": 26
        },
        {
            "author": "Eks Dev",
            "body": "Paul,\nWhat is exact semantics of skipTo(int) in Matcher?\n\n- is it OK to skip back and forth before I reach end?\ne.g.: skipTo(0); skipTo(333); skipTo(0); \n\n- once I reach end, skipTo(int) does nothing (BitsMatcher, exhausted). It is impossible to reposition Matcher after that\n\nIs this intended behavior, \"skip forward until you reach end, and then, you are at the end :)\" ? \n\n\n\n\n",
            "date": "2006-09-04T11:41:44.000+0000",
            "id": 27
        },
        {
            "author": "Eks Dev",
            "body": "Here are some Matcher implementations,\n\n- OpenBitsMatcher- the same as the code Paul wrote for BitsMatcher, with replaced OpenBitSet instead \n\n-DenseOpenBitsMatcher  - Using solr BitSetIterator (for skipTo() to work, one method in BitSetIterator should become public)\n\nAlso attached one simple  test (just basic fuctionality) that also contains one dummy relative performance  test \n\nPerf. test simply iterates over different Matcher implementations  and measures ellapsed time (not including Matcher creation, pure forward scan to the end) for different set bit densities.\n\nimho, this code is not sufficiantly tested nor commented, needs an hour or two.  \n\nAs expected, Yonik made this ButSetIterator really fast. What was surprise for me was OpenBitSet nextSetBit() comparing bad to the BitSet  (or I made some dummy mistake somewhere?)",
            "date": "2006-09-04T21:02:22.000+0000",
            "id": 28
        },
        {
            "author": "Eks Dev",
            "body": "Paul,\nWhat is next now, we did on our app enough experiments and are now sure that this patch causes no incompatibilities. \nWe also tried to replace our filters with OpenBitSet and VInt matchers and results there are more than good, our app showed crazy  30% speed-up!!! Hard to identify where from exactly, but I suspect VInt matcher in case of not too dense BitVectors increased our Filter Cache utilization significantly.\n\nI would propose to commit this patch before we go further with something that would actually utilize Matcher. Just to avoid creating monster patch on patch ... \n\nThis is ground work, and now using Matcher will be pure poetry, I see a lot of places we could see beter life by using use Matchers, ConstantScoringQuery, PreffixFilter, ChainedFilter (becomes obsolete now)... actually replace all uses of BitSet with OpenBitSet (or a bit smarter with SortedIntList. VInt...)...\nThan question here, do we create dependancy to Solr from Lucene, or we \"migrate\" OpenBitSet to Lucene (as this dependancy allready exists) or we copy-paste and have two OpenBitSets, Yonik? As far as I am concerned, makes no real diference.\n\nDo you, or someone else see now things to be done before commiting this? \n\n",
            "date": "2006-09-14T10:12:15.000+0000",
            "id": 29
        },
        {
            "author": "Paul Elschot",
            "body": "> Do you, or someone else see now things to be done before commiting this?\n\nYes. In the steps listed here:\nhttp://wiki.apache.org/jakarta-lucene/HowToContribute\nthe next step is to be patient.\nWether being patient is something that can be done\nis open question...\n\nPaul Elschot.\n\n",
            "date": "2006-09-14T18:40:42.000+0000",
            "id": 30
        },
        {
            "author": "Paul Elschot",
            "body": "In the inheritance from Matcher to Scorer there is an asymmetry\nin this patch.\n\nMatcher provides a default implementation for Matcher.explain()\nbut Scorer does not, and this might lead to unexpected surprises\nfor future Scorers when the current Matcher.explain() is used.\nOne could add an abstract Scorer.explain() to catch these, or\nprovide a default implementation for Scorer.explain().\n\nWith matcher implementations quite a few other implementation\ndecisions need to be taken. \nAlso any place in the current code where a Scorer is used, but none\nof the Scorer.score() methods, is a candidate for a change from\nScorer to Matcher.\nThis will be mostly the current filtering implementations,\nbut ConstantScoringQuery is another nice example.\n\nRegards,\nPaul Elschot\n",
            "date": "2006-09-15T07:04:21.000+0000",
            "id": 31
        },
        {
            "author": "Paul Elschot",
            "body": "I wrote:\n\n> One could add an abstract Scorer.explain() to catch these, or\n> provide a default implementation for Scorer.explain().\n\nby mistake. The good news is that the patch leaves the \nthe existing abstract Scorer.explain() method unaffected.\n",
            "date": "2006-09-24T19:27:00.000+0000",
            "id": 32
        },
        {
            "author": "Paul Elschot",
            "body": "Corrected javadoc refs to use IndexInput and IndexOutput.",
            "date": "2006-11-01T20:01:24.000+0000",
            "id": 33
        },
        {
            "author": "Paul Elschot",
            "body": "I have just resolved some minor local conflicts on the updated copyrights of four java  files.\nPlease holler when a fresh  patch is needed.",
            "date": "2006-11-17T12:26:19.000+0000",
            "id": 34
        },
        {
            "author": "Paul Elschot",
            "body": "As 2.1 is out, here is a new patch to try and revive this.\nThis replaces the pevious Matcheryyyymmdd.patch one of 2006",
            "date": "2007-02-26T20:03:43.777+0000",
            "id": 35
        },
        {
            "author": "Hoss Man",
            "body": "It's been a while since i looked at this issue, but it's come up in discussion recently so i took another glance...\n\nPaul: I notice Filter.getMatcher returns null, and IndexSearcher tests for that and uses it to decide whether or not to iterator over the (non null) Matcher, or over the BitSet from Filter.bits.  is there any reason that logic can't be put in getMatcher, so that if subclasses of Filter don't override the getMatcher method it will call bits and then return a Matcher that iterates over the set Bits?\n\n(this is the roll-out approach i advocated a while back when discussing this on email, excecept that at the time Matcher was refered to as SearchFilter: http://www.nabble.com/RE%3A-Filter-p2605271.html )\n\nThinking about it now, we could even change Filter.bits so it's no longer abstract ... it could have an implementation that would call getMatcher, and iterate over all of the matched docs setting bits on a BitSet that is then returned ... the class would still be abstract, and the class javadocs  would make it clear that subclasses must override at least one of the methods ... legacy Filters will work fine because they'll already have a bits method, and people writing new Filters will see that bits is deprecated, so they'll just write a getMatcher method and be done.\n\nThis appears to be the same approach taken with Analyzer.tokenStream back in 1.4.3...\n\nhttp://lucene.apache.org/java/1_4_3/api/org/apache/lucene/analysis/Analyzer.html",
            "date": "2007-03-15T18:06:40.518+0000",
            "id": 36
        },
        {
            "author": "Paul Elschot",
            "body": "Hoss,\n\n>Paul: I notice Filter.getMatcher returns null, and IndexSearcher tests for that and uses\n> it to decide whether or not to iterator over the (non null) Matcher, or over the BitSet\n> from Filter.bits. is there any reason that logic can't be put in getMatcher, so that if\n> subclasses of Filter don't override the getMatcher method it will call bits and then\n> return a Matcher that iterates over the set Bits?\n\nTwo reasons:\n- uncertainty over performance of a Matcher instead of a BitSet,\n- this way backward compatibility very easily guaranteed.\n\nThere is also LUCENE-730, which may interfere with the removal of BitSet,\nsince it allows documents to be scored out of order. However, LUCENE-730\nshould only be used at the top level of a query search and without a Filter.\nI cannot think of an actual case in which there might be interference, but\nI may not have not looked into that deep enough.\n\n> we could even change Filter.bits so it's no longer abstract ... it could have\n> an implementation that would call getMatcher, and iterate over all of the matched\n> docs setting bits on a BitSet that is then returned ... the class would still be\n> abstract, and the class javadocs would make it clear that subclasses must override\n> at least one of the methods...\n\nI must say that creating a BitSet from a Matcher never occurred to me.\nAnyway, when Filter.bits() is deprecated I have no preference about how\nit is actually removed.\n",
            "date": "2007-03-16T19:09:25.047+0000",
            "id": 37
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Paul:\nApplied the patch, applied cleanly, run ant test -> BUILD SUCCESSFUL :)\n\nI'm primarily interested in using this in order to get matches, but avoid scoring.  From what I can tell, I'd just need to switch to using the new match(Query, MatchCollector) method in IndexSearcher.  However, I need Sort and TopFieldDocs, and I don't see a match method with those.  Is there a reason why such a match method is not in the patch?\n",
            "date": "2007-03-23T19:54:04.979+0000",
            "id": 38
        },
        {
            "author": "Paul Elschot",
            "body": "Otis:\n\n> However, I need Sort and TopFieldDocs, and I don't see a match method with those.\n> Is there a reason why such a match method is not in the patch? \n\nA bit silly perhaps, but what sort criterion would like to have used when no score() value is available?\n\nI don't know the sorting code, but it might be possible to use a field value for sorting.\nIn that case the sorting code for a Matcher would need to check whether the sort criterion does\nnot imply the use of a score value.\nI personally have no use for sorting by field values, so that is why I never thought of combining this with a Matcher.\n\n\n\n",
            "date": "2007-03-23T20:13:25.284+0000",
            "id": 39
        },
        {
            "author": "Yonik Seeley",
            "body": "> BitsMatcher could also work without the \"exhausted\" flag, but then an infinite loop\n> might occur when trying to continue after the first time next() or skipTo() returned false.\n> Continuing after false was returned in these cases is a bug, however an infinite loop\n> can be difficult to debug. I'd rather be on the safe side of that with the exhausted flag and wait for an actual \n> profile to show the performance problem.\n\nWe know that matchers will be inner-loop stuff.  It seems like any scorers that call next() after false was returned should be fixed.",
            "date": "2007-03-24T19:39:59.798+0000",
            "id": 40
        },
        {
            "author": "Paul Elschot",
            "body": "> We know that matchers will be inner-loop stuff. It seems like any scorers that call next() after false was returned should be fixed.\n\nI fully agree. The \"exhausted\" flag is not much more than a matter of taste.\n\nIn case the speed advantage of removing this flag is preferred, I don't mind resolving the eventual conflict in my working copy.\nBut I don't know yet how I would resolve that conflict :)",
            "date": "2007-03-24T23:15:55.711+0000",
            "id": 41
        },
        {
            "author": "Yonik Seeley",
            "body": "> In case the speed advantage of removing this flag is preferred, I don't mind resolving the eventual conflict in my\n> working copy.  But I don't know yet how I would resolve that conflict :)\n\nAh, that's a bit different.  You mean there are cases that are non-trivial to fix where next() is called after false is returned?",
            "date": "2007-03-24T23:22:40.639+0000",
            "id": 42
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Perhaps I did something wrong with the benchmark, but I didn't get any speed-up when using searcher.match(Query, MatchCollector) vs. searcher.search(Query, HitCollector).\n\nHere are the benchmark numbers (50000 queries with each), HitCollector first, MatchCollector second:\n\nHITCOLLECTOR:\n\n     [java] ------------> Report Sum By (any) Name (11 about 41 out of 41)\n     [java] Operation           round mrg buf   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\n     [java] Rounds_4                0  10  10        1       808020        787.5    1,026.04     7,217,624     17,780,736\n     [java] Populate -  -  -  -  -  - - - - - -  -   4 -  -  - 2003 -  -   129.9 -  -  61.67 -   9,938,986 -   13,821,952\n     [java] CreateIndex             -   -   -        4            1          4.4        0.91     3,937,522     10,916,864\n     [java] MAddDocs_2000 -  -  -   - - - - - -  -   4 -  -  - 2000 -  -   138.1 -  -  57.92 -   9,368,584 -   13,821,952\n     [java] Optimize                -   -   -        4            1          1.4        2.83     9,938,218     13,821,952\n     [java] CloseIndex -  -  -  -   - - - - - -  -   4 -  -  -  - 1 -  - 2,000.0 -  -   0.00 -   9,938,986 -   13,821,952\n     [java] OpenReader              -   -   -        4            1         24.0        0.17     9,957,592     13,821,952\n     [java] SearchSameRdr_50000 -   - - - - - -  -   4 -  -   50000 -  - 1,070.3 -  - 186.86 -  10,500,146 -   13,821,952\n     [java] CloseReader             -   -   -        4            1      4,000.0        0.00     9,059,756     13,821,952\n     [java] WarmNewRdr_50 -  -  -   - - - - - -  -   4 -  -  100000 -   16,237.7 -  -  24.63 -   9,060,268 -   13,821,952\n     [java] SrchNewRdr_50000        -   -   -        4        50000        265.9      752.02    10,800,006     13,821,952\n\n\n     [java] ------------> Report sum by Prefix (MAddDocs) and Round (4 about 4 out of 41)\n     [java] Operation     round mrg buf   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\n     [java] MAddDocs_2000     0  10  10        1         2000         94.6       21.15     7,844,112     10,407,936\n     [java] MAddDocs_2000 -   1 100  10 -  -   1 -  -  - 2000 -  -   136.7 -  -  14.63 -   8,968,144 -   11,309,056\n     [java] MAddDocs_2000     2  10 100        1         2000        173.2       11.55    10,528,264     15,740,928\n     [java] MAddDocs_2000 -   3 100 100 -  -   1 -  -  - 2000 -  -   188.7 -  -  10.60 -  10,133,816 -   17,829,888\n\n\nMATCHCOLLECTOR:\n\n\n     [java] ------------> Report Sum By (any) Name (11 about 41 out of 41)\n     [java] Operation           round mrg buf   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\n     [java] Rounds_4                0  10  10        1       808020        781.0    1,034.62    10,566,608     15,859,712\n     [java] Populate -  -  -  -  -  - - - - - -  -   4 -  -  - 2003 -  -   130.9 -  -  61.23 -  10,963,452 -   14,806,016\n     [java] CreateIndex             -   -   -        4            1         33.9        0.12     3,616,570     11,020,288\n     [java] MAddDocs_2000 -  -  -   - - - - - -  -   4 -  -  - 2000 -  -   137.3 -  -  58.29 -  10,445,568 -   14,806,016\n     [java] Optimize                -   -   -        4            1          1.4        2.82    10,979,398     14,806,016\n     [java] CloseIndex -  -  -  -   - - - - - -  -   4 -  -  -  - 1 -  - 2,000.0 -  -   0.00 -  10,963,452 -   14,806,016\n     [java] OpenReader              -   -   -        4            1         22.0        0.18    10,982,058     14,806,016\n     [java] SearchSameRdr_50000 -   - - - - - -  -   4 -  -   50000 -  - 1,064.7 -  - 187.84 -  11,060,036 -   14,806,016\n     [java] CloseReader             -   -   -        4            1      4,000.0        0.00    10,353,206     14,806,016\n     [java] WarmNewRdr_50 -  -  -   - - - - - -  -   4 -  -  100000 -   16,419.0 -  -  24.36 -  10,431,062 -   14,806,016\n     [java] SrchNewRdr_50000        -   -   -        4        50000        263.0      760.34    11,912,358     14,806,016\n\n\n     [java] ------------> Report sum by Prefix (MAddDocs) and Round (4 about 4 out of 41)\n     [java] Operation     round mrg buf   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\n     [java] MAddDocs_2000     0  10  10        1         2000         92.2       21.69     7,844,112     10,407,936\n     [java] MAddDocs_2000 -   1 100  10 -  -   1 -  -  - 2000 -  -   136.6 -  -  14.64 -   7,720,352 -   10,407,936\n     [java] MAddDocs_2000     2  10 100        1         2000        167.8       11.92    11,325,952     17,571,840\n     [java] MAddDocs_2000 -   3 100 100 -  -   1 -  -  - 2000 -  -   199.3 -  -  10.03 -  14,891,856 -   20,836,352\n\n\n\nThis is what I did for the benchmark.  I used Doron's handy conf/benchmark.\nI added a new .alg based on micro-standard.alg, here's the diff:\n\n\n$ diff conf/micro-standard.alg conf/matcher-micro-standard.alg \n60c60\n<     { \"SearchSameRdr\" Search > : 50000\n---\n>     { \"SearchSameRdr\" SearchMatch > : 50000\n65c65\n<     { \"SrchNewRdr\" Search > : 50000\n---\n>     { \"SrchNewRdr\" SearchMatch > : 50000\n\n\nThen I added 2 new Tasks for benchamrking the Matcher (searcher.search(Query, MatchCollector)) and modified the ReadTask to call searcher.search(Query, HitCollector) instead of the method to get Hits.\n\nI commented out all search results traversal and doc retrieval, as I didn't care to measure that.\n",
            "date": "2007-04-05T21:33:18.734+0000",
            "id": 43
        },
        {
            "author": "Doron Cohen",
            "body": "The benchmark does not search with filters. Is any speedup still expected? (why?)\n\nI applied the patch on current trunk and ran the benchmark - it shows that when all queries use the same reader, Match is faster while when each query opens its own reader bitset is faster. Is this an expected result? \n\n{noformat}\nOperation           round   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\nSrchMtchSamRdr_5000     -       10         5000        642.2       77.85    12,331,866     16,408,576\nSrchBitsSamRdr_5000 -   - -  -  10 -  -  - 5000 -  -   586.9 -  -  85.20 -   9,515,875 -   12,009,472\nSrchMtchNewRdr_500      -       10          500        134.7       37.11    13,376,113     17,171,660\n{noformat}\n\nThis test is using all Reuters documents and the searches rounds are repeated 10 times. The Match tasks were not included so I wrote them. The updated bench-diff.txt attached contains these task classes and the algorithm.  (When you use this, note that once the index is created you can comment the first part - the \"Populate\" part - and then only rerun the querying part.)\n",
            "date": "2007-04-08T03:59:14.017+0000",
            "id": 44
        },
        {
            "author": "Doron Cohen",
            "body": "One line was cut out - here are the four lines again\n\nOperation           round   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\nSrchMtchSamRdr_5000     -       10         5000        642.2       77.85    12,331,866     16,408,576\nSrchBitsSamRdr_5000 -   - -  -  10 -  -  - 5000 -  -   586.9 -  -  85.20 -   9,515,875 -   12,009,472\nSrchMtchNewRdr_500      -       10          500        134.7       37.11    13,376,113     17,171,660\nSrchBitsNewRdr_500 -  - - -  -  10 -  -  -  500 -  -   154.0 -  -  32.47 -  15,351,395 -   17,522,688\n",
            "date": "2007-04-08T04:07:42.576+0000",
            "id": 45
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Doron, thanks for jumping on this!\n\n1. I thought I'd see better performance with the Matcher because it skips scoring.  While Paul's patch does make changes to the Filtering code, I'm more focused on HitCollector vs. MatchCollector performance here.  Am I missing something here?  If scoring is skipped, we should see at least some speed improvement, and your results show that.\n\n2. You said you *did* see MatchCollector was faster than HitCollector.  Hmmm, weird, not in my 4 runs:\n\nMatcher:\n [java] SearchSameRdr_50000 - - - - - - - - 4 - - 50000 - - 1,064.7 - - 187.84 - 11,060,036 - 14,806,016 \nHitCollector: \n[java] SearchSameRdr_50000 - - - - - - - - 4 - - 50000 - - 1,070.3 - - 186.86 - 10,500,146 - 13,821,952 \n\nI'll try it again on a different computer.  My previous runs were on a Mac with OSX.\n\n3. My bench-diff.txt did include Match tasks:\n\n$ grep Match bench-diff.txt | grep class\npublic class SearchMatchTask extends MatchTask {\npublic abstract class MatchTask extends ReadTask {\n\n... but I didn't svn add them, so I produced the \"diff\" by simply cat-ing the new tasks to bench-diff.txt .  So if you used my bench-diff.txt as a patch, it wouldn't have worked.  Not a big deal, just clarifying.\n",
            "date": "2007-04-08T05:21:02.642+0000",
            "id": 46
        },
        {
            "author": "Doron Cohen",
            "body": "...right, your diff-txt had the Match tasks - I missed that - checked it, it is exactly what I did, so we're ok here. \n\nWhen you rerun, you may want to use my alg - to compare the two approaches in one run. You can run this by something like:\n     ant run-task -Dtask.mem=256M -Dtask.alg=conf\\matcher-vs-bitset.alg\n\nAlso, to get cleaner results, add the line:\n     ResetSystemSoft\njust in the beginning of the \"search round\" - this resets the (query) inputs and also calls GC.\n\nI tried like this twice, and got inconsistent results:\n\nWhen the bitset searches preceded the match searches:\n     [java] Operation           round   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\n     [java] SrchBitsSamRdr_5000     -       10         5000        706.4       70.78     7,511,219     16,573,645\n     [java] SrchMtchSamRdr_5000 -   - -  -  10 -  -  - 5000 -  -   689.6 -  -  72.50 -   8,223,005 -   11,926,323\n     [java] SrchBitsNewRdr_500      -       10          500        152.5       32.80    14,360,618     16,962,356\n     [java] SrchMtchNewRdr_500 -  - - -  -  10 -  -  -  500 -  -   171.3 -  -  29.19 -  15,150,797 -   17,395,712\n\nWhen the match searches preceded the bitset searches:\n     [java] Operation           round   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\n     [java] SrchMtchSamRdr_5000     -       10         5000        763.5       65.49     9,563,243     17,128,244\n     [java] SrchBitsSamRdr_5000 -   - -  -  10 -  -  - 5000 -  -   729.3 -  -  68.56 -  10,003,775 -   13,001,114\n     [java] SrchMtchNewRdr_500      -       10          500        175.7       28.46    12,068,559     17,524,326\n     [java] SrchBitsNewRdr_500 -  - - -  -  10 -  -  -  500 -  -   183.7 -  -  27.22 -  15,098,480 -   17,974,476\n\nMy conclusion from this is that the speed-up, if exists, is minor, at least for the setup of this test. \n\nThere are only 15 unique queries in this test - also printed in the log - are these the queries you would expect to save in? \n\nI didn't follow this issue very closely so I don't know where the saving is expected here. Both SearchTask and MatchTask now do nothing in collect, so no difference at the actual collect() call.\n\nAlso, Scorer.score(HitCollector) and Matcher.match(MatchCollector) are very similar:\n  public void score(HitCollector hc) throws IOException {\n    while (next()) {\n      hc.collect(doc(), score());\n    }\n  }\n  public void match(MatchCollector mc) throws IOException {\n    while (next()) {\n      mc.collect(doc());\n    }\n  }\nEspecially for the case that the collect() method is doing nothing, as in this test.\n\nI think there is a potential gain for large boolean OR queries, because score() would have to call next() on all TermScorers and collect/sum their scores, while match() could use skipTo(last+1) because any match encountered is a match and there is no need to sum the individual scores for the same doc by other scorers. However as far as I can tell, current match() implementation does not take advantage of this, but I may be overlooking something?",
            "date": "2007-04-08T20:20:29.133+0000",
            "id": 47
        },
        {
            "author": "Yonik Seeley",
            "body": "> When you rerun, you may want to use my alg - to compare the two approaches in one run.\n\nThis is more dangerous though.  GC from one method's garbage can penalize the 2nd methods performance.\nAlso, hotspot effects are hard to account for (if method1 and method2 use common methods, method2 will often execute faster than method one because more optimization has been done on those common methods).\n\nThe hotspot effect can be minimized by running the test multiple times in the same JVM instance and discarding the first runs, but it's not so easy for GC.",
            "date": "2007-04-09T18:32:48.479+0000",
            "id": 48
        },
        {
            "author": "Mike Klaas",
            "body": "Instead of discarding the first run, the approach I usually take is to run 3-4 times and pick the minimum.  You can then run several of these \"sets\" and average over the minimum of each.  GC is still an issues, though.  It is hard to get around when it is a mark&sweep collector (reference counting is much friendlier in this regard)",
            "date": "2007-04-09T19:27:38.580+0000",
            "id": 49
        },
        {
            "author": "Doron Cohen",
            "body": "> > When you rerun, you may want to use my alg - to compare the two approaches in one run. \n> This is more dangerous though. \n\nAgree. I was trying to get rid of this by splitting each round to 3: - gc(), warm(), work() - when work() and warm() are the same, just that warm()'s stats are disregarded. Still switching the order of \"by match\" and \"by bits\" yield different results. \n\nSometimes we would like not to disregard GC - in particular if one approach is creating more (or more complex) garbage than another approach. \n\nPerhaps we should look at two measures: best & avg/sum (2nd ignoring first run, for hotspot). \n",
            "date": "2007-04-09T19:34:13.176+0000",
            "id": 50
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Doron: just to address your question from Apr/7 - I expect/hope to see an improvement in performance because of this difference:\n\n      hc.collect(doc(), score()); \n      mc.collect(doc()); \n\nthe delta being the cost of the score() call that does the scoring.  If I understand things correctly, that means that what grant described at the bottom of http://lucene.apache.org/java/docs/scoring.html will all be skipped.  No Scorer, no BooleanScorer(2), no ConjunctionScorer...\n",
            "date": "2007-04-09T21:02:44.026+0000",
            "id": 51
        },
        {
            "author": "Doron Cohen",
            "body": "> No Scorer, no BooleanScorer(2), no ConjunctionScorer... \n\nThanks, I was reading \"score\" instead of \"score()\"...\n\nBut there is a scorer in the process, it is used for next()-ing to matched docs. So most of the work - preparing to be able to compute the scores - was done already. The scorer doc queue is created and populated. Not calling score() is saving the (final) looping on the scorers for aggregating their scores, multiplying by coord factor, etc. I assume this is why only a small speed up is seen. \n",
            "date": "2007-04-10T01:14:12.263+0000",
            "id": 52
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Ahhhh.  I'll look at the patch again tomorrow and follow what you said.  All this time I was under the impression that one of the points or at least side-effects of the Matcher was that scoring was skipped, which would be perfect where matches are ordered by anything other than relevance.\n\n",
            "date": "2007-04-10T02:35:47.509+0000",
            "id": 53
        },
        {
            "author": "Marvin Humphrey",
            "body": "DisjunctionSumScorer (the ORScorer) actually calls Scorer.score() on all of the matching scorers in the ScorerDocQueue during next(), in order to accumulate an aggregate score.  The MatchCollector can't save you from that.",
            "date": "2007-04-10T02:54:55.474+0000",
            "id": 54
        },
        {
            "author": "Paul Elschot",
            "body": "That could be improved in a DisjunctionMatcher.\nWith a bit of bookkeeping DisjunctionSumScorer could also delay calling score() on the subscorers\nbut the bookkeeping would affect performance for the normal case.\n\nFor the usual queries the score() call will never have much of a performance impact.\nThe reason for this is that TermScorer.score() is really very efficient, iirc it caches\nweighted tf() values for low term frequencies.\nAll the rest is mostly additions, and occasionally a multiplication for a coordination factor.\n\nTo determine which documents match the query, the index need to be accessed,\nand that takes more time than score value computations because the complete index\nalmost never fits in the fastest cache.\n\n",
            "date": "2007-04-10T07:22:59.655+0000",
            "id": 55
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Ah, too bad. :(\nLast time I benchmarked Lucene searching on Sun's Niagara vs. non-massive Intel boxes, Intel boxes with Linux on them actually won, and my impression was that this was due to Niagara's weak FPU (a known weakness in Niagara, I believe).  Thus, I thought, if we could just skip scoring and various floating point calculations, we'd see better performance, esp. on Niagara boxes.\n\nPaul, when you say \"fastest cache\", what exactly are you referring to?  The Niagara I tested things on had 32GB of RAM, and I gave the JVM 20+GB, so at least the JVM had plenty of RAM to work with.\n",
            "date": "2007-04-10T15:10:53.967+0000",
            "id": 56
        },
        {
            "author": "Paul Elschot",
            "body": "By fastest cache I meant the L1 cache of the processor. The size is normally in tens of kilobytes.\nAn array lookup hitting that cache takes about as much time as a floating point addition.\n\nDuring a query search the use of a.o. the term frequencies, the proximity data, and the document weights normally cause an L1 cache miss.\n\nI would expect that by not doing the score value computations, only the cache misses for document weights can be saved.\n",
            "date": "2007-04-10T18:59:48.061+0000",
            "id": 57
        },
        {
            "author": "Hoss Man",
            "body": "I'm a little behind on following this issue, but if i can attempt to sum up the recent discussion about performance...\n\n   \"Migrating towards a \"Matcher\" API *may* allow some types of Queries to be faster in situations where clients can use a MatchCollector instead of a HitCollector, but this won't be a silver bullet performance win for all Query classes -- just those where some of the score calculations is (or can be) isolated to the score method (as opposed to skipTO or next)\"\n\nI think it's important to remember the motivation of this issue wasn't to improve the speed performance of non-scoring searchers, it was to decouple the concept of \"Filtering\" results away from needing to populate a (potentially large) BitSet when the logic neccessary for Filtering can easily be expressed in terms of a doc iterator (aka: a Matcher) -- opening up the possibility of memory performance improvements.  \n\nA second benefit that has arisen as the issue evolved, has been the API generalization of the \"Matcher\" concept to be a super class of Scorer for simpler APIs moving forward.\n\n\n",
            "date": "2007-04-10T22:24:15.320+0000",
            "id": 58
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Right.  I was under the wrong impression that the Matcher also happens to avoid scoring.  However, now that we've all looked at this patch (still applies cleanly and unit tests all pass), and nobody had any criticisms, I think we should commit it, say this Friday.\n\nAs I'm in the performance squeezing mode, I'll go look at LUCENE-730, another one of Paul's great patches, and see if I can measure performance improvement there.\n",
            "date": "2007-04-11T02:07:53.188+0000",
            "id": 59
        },
        {
            "author": "Hoss Man",
            "body": "I'm still behind on following this issue, but Otis: if you are interested in moving forward with this, you might consider trying the cahnges i proposed in my \"15/Mar/07 11:06 AM\" Comment...\n\nhttps://issues.apache.org/jira/browse/LUCENE-584#action_12481263\n\n...I think it would keep IndexSearcher a little cleaner, and make it easier for people to migrate existing Filter's gradually (without requiring extra work for people writing new \"Matcher\" style Filters from scratch)",
            "date": "2007-04-13T18:00:44.773+0000",
            "id": 60
        },
        {
            "author": "Paul Elschot",
            "body": "With 2.2 out, and LUCENE-730 out of the way, wouldn't this be a good moment for some progress with this issue?\nThe patch still applies cleanly, and I'd like to start working on a skipping extension of SortedVIntList, much like the latest index format for document lists.\n",
            "date": "2007-07-09T17:31:58.268+0000",
            "id": 61
        },
        {
            "author": "Paul Elschot",
            "body": "This DefaultMatcher2007072.patch adds a default Matcher to be used in Filter instead of the BitSet . It contains static methods that create a default Matcher from a BitSet and from an OpenBitSet. The patch also add OpenBitSet to org.apache.lucene.util; it was taken from a recent solr revision.\n\nIn this way the deprecation of Filter.bits(IndexReader) can be done by replacing implementations of that method by Filter.getMatcher(IndexReader) and adding the above default Matcher in the return statement:\nreturn DefaultMatcher.defaultMatcher(bits);\n\nThe idea is to have this hook available so that a sensible default Matcher is easily available, that can also be adapted to use better Matcher implementations when these become available.\nThe current implementation uses a SortedVIntList when it is smaller than an (Open)BitSet.\n\nI have begun introducing the default matcher in my working copy of the core, but as expected, that turns out to be quite a bit of work.\nBefore I continue with that, I'd like to have comments on this default matcher approach.\n",
            "date": "2007-07-25T10:21:05.138+0000",
            "id": 62
        },
        {
            "author": "Paul Elschot",
            "body": "There is some code in contrib where a Filter is assumed to have BitSet available:\n\ncontrib/queries/src/java/org/apache/lucene/search/BooleanFilter.java\ncontrib/miscellaneous/src/java/org/apache/lucene/misc/ChainedFilter.java\n\nWhen Filter is going to move from BitSet to Matcher, these will have to be reimplemented.\nThey basically use Filters to provide BitSets, but it seems to me that they also\ncould use lists of BitSets, for example.\n",
            "date": "2007-07-25T15:10:30.534+0000",
            "id": 63
        },
        {
            "author": "Paul Elschot",
            "body": "The whole thing in three patches:\n\nThe Matcher-ground patch is the groundwork, which should be very similar to the earlier groundwork patch.\n\nThe Matcher-default patch provides a default implementation, the same as the one I posted earlier today. Among others, It includes OpenBitSet from solr in org.apache.lucene.util .\n\nThe Matcher-core uses the default implementation inside the rest of the lucene core and test code. It replaces Filter.bits() methods with Filter.getMatcher() methods in the subclasses of Filter.\n\n\nAll core tests pass with these patches aplied., except the one below.\nI could not determine why this test fails, and the only\nreason I can think of now is that Matcher is not serializable.\nCould someone give me a clue on this?\n\n    [junit] Testsuite: org.apache.lucene.search.TestRemoteCachingWrapperFilter\n    [junit] Tests run: 1, Failures: 1, Errors: 0, Time elapsed: 1.32 sec\n    [junit]\n    [junit] Testcase: testTermRemoteFilter(org.apache.lucene.search.TestRemoteCachingWrapperFilter):    FAIL\n    [junit] expected:<1> but was:<0>\n    [junit] junit.framework.AssertionFailedError: expected:<1> but was:<0>\n    [junit]     at org.apache.lucene.search.TestRemoteCachingWrapperFilter.search(TestRemoteCachingWrapperFiava:84)\n    [junit]     at org.apache.lucene.search.TestRemoteCachingWrapperFilter.testTermRemoteFilter(TestRemoteCarapperFilter.java:109)\n    [junit]\n    [junit]\n    [junit] Test org.apache.lucene.search.TestRemoteCachingWrapperFilter FAILED\n\n\nFinally, contrib may not even compile with the patches applied.\nI used a version of Filter with an abstract getMatcher() method for the Matcher-core patch,\nand I also used that to cut the explicit BitSet things from my contrib working copy.\nHowever, I don't want to provide a patch for contrib yet, it's too far from ready here,\nand I'd like some comments on how to go about that first.\n",
            "date": "2007-07-25T18:12:36.678+0000",
            "id": 64
        },
        {
            "author": "Mark Harwood",
            "body": "Hi Paul,\nNot sure if I'm missing something but I think this patch may not work for scenarios other than the simple option of a single filter being used on a search.\n\nA Matcher does not have the same utility as a BitSet because using a BitSet you can:\n\n1) iterate across it using multiple threads.\n2) Clone it.\n3) Merge it quickly with other bitsets using Boolean logic .\n4) Use it more than once.\n\nI think these differences become important in the following scenarios :\n\nIn CachingWrapperFilter I don't think you can cache Matchers instead of bitsets - because Matchers don't have features 1 and 4\n\nBooleanFilter and ChainedFilter in contrib don't work with Matchers because there is no support  for 3) \n\nIs there something obvious I've missed?\n\nCheers\nMark",
            "date": "2007-07-25T19:48:34.203+0000",
            "id": 65
        },
        {
            "author": "Paul Elschot",
            "body": "Have a look at BitSetMatcher in the -default patch. It is constructed from a BitSet, and it has a method getMatcher() that returns a Matcher that acts as a searching iterator over the BitSet.\n\nSo that is 1) to 4), at least potentially. A clone() method is currently not implemented iirc, but each call to getMatcher() will return a new iterator over the underlying BitSet. And when guaranteed non modifyability is needed, a constructor can take a copy of the given document set, in whatever form.\n\nThe point of Matcher is that it allows other implementations than BitSet, like OpenBitSet and SortedVIntList. Both have the properties that you are looking for. SortedVIntList can\nsave a lot of memory when compared to (Open)BitSet, and OpenBitSet is somewhat faster than BitSet. \n\nI'd like to have a skip list version of SortedVIntList, too. This would be slightly larger than SortedVIntList, but more efficient on skipTo().\n\nBut the first thing that is necessary is to have Filter independent from BitSet.\n\nThe real pain with that is going to be the code that currently implements Filters\noutside the lucene code base, and a default implementation of a Matcher\nshould be of help there, just as it is in the -core patch now.\n\nThe default implementation will probably need to be improved from its current\nstate, but that can be done later. For example, one could also use OpenBitSet\nin all cases, and even collect the filtered documents directly in that.\n\nCheers,\nPaul Elschot",
            "date": "2007-07-25T21:54:08.497+0000",
            "id": 66
        },
        {
            "author": "Paul Elschot",
            "body": "I forgot to mention that boolean logic on Matchers is already in present in BooleanScorer2.\nThis is because each Scorer is a Matcher.",
            "date": "2007-07-25T22:05:03.624+0000",
            "id": 67
        },
        {
            "author": "Mark Harwood",
            "body": "Thanks for the reply, Paul.\n\nI saw BitSetMatcher etc and appreciate the motivation behind the design for alternative implementations . What concerns me with the Matcher API in general is that Matchers have non-threadsafe safe state (i.e. the current position required to support next() )and as such aren't safely cachable in the same way as BitSets. I see the searcher code uses the safer skipTo() rather than next()  but there's still the \"if(exhausted)\" thread safety problem to worry about which is why I raised points 1 and 4.\n\nAdditionally, combining Bitsets using Booolean logic is one method call whereas combining heterogenous Matchers using Boolean logic requires iteration across them and therefore potentially many method calls (point 3). I haven't benchmarked this but I imagine it to be significantly slower?\nI use BooleanFilter a lot for security where many large sets are cached and combined on the fly - caching all the possible combinations as single bitsets would lead to too many possible combinations. \n\nCheers\nMark",
            "date": "2007-07-26T04:08:47.120+0000",
            "id": 68
        },
        {
            "author": "Paul Elschot",
            "body": "Mark,\n\nThe exhausted flag is only in the iterator/Matcher, not in the underlying set data structure. One can use as many iterators as necessary, for example one per thread, and then there is never a threadsafety problem. (See BitSetMatcher.getMatcher() which uses a local class for the resulting Matcher.)\n\nYou wrote: I use BooleanFilter a lot for security where many large sets are cached and combined on the fly - caching all the possible combinations as single bitsets would lead to too many possible combinations.\n\nThat can still be done, but one needs to get to the BitSets for example by caching them outside the Filters and constructing the resulting BitSetMatcher for the combined Filter on the fly.\n\nAn alternative would be to have a BooleanQuery.add(Matcher, Occur), where the occurrence can only be required or prohibited. Then there is no need to construct any resulting filter because the boolean logic will be executed during the search.  This might even be more efficient than combining the full BitSets ahead of the search.\n\nAnd with many large BitSets cache memory savings from more compact implementations can also be helpful.\n\n",
            "date": "2007-07-26T08:47:08.748+0000",
            "id": 69
        },
        {
            "author": "Paul Elschot",
            "body": "Mark,\n\nAn easy way to keep things like BooleanFilter working could be to\nintroduce a subclass of Filter, say BitsFilter that adds a bits(IndexReader) method.\nThis class should also implement getMatcher(), the default implementation could\nbe used for that initially.\nThen BooleanFilter could simply be a subclass of BitsFilter, possibly without further\nmodifications, although I would prefer to rename it to BooleanBitsFilter.\n\nThat would only involve some deprecation warnings in BitsFilter for the period\nthat Filter.bits() is deprecated.\n\nI would not even mind cooking this up as patch to contrib.\n\nThoughts?\n",
            "date": "2007-07-28T09:16:51.893+0000",
            "id": 70
        },
        {
            "author": "Paul Elschot",
            "body": "A different take in the patches of 20070730.\n\nIn this version class Filter has only one method:\npublic abstract Matcher getMatcher(IndexReader).\n\nClass BitSetFilter is added as a subclass of Filter, and it has the familiar\npublic abstract BitSet bits(IndexReader),\nas well as a default implementation of the getMatcher() method.\n\nIn the ..core.. patch, and in the ..contrib.. patches (to follow), most uses of Filter simply replaced by BitSetFilter. This turned out to be an easy way of dealing\nwith this API change in Filter.\n\nThis change to Filter and its replacement by BitSetFilter could well be taking\nthings too far for now, and I'd like to know whether other approaches\nare preferred.\n\nThe ..default.. patch contains a default implementation of a Matcher from a BitSet, and it has OpenBitSet and friends from solr, as well as SortedVIntList as posted earlier.\n\n\n\n\n\n",
            "date": "2007-07-30T19:15:38.304+0000",
            "id": 71
        },
        {
            "author": "Paul Elschot",
            "body": "Some 20070730 patches to contrib using BitSetFilter.\nThe contrib-misc and contrib-queries patches are reasonbly good,\ntheir tests pass and replacing Filter by BitSetFilter is right for them.\n\nHowever, I'm not happy with the contrib-xml patch to the xml-query parser.\nI had to criple some of the code and to disable the TestQueryTemplateManager test.\nI don't know how to get around this, basically because I don't know whether\nit is a good idea at all to move the xml-query-parser to BitSetFilter. It might be\nbetter to move it to Filter.getMatcher() instead, but I have no idea how to do this.\n",
            "date": "2007-07-30T19:24:50.005+0000",
            "id": 72
        },
        {
            "author": "Paul Elschot",
            "body": "Uploading the patches again, this time with the ASF license.",
            "date": "2007-07-30T19:27:06.866+0000",
            "id": 73
        },
        {
            "author": "Paul Elschot",
            "body": "Some more remarks on the 20070730 patches.\n\nTo recap, this introduces Matcher as a superclass of Scorer to take the role that BitSet currently has in Filter.\n\nThe total number of java files changed/added by these patches is 47, so some extra care will be needed.\nThe following issues are still pending:\n\nWhat approach should be taken for the API change to Filter (see above, 2 comments up)?\n\nI'd like to get all test cases to pass again. TestRemoteCachingWrapperFilter still does not pass, and\nI don't know why.\n\nFor xml-query-parser in contrib I'd like to know in which direction to proceed (see 1 comment up).\nDoes it make sense to try and get the TestQueryTemplateManager test to pass again?\n\nThe ..default.. patch has taken OpenBitSet and friends from solr to have a default implementation.\nHowever, I have not checked whether there is unused code in there, so some trimming may still\nbe appropriate.\n\nOnce these issues have been resolved far enough, I would recommend to introduce this shortly after a release so there is some time to let things settle.\n\n",
            "date": "2007-07-30T19:50:31.318+0000",
            "id": 74
        },
        {
            "author": "Mark Harwood",
            "body": "Hi Paul,\nMany thanks for your responses.\nSorry for the delay in communications - just got back from 2 weeks holiday and slowly picking my way through this patch. \n\nYou said: \"there is never a threadsafety problem. (See BitSetMatcher.getMatcher() which uses a local class for the resulting Matcher.)\"\n\nDid you mean BitSetFilter.getMatcher()? BitSetMatcher has no getMatcher method.\n\nIf so, doesn't my original thread safety issue still stand? - CachingWrapperFilter is caching Matchers (not Filters which are factories for matchers). \n\nThe existing approach of adding a <CachedFilter> tag around my XML-based query templates offers a major speed up in my applications and I don't see this supported in this patch currently which gives me some concern. This existing caching technique is based on the use of CachingWrapperFilter.\n\nThe proposed framework seems to be missing a means of caching reusable, threadsafe  Matchers in a type-independent fashion. One solution (which I think you may be suggesting with the \"getMatcher\" comment) is to cache Filter objects and use Filter.getMatcher(reader) as a factory method for thread-specific, single-use Matchers but this would suggest that any caching then becomes an implied responsibility/overhead of each Filter implementation. Not too great. CachingWrapperFilter is an example of a better design where the caching policy has been implemented in a single class and it can be used to decorate any Filter implementation (RangeFilter etc) with the required caching behaviour. Unfortunately with this proposed patch there is no way that any such single caching policy can work with any Filter because Matcher is not reusable/cachable. Time to remove any  thread-specific state from Matcher?\n\n\nCheers\nMark\n\n\n\n\n\n\n\n\n\n\n\n",
            "date": "2007-08-08T22:55:38.058+0000",
            "id": 75
        },
        {
            "author": "Mark Harwood",
            "body": "Some further thought on the roles/responsibilities of the various components:\n\nGiven a blank sheet of paper (a luxury we may not have) the minimum requirements I would have could be met with the following:\n(note that use of the words \"Matcher\" and \"Filter\" etc have been removed because sets of doc IDs have applications outside of filtering/querying e.g. category counts)\n\ninterface DocIdSetFactory\n{\n    DocIdSet getDocIdSet(IndexReader reader)\n}\nThis is more or less equivalent to the purpose of the existing \"Filter\" - different implementations define their own selection criteria and produce a set of matching doc Ids e.g. equivalent of RangeFilter. Each implementation must implement \"hashcode\" and \"equals\" methods based on it's criteria so the factory can be cached and reused (in the same way Query objects are expected to). The existing CachedFilterBuilder in the XMLQueryParser provides one example of a strategy for caching Filters using this facility. \n\n\ninterface DocIdSet\n{\n    DocIdSetIterator getIterator();\n}\nThis interface defines an immutable, threadsafe (and therefore cachable) collection of doc IDs. Different implementations provide space-efficient alternatives for sparse or heavily populated sets e.g. BitSet, OpenBitSet, SortedVIntList. As an example caching strategy - the existing CachingWrapperFilter would cache these objects in a WeakHashMap keyed on IndexReader.\n\ninterface DocIdSetIterator\n{\n    boolean next();\n    int getDoc();\n   ....etc\n}\nA thread unsafe, single use object, (probably with only one implementation) that is used to iterate across any DocIdSet. Not cachable and used by Scorers.\n\nIn the existing proposal it feels like DocIdSet and DocIdSetIterator are rolled into one in the form of the Matcher which complicates/prevents caching strategies.\n\nCheers\nMark\n\n\n",
            "date": "2007-08-09T07:09:29.338+0000",
            "id": 76
        },
        {
            "author": "Paul Elschot",
            "body": "Mark,\n\nI said: \"there is never a threadsafety problem. (See BitSetMatcher.getMatcher() which uses a local class for the resulting Matcher.)\"\nThat was a mistake. BitSetMatcher is a Matcher constructed from a BitSet, and SortedVIntList has a getMatcher() method, and I confused the two.\n\nA Matcher is intended to be used in a single thread, so I don't expect thread safety problems.\n\nThe problem for the XML parser is that with this patch, the implementing data structure of a Filter becomes\nunaccessible from the Filter class, so it cannot be cached from there.\nThat means that some cached data structure will have to be chosen, and one way to do\nthat is by using class BitSetFilter from the patch. This has a bits() method just like the current Filter class.\nCachingWrapperFilter could then become a cache for BitSetFilter.\n\nThere is indeed no caching of filters in this patch.\nThe reason for that is that some Filters do not need a cache. For example:\nclass TermFilter {\n  TermFilter(Term t) {this.term = t;}\n  Matcher getMatcher(reader) {return new TermMatcher( reader.termDocs(this.term);}\n}\nTermMatcher does not exist (yet), but it could be easily introduced by leaving all the\nscoring out of the current TermScorer.\n\nAs for DocIdSet, as long as this provides a Matcher as an iterator, it can be used to\nimplement a (caching) filter.\n\nI don't think this patch complicates the implementation of caching strategies.\nFor example one could define:\nclass CachableFilter extends Filter {\n  ... some methods to access the underlying data structure to be cached. ...\n}\nor write a similar adapter for some subclass of Filter and then write a FilterCache that caches these.\n\nI did consider defining Matcher as an interface, but I preferred not to do that because\nof the default explain() method in the Matcher class of the patch.\n",
            "date": "2007-08-09T19:45:10.888+0000",
            "id": 77
        },
        {
            "author": "Mark Harwood",
            "body": "Hi Paul,\n\nNot sure we've reached a common understanding here yet.\n\nYou said \"That was a mistake. BitSetMatcher is a Matcher constructed from a BitSet, and SortedVIntList has a getMatcher() method, and I confused the two. \"\nOk, thanks for the clarification. I still feel uncomfortable because the method getMatcher() is not abstracted to a common interface. This was the thinking behind my \"getIterator\" method on DocIdSet.\n\nI too made a mistake in my earlier comments. DocIdSetIterator does NOT have \"probably one implementation\". There would be an implementation for each different type of DocIdSet (Bitset/OpenBitSet/VIntList).\n\nYou said \"some Filters do not need a cache. For example: TermFilter\".  I'm not sure why that has been singled out as not worthy of caching. I have certain terms (e.g. gender:male) where the TermDocs is very large (50% of all docs in the index!) so multiple calls to TermDocs for term \"gender:male\" (if that is what you are suggesting) is highly undesirable. These are typically handled in the XMLQueryParser using syntax like this:\n  <CachedFilter>\n        <TermsFilter fieldName=\"gender\">male</TermsFilter>\n  </CachedFilter>\n\nYou said: \"CachingWrapperFilter could then become a cache for BitSetFilter. \"\nThis means that the only caching strategy is one based on bitsets - does this not lose perhaps the main benefit of your whole proposal? - the ability to have alternative space efficient storage of sets of document ids e.g. SortedVIntList.\n\nIf this is undesirable (my guess is \"yes\") then the proposal in my previous comment is a solution which allows for caching of any/all types of the new sets (openBitSet,BitSet,SortedVIntList etc) Regardless of my choice of class names or decisions over interfaces vs abstract classes do you not at least agree the need for 3 types of functionality:\n\n1) A factory for instantiating sets of document ids matching a particular set of criteria (which can be costly to call). While the factory is not expected to implement a caching  strategy it is expected to implement hashcode/equals simply to aid any caching services which would need this help to identify previously instantiated sets which share the same criteria as ant new requests (This service I identified as my \"DocIdSetFactory\" and TermsFilter/RangeFilter would be example implementations). \n2) An object representing an instantiated set of document ids which can be cached and can create iterators for use in seperate threads (identified as my DocIdSet -  example implementations being called something like BitSetDocSet, SortedVIntList) \n3) An iterator for a set of document ids (my DocIdSetIterator - example impls being called something like BitSetDocSetIterator SortedVIntListIterator)\n\nEach type of functionality can have different implementations so the functionality must be defined using an interface or abstract class. \nIf we can agree this much as a set of responsibilities then we can begin to map these services onto something more concrete.\n\n\nCheers\nMark\n\n\n\n\n",
            "date": "2007-08-09T21:32:26.596+0000",
            "id": 78
        },
        {
            "author": "Paul Elschot",
            "body": "Mark,\n\nI think we are one the same line, it's just that I don't want to go that far now.\nHave another look at the title of this issue, it may be in your title bar, but otherwise \nit's quite a bit of scrolling so I'll repeat it here: \"Decouple Filter from BitSet\". \nThat is the main thing that this patch tries to do.\n\nAnd that also makes it a starting point for caching of different data structures for Filters.\nCaching of Filters is very much needed, but I'd rather see that as another issue.\n\nThe DefaultMatcher class tries to do some compression by using a SortedVIntList when that is smaller than a BitSet, and that is about as far as I'd like to go now.\n\nProost,\nPaul Elschot\n",
            "date": "2007-08-09T22:28:26.402+0000",
            "id": 79
        },
        {
            "author": "Mark Harwood",
            "body": "OK, I appreciate caching may not be a top priority in this proposal but I have live systems in production using XMLQueryParser and which use the existing core facilities for caching. As it stands this proposal breaks this functionality (see \"FIXME\" in contrib's CachedFilterBuilder and my concerns over use of  unthreadsafe Matcher in the core class CachingWrapperFilter)\n\nI am obviously concerned by this and keen to help shape a solution which preserves the existing capabilities while adding your new functionality. I'm not sure I share your view that support for caching can be treated as a separate issue to be dealt with at a later date. There are a larger number of changes proposed in this patch and if the design does not at least consider future caching issues now, I suspect much will have to be reworked later. The change I can envisage most clearly is expressed in my concern that the DocIdSet and DocIdSetIterator services I outlined are being combined in Matcher as it stands now and these functions will have to be separated.\n\nCheers\nMark",
            "date": "2007-08-09T23:14:32.900+0000",
            "id": 80
        },
        {
            "author": "Hoss Man",
            "body": "I, unfortunately, haven't had the time to read through everything in the latest patches, but catching up on my jira mail one of Paul's comments jumped out at me, so i wanted to make sure it's completley clear: this latest set of patches completely breaks backwards compatibility for any clients who have Filter subclasses, or methods that take a Filter as a param, since the Filter class now has an abstract getMatcher method and no longer supports an abstract BitSet method -- presumably the expectation being that all client code should have a search/replace done from Filter=>BitSetFilter\n\nwhich begs the question: why not eliminate BitSetFilter and move it's getMatcher impl to the Filter class?  (if the concern is just that there be a \"higher level\" class in which both methods are abstract, why not insert a parent with some new name above the Filter class?)\n\n\n\n\nFor the record: it really bothers me that the old attachments got deleted ... the inability to refresh my memory by looking at the older patches and compare them with the current patches is extremely frustrating",
            "date": "2007-08-23T05:55:50.725+0000",
            "id": 81
        },
        {
            "author": "Paul Elschot",
            "body": "This set of patches indeed break backward compatibility with the current Filter class.\nThat was done to show the ideal end situation, and to make sure that the patched code is indeed there.\n\nTo get backward compatibility I'd prefer to temporarily copy the functionality from BitSetFilter into the Filter class, while still leaving BitSetFilter as it is:\n\npublic class Filter {\n   /** @deprecated use class BitSetFilter instead */\n  public abstract BitSet bits(IndexReader reader);\n\n  /** this method will become abstract once the bits() method is removed from Filter: */\n  public Matcher getMatcher(IndexReader reader) {return DefaultFilter.defaultFilter(bits(reader));}\n}\n\nThe main difference between the current set of patches and the removed patches is indicated\nin my first comment of 25 July 2007 above.\nI still have the older versions of the patch lying around here, so if you need a particular one, just indicated the date, and I'll repost or send it.\n",
            "date": "2007-08-30T19:11:48.474+0000",
            "id": 82
        },
        {
            "author": "Paul Elschot",
            "body": "Another way to decouple from BitSet would be to keep introduce a new superclass of Filter that only has an abstract getMatcher() method, and to add an implementation of that method in the current Filter class.\nThat would boil down to the current patch with two classes renamed:\nFilter ->  new class with abstract getMatcher() method.\nBitSetFilter -> Filter.\n\nThis would avoid all backward compatibility issues, except for the unlikely case in which a getMatcher() method is already implemented in an existing subclass of Filter.\nAlso, to take advantage of the independence of BitSet in other implementations, only this new class would need to be used.\nThe only disadvantage I can see is that Filter is not renamed to BitSetFilter, which it actually is. But that can be fixed by making the javadoc of Filter explicit about the use of BitSet.\n\nFor the lucene core and some of the contrib, this would mean that it would move to this new superclass of Filter. Again, I don't expect backward compatibility issues there.\n\nDoes anyone see any problems with this approach?\nWhen not, what name should this new superclass of Filter have? I'm thinking of MatchFilter, any other suggestions?",
            "date": "2007-09-01T20:21:09.089+0000",
            "id": 83
        },
        {
            "author": "Paul Elschot",
            "body": "This time (20070905), as indicated in the previous post, a set of patches that add MatchFilter as the new superclass of Filter. Backward compatibility is quite good, no changes at all are necessary in contrib.\n\nIn the 1ground patch, the current core API is moved from Filter to MatchFilter. Since Filter is a subclass of MatchFilter, I do not expect backward compatibility issues with this, but it is a quite extensive API change.\n\nIn the 2default patch, some support for MatchFilter caching was added in classes DefaultMatcher and MatcherProvider. OpenBitSet and some support for that was added from solr here, but OpenBitSet is not used (yet). SortedVIntList is also added, and this is used for caching in CachingWrapperFilter as below.\n\nIn the 3core patch, this caching support is used in CachingWrapperFilter. See also java-dev of yesterday and today for a fixed thread safety problem there.\nThe remainder of the core code is also adapted to the use of Matcher in the 3core patch. ConstantScoreQuery is a nice example.\n\nI also added the Apache Licence to all new files.\n\nAll tests pass with the patches applied, core and contrib.\nQuite a bit of javadoc is included, and the javadocs build with only one (unrelated) warning.\n\nThese 3 patches modify 35 source code files, so please tread carefully. They were generated against revision 573048.\nI did some local svn mv, svn add, and svn rm, and I hope I got\nthat right in the end. In case the patches do not apply cleanly, please holler.\n\nI will remove my previous patch set in a week or so.\n",
            "date": "2007-09-05T21:27:49.825+0000",
            "id": 84
        },
        {
            "author": "robert engels",
            "body": "I don't think \n\npublic interface AbstractBitSet\n\nis according to standards.\n\nIt should just be\n\npublic interface BitSet\n\npossibly\n\npublic interface IBitSet\n\nif coming from the Windows world.\n\nSince it is in a different package, there is no collision with the standard BitSet class.",
            "date": "2007-09-18T15:51:41.274+0000",
            "id": 85
        },
        {
            "author": "Paul Elschot",
            "body": "The posted patch proposes to use this class to determine which documents should be filtered:\n\npublic abstract class Matcher {\n  public abstract boolean next() throws IOException;\n  public abstract boolean skipTo(int target) throws IOException;\n  public abstract int doc();\n  // plus a few more methods\n}\n\nThis class is then used as a superclass of org.apache.lucene.search.Scorer.\n",
            "date": "2007-09-18T20:13:52.605+0000",
            "id": 86
        },
        {
            "author": "Paul Elschot",
            "body": "As the current patch set is large, I've been pondering how to do this in a series of smaller patches that can each be applied by itself. This is possible in the following way:\n\n1. introduce Matcher as superclass of Scorer and adapt javadocs to use matching consistently.\n2. introduce MatchFilter as superclass of Filter and add a minimal DefaultMatcher to be used in IndexSearcher, i.e. add BitSetMatcher\n3. change the current Searcher/Searchable API to use MatchFilter instead of Filter.\n\nStep 1 can be reasonably done before a new a release.\nAfter step 2 this issue might be closed, and all the rest could be treated as new issues.\n\nAfter that three (almost) independent paths can be followed:\n4. add more data structures to be used for filter caches.\n5. adapt CachingWrapperFilter to provide a Matcher from a cached datastructure, for example SortedVIntList or BitSet or OpenBitSet.\n6. further use of Matcher, mostly in BooleanScorer2.\n\nMy question is: shall I go ahead and provide a patch for step 1?\n\nAt the moment I'm refining BooleanScorer2. to use Matcher. This is for the case of multiple prohibited clauses, and also to allow the use of required and prohibited Matchers to allow adding filtering clauses to BooleanQuery.\n",
            "date": "2007-09-22T08:15:11.692+0000",
            "id": 87
        },
        {
            "author": "Paul Elschot",
            "body": "This Matcher-20071008-1ground.patch replaces the previous version because in between there was a conclict with the javadocs of Scorer for document ordering.\n\nIn today's version, Scorer is unchanged, except for the superclass Matcher, and Matcher reuses the javadocs of Scorer as much as possible.",
            "date": "2007-10-08T18:13:08.841+0000",
            "id": 88
        },
        {
            "author": "Paul Elschot",
            "body": "Attached once more, this time with licence granted to ASF.",
            "date": "2007-10-08T18:15:30.166+0000",
            "id": 89
        },
        {
            "author": "Paul Elschot",
            "body": "Resolved a local conflict in the javadocs of HitCollector.",
            "date": "2007-11-22T18:31:27.163+0000",
            "id": 90
        },
        {
            "author": "Paul Elschot",
            "body": "Resolved a local conflict in the javadocs of HitCollector. This time with licence granted to ASF.",
            "date": "2007-11-22T18:33:37.816+0000",
            "id": 91
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\n1. introduce Matcher as superclass of Scorer and adapt javadocs to use matching consistently.\n2. introduce MatchFilter as superclass of Filter and add a minimal DefaultMatcher to be used in IndexSearcher, i.e. add BitSetMatcher\n{quote}\n\nPaul, I like the iterative plan you suggested. I started reviewing the\nMatcher-20071122-1ground.patch. I've some question:\n- Is the API fully backwards compatible?\n- Did you make performance tests to check whether BitSetMatcher is \nslower than using a bitset directly?\n- With just the mentioned patch applied I get compile errors, \nbecause the DefaultMatcher is missing. Could you provide a patch that\nalso includes the BitSetMatcher and Filter#getMatcher() returns it?\nAlso I believe the patch should modify Hits.java to use MatchFilter \ninstead of Filter? And a unit test that tests the BitSetMatcher \nwould be nice!",
            "date": "2007-11-28T07:57:40.077+0000",
            "id": 92
        },
        {
            "author": "Paul Elschot",
            "body": "The patch is backwards compatible, except for current subclasses of Filter already have a getMatcher method. The fact that no changes are needed to contrib confirms the compatibility.\n\nI have made no performance tests on BitSetMatcher for two reasons.\nThe first reason is that OpenBitSet is actually faster than BitSet (have a look at the graph in the SomeMatchers.zip file attachment by Eks Dev), so it seems to be better to go in that direction.\nThe second is that it is easy to do the skipping in IndexSearcher on a BitSet directly by using nextSetBit on the BitSet instead of skipTo on the BitSetMatcher. For this it would only be necessary to check whether the given MatchFilter is a Filter.\nAnyway, I prefer to see where the real performance bottlenecks are before optimizing for performance.\n\nDefaultMatcher should be in the ...2default... patch.\nThe change in Hits to use MatchFilter should be in the ...3core.. patch.\n\nSo far, I never tried to use these patches on their own, I have only split them for a better overview. Splitting the combined patches to iterate would need a different split, as you found out. It might even be necessary to split within a single class, but I'll gladly do that.\n",
            "date": "2007-11-28T08:43:29.804+0000",
            "id": 93
        },
        {
            "author": "Michael Busch",
            "body": "OK, here's a patch that compiles cleanly on current trunk and all tests \npass. It includes:\n- all changes from Matcher-20071122-1ground.patch \n- util/BitSetMatcher.java from Matcher-20070905-2default.patch \n- Hits.java changes from Matcher-20070905-3core.patch\n- Filter#getMatcher() returns the BitSetMatcher\n\nWould you be up for providing testcases?\n\nAs I said I haven't fully reviewed the patch, but I'm planning to do \nthat soon. I can vouch that all tests pass after applying the patch.",
            "date": "2007-11-28T09:25:07.283+0000",
            "id": 94
        },
        {
            "author": "Paul Elschot",
            "body": "With the full patch applied, the following test cases use a BitSetMatcher:\n\nTestQueryParser\nTestComplexExplanations\nTestComplexExplanationsOfNonMatches\nTestConstantScoreRangeQuery\nTestDateFilter\nTestFilteredQuery\nTestMultiSearcherRanking\nTestPrefixFilter\nTestRangeFilter\nTestRemoteCachingWrapperFilter\nTestRemoteSearchable\nTestScorerPerf\nTestSimpleExplanations\nTestSimpleExplanationsOfNonMatches\nTestSort\n\nso I don't think it is necessary to provide seperate test cases.",
            "date": "2007-11-28T20:58:17.709+0000",
            "id": 95
        },
        {
            "author": "Michael Busch",
            "body": "Yes you're right, I ran the tests w/ code coverage analysis enabled, and the\nBitSetMatcher is fully covered. Good!",
            "date": "2007-11-28T21:45:57.004+0000",
            "id": 96
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nThe patch is backwards compatible,\n{quote}\n\nI think that custom Searcher or Searchable implementations won't compile anymore?\nBecause the signature of some abstract methods changed, e. g. in Searchable:\n\n{code:java}\n@@ -86,13 +86,14 @@\n    * <p>Called by {@link Hits}.\n    *\n    * <p>Applications should usually call {@link Searcher#search(Query)} or\n-   * {@link Searcher#search(Query,Filter)} instead.\n+   * {@link Searcher#search(Query,MatchFilter)} instead.\n    * @throws BooleanQuery.TooManyClauses\n    */\n-  TopDocs search(Weight weight, Filter filter, int n) throws IOException;\n+  TopDocs search(Weight weight, MatchFilter filter, int n) throws IOException;\n{code}",
            "date": "2007-12-01T22:19:13.374+0000",
            "id": 97
        },
        {
            "author": "Paul Elschot",
            "body": "I tried implementing a Searchable, and indeed ran into compilation errors.\nSo, backward compatibility is indeed not complete.\n\nAlso, Searchable is an interface, so it should not be changed.\nIn case there are other interfaces affected by the patch these should not be changed either.\n\nThere are two ways out of this:\n\nDo a name change on MatcherFilter/Filter -> Filter/BitSetFilter.\nChanging the current Filter to BitSetFilter gives other problems with contrib packages.\nI tried this some time ago, see above, but I could not make it work.\n\nI'd prefer to add an interface (or abstract class?) like Searchable that uses MatchFilter for those implementers that want to take advantage of MatchFilter.\nI don't expect problems from leaving the Searchable interface available unchanged.\nOther interfaces that use Filter can be treated the same way, in case there are any.\n\n\n",
            "date": "2007-12-02T10:56:20.133+0000",
            "id": 98
        },
        {
            "author": "Michael Busch",
            "body": "Why do we actually need the new MatchFilter class at all?\nFilter is an abstract class, not an interface. So I think we could\nsimply add the new method getMatcher() like you already did\nin your patch:\n\n{code:java}\n  /**\n   * @return A Matcher constructed from the provided BitSet.\n   * @see    DefaultMatcher#defaultMatcher(BitSet)\n   */\n  public Matcher getMatcher(IndexReader reader) throws IOException {\n    return new BitSetMatcher(bits(reader));\n  }\n{code}\n\nThis shouldn't break existing Filter implementations? \nMaybe I'm missing an apparent reason why we need the MatchFilter\nclass?",
            "date": "2007-12-02T22:31:54.258+0000",
            "id": 99
        },
        {
            "author": "Paul Elschot",
            "body": "For example, OpenBitSetFilter would like this:\n{code}\nclass OpenBitSetFilter  /* ... */ {\n  OpenBitSet bits(reader) { ... }\n  Matcher getMatcher(reader) { ... }\n}\n{code}\nSince the only thing needed by an IndexSearcher would be the Matcher,\nMatchFilteris  what Filter and OpenBitSetFilter have in common:\nthe getMatcher() method.\n\n",
            "date": "2007-12-02T23:03:21.139+0000",
            "id": 100
        },
        {
            "author": "Michael Busch",
            "body": "What about adding the getMatcher() method to Filter and\ndeprecating bits(IndexReader)? Then when we release\n3.0 we can remove bits() and the only method in Filter\nwill be getMatcher().\n\nThen this patch should be backwards compatible\nand we'd do the API change with the next major release.\nAny objections?",
            "date": "2007-12-02T23:16:54.677+0000",
            "id": 101
        },
        {
            "author": "Paul Elschot",
            "body": "I had not thought about deprecating yet, but it should work nicely.\nI suppose you want to add a class BitSetFilter (subclass of Filter) as the preferred alternative\nto the deprecated method?\nInitially Filter and BitSetFilter would  be very similar, except that Filter.bits() would be deprecated.\nLater, after  removal of Filter.bits(), Filter.getMatcher() would be declared abstract.\n\nI tried to do something pretty close to this for contrib/xml-query-parser, but I could not make that work,\nwhich is why I changed to adding a new superclass MatchFilter.\nNevertheless, I think the deprecation above should work, but at the moment I can't foresee the consequences.\n",
            "date": "2007-12-02T23:33:36.130+0000",
            "id": 102
        },
        {
            "author": "Michael Busch",
            "body": "OK, here's a new version of the patch.\nChanges:\n- Removed MatchFilter entirely.\n- Filter.bits(IndexReader) is now deprecated and not abstract anymore. \nFilter.bits(IndexReader) returns null, and Filter.matcher(IndexReader)\nreturns the new BitSetMatcher. This allows to create new Filters that \nonly implement the new getMatcher(IndexReader) method. Existing filters\non the other hand will still work together with the BitSetMatcher.\n\n- The new class BitSetFilter extends Filter and defines the abstract\nmethod bits(IndexReader), just as Filter did before this patch.\n\n- I deprecated also CachingWrapperFilter and RemoteCachingWrapperFilter\nand added corresponding CachingBitSetFilter and RemoteCachingBitSetFilter\nwhich do essentially the same but only accept BitSetFilters.\n\nAll testcases pass and believe this should be fully backwards compatible.\nAlso, all core classes that call Filter.bits() are deprecated themselves.\n\nIn Lucene 3.0 we should make the following changes:\n- Remove Filter.bits() and define Filter.getMatcher() abstract.\n- Remove CachingWrapperFilter and RemoteCachingWrapperFilter\n(and corresponding testcases)\n- Add new matchers, like the OpenBitSetMatcher and SortedVIntMatcher\nand add the DefaultMatcher class. (these classes are all located in\nPaul's patch files)",
            "date": "2007-12-03T05:53:34.105+0000",
            "id": 103
        },
        {
            "author": "Paul Elschot",
            "body": "A few remarks on the lucene-584-take2 patch:\n\nIn the @deprecated javadoc at Filter.bits() a reference to BitSetFilter could be added.\n\nWhile Filter.bits() is still deprecated, one could also use the BitSet in IndexSearcher\nin case this turns out to be performance sensitive; see also my remark of 28 November.\n\nA few complete (test) classes are deprecated, it might be good to add the target release\nfor removal there.\n\nFor the rest this patch looks good to me. Did you also run ant test-contrib ?",
            "date": "2007-12-03T16:47:59.090+0000",
            "id": 104
        },
        {
            "author": "Mark Harwood",
            "body": "To go back to post #1 on this topic:\n\n   _\"Sparsely populated =java.util.BitSet=s are not efficient and waste lots of memory. It would be desirable to have an alternative BitSet implementation with smaller memory footprint.\"_\n\nGiven the motivation to move to more memory efficient structures  why is the only attempt at caching dedicated exclusively to caching the very structures we were trying to move away from?.....\n\n       _\"I deprecated also CachingWrapperFilter and RemoteCachingWrapperFilter and added corresponding CachingBitSetFilter and RemoteCachingBitSetFilter\"_\n\nDoes this suggest we are to have type-specific CachingXxxxxFilters and RemoteCachingXxxxxFilters created for every new filter type? Why not provide a single caching mechanism that works for all those other, new, more memory-efficient structures? I beleive the reason this hasn't been done is due to the issue I highlighted earlier - the cachable artefacts (what I chose to call \"DocIdSet\" here: [#action_12518642] ) are not modelled in  a way which promotes re-use. That's why we would end up needing a specialised caching implementations for each type. \n\nIf we are to move forward from the existing Lucene implementation it's important to note the change:\n\n* Filters currently produce, at great cost, BitSets. Bitsets provide both a cachable data structure and a thread-safe, reusable  means of iterating across the contents.\n\n* By replacing BitSets with Matchers this proposal has removed an important aspect of the existing design -  the visibility (and therefore cachability) of these expensive-to-recreate data structures. Matchers are single-use, non-threadsafe objects and hide the data structure over which they iterate. With this change if I want to implement a caching mechanism in my application I need to know the Filter type and what sort of data structure it returns and get it from it directly:\n  if(myFilter instanceof BitSetFilter)    wrap specific data structure using CachingBitSetFilter\n  else\n  if(myFilter instanceof OpenBitSetFilter)   wrap specific data structure using CachingXxxxxFilter\n  else...\n\n...looks like an Anti-pattern to me. Worse, this ties the choice of datastructure to the type of Filter that produces it. Why can't my RangeFilter be free to create a SortedVIntList or a BitSet depending on the sparseness of matches for a particular set of criteria?\n\nI'm not saying \"lets just stick with Bitsets\", just consider caching more in the design. Post [#action_12518642] lays out how this could be modelled with the introduction of DocIdSet and DocIdSetIterator as separate responsibilities (whereas Matcher currently combines them both).\n\nCheers\nMark\n\n\n\n\n\n\n\n\n\n\n\n\n",
            "date": "2007-12-03T17:05:24.314+0000",
            "id": 105
        },
        {
            "author": "Paul Elschot",
            "body": "Mark, in the latest Matcher....-2default.patch there is the org.apache.lucene.MatcherProvider interface with this javadoc:\n\n/** To be used in a cache to implement caching for a MatchFilter. */\n\nThis interface has only one method:\n\npublic Matcher getMatcher();\n\n\nThere is also a cache for filters in the Matcher....3core.patch in the class CachingWrapperFilter .\n\nWould those be a good starting point?\n",
            "date": "2007-12-03T19:34:54.208+0000",
            "id": 106
        },
        {
            "author": "Mark Harwood",
            "body": "I'm getting lost as to which patches we're considering here. I was looking at lucene-584-take2 patch.\n\nMatcherProvider in the earlier patch does look like something that will help with caching.\n\n>>Would those be a good starting point?\n\nOverall I feel uncomfortable with a lot of the classnames. I think the use of \"Matcher\" says more about what you want to do with the class in this particular case rather than what _it_ does generally. I have other uses in mind for these classes that are outside of filtering search results. For me, these classes can be thought of much more simply as utility classes in the same mould as the java Collections API. Fundamentally, they are efficient implementations of sets/lists of integers with support for iterators. The whole thing would be a lot cleaner if classes were named around this scheme.\n\"MatcherProvider\" for example is essentially a DocIdSet  which creates forms of DocIdSetIterators (Matchers) and could also usefully have a size() method. \n\n",
            "date": "2007-12-03T21:13:13.938+0000",
            "id": 107
        },
        {
            "author": "Paul Elschot",
            "body": "In case there is a better name than Matcher for a Scorer without a score() method (and maybe without an explain() method), I'm all ears. Names are important, and at this point they can still be changed very easily.\n\nFor Matcher I'd rather have a method to estimate the number of matching docs than a size() method. This estimate would be useful in implementing conjunctions, as the Matchers with the lowest estimates could be used first. However, this is another issue.\n",
            "date": "2007-12-03T22:50:06.590+0000",
            "id": 108
        },
        {
            "author": "Mark Harwood",
            "body": "For the data structures (bitset/openbitset/sorted VintList/) I would suggest one of these: IntSet, IntegerSet or IntegerSequence as names for the common interface.\nI did a quick Google for IntegerSet and you are in the number one spot, Paul :) [http://www.google.com/search?hl=en&q=integerset+bitset]\n\n// A cachable, immutable, sorted, threadsafe collection of ints.\ninterface IntegerSet\n{\n   IntegerSetIterator getIterator();\n   int size(); //negative numbers could be used to represent estimates?\n}\n\n// A single-use thread-unsafe iterator.\ninterface IntegerSetIterator\n{\n    boolean next();\n    boolean skipTo(int next);\n    int currentValue();\n}\n\nIf _detailed_ explanations of hits are required these should really sit with the source not the result- i.e. with the Filters. They contain all the match criteria used to populate IntegerSets  and can be thought of more generically as IntegerSetBuilder. \n\n//Contains criteria to create a set of matching documents. MUST implement hashcode and equals based on this criteria to enable use as cache keys for IntegerSets.\ninterface IntegerSetBuilder extends Serializable\n{\n      IntegerSet build (IndexReader reader)\n      Explanation explain(int docNr);\n}\n\n\n\nA single CachingIntegerSetBuilder class would be able to take ANY IntegerSetBuilder as a source, cache ANY type of IntegerSet they produced and defer back to the original IntegerSetBuilder for a full and thorough explanation of a match even when the match occurred on a cached IntegerSet, if required.\n\nclass CachingIntegerSetBuilder implements IntegerSetBuilder\n{\n     private WeakHashMap perIndexReaderCache;\n     public CachingIntegerSetBuilder(IntegerSetBuilder delegate) {....}\n     .....\n}\n\nThe reason for introducing IntegerSetBuilder as a more generic name than \"Filter\" is IntegerSets have uses outside of  filtering e.g. to do category counts or clustering. In these use cases they don't actually perform anything to do with filtering.  It may actually be better named DocIdSetBuilder given that it is tied to Lucene's IndexReader and therefore limited to producing sets of document ids.\n",
            "date": "2007-12-04T10:49:56.070+0000",
            "id": 109
        },
        {
            "author": "Paul Elschot",
            "body": "For the moment a DocId is an int, but that might change to long sooner than we think. So DocIdSet... would be a better name than IntegerSet..., and it's better to use an abstract superclass than an interface:\n\n{code}\nabstract class DocIdSetIterator {\n  boolean next();\n  boolean skipTo(int next);\n  int doc();\n}\n\n// and the rest is in the patch, except the superclass for Matcher:\n\nabstract class Matcher extends DocIdSetIterator {\n  Explanation explain(int doc);\n}\n\nabstract class Scorer extends Matcher {\n  float score();\n  ...\n}\n{code}\n\nWould this DocIdSetIterator be close enough to the IntegerSetIterator?\n",
            "date": "2007-12-04T18:40:31.152+0000",
            "id": 110
        },
        {
            "author": "Michael Busch",
            "body": "OK, I created a new patch based on the recent feedback.\n\nThis patch introduces two new abstract classes:\n{code:java}\n/**\n * A DocIdSet contains a set of doc ids. Implementing classes must provide\n * a {@link DocIdSetIterator} to access the set. \n */\npublic abstract class DocIdSet {\n  public abstract DocIdSetIterator iterator();\n}\n\n/**\n * This abstract class defines methods to iterate over a set of\n * non-decreasing doc ids.\n */\npublic abstract class DocIdSetIterator {\n  public abstract int doc();\n  \n  public abstract boolean next() throws IOException;\n    \n  public abstract boolean skipTo(int target) throws IOException;\n}\n{code}\n\nAdditional changes:\n\n- Scorer extends DocIdSetIterator now.\n\n- Filter.bits(IndexReader) is not abstract anymore. It is deprecated and \nreturns null. Added method Filter.getDocIdSet(IndexReader) which returns\nnew DocIdBitSet(bits(reader)) for backwards compatibility.\n\n- Added getDocIdSet(IndexReader) implementations to all core readers and\ndeprecated bits(IndexReader). The Filters (e. g. RangeFilter) are now\nusing OpenBitSet instead of BitSet.\n\n- Made according changes to the SpanFilter classes.\n\n- Fixed a bug in OpenBitSetIterator. It has an integer curDocId now, which\ndoc() returns. Before doc() sometimes returned wrong values. I also added\nTestOpenBitSet (take from current Solr trunk).\n\nI haven't changed the contrib Filter implementations yet, they still use \nthe old (deprecated) API. We should address this with a different issue.\n\nAll core & contrib tests pass. This patch should also be fully backwards\ncompatible.",
            "date": "2008-01-10T08:04:46.847+0000",
            "id": 111
        },
        {
            "author": "Paul Elschot",
            "body": "On the take3 patch of 10 Jan 2008:\n\nSortedVIntList extends DocIdSet: nice, thanks.\n\nPrefixGenerator is used but not defined in the patch, so it will not compile.\n\nNevertheless, with all tests passing, I think this is a good way to\nmake Filter independent of BitSet.\n\n\nMinor concerns:\n\nThere is neither a BitSetFilter nor an OpenBitSetFilter in the patch.\nThese might be useful for existing code currently implementing Filter\nto overcome the deprecation of Filter.bits().\nWith the current core moving to OpenBitSet, it might also use an\nexplicit OpenBitSetFilter.\n\nSome javadoc changes did not make it into the take3 patch, I'll check these later.\n\nFilteredQuery.explain(): When a document does not pass the Filter\nI think it would be better not to use setValue(0.0f) on the resulting\nExplanation. However, this may be necessary for backward compatibility.\n\n\nFor the future:\n\nAbout adding a Filter as a clause to BooleanScorer, and adding\nDocSetIdIterator as a \"Scorer\" to ConjunctionScorer:\nThis is the reason for the CHECKME in IndexSearcher for using\nConjunctionScorer when a filter is given.\nA ConjunctionScorer that accepts a DocIdSetIterator could also be used in\nFilteredQuery.",
            "date": "2008-01-10T11:21:31.236+0000",
            "id": 112
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nOn the take3 patch of 10 Jan 2008:\n{quote}\n\nThanks for the review!\n\n{quote}\nPrefixGenerator is used but not defined in the patch, so it will not compile.\n{quote}\n\nNot sure I understand what you mean. PrefixGenerator is (and was) \ndefined in PrefixFilter.java. It compiles for me.\n\n{quote}\nThere is neither a BitSetFilter nor an OpenBitSetFilter in the patch.\nThese might be useful for existing code currently implementing Filter\nto overcome the deprecation of Filter.bits().\nWith the current core moving to OpenBitSet, it might also use an\nexplicit OpenBitSetFilter.\n{quote}\n\nI think that it should be straightforward for users having filters that use\nBitSets to wrap the new DocIdBitSet around the BitSet, just as Filter currently \ndoes for backwards compatibility?\n\n{quote}\nSome javadoc changes did not make it into the take3 patch, I'll check these later.\n{quote}\n\nOh, which ones?\n\n{quote}\nFilteredQuery.explain(): When a document does not pass the Filter\nI think it would be better not to use setValue(0.0f) on the resulting\nExplanation. However, this may be necessary for backward compatibility.\n{quote}\n\nYeah, it used to work this way, that's why I didn't change it for backwards-\ncompatibility reasons.\n\n{quote}\nAbout adding a Filter as a clause to BooleanScorer, and adding\nDocSetIdIterator as a \"Scorer\" to ConjunctionScorer:\nThis is the reason for the CHECKME in IndexSearcher for using\nConjunctionScorer when a filter is given.\nA ConjunctionScorer that accepts a DocIdSetIterator could also be used in\nFilteredQuery.\n{quote}\n\nWell, let's address this with a different issue after this one is committed.\nI might have some concerns here, but I've to further think about it.",
            "date": "2008-01-10T19:18:12.309+0000",
            "id": 113
        },
        {
            "author": "Paul Elschot",
            "body": "As for PrefixGenerator:\nin my (up to date) trunk directory, this command: find . -name '*PrefixGenerator*'\nonly gave this result: ./build/classes/java/org/apache/lucene/search/PrefixGenerator.class\nand that disappeared after ant clean.\nIt seems that the source class was removed from the trunk.\n\n{quote}\nI think that it should be straightforward for users having filters that use\nBitSets to wrap the new DocIdBitSet around the BitSet, just as Filter currently\ndoes for backwards compatibility?\n{quote}\n\nBitSetFilter would inherit from Filter, and have an abstract bits() method, not deprecated.\nThis would be useful for people that don't what to move to OpenBitSet yet.\nA rename (and maybe a package change) from Filter to BitSetFilter should be sufficient\nin their code to get rid of the deprecation warning for Filter.bits().\n\nOpenBitSetFilter similar, and that could be used in a few places in the patch iirc.\n\nThe javadoc changes I meant came with Matcher and use 'match' consistently for documents\nthat are collected during a query search.\n\n",
            "date": "2008-01-10T22:05:02.164+0000",
            "id": 114
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nAs for PrefixGenerator:\nin my (up to date) trunk directory, this command: find . -name 'PrefixGenerator'\nonly gave this result: ./build/classes/java/org/apache/lucene/search/PrefixGenerator.class\nand that disappeared after ant clean.\nIt seems that the source class was removed from the trunk.\n{quote}\n\nAs I said, PrefixGenerator is defined in PrefixFilter.java.",
            "date": "2008-01-11T08:44:14.770+0000",
            "id": 115
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nBitSetFilter would inherit from Filter, and have an abstract bits() method, not deprecated.\n{quote}\n\nOK I added a BitSetFilter. The rest of the patch is identical to take3.\n\nI thought that I copied all your javadoc changes that still applied (after the removal of Matcher, MatchFilter, etc.) over into this patch. But well, if you think I missed any important ones let me know or feel free to update the patch!",
            "date": "2008-01-11T08:58:06.730+0000",
            "id": 116
        },
        {
            "author": "Paul Elschot",
            "body": "I'm sorry about my PrefixGenerator remarks, I did not read your answer accurately.\n\nOn the take4 patch of 11 Jan 2008:\n\nI have started in a fresh trunk checkout that passed all tests.\nBoth parts of take4 apply cleanly, using patch -p0 < ... .\nant jar, ant test-core and ant test-contrib all pass nicely.\n\nI remember having problems with moving contrib/xml-queryparser from Filter\nto BitSetFilter, see my comment of 30 July 2007.\nSo I'd like to verify that this can be done, and I hope Mark Harwood can give\nsome hints as to how to do this.\n\nFor me, this was the main reason to make this move:\nfrom Filter with subclass BitSetFilter (as in the take4 patch, and in my first attempts)\nto MatchFilter with subclass Filter (as in Matcher... patches of Sep and Nov 2007).\nIn these Matcher... patches no changes were necessary to contrib/xml-queryparser.\n\n\nLess important for now:\n\nThe test classes extend TestCase, but iirc there is also a LuceneTestCase for this.\n\nOn the take4 patch ant javadocs-core gives this:\nBitSetFilter.java:40: warning - Tag @link: reference not found: DocIdBitSetIterator\n",
            "date": "2008-01-11T10:30:18.085+0000",
            "id": 117
        },
        {
            "author": "Paul Elschot",
            "body": "I tried to move contrib from Filter.bits() to BitSetFilter.bits().\n\nThe ContribQueries20080111.patch does that with contrib/queries,\nand with that applied the xml-query-parser tests still pass.\nI don't expect changes will be needed to xml-query-parser because it\ndoes not use Filter.bits().\nAt the moment I don't know why I had problems with it half a year ago.\n\n\nFor contrib/miscellaneous the changes needed to ChainedFilter are more involved:\n\nTo make the tests pass, I had to make RangeFilter and QueryFilter subclasses of BitSetFilter, and to remove the final keyword from BitSetFilter.getDocIdSet().\nThe alternative would be to add BitSet versions of RangeFilter and QueryFilter\nto ChainedFilterTest.\nSo it can be made to work, but ChainedFilter and/or ChainedFilterTest will need to be changed.\n\nStepping back a bit, I think ChainedFilter might better move to OpenBitSetFilter.\nNo patch for contrib/miscelleneous, it's too ugly at the moment here.\n\nThe conclusion is that I see no real problems with the take4 patch to move contrib\nfrom Filter.bits to BitSetFilter.bits.",
            "date": "2008-01-11T14:06:24.134+0000",
            "id": 118
        },
        {
            "author": "Eks Dev",
            "body": "it looks like  ChainedFilter could  become obsolete if Filter/DocSetIdIterator gets added as a Clause to the  BooleanQuery? I am thinking along the lines: ChainedFilter evaluates boolean expression of docId-s, that is exactly what BooleanQuery does plus \"a bit\" more (scoring)... ",
            "date": "2008-01-11T14:44:59.878+0000",
            "id": 119
        },
        {
            "author": "Paul Elschot",
            "body": "{quote}\nit looks like ChainedFilter could become obsolete if Filter/DocSetIdIterator gets added as a Clause to the BooleanQuery?\n{quote}\n\nThe function is indeed the same, but ChainedFilter works directly on BitSets and BooleanQuery works on input Scorers/DocIdSetIterators and outputs collected docids (and score values). Working directly on  (Open)BitSets is normally faster, so ChainedFilter can have a good use.\nAnd boolean operations on DocIdSets are not (yet) directly available in Lucene. The various boolean scorers have the logic, but currently only for Scorers.\n\nThat leaves the question on what to do with ChainedFilter here. Any ideas?\nThe easiest way is to open another issue for it. This will have to be resolved before Filter.bits() is removed.\n",
            "date": "2008-01-11T19:24:19.651+0000",
            "id": 120
        },
        {
            "author": "Eks Dev",
            "body": "hmm, in order to have fast and/or operations we need to know the type of the underlaying object in Filter, and sometimes we must use iterators (e.g. case where one Filter/DocSetId is int list and another Hash bit set ). I guess, knowing type of DocIdSet is the trick to pool. \n \nDefault implementation of ChainedFilter (there is also BooleanFilter somewhere in contrib, I like it more) should be using iterator (like scorers), and at a few key points checking if(first instance of SomeInstanceOfDocIdSet && second  SomeInstanceOfDocIdSet) first.doFastOR/AND(second);\n\nsomething in that direction looks reasonable to me for ChainedFilter \nIf it proves to be really better to have it around. I am still of an opinion that it would be better to integrate DocIdSet into BooleanQuery as a clause, somehow, that would be some kind of ConstantBoolean(MUST/SHOULD/NOT)Clause, much cleaner from design/usability point of view, even at some minor penalty in performance (anyhow, you can always combine filters before you enter scorers) but you are right that is another issue... let us stop polluting this issue :) \n    ",
            "date": "2008-01-11T20:40:26.481+0000",
            "id": 121
        },
        {
            "author": "Paul Elschot",
            "body": "I moved Filter \"forward\" by removing the deprecated bits() method\nand declaring the getDocIdSet() method abstract.\n\nTo get ant test-core passing with this it was necessary to\nupdate some test code to implement Filter.getDocIdSet(),\nand a patch for that is attached: Test20080111.patch .\n\nThe change to Filter is not included in the patch.\nAlso, in a few places in the take4 patch Filter.bits() is used\ndeprecated methods. These methods had to be removed, but this\nremoval is not included in the patch.\n",
            "date": "2008-01-11T20:47:02.994+0000",
            "id": 122
        },
        {
            "author": "Paul Elschot",
            "body": "Upload once more, this time with licence.",
            "date": "2008-01-11T20:48:26.507+0000",
            "id": 123
        },
        {
            "author": "Michael Busch",
            "body": "I think I understand now which problems you had when you wanted to \nchange BooleanFilter and xml-query-parser to use the new Filter APIs.\n\nBooleanFilter is optimized to utilize BitSets for performing boolean\noperations fast. Now if we change BooleanFilter to use the new \nDocIdSetIterator, then it can't use the fast BitSet operations (e. g.\nunion for or, intersect for and) anymore. \n\nNow we can introduce BitSetFilter as you suggested and what I did in\nthe take4 patch. But here's the problem: Introducing subclasses of \nFilter doesn't play nicely with the caching mechanism in Lucene.\nFor example: if we change BooleanFilter to only work with \nBitSetFilters, then it won't work with a CachingWrapperFilter anymore,\nbecause CachingWrapperFilter extends Filter. Then we would have to\nintroduce new CachingWrapper***Filter, for the different kinds of\nFilter subclasses, which is a bad design as Mark pointed out in his\ncomment: https://issues.apache.org/jira/browse/LUCENE-584?focusedCommentId=12547901#action_12547901\n\nOne solution would be to add a getBitSet() method to DocIdBitSet.\nDocIdBitSet is a new class that is basically just a wrapper around a\nJava BitSet and provides a DocIdSetIterator to access the BitSet.\n\nThen BooleanFilter could do something like this:\n{code:java}\nDocIdSet docIdSet = filter.getDocIdSet();\nif (docIdSet instanceof DocIdBitSet) {\n  BitSet bits = ((DocIdBitSet) docIdSet).getBitSet();\n  ... // existing code\n} else {\n  throw new UnsupportedOperationException(\"BooleanFilter only \n  supports Filters that use DocIdBitSet.\");\n}\n{code}\n\nBut then, changing the core filters to use OpenBitSets instead of\nJava BitSets is technically an API change, because BooleanFilter\nwould not work anymore with the core filters.\n\nSo if we took this approach we would have to wait until 3.0 to move\nthe core from BitSet to OpenBitSet and also change BooleanFilter \nthen to use OpenBitSets. BooleanFilter could then also work with\neither of the two BitSet implementions, but probably not with those\ntwo mixed.\n\nAny feedback about this is very welcome. I'll try to further think\nabout how to marry the new Filter API, caching mechanism and Filter\nimplementations like BooleanFilter nicely.",
            "date": "2008-01-15T00:02:46.588+0000",
            "id": 124
        },
        {
            "author": "Eks Dev",
            "body": "Michal, would this work? \n1. providing default implementation for basic methods that is using skipping iterator(always there), so it works by default for *all* implementations, something along the lines:\n\n/**\n * A DocIdSet contains a set of doc ids. Implementing classes must provide\n * a {@link DocIdSetIterator} to access the set. \n */\npublic abstract class DocIdSet {\n\tpublic abstract DocIdSetIterator iterator();\n\npublic  DocIdSet and(DocIdSet){\n// default implementation using *iterator*;\n}\n\npublic  DocIdSet or(DocIdSet){\n// default implementation using iterator;\n}\n\n}\n\n2.  And then we *optimize* particular cases, e.g\n\npublic class DocIdBitSet extends DocIdSet{   \n        BitSet bits; // Must be there in order for iterator to work....\n\n\tpublic DocIdSetIterator iterator(){\n\t\t//this is easy...\n\t}\n\npublic  DocIdSet and(DocIdSet dis){\n\tif (dois instanceof DocIdBitSet) {\n                //not exactly like this, but the idea is there\n  \t\t this.bits.and(((DocIdBitSet) dis));\n\t\t return this;\n \t}\n\treturn super.and(DocIdSet);\n  \n }\n}\n\nSo it works always, and it works fast if need be, one instanceof check does not hurt there. Did I miss something obvious?\n\n\n\n",
            "date": "2008-01-15T09:44:19.914+0000",
            "id": 125
        },
        {
            "author": "Paul Elschot",
            "body": "I indeed recall having an problem with remote filter caching. At the time I thought it was related to serialization but I could not resolve it that way. Never mind, it does not matter anymore.\n\nBooleanFilter and ChainedFilter have the same issue here. As they provide just about the same functionality, could they perhaps be merged?\n\nThe solution using DocIdSet.and() and DocIdSet.or() looks good to me, but it will require some form of collector for the results, much like HitCollector.collect(doc, score) now and MatchCollector.collect(doc) in the Matcher...patch.\nThe boolean operations could then be accumulated into a BitSet or into an OpenBitSet, using a special case for DocId(Open)BitSet.\n\nI'd like these boolean operations on DocIdSets to be general enough for use in Scorers, for example for the conjunctions in ConjunctionScorer, PhraseScorer and in the two NearSpans. But that is another issue.\n\n",
            "date": "2008-01-15T18:52:34.982+0000",
            "id": 126
        },
        {
            "author": "Mark Harwood",
            "body": "Hi Paul,\nJust eyeballed the code but not had a chance to patch and run it yet.\n\nI was wondering about the return type for skipTo() after looking at these types of calls:\n       if (docIdSetIterator.skipTo(i) && (docIdSetIterator.doc() == i))\n\nYou could save a method invocation in cases like this if skipTo() returned the next doc id rather than a boolean. Returning a -1 would be the equivalent of what used to be \"false\".\nNot tried benchmarking it but does this seem like something worth considering?\n\nCheers\nMark",
            "date": "2008-01-31T17:27:40.617+0000",
            "id": 127
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nYou could save a method invocation in cases like this if skipTo() returned the next doc id rather than a boolean. Returning a -1 would be the equivalent of what used to be \"false\".\n{quote}\n\nTo change the signature of skipTo()  would be an API change, because with this patch Scorer extends DocIdSetIterator.\n\n-Michael",
            "date": "2008-02-01T03:46:33.373+0000",
            "id": 128
        },
        {
            "author": "Michael Busch",
            "body": "OK here's a new version of the patch.\n\nIt's based on the take4 patch with the following changes:\n- removed BitSetFilter\n- added getBitSet() method to DocIdBitSet\n- added Paul's Test20080111.patch\n- changed TestScorerPerf to use a DocIdBitSet\n- changed ChainedFilterTest, CachedFilterBuilder, TestRemoteSearchable \nto use QueryWrapperFilter instead of deprecated QueryFilter\n\nComments:\n- As mentioned in my previous comment it's not possible to wrap a \nCachingWrapperFilter around a BitSetFilter and then retrieve the BitSet \nfrom the CachingWrapperFilter. That's the reason why I removed \nBitSetFilter and added the getBitSet() method to DocIdBitSet instead.\nSo you can do something like this:\n{code:java}\nDocIdSet docIdSet = filter.getDocIdSet();\nif (docIdSet instanceof DocIdBitSet) {\n  BitSet bits = ((DocIdBitSet) docIdSet).getBitSet();\n  ...\n}\n{code}\n- I didn't include Paul's ContribQueries20080111.patch because it only \nchanges some contrib filters to extend BitSetFilter instead of Filter.\n- I like Eks' suggestion of implementing the BooleanFilter in a way that \nit can use any DocIdSetIterator and optimize special cases, when DocIdSet \nis a DocIdBitSet, OpenBitSet, etc. We should do this with a different JIRA \nissue - this patch is already big enough.\n\n\nAll core & contrib tests pass.\n\nI'd like to commit this in a couple of days if nobody objects.\n",
            "date": "2008-02-01T03:54:24.805+0000",
            "id": 129
        },
        {
            "author": "Paul Elschot",
            "body": "The take5 patch tests ok here.\n\nOne very minor remark: the javadoc at RangeFilter.getDocIdSet still mentions BitSet.\n",
            "date": "2008-02-01T18:57:50.875+0000",
            "id": 130
        },
        {
            "author": "Michael Busch",
            "body": "Thanks, Paul for testing and reviewing.\n\nI'll correct the javadocs.\n\nOK, I will commit this tomorrow if nobody objects!",
            "date": "2008-02-01T19:03:26.300+0000",
            "id": 131
        },
        {
            "author": "Michael Busch",
            "body": "Committed.\n\nI looked again at all the comments here - wow this issue was open for a long time and at lot of work was done here.\n\nPaul, thanks for your patience and all your hard work!!",
            "date": "2008-02-02T19:16:38.661+0000",
            "id": 132
        },
        {
            "author": "Paul Elschot",
            "body": "Thanks, my pleasure.\n\nI have attached a patch to CHANGES.txt to explicitly state that filters outside the lucene code base will need to be adapted.",
            "date": "2008-02-03T08:57:06.417+0000",
            "id": 133
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nI have attached a patch to CHANGES.txt to explicitly state that filters outside the lucene code base will need to be adapted.\n{quote}\n\nI added your comment to CHANGES.txt, Paul. Thanks again!",
            "date": "2008-02-04T07:43:20.084+0000",
            "id": 134
        },
        {
            "author": "Mark Miller",
            "body": "I think there is still an issue here. The code below just broke for me.\n\njava.lang.ClassCastException: org.apache.lucene.util.OpenBitSet cannot be cast to java.util.BitSet\n\tat org.apache.lucene.search.CachingWrapperFilter.bits(CachingWrapperFilter.java:55)\n\tat org.apache.lucene.misc.ChainedFilter.bits(ChainedFilter.java:177)\n\tat org.apache.lucene.misc.ChainedFilter.bits(ChainedFilter.java:152)\n\tat org.apache.lucene.search.Filter.getDocIdSet(Filter.java:49)\n\n{code}\n  public void testChainedCachedQueryFilter() throws IOException, ParseException {\n    String path = \"c:/TestIndex\";\n    Analyzer analyzer = new WhitespaceAnalyzer();\n    IndexWriter writer = new IndexWriter(path, analyzer, true);\n\n    Document doc = new Document();\n    doc.add(new Field(\"category\", \"red\", Store.YES, Index.TOKENIZED));\n    doc.add(new Field(\"content\", \"the big bad fox\", Store.NO, Index.TOKENIZED));\n    writer.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"category\", \"red\", Store.YES, Index.TOKENIZED));\n    doc.add(new Field(\"content\", \"the big bad pig\", Store.NO, Index.TOKENIZED));\n    writer.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"category\", \"red\", Store.YES, Index.TOKENIZED));\n    doc.add(new Field(\"content\", \"the horrific girl\", Store.NO, Index.TOKENIZED));\n    writer.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"category\", \"blue\", Store.YES, Index.TOKENIZED));\n    doc.add(new Field(\"content\", \"the dirty boy\", Store.NO, Index.TOKENIZED));\n    writer.addDocument(doc);\n    doc = new Document();\n    doc.add(new Field(\"category\", \"blue\", Store.YES, Index.TOKENIZED));\n    doc.add(new Field(\"content\", \"the careful bad fox\", Store.NO, Index.TOKENIZED));\n    writer.addDocument(doc);\n\n    writer.close();\n\n    Searcher searcher = null;\n\n    searcher = new IndexSearcher(path);\n\n    QueryParser qp = new QueryParser(\"field\", new KeywordAnalyzer());\n    Query query = qp.parse(\"content:fox\");\n    QueryWrapperFilter queryFilter = new QueryWrapperFilter(query);\n    CachingWrapperFilter cwf = new CachingWrapperFilter(queryFilter);\n\n    TopDocs hits = searcher.search(query, cwf, 1);\n    System.out.println(\"hits:\" + hits.totalHits);\n\n    queryFilter = new QueryWrapperFilter(qp.parse(\"category:red\"));\n    CachingWrapperFilter fcwf = new CachingWrapperFilter(queryFilter);\n    Filter[] chain = new Filter[2];\n    chain[0] = cwf;\n    chain[1] = fcwf;\n    ChainedFilter cf = new ChainedFilter(chain, ChainedFilter.AND);\n\n    hits = searcher.search(new MatchAllDocsQuery(), cf, 1);\n\n    System.out.println(\"red:\" + hits.totalHits);\n\n    queryFilter = new QueryWrapperFilter(qp.parse(\"category:blue\"));\n    CachingWrapperFilter fbcwf = new CachingWrapperFilter(queryFilter);\n    chain = new Filter[2];\n    chain[0] = cwf;\n    chain[1] = fbcwf;\n    cf = new ChainedFilter(chain, ChainedFilter.AND);\n\n    hits = searcher.search(new MatchAllDocsQuery(), cf, 1);\n\n    System.out.println(\"blue:\" + hits.totalHits);\n\n  }\n\n{code}\n\n",
            "date": "2008-03-10T21:31:52.830+0000",
            "id": 135
        },
        {
            "author": "Paul Elschot",
            "body": "From the traceback I suppose this happened at the end, using the ChainedFilter?\nIirc ChainedFilter is from contrib/..., and it is mentioned at LUCENE-1187 as one of the things to be done.\nCould you contribute this code as a contrib/... test case there?\nSorry, I don't remember exactly from which contrib module ChainedFilter is.",
            "date": "2008-03-11T07:58:43.505+0000",
            "id": 136
        },
        {
            "author": "Wouter Heijke",
            "body": "We got the same error here on a 15Gb index with Lucene 2.4.0:\n\njava.lang.ClassCastException: java.util.BitSet cannot be cast to org.apache.lucene.search.DocIdSet\n org.apache.lucene.search.CachingWrapperFilter.getDocIdSet(CachingWrapperFilter.java:76)\n org.apache.lucene.misc.ChainedFilter.getDocIdSet(ChainedFilter.java:200)\n org.apache.lucene.misc.ChainedFilter.getDocIdSet(ChainedFilter.java:145)\n org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:140)\n org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:112)\n org.apache.lucene.search.Searcher.search(Searcher.java:136)",
            "date": "2008-10-29T14:20:26.519+0000",
            "id": 137
        },
        {
            "author": "Paul Elschot",
            "body": "Wouter, about this:\n{{java.lang.ClassCastException: java.util.BitSet cannot be cast to org.apache.lucene.search.DocIdSet}}\n\nLUCENE-1187 should have fixed this, so could you file a bug report?\nIn case you need a workaround, also have a look at LUCENE-1296.\n\n\n",
            "date": "2008-10-30T07:18:22.629+0000",
            "id": 138
        },
        {
            "author": "Mark Miller",
            "body": "I think I have tracked down this issue as the one changing things most regarding Scorer documentation in org.apache.lucene.search.package.html.\n\nI've started updating it, but it needs a tad more work I think - reopening this issue as a convenient marker for this work.",
            "date": "2009-08-21T01:27:10.938+0000",
            "id": 139
        },
        {
            "author": "Michael Busch",
            "body": "Mark, are you working on this? Wanna assign this to you?",
            "date": "2009-08-21T15:27:14.825+0000",
            "id": 140
        },
        {
            "author": "Mark Miller",
            "body": "Its better now I think - could prob be improved still (by someone who has sunk their head into the new Scorer stuff more than I have) - but I read over the code and did what I could. At the least, its no longer wildly out of whack.",
            "date": "2009-08-22T21:18:04.825+0000",
            "id": 141
        }
    ],
    "component": "core/search",
    "description": "{code}\npackage org.apache.lucene.search;\n\npublic abstract class Filter implements java.io.Serializable \n{\n  public abstract AbstractBitSet bits(IndexReader reader) throws IOException;\n}\n\npublic interface AbstractBitSet \n{\n  public boolean get(int index);\n}\n\n{code}\n\nIt would be useful if the method =Filter.bits()= returned an abstract interface, instead of =java.util.BitSet=.\n\nUse case: there is a very large index, and, depending on the user's privileges, only a small portion of the index is actually visible.\nSparsely populated =java.util.BitSet=s are not efficient and waste lots of memory. It would be desirable to have an alternative BitSet implementation with smaller memory footprint.\n\nThough it _is_ possibly to derive classes from =java.util.BitSet=, it was obviously not designed for that purpose.\nThat's why I propose to use an interface instead. The default implementation could still delegate to =java.util.BitSet=.\n\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-584",
    "issuetypeClassified": "REFACTORING",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Decouple Filter from BitSet",
    "systemSpecification": true,
    "version": "2.1"
}