{
    "comments": [
        {
            "author": "Grant Ingersoll",
            "body": "I frankly don't like renaming something like this.  This is, once again, a case of back compatibility biting us.  If instead of working around back compat. we had just made Analyzer.tokenStream be reusable, we wouldn't have to do this.  Now, instead, we are going to have a convoluted name for something (reusableTS).\n\nIn my mind, better to just make .tokenStream do the right thing and get rid of reusableTokenStream.",
            "date": "2009-06-09T21:05:41.953+0000",
            "id": 0
        },
        {
            "author": "Earwin Burrfoot",
            "body": "Second this. Though I lost any hope for sane Lucene release/compat rules.",
            "date": "2009-06-09T21:24:00.960+0000",
            "id": 1
        },
        {
            "author": "Mark Miller",
            "body": ">>Second this. Though I lost any hope for sane Lucene release/compat rules. \n\nWhy? Have you seen anyone arguing for anything else?\n\nIf there are sane/smart ways to change our back compat policy, I think you have seen that no one would object.\n\nIts a complicated topic that has come up for discussion many times, but I don't think the current policy is insane. And I have seen most people supporting whatever is best for Lucene. But - see all of the posts on the topic. Its complicated. Nobody even really torpedoed anything, its more that enough issues were raised and no one with a proper amount of authority felt comfortable stepping up to the plate. Mike was gung ho for it for a while, and even he backed off. Thats a great indication to me that the issue is not simple. Back compat currently is not insane, but I think we all agree it should be loosened somehow in the future.\n\nThe way Lucene stuff generally goes, if someone like Grant or Mike really wanted to push changes, the changes would happen. I think they both see that the effort involved in such a change is not small though. Back compat is like our constitution. Its  a pain in the butt to change in a way that everyone could get on board with. Even still, if someone really wanted to, they could probably push through that. It seems we havn't gotten to such a point with anyone yet though.\n\nGiving up is really not the answer though - thats why the discussion has come and gone in the past. The effort to get anything done grew (in terms of ideas as much as any implementation), and one by one, the participants dropped out.",
            "date": "2009-06-09T21:44:35.774+0000",
            "id": 2
        },
        {
            "author": "Earwin Burrfoot",
            "body": "bq. If there are sane/smart ways to change our back compat policy, I think you have seen that no one would object.\nIt's not a matter of finding a smart way. It is a matter of sacrifice that has to be made and readiness to take the blame for decision that can be unpopular with someone.\nYou go zealously for back-compat - you sacrifice readability/maintainability of your code but free users from any troubles when they want to 'simply upgrade'. You adopt more relaxed policy - you sacrifice users' time, but in return you gain cleaner codebase and new stuff can be written and used faster.\nThere's no way to ride two horses at once.\n\nSome people are comfortable with current policies. Few cringe when they hear things like above. Most theoretically want to relax the rules. Nobody's ready to give up something for it.\n\nOkay, there's an escape hatch I (and someone else) mentioned on the list before. Adopting a fixed release cycle with small intervals between releases (compared to what we have now). Fixed - as in, releases are made each N months instead of when everyone feels they finished and polished up all their pet projects and there's nothing else exciting to do. That way we can keep the current policy, but deletion-through-deprecation approach will work, at last!\nThis solution is halfassed, I can already see discussions like \"That was a big change, let's keep the deprecates around longer, say - for a couple of releases.\", it doesn't solve good-name-thrashing problem, as you have to go through two rounds of deprecation to change semantics on something, but keep the name.\nBut this is something better than what we have now, a-a-and this is something that needs commiter backing.\n\nbq. Thats a great indication to me that the issue is not simple.\nThe issue is simple, the choice is not. And maintaining status quo is free.\n\nbq. Giving up is really not the answer though\nIt is the answer. I have no moral right to hammer my ideals into heads that did tremendously more for the project, than I did. And maintaining a patch queue over Lucene trunk is not 'that' hard.\n",
            "date": "2009-06-09T23:17:38.085+0000",
            "id": 3
        },
        {
            "author": "Grant Ingersoll",
            "body": "bq. If there are sane/smart ways to change our back compat policy, I think you have seen that no one would object.\n\nThe sane/smart way is to do it on a case by case basis.  Here is a specific case.  Generalizing it a bit, the place where it should be more easily relaxable are the cases where we know very few people make customizations, as in implementing Fieldable or FieldCache.\n\nAs for this specific case, the original change was the thing that broke back compat.  So, given it is already broken, why not fix it the right way?",
            "date": "2009-06-10T02:33:29.122+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "bq. So, given it is already broken, why not fix it the right way?\n\nBecause two wrongs don't make a right?\n\n(I assume you're suggesting changing tokenStream to match reusableTokenStream, ie allowing it to return a reused TokenStream between calls, and then deprecating reusableTokenStream).\n\nApps that get multiple TokenStreams from a single Analyzer and then iterate through them, would silently break, if we up and made this 2nd non-back-compatible change.",
            "date": "2009-06-10T11:12:57.567+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "bq. The sane/smart way is to do it on a case by case basis.\n\nRight, and the huge periodic discussions on back-compat do soften\n\"our\" stance on these.  For example LUCENE-1542 was just such a case,\nwhere we chose to simply fix the [rather nasty] bug at the expense of\npossible apps relying on the broken behavior.\n\nLUCENE-1679 is another (rather trivial) example, where we plan to\nchange certain fields in WildcardTermEnum to be final.\n",
            "date": "2009-06-10T11:16:22.798+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. Mike was gung ho for it for a while, and even he backed off. \n\nWell... my particular itch (most recently!) was an addition to Lucene\nthat'd let us conditionalize the default settings so that new users\nget the latest & greatest, but back-compat users can easily preserve\nold behavior.\n\nIe, it was a software change, not a policy change; I tried hard to\nsteer clear of any proposed changes to back-compat policy.\n\nBut, for better or worse, back-compat policy is one of those\n\"magnetic\" topics: whenever you get too close to it, it suddenly\nsticks to you and takes over your thread.\n\nAnd in the end we arrived at a workable solution to my particular\nitch, which is to make such settings explicit or switch to new APIs\nthat change the defaults (eg the new FSDir.open).\n\nThat said, improving our back compat policy *is* an important and\namazingly complex topic.\n",
            "date": "2009-06-10T13:26:19.137+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. The way Lucene stuff generally goes, if someone like Grant or Mike really wanted to push changes, the changes would happen. \n\nWell, it's consensus that we all need to reach (at least enough\nconsensus to vote on it), and on complex topics it's not easy to get\nto consensus.\n\nbq. Giving up is really not the answer though - thats why the discussion has come and gone in the past.\n\nI don't think anyone has given up.  The issue still smoulders and\nflares up here and there (like, this issue).  Eventually we'll get\nenough consensus for something concrete to change.\n\n\nbq. I have no moral right to hammer my ideals into heads that did tremendously more for the project, than I did.\n\nIn fact you do & should.  This is exactly how change happens.  Here's\na great (though sexist) quote:\n\n\"The reasonable man adapts himself to the world; the unreasonable one persists to adapt the world to himself. Therefore all progress depends on the unreasonable man.\" - George Bernard Shaw\n\n\n",
            "date": "2009-06-10T13:26:46.265+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Adopting a fixed release cycle with small intervals between releases (compared to what we have now). \n\nI think this is almost a good solution, though instead of \"fixed\" it\ncould be that we try [harder] to do major releases more frequently.\nLet's face it: Lucene is changing quite quickly now, so it seems\nreasonable that the major releases also come quickly.\n\nI say \"almost\" because.... alot of the pain in implementing our\ncurrent policy is the need to have a \"stepping stone\" between old and\nnew.  Ie, we now must always do a release that deprecates old APIs and\nintroduces new ones so that you can upgrade to that, fix deprecations,\nand you know you're set for the next major release.  So eg changes to\ninterfaces is a big problem.  If we were free to suddenly make a new\nmajor releases, with instructions on how to migrate old -> new, that'd\nbe very liberating.\n\nI think nearly everyone agrees our back-compat policy is exceptionally\ncostly.  On a given interesting change to Lucene, a very large part of\nthe effort is spent on preserving back-compat. It causes all kinds of\nspooky code, pollutes the APIs, causes us to go forward with sub-par\nnames, etc.  The freedom Marvin has to make changes to Lucy is\nfabulous, though in exchange, it's not yet released...\n\nI think most would also agree that it's far from easy even carrying\nout the policy we have without making mistakes: this change (addition\nof reusableTokenStream) violated our policy (I did it by accident and\nnobody noticed until now).  I actually believe programming languages /\nruntime envs need to provide more support for developers; we have\ninadequate tools now.  But we can't wait for that...\n",
            "date": "2009-06-10T13:27:24.715+0000",
            "id": 9
        },
        {
            "author": "Shai Erera",
            "body": "We've had this thread http://www.nabble.com/Lucene%27s-default-settings---back-compatibility-td23605466.html, and in the latest post (http://www.nabble.com/Re%3A-Lucene%27s-default-settings---back-compatibility-p23792927.html) I tried to put together some wording for a revised (and relaxed) back-compat policy. I believe it was Grant who asked for some writeup to get to the users' list, and I read also that we may want to discuss each item separately, to get to a consensus.\n\nPerhaps we can continue the discussion on that thread, and try to get to a consensus on any of the items? We don't necessarily need to change all of it in one day, but getting some feedback from you on any of the items can help bring that discussion back to life, and hopefully reach a consensus.\n\nAs was said on this thread, persistence will eventually drive us to reach a consensus, so I'm being persistent :).",
            "date": "2009-06-10T16:13:07.740+0000",
            "id": 10
        },
        {
            "author": "Michael McCandless",
            "body": "OK, inspired by Uwe's persistence on LUCENE-1693, I realized one clean\nway to fix the back-compat break here is by using reflection when\ncreating the Analyzer as to whether the class overrides the\ntokenStream method.  Then, in reusableTokenStream we forcefully\nfallback to tokenStream, if it does.\n\nAttached patch, with a test case showing the issue, implements this\napproach, and it works well.  With this approach there's no reason to\ndeprecate tokenStream.\n",
            "date": "2009-07-13T11:13:01.568+0000",
            "id": 11
        },
        {
            "author": "Uwe Schindler",
            "body": "Your solution is also cool, to fix the last problems with the core token streams in LUCENE-1693: If somebody overrides a deprecated method in one of the core tokenstreams (that are not final), the method is never called, because the indexer uses incrementToken per default. The same can be used to fix this problem in TokenStream, too.\n\nI will prepare a patch for this (I am currently preparing a new patch with some tests and the solution for the problems with number of attribute instances may not be equals number of attributes).",
            "date": "2009-07-13T12:00:35.617+0000",
            "id": 12
        }
    ],
    "component": "modules/analysis",
    "description": "The addition of reusableTokenStream to the core analyzers unfortunately broke back compat of external subclasses:\n\n    http://www.nabble.com/Extending-StandardAnalyzer-considered-harmful-td23863822.html\n\nOn upgrading, such subclasses would silently not be used anymore, since Lucene's indexing invokes reusableTokenStream.\n\nI think we should should at least deprecate Analyzer.tokenStream, today, so that users see deprecation warnings if their classes override this method.  But going forward when we want to change the API of core classes that are extended, I think we have to  introduce entirely new classes, to keep back compatibility.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1678",
    "issuetypeClassified": "OTHER",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Deprecate Analyzer.tokenStream",
    "systemSpecification": true,
    "version": ""
}