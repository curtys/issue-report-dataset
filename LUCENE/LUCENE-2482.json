{
    "comments": [
        {
            "author": "Andrzej Bialecki ",
            "body": "Patch with the tool and a unit test.",
            "date": "2010-05-27T19:16:43.404+0000",
            "id": 0
        },
        {
            "author": "Eks Dev",
            "body": "nice! \nThere is also another interesting use case for sorting index, performance and index size!\n\nWe use a couple of fields with low cardinality (zip code, user group... and likes). Having index sorted on these makes rle compression of  postings really effective, making it possible to load all values into couple of M-bytes of ram.\nAt a moment we just sort collection before indexing.\n\nWould  it be possible somehow to use a combination of stored fields and to specify comparator? Even comparing them as byte[] would do the trick for this business case as it is only important to keep the same values together, order is irrelevant. Of course, having decoder to decode byte[] before comparing would be useful (e.g. for composite fields) , but would work in many cases without it.   \n\nThis works fine even with moderate update rate, as you can re-sort periodically. It does not have to be totally sorted, everything works, just slightly more memory is needed for filters\n\nWith flex, having postings that use rle compression is quite possible ... this tool could become \"optimizeHard()\" tool for some indexes :)",
            "date": "2010-05-27T20:44:22.437+0000",
            "id": 1
        },
        {
            "author": "Andrzej Bialecki ",
            "body": "Re: combination of fields + a comparator: sure, why not, take a look at the implementation of the DocScore inner class - you can stuff whatever you want there.\n\nI'm not sure if I follow your use case though ... please remember that this re-sorting is applied exactly the same to all postings, so savings on one list may cause bloat on another list.",
            "date": "2010-05-27T21:10:59.289+0000",
            "id": 2
        },
        {
            "author": "Eks Dev",
            "body": "Re: I'm not sure if I follow your use case though\n\nSimple case, you have a 100Mio docs with 2 fields, CITY and  TEXT\n\nsorting on CITY makes postings look like: \n    Orlando:                  ---------------------------------\n New York:                                                               -------------------------------------\nperfectly compressible. \n\nwithout really affecting distribution (compressibility) of terms from the TEXT field.\n\nIf CITY would remain in unsorted order (e.g. uniform distribution), you deal with very large postings for all terms coming from this field  \n\nSorting on many fields helps often, e.g. if you have hierarchical compositions like 1 CITY with many  ZIP_CODES...  philosophically, sorting always increases compressibility and improves locality of reference... but sure, you need to know what you want",
            "date": "2010-05-27T21:41:56.456+0000",
            "id": 3
        },
        {
            "author": "Andrzej Bialecki ",
            "body": "If there are no objections I'd like to commit this soon.",
            "date": "2010-08-11T08:03:43.248+0000",
            "id": 4
        },
        {
            "author": "Andrzej Bialecki ",
            "body": "Committed in rev. 998948.",
            "date": "2010-09-20T14:46:42.761+0000",
            "id": 5
        },
        {
            "author": "Andrzej Bialecki ",
            "body": "..to remember we need a port of this tool to 4.0",
            "date": "2010-09-21T10:25:38.840+0000",
            "id": 6
        },
        {
            "author": "Koji Sekiguchi",
            "body": "I think this is an interesting tool. I'm wondering if Solr can call it, as Solr does merge indexes. \n\nIs there any restrictions on this? I've never looked into deeper it, but for example, I see isPayloadAvailable() returns always false. Does it mean that it doesn't support payload?\nCan it support multiple Sorts on indexed fields other than stored float field?",
            "date": "2010-09-29T01:11:39.363+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "We need to fix this on 4.0 too.",
            "date": "2010-11-19T18:10:04.136+0000",
            "id": 8
        },
        {
            "author": "Robert Muir",
            "body": "bq. I'm not sure if I follow your use case though ... please remember that this re-sorting is applied exactly the same to all postings, so savings on one list may cause bloat on another list.\n\nHi Andrzej, I came across this the other day, and thought it would be really interesting in the context of some of our newer codecs\nunder development in trunk and the bulkpostings branch.\n\nI found the results presented there based on index sorting for codecs like simple9 to be really compelling, significant reduction\nin bits/posting for docids especially, because it can pack a lot of small deltas efficiently.\n\n{noformat}\nThe \ufb01rst method reorders the documents in a text collection based on the number of\ndistinct terms contained in each document. The idea is that two documents that each\ncontain a large number of distinct terms are more likely to share terms than are a\ndocument with many distinct terms and a document with few distinct terms. Therefore,\nby assigning docids so that documents with many terms are close together, we may\nexpect a greater clustering e\ufb00ect than by assigning docids at random.\n\nThe second method assumes that the documents have been crawled from the Web (or\nmaybe a corporate Intranet). It reassigns docids in lexicographical order of URL. The\nidea here is that two documents from the same Web server (or maybe even from the\nsame directory on that server) are more likely to share common terms than two random\ndocuments from unrelated locations on the Internet.\n{noformat}\n\nhttp://www.ir.uwaterloo.ca/book/06-index-compression.pdf (see page 214: doc id reordering)\n",
            "date": "2011-01-16T22:54:22.277+0000",
            "id": 9
        },
        {
            "author": "Juan Grande",
            "body": "Hi! I'm attaching a patch with an implementation of this feature for Lucene 4.0. I'm not sure if the style is right because I can't download the codestyle.xml file for Eclipse.",
            "date": "2011-01-20T20:53:16.746+0000",
            "id": 10
        },
        {
            "author": "Shai Erera",
            "body": "Looks like it needs some more work - moving to 3.2",
            "date": "2011-01-23T14:18:10.287+0000",
            "id": 11
        },
        {
            "author": "Robert Muir",
            "body": "bulk move 3.2 -> 3.3",
            "date": "2011-06-03T16:40:41.991+0000",
            "id": 12
        },
        {
            "author": "Pablo Castellanos",
            "body": "Hi, I wanted to implement some early termination strategies over my Lucene index so I started playing with the 4.0 patch as I need to reorder it.\n\nSo I have found that a lot of functions have changed in the past year and I had to go for some modifications, mainly:\n\n{code}\n/*@Override\npublic TermFreqVector[] getTermFreqVectors(int docNumber)\n        throws IOException {\n  return super.getTermFreqVectors(newToOld[docNumber]);\n}*/\n\n@Override\npublic Fields getTermVectors(int docID) throws IOException {\nreturn super.getTermVectors(newToOld[docID]);\n}\n\n/*@Override\npublic Document document(int n, FieldSelector fieldSelector)\n        throws CorruptIndexException, IOException {\n  return super.document(newToOld[n], fieldSelector);\n}*/\n\n@Override\npublic void document(int docID, StoredFieldVisitor visitor)\nthrows CorruptIndexException, IOException {\nsuper.document(newToOld[docID], visitor);\n}\n{code}\n\nThere exists also a getDeletedDocs function and I haven't found any good replacement for it\n\n{code}\n    /*@Override\n    public Bits getDeletedDocs() {\n      final Bits deletedDocs = super.getDeletedDocs();\n\n      if (deletedDocs == null)\n        return null;\n\n      return new Bits() {\n        @Override\n        public boolean get(int index) {\n          return deletedDocs.get(newToOld[index]);\n        }\n\n        @Override\n        public int length() {\n          return deletedDocs.length();\n        }\n      };\n    }*/\n{code}\n\nAfter applying these changes and using the code against my lucene index I get some weird results. It seems that the new sorting has worked but the posting list that access to the documents is still pointing to the old data.\n\nImagine that I have 2 documents in my index and that I want to sort them by price (So the most expensive item should have a lower docId)\n\nDocument 1\n{panel}docId:1, name: iPod, price: 100${panel}\n\nDocument 2\n{panel}docId:2, name: iPhone, price: 300${panel}\n\nI run my modified version of IndexSorter over it and after that I try to query the new index, so if I query for _name:iPhone_ I get:\n{panel}docId:2, name: iPod, price: 100${panel}\n\nThat leads me to believe that the documents have been sorted but the new index is using the old posting list. \n\nSo I have two questions, are you planning on updating this code for newer versions of Lucene 4.0 or am I on my own to get it to work? And if this is the case, where should I look for getting a solution for my problem?\n\nThanks in advance for your help.",
            "date": "2012-02-02T20:45:27.387+0000",
            "id": 13
        },
        {
            "author": "Robert Muir",
            "body": "This issue is actually fixed in 3.x, but is still open for a 4.0 port.\n\nI'll open an issue (with fix version of 4.0) for the trunk port.",
            "date": "2012-03-25T17:02:25.903+0000",
            "id": 14
        },
        {
            "author": "Robert Muir",
            "body": "I opened LUCENE-3918 for the trunk port to eliminate confusing in JIRA: the 3.x work has been done for a while.",
            "date": "2012-03-25T17:04:11.786+0000",
            "id": 15
        },
        {
            "author": "Matthew Willson",
            "body": "Hi all -- few quick questions if anyone is still watching this.\n\n* Could this be used to achieve an impact ordered index, as in e.g. [1], where documents in a given term's postings list are ordered by score contribution or term frequency?\n\n* Any caveats or things one should be aware of when it comes to index sorting in combination with different index merge strategies, and some of the more advanced stuff in Solr for managing distributed indexes?\n\n* Anyone aware of any other work along the lines of early stopping / dynamic pruning optimisations in Lucene? e.g. MaxScore from [1] (I think Xapian [2] calls it 'operator decay') or accumulator pruning based algorithms from [1] (perhaps in combination with impact ordering)? in particular is there anything in Lucene 4's approach to scoring and indexing which would make these hard in principle?\n\nAny pointers gratefully received.\n\n[1] Buettcher Clarke & Cormack \"Implementing and Evaluating search engines\" ch. 5 pp. 143-153\n[2] http://xapian.org/docs/matcherdesign.html",
            "date": "2012-11-09T18:31:24.046+0000",
            "id": 16
        }
    ],
    "component": "modules/other",
    "description": "A tool to sort index according to a float document weight. Documents with high weight are given low document numbers, which means that they will be first evaluated. When using a strategy of \"early termination\" of queries (see TimeLimitedCollector) such sorting significantly improves the quality of partial results.\n\n(Originally this tool was created by Doug Cutting in Nutch, and used norms as document weights - thus the ordering was limited by the limited resolution of norms. This is a pure Lucene version of the tool, and it uses arbitrary floats from a specified stored field).",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2482",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Index sorter",
    "systemSpecification": true,
    "version": "3.1, 4.0-ALPHA"
}