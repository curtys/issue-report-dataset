{
    "comments": [
        {
            "author": "Yonik Seeley",
            "body": "Background:\nhttp://search.lucidimagination.com/search/document/4b2b4210e2516769/analysis_back_compat_break\nhttp://search.lucidimagination.com/search/document/26c044ecbce3ed29",
            "date": "2009-09-18T00:03:12.033+0000",
            "id": 0
        },
        {
            "author": "Mark Miller",
            "body": "At the worst, we can just clone the delegate and not be reusable (the javadoc says you don't have to be reusable)\n\nNot ideal, but it will fix, and cease to be a (possible performance) problem in 3.0 :)",
            "date": "2009-09-18T00:27:47.796+0000",
            "id": 1
        },
        {
            "author": "Mark Miller",
            "body": "Now give us some better options Uwe :)",
            "date": "2009-09-18T00:29:23.925+0000",
            "id": 2
        },
        {
            "author": "Robert Muir",
            "body": "alternative patch, should not change performance.",
            "date": "2009-09-18T00:55:58.900+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "better patch with testcase for the issue.\n\nreally, its just that in next() tokenwrapper must be cloned before calling incrementToken, instead of after.",
            "date": "2009-09-18T01:32:33.832+0000",
            "id": 4
        },
        {
            "author": "Yonik Seeley",
            "body": "edit: collision w/ robert.\nStill wonder if it's safe to get rid of that second clone()... the combinations are mind-bending.",
            "date": "2009-09-18T01:36:34.024+0000",
            "id": 5
        },
        {
            "author": "Mark Miller",
            "body": "Nice - thanks Robert!",
            "date": "2009-09-18T01:50:41.534+0000",
            "id": 6
        },
        {
            "author": "Jason Rutherglen",
            "body": "With SOLR-908 CommonGramsQueryFilter which uses the old API,\nwe've been seeing since we upgraded to Solr 1.4/Lucene 2.9,\nrandom negations to query clauses. It almost looks like there's\nsome sort of shared state or multithreading issue, however I've\nalso thought somehow it's related to mixing the old and new\nAPIs. Unfortunately it's so inconsistent I don't have a test\ncase that reproduces it (happens in production only). \n\nIs there any sort of shared state in the analyzing, possibly\nbetween instances that is fixed in this patch?",
            "date": "2009-09-18T01:54:16.227+0000",
            "id": 7
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nedit: collision w/ robert.\nStill wonder if it's safe to get rid of that second clone()... the combinations are mind-bending. \n{quote}\n\nyonik, hmm i think the second clone() is a hint there remains another problem\nif you look at my patch, it only fixes the case where you have a tokenstream supporting incrementToken(), and you use both next() and next(Token) apis.\n\nwhat if the tokenstream only supports next(reusableTS) ?\nif you call next(token) then next(), i think in that case you will have the same problem.\nthis still won't introduce any extra cloning, just fix the logic so it doesnt overwrite the tokenWrapper, and returns a \"full private copy\" like the javadocs say.\n\n (i'll add another test and upload a new patch)",
            "date": "2009-09-18T02:17:14.853+0000",
            "id": 8
        },
        {
            "author": "Robert Muir",
            "body": "bq. what if the tokenstream only supports next(reusableTS) ?\n\nok i tested the 2nd scenario and it is ok.\nif you want my additional tests, i can add them, but the existing patch is fine... i confused myself worrying about this 2nd case.\nin this case when the consumer calls next(reusableTS), no delegate is involved since its overridden... duh :)\n\n",
            "date": "2009-09-18T02:55:27.202+0000",
            "id": 9
        },
        {
            "author": "Robert Muir",
            "body": "bq. Still wonder if it's safe to get rid of that second clone()... the combinations are mind-bending. \n\nits not safe to do this for the case of tokenstream that only supports next(reusableTS) but not incrementToken.\notherwise, next() does not return a full copy, but a reference to the delegate, which will be overwritten by future calls to next().\nif you want to get rid of it, then you need to clone the delegate before deferring to next(Token).\n",
            "date": "2009-09-18T02:59:09.343+0000",
            "id": 10
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nIs there any sort of shared state in the analyzing, possibly\nbetween instances that is fixed in this patch?\n{quote}\n\nYes. if for instance you call foo = ts.next(reusableToken), then call bar = ts.next() \nfoo will be overwritten by bar in the second call.\nthis is because it is incorrectly \"reused\" in next()... see the testcase i attached for an example.\n",
            "date": "2009-09-18T03:42:17.933+0000",
            "id": 11
        },
        {
            "author": "Uwe Schindler",
            "body": "Good morning all together! What a nice day and then this problem :-)\n\nHere is my solution for the problem: Michael and me never thought about mixing the old and very old API as consumer, which seems to be used. The problem is now, that the behaviour changed for calling next(). The original 2.4.1 code looks the following:\n\n{code}\npublic Token next() throws IOException {\n  final Token reusableToken = new Token();\n  Token nextToken = next(reusableToken);\n\n  if (nextToken != null) {\n    Payload p = nextToken.getPayload();\n    if (p != null) {\n      nextToken.setPayload((Payload) p.clone());\n    }\n  }\n\n  return nextToken;\n}\n{code}\n\nThe difference is, that a new token is created *before* the call to the reusable next() methods (incrementToken() is somehow reuseable, too).\n\nThe attached patch, restores exactly this functionality, but also for incrementToken(). It also removes an unneeded assignment to the delegate in the case of next(Token) delegating to next() (which is also a bug, because it makes the token no longer private for the caller - it can be overridden by a later call to incrementToken()) - sorry for that.\n\nTokens generated by next() must be always private and not shared or reused as reusableToken for later next/incrementToken calls by the API. This is the problem of Robert's patch. The full private token (which was cloned before) is then also available as delegate for later calls to incrementToken() (for next(Token) the delegate is replaced, as Robert noticed, so no problem here).\n\nThe wrapper around incrementToken() does the following:\n- save the current delegate\n- replace delegate by a new Token (just like the old next() in 2.4.1)\n- call incrementToken and assign to nextToken variable\n- restore the reusable delegate\n- after that all goes like for next(Token)\n\nSimply said: the next() wrapper is completely decoupled and always uses a completely private (new) Token instance.\n\nI am not sure, why this payload cloning code is in 2.4.1, but I moved it here, too. I think it is because of some old bug, where a payload was assigned in next(Token), that was also shared by the TokenStream itsself between more than one tokens. Using this code, the Token is for sure full private (and even not reused later as before).\n\nUsing this patch, you should now even be able to mix all three APIs in one filter/consumer - but I still would'nt do this :-)",
            "date": "2009-09-18T06:50:10.628+0000",
            "id": 12
        },
        {
            "author": "Uwe Schindler",
            "body": "This is just a patch that enhances/rectifies the BW testcase. It corrects the messages in assertTrue, because they should refelct that something is going wrong (just cosmetics). But it adds a test for correctness of other token's contents to these POSToken tests, not only if the one is a proper noun.\n\nIt also mixes consuming the new API into Robert's test and the call to next(Token), to check if the full-private Token returned from next() is still valid.\n\nNothing special, no other changes in core code.",
            "date": "2009-09-18T09:15:39.867+0000",
            "id": 13
        },
        {
            "author": "Uwe Schindler",
            "body": "I would suggest to create a new RC because of this issue. The TokenStream BW stuff is very tricky and is not limited to only one TokenStream. When fixing thigs here, you must always also look into issues that could arise by mixing old/new API. The current issue is a typical example for that. Your brain is always \"fuming\", when you think about what happens if TF1 calls TF2 using old API, but TF2 is new API and calls TF3 using new API. TF3 itsself is again very old API without reuse and so on.\n\nBut this one is new, a reusable TF is calling another TS mixing the APIs, but the changes also affect the other variants. So testing, testing, testing and take a cold shower when your brain starts getting hot :-)\n\nI will commit the current patch later in the afternoon, when you are awake at the west coast.",
            "date": "2009-09-18T10:34:33.630+0000",
            "id": 14
        },
        {
            "author": "Mark Miller",
            "body": "Commit away as soon as you can Uwe - I pump out RC5 as soon as I can right after.",
            "date": "2009-09-18T12:44:15.802+0000",
            "id": 15
        },
        {
            "author": "Uwe Schindler",
            "body": "OK, will do. Do you know if Yonik also reviewed this patch, because he was the person who reported the bug. Maybe he tests with his failing TS. Also Jason could check out this patch with his problem (SOLR-908).\n\nI will commit in 2 hours, is this early enough?",
            "date": "2009-09-18T12:53:17.759+0000",
            "id": 16
        },
        {
            "author": "Mark Miller",
            "body": "I tested the patch I did with the failing test, and it worked - so I'm sure yours does too - I'll do a test with the latest patch right now though.\n\nThe original report came from Gregg Donovanin Solr land.\n\nHe made a nice little unit test that fails in Solr showing the problem (see the links Yonik posted).\n\nhttps://issues.apache.org/jira/browse/SOLR-1445\n\n2 hours is fine with me - I just would like to get the RC out today if possible. ",
            "date": "2009-09-18T13:04:44.624+0000",
            "id": 17
        },
        {
            "author": "Mark Miller",
            "body": "I can confirm the latest patch fixes the Solr issue that prompted this.",
            "date": "2009-09-18T13:19:25.293+0000",
            "id": 18
        },
        {
            "author": "Robert Muir",
            "body": "Uwe, i tested your patch, this is good :)\n\nJust out of curiousity though, I am not sure i see the problem with next() then incrementToken() with my patch.\n(Your patch is better imho, this is not the issue).\n\nI tried your modified test and it passes with my patch also, is there something I am missing?",
            "date": "2009-09-18T14:24:01.874+0000",
            "id": 19
        },
        {
            "author": "Robert Muir",
            "body": "nevermind: found it.\n\nUwe's patch plus a testcase that passes with his fix, but fails with the old patch i supplied.\n\nwhat Uwe fixed was the case where TokenStream only supports next(Token), but you consume it foo = incrementToken(), followed by bar = next()\nin this case bar should be fully private and not overwrite the contents of foo.",
            "date": "2009-09-18T14:51:21.037+0000",
            "id": 20
        },
        {
            "author": "Uwe Schindler",
            "body": "Thanks Robert, I added your test and did some more tests with the round robin stream. We can now be sure, that it is fully private, not even the attributes are touched :-) -> but I see no real sense in this requirement :-) People should never use old and the brand new API in one consumer. Mixing old and very-old is ok and was obviously used.\n\nI will commit shortly.\n\nJust one question: Does anybody know, why there is this extra payload cloning?",
            "date": "2009-09-18T15:21:18.251+0000",
            "id": 21
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. Just one question: Does anybody know, why there is this extra payload cloning?\n\nThis was introduced at the end of LUCENE-1057 without patch in JIRA. So it must have something to do with this. Maybe Yonik can explain.",
            "date": "2009-09-18T15:32:55.752+0000",
            "id": 22
        },
        {
            "author": "Mark Miller",
            "body": "The copy of payload came in LUCENE-1057.\n\nThe clone came in LUCENE-1062.",
            "date": "2009-09-18T15:34:02.487+0000",
            "id": 23
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed revision: 816673\n\nI added no CHANGES entry as we are all committers and no external persons involved. This bug was not in any previous release.\n\nThanks Robert for the great tests and all others for help resolving this bug. Mark, go on with the RC5! ;-)",
            "date": "2009-09-18T15:39:13.823+0000",
            "id": 24
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. This was introduced at the end of LUCENE-1057 without patch in JIRA. So it must have something to do with this. Maybe Yonik can explain.\n\nUrg... 2 years ago.\nI think it was because Token.clone() didn't clone the payload, so next() would do it to create a fully private copy.\nIs it stil applicable?  So many changes, I don't know.",
            "date": "2009-09-18T15:52:52.537+0000",
            "id": 25
        },
        {
            "author": "Uwe Schindler",
            "body": "Token.clone() is not called by next() anymore (and even not in 2.4.1) - because of this we need the Payload cloning (Token.clone() would do it). The full private Token is done like this now (and this was the same in 1057): next(Token) is simply called with a new Token instance. The fix for this issue does it in the same way (like 2.4.1). The extension here is, that it now works exactly the same with incrementToken(). After calling next(Token) with the private token, the Payload is explicitely cloned.\n\nAs I told some comments above, I think more the problem is the following: If a next(Token) or incrementToken() method sets a Payload, the payload data is not copied, its only a reference to the byte array. E.g. the next(Token) methods uses a pre-allocated array and sets this always as data (which is perfectly legal in the reuse case), only modifying the data contents. If you call next(Token) with a new allocated Token, this Token is private, but if next(Token) sets again the preallocated byte array, it is not private anymore (you will se the modifications in the previous token, too). You would have the same bug like now (even in 2.4.1). I think because of this the payload is cloned separately to be sure that it is private like the newly allocated Token.",
            "date": "2009-09-18T16:03:50.564+0000",
            "id": 26
        },
        {
            "author": "Mark Miller",
            "body": "bq. I think because of this the payload is cloned separately to be sure that it is private like the newly allocated Token.\n\nThats what it appears to be if you look at the tests added with the change -\n\none of the tests is a next(Token) impl that just keeps setting the payload with the same payload instance that it has as a field.",
            "date": "2009-09-18T16:06:34.419+0000",
            "id": 27
        },
        {
            "author": "Mark Miller",
            "body": "bq. Thanks Robert for the great tests and all others for help resolving this bug. Mark, go on with the RC5! \n\nThanks a lot Uwe! I really appreciate the speed with which you have been addressing these RC issues!\n\nIts taken a while to get this release out, but we have barley wasted a moment in cranking along.",
            "date": "2009-09-18T16:13:18.886+0000",
            "id": 28
        },
        {
            "author": "Jason Rutherglen",
            "body": "For SOLR-908, I can try out the patch, though we've reverted\nback to Solr trunk from 8/31, unfortunately, I can't reproduce\nthe bug using a multithreaded query parsing unit test.\n\nI decided the best avenue, given it must be thread related to\nbehave so randomly, is to alter QueryParser.getFieldQuery to not\ncall analyzer.reusableTokenStream and only use\nanalyzer.tokenStream. \n\nThis effectively avoids the use of threadlocal reusable\ntokenstreams for query parsing. I am left wondering about the\nstate of our index using reusable tokenstreams but luckily we\nhave so many documents, that this is less of a concern. \n\nThe queries being truncated is of course very serious as users\nsee irrelevant results and assume that Lucene/Solr 2.9/1.4 is no\ngood.",
            "date": "2009-09-18T16:57:20.998+0000",
            "id": 29
        },
        {
            "author": "Yonik Seeley",
            "body": "I've been doing some more testing... everything looks good.\nI did some random testing too, just to see if there are any combination corner cases we forgot about... it tries random combination of filters that support and used the different old/new stile APIs.  It was inline with other Solr tests, so I just cut-n-pasted it to this file for posterity.",
            "date": "2009-09-18T20:38:28.635+0000",
            "id": 30
        },
        {
            "author": "Uwe Schindler",
            "body": "A really funny test fragment. Fascinating :-) Good to hear that the API even passes this test! Thanks for testing!",
            "date": "2009-09-18T21:19:10.610+0000",
            "id": 31
        }
    ],
    "component": "",
    "description": "Old and new style token streams don't mix well.\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1919",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Analysis back compat break",
    "systemSpecification": true,
    "version": ""
}