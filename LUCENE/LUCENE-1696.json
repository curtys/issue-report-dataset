{
    "comments": [
        {
            "author": "Simon Willnauer",
            "body": "all tests pass",
            "date": "2009-06-16T14:35:49.990+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "Simon, I think if you want to handle accents in a language-dependent/correct way, you can use contrib/collation for this purpose.\n\ni don't see an alternative, otherwise you will end out with 50-100 sets of language-dependent rules [essentially duplicating the logic collation already knows about]",
            "date": "2009-06-16T14:56:08.258+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "i uploaded a testcase under LUCENE-1581 showing how this works with contrib/collation.",
            "date": "2009-06-16T15:12:13.647+0000",
            "id": 2
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. i don't see an alternative, otherwise you will end out with 50-100 sets of language-dependent rules [essentially duplicating the logic collation already knows about]\n\nI agree, that this would end up in a mess. Still collation is not an option as I can not rely on the local in that use-case.\nI might have to stick with my changes for umlauts at least. :)",
            "date": "2009-06-16T15:29:16.973+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "show how to do this with german... its a bit more involved since its non-standard collation behavior, but not too difficult.\n\nyou can do this with the jdk version too, i always show the ICU implementation because of its performance. both are available in contrib/collation\n",
            "date": "2009-06-16T15:33:58.030+0000",
            "id": 4
        },
        {
            "author": "Simon Willnauer",
            "body": "Thanks robert,\nI did know about collation before and I validated it for the usecase - I do not know what language / local my docs are so I can not set the correct one. Nevermind. :)",
            "date": "2009-06-16T15:38:15.089+0000",
            "id": 5
        },
        {
            "author": "Robert Muir",
            "body": "simon, actually i think its documented you can use ENGLISH collator and it will behave like asciifolding filter (simply remove all diacritics).\nyou could then apply the tailorings like the example and get the behavior you want, versus maintaining a custom asciifoldingfilter...",
            "date": "2009-06-16T15:40:16.376+0000",
            "id": 6
        },
        {
            "author": "Simon Willnauer",
            "body": "\nbq. simon, actually i think its documented you can use ENGLISH collator and it will behave like asciifolding filter (simply remove all diacritics).\nyou could then apply the tailorings like the example and get the behavior you want, versus maintaining a custom asciifoldingfilter... \nwill try, thanks!",
            "date": "2009-06-16T15:43:36.442+0000",
            "id": 7
        },
        {
            "author": "Robert Muir",
            "body": "since this seems to be a recurring theme maybe a javadoc modification would be useful.\n\notherwise i imagine you might receive lots of bug reports saying 'asciifoldingfilter does X for Y language incorrectly'.\n\npart of the confusion might be because the docs say it 'converts to their ASCII equivalents' and 'equivalent' means different things to different people in different languages...\n",
            "date": "2009-06-16T15:57:30.360+0000",
            "id": 8
        },
        {
            "author": "Mark Miller",
            "body": "Patch looks good! I'll just hold off till the token api improvement patch is finished, just in case we need to make an adjustment here.",
            "date": "2009-06-18T04:40:48.146+0000",
            "id": 9
        },
        {
            "author": "Simon Willnauer",
            "body": "I will be around and fix / adjust it if it needs some changes. If I do not react please send me a ping on this issue. Thanks",
            "date": "2009-06-18T07:55:28.645+0000",
            "id": 10
        },
        {
            "author": "Uwe Schindler",
            "body": "I already iplmeneted the new API in this filter for LUCENE-1693. Patch will come shortly together with this issue.\n\nThe old API can be removed, the filter is now final and so next() and nextToken() can be left unimplemented.",
            "date": "2009-07-14T14:22:53.746+0000",
            "id": 11
        },
        {
            "author": "Mark Miller",
            "body": "Heh - hate to sound like a broken record, but: making this class final breaks back compat?",
            "date": "2009-07-14T14:26:02.050+0000",
            "id": 12
        },
        {
            "author": "Uwe Schindler",
            "body": "No, it is a new class in 2.9 :-) ASCIIFoldingFilter is not in 2.4.1",
            "date": "2009-07-14T14:28:10.923+0000",
            "id": 13
        },
        {
            "author": "Mark Miller",
            "body": "Ah, thanks. Thats hard to keep track of. It feels like I committed this so long ago that it couldn't possibly be new ;)",
            "date": "2009-07-14T14:30:37.960+0000",
            "id": 14
        },
        {
            "author": "Uwe Schindler",
            "body": "Resolved with LUCENE-1693. Thanks Simon for the original patch!",
            "date": "2009-07-24T22:51:00.239+0000",
            "id": 15
        }
    ],
    "component": "modules/analysis",
    "description": "I added an implementation of incrementToken to ASCIIFoldingFilter.java and extended the existing  testcase for it.\nI will attach the patch shortly.\nBeside this improvement I would like to start up a small discussion about this filter. ASCIIFoldingFitler is meant to be a replacement for ISOLatin1AccentFilter which is quite nice as it covers a superset of the latter. I have used this filter quite often but never on a as it is basis. In the most cases this filter does the correct thing (replace a special char with its ascii correspondent) but in some cases like for German umlaut it does not return the expected result. A german umlaut  like '\u00e4' does not translate to a but rather to 'ae'. I would like to change this but I'n not 100% sure if that is expected by all users of that filter. Another way of doing it would be to make it configurable with a flag. This would not affect performance as we only check if such a umlaut char is found. \nFurther it would be really helpful if that filter could \"inject\" the original/unmodified token with the same position increment into the token stream on demand. I think its a valid use-case to index the modified and unmodified token. For instance, the german word \"s\u00fcd\" would be folded to \"sud\". In a query q:(s\u00fcd) the filter would also fold to sud and therefore find sud which has a totally different meaning. Folding works quite well but for special cases would could add those options to make users life easier. The latter could be done in a subclass while the umlaut problem should be fixed in the base class.\n\nsimon ",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1696",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Added New Token API impl for ASCIIFoldingFilter",
    "systemSpecification": true,
    "version": "2.9"
}