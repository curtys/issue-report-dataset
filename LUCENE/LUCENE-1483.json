{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "Mark did you intend to attach the patch here?",
            "date": "2008-12-09T09:48:43.568+0000",
            "id": 0
        },
        {
            "author": "Mark Miller",
            "body": "I had meant to attach a patch, but then a bunch of stuff wasn't working...\n\nThis is still a poor mans patch. I need to switch to using the expose subreaders patch. This also doesnt include the multisearcher sort patch yet, because when I tried the first one (2nd rev) everything broke. I'll work on integrating that later.\n\nI think all tests pass except for the very last sort test.\n\nSome cleanup needed, including the possible drop of using MultiSearcher itself.\n\nBasically, its still in a proof of concept stage.",
            "date": "2008-12-09T11:43:59.333+0000",
            "id": 1
        },
        {
            "author": "Marvin Humphrey",
            "body": "> Quick micro bench - did it twice and both times came out 17% slower.\n\nI'd guess that all the OO construction/destruction costs in this part of your patch are slowing things down.\n\n{code}\n+    Searchable[] searchers = new Searchable[readers.length];\n+    for(int i = 0; i < readers.length; i++) {\n+      searchers[i] = new IndexSearcher(readers[i]);\n+    }\n+\n+    MultiSearcher multiSearcher = new MultiSearcher(searchers);\n+    return multiSearcher.search(weight, filter, nDocs, sort);\n{code}",
            "date": "2008-12-09T14:20:11.788+0000",
            "id": 2
        },
        {
            "author": "Mark Miller",
            "body": "I'll be sure to include that info with the next set of results. \n\nI don't think those results represent getting lucky though: its 4 rounds and 2 runs with the same results (17% both runs). Nothing scientific, just did it real quick to get a base feel of the slowdown before the patch is finished up.\n\n*EDIT* Just like I forgot to take the optimize out of the sort alg when I pasted it here, looks like I missed it for the benches as well. Disregard those numbers.\n\nHere is the alg I used:\n\n{noformat}\n\nmerge.factor=mrg:50\ncompound=false\n\nsort.rng=20000:10000:20000:10000\n\nanalyzer=org.apache.lucene.analysis.standard.StandardAnalyzer\ndirectory=FSDirectory\n#directory=RamDirectory\n\ndoc.stored=true\ndoc.tokenized=true\ndoc.term.vector=false\ndoc.add.log.step=100000\n\ndocs.dir=reuters-out\n\ndoc.maker=org.apache.lucene.benchmark.byTask.feeds.SortableSimpleDocMaker\n\nquery.maker=org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker\n\n# task at this depth or less would print when they start\ntask.max.depth.log=2\n\nlog.queries=true\n# -------------------------------------------------------------------------------------\n\n{ \"Rounds\"\n\t{ \"Run\"\n      ResetSystemErase\n\n      { \"Populate\"\n        -CreateIndex\n        { \"MAddDocs\" AddDoc(100) > : 500000\n        -CloseIndex\n      }\n    \n      { \"TestSortSpeed\"\n        OpenReader  \n        { \"LoadFieldCacheAndSearch\" SearchWithSort(sort_field:int) > : 1 \n        { \"SearchWithSort\" SearchWithSort(sort_field) > : 5000\n        CloseReader \n      \n      }\n    \n      NewRound\n     } : 4\n\n} \n\nRepSumByName\n\n{noformat}",
            "date": "2008-12-09T14:53:40.884+0000",
            "id": 3
        },
        {
            "author": "Mark Miller",
            "body": "Okay, I straightened things out, and now it looks like possibly no loss (for few segments anyway). Last I looked at the index, only 6 segments. I've got to put real time into all this later though. Only been able to give it some very backgroundish time this morning.",
            "date": "2008-12-09T15:17:24.081+0000",
            "id": 4
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. Okay, I straightened things out, and now it looks like possibly no loss\n\nSo if there was a 17%  loss on the optimized index, and very little loss on a segmented index, I assume that means that matching/scoring is enough slower on the segmented index that the loss in sorting performance doesn't matter as much?\n",
            "date": "2008-12-09T15:30:41.655+0000",
            "id": 5
        },
        {
            "author": "Mark Miller",
            "body": "Ignore those first results entirely. It turns out I had the latest 1471 patched in. That shouldnt slow down a single segment though. Neither this or 1471 should have slowed things down because they only affect multisegment and multiindex searches I thought. Odd, but I just junked all of that and started fresh, did the tests a little closer to right, and see the numbers looking the same. Didn't want to get too into benching before its sorted out a bit more.  I'll try to get enough time to be more rigorous later though.  My free moments are under heavy attack by the female that appears to have made herself at home in my house.\n\nAs a side not, 1471 doesn't work in a couple ways with this patch - it throws both a nullpointer exception and a class cast exception in different circumstances.",
            "date": "2008-12-09T15:41:31.845+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "I think there should be very little impact to performance, for single or multi segment indices, for the search itself against a warmed reader.  (And actually LUCENE-1471 should make things a wee bit faster, especially if n,m are largeish, though this will typically be in the noise).\n\nBut warming after reopen should be much faster with this patch (we should try to measure that too).",
            "date": "2008-12-09T16:10:24.174+0000",
            "id": 7
        },
        {
            "author": "Mark Miller",
            "body": "bq.I think there should be very little impact to performance, for single or multi segment indices, for the search itself against a warmed reader. (And actually LUCENE-1471 should make things a wee bit faster, especially if n,m are largeish, though this will typically be in the noise). \n\nThat seems to be inline with what I got with 6 segments. I'm running some 30-50 seg range tests on my other laptop now.\n\nbq. But warming after reopen should be much faster with this patch (we should try to measure that too).\n\nI've got a base alg for that type of thing around somewhere too, from 831. It should be about the same, which means pretty dramatic reopen improvements if you multiple segments, especially if the new segment is small. Its likely to be small in comparison to all of the segs anyway, which means pretty great improvements. ",
            "date": "2008-12-09T16:32:16.364+0000",
            "id": 8
        },
        {
            "author": "Mark Miller",
            "body": "Ill bench again after this issue is polished up, but it looks like at 100 segments I am seeing the 20% drop. I didn't see any drop at 6 segments in a retest.\n\nIll do some longer, more thought out benchmarks when the patch is in better shape.",
            "date": "2008-12-09T19:00:57.581+0000",
            "id": 9
        },
        {
            "author": "Michael McCandless",
            "body": "\nHmmmmmmm.\n\nOK I think I see what could explain this: insertion into the pqueue is\nfairly costly.  So, because we now make 100 pqueues, each gathering\ntop N results, we are paying much more insertion cost overall than the\nsingle queue that IndexSearcher(MultiReader) uses.\n\nSo.... how about still doing the searches per-sub-reader(searcher),\nbut, make a HitCollector that gathers the results into a single\npqueue, passing that HitCollector to each sub-searcher?\n\nIf that turns out OK, then I think it would make LUCENE-1471 moot\nbecause we should similarly change MultiSearcher to use a single\nshared pqueue.\n\nActually I think this approach should be a bit faster, because there\nis some very small method call overhead to how MultiReader implements\nTermDocs/Positions by \"concatenating\" its sub-readers.  So by pushing\nSearcher down onto each SegmentReader we should gain a bit, but it\ncould very well be in the noise.  For this reason we may in fact want\nto do this same thing for the \"normal\" (sort by relevance)\nIndexSearcher.search.\n\nI wish I thought of this sooner.  Sorry for the runaround Mark!\n",
            "date": "2008-12-09T19:37:18.321+0000",
            "id": 10
        },
        {
            "author": "Doug Cutting",
            "body": "> make a HitCollector that gathers the results into a single pqueue\n\nThat's good when everything's local, but bad when things are distributed.  If we movE RemoteSearchable to contrib (as discussed in LUCENE-1314) then this may not be a problem, but we might still leave hooks so that someone can write a search that uses a separate top-queue per remote segment.",
            "date": "2008-12-09T20:17:12.923+0000",
            "id": 11
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n>> make a HitCollector that gathers the results into a single pqueue\n>\n> That's good when everything's local, but bad when things are distributed. If we movE RemoteSearchable to contrib (as discussed in LUCENE-1314) then this may not be a problem, but we might still leave hooks so that someone can write a search that uses a separate top-queue per remote segment.\n{quote}\n\nGood point; so this means we can't blindly do this optimization to MultiSearcher (w/o having option to do separate queues, merged in the end).  But for IndexSearcher(Multi*Reader).search it should be safe?",
            "date": "2008-12-09T20:57:39.916+0000",
            "id": 12
        },
        {
            "author": "Doug Cutting",
            "body": "> But for IndexSearcher(Multi*Reader).search it should be safe?\n\nRight.  Perhaps this is a reason to encourage folks to use MultiReader instead of MultiSearcher.  Are there cases, other than distributed, where MultiSearcher is required?  If not, perhaps it could be moved to the contrib/distributed layer too.",
            "date": "2008-12-09T21:18:38.829+0000",
            "id": 13
        },
        {
            "author": "Mark Miller",
            "body": "bq. make a HitCollector that gathers the results into a single pqueue \n\nWell it certainly made the code cleaner and the patch a bit nicer, but on first quick test, I still see the 20% slowdown with 100 more/less segments.\n\nI'm looking through too see where I may have done something funny.",
            "date": "2008-12-09T23:04:21.957+0000",
            "id": 14
        },
        {
            "author": "Michael McCandless",
            "body": "bq. on first quick test, I still see the 20% slowdown with 100 more/less segments.\n\nArgh!  Can you post your current patch?",
            "date": "2008-12-10T00:02:10.832+0000",
            "id": 15
        },
        {
            "author": "Mark Miller",
            "body": "Here is what I've got. The final sort test still fails, but the rest should pass.\n\n- Mark",
            "date": "2008-12-10T00:11:31.726+0000",
            "id": 16
        },
        {
            "author": "Mark Miller",
            "body": "I also did a quick reopen alg. The speed gain on this can really vary depending on index access patterns. I tried adding 500000 (very small) docs with a random sort field. Then added 50000 docs and then reopen 10 times. Repeat all 4 times. Comparison is of the time it takes to load the fieldcache and do one search. With this patch it came out about 40-50% faster. Obviously going to depend on many factors in real world though. In certain applications I'm sure it could be many times faster or slower.",
            "date": "2008-12-10T00:31:48.892+0000",
            "id": 17
        },
        {
            "author": "Mark Miller",
            "body": "Doing a little profiling on the new code and off the top results of interest are:\n\nFieldSortedHitQueue.lessThan(object,object) approx 12%\nFieldSortedHitQueue.insertWIthOverflow(object) approx 12%\nMultiReaderTopFieldDocCollector.collect(int,float) 6.3%\nFieldSortedHitQueue$4.compare() 5.3 %\n\nand on...\n\n\nFor Lucene trunk, a day or two ago:\n\nFieldSortedHitQueue.insertWIthOverflow(object) approx 11%\nTopFieldDocCollector.collect(int,float) 7.1%\nFieldSortedHitQueue.lessThan(object,object) approx 6.7%\nFieldSortedHitQueue.updateMaxScore 3.2%\nFieldSortedHitQueue$4.compare() 3.2 %\n",
            "date": "2008-12-10T00:58:57.340+0000",
            "id": 18
        },
        {
            "author": "Mark Miller",
            "body": "I think I see my mistake. Dumb one - I think I did it well trying to get things to work and didn't realize I left it in. I'll put up another patch after some benches finish.",
            "date": "2008-12-10T23:32:46.522+0000",
            "id": 19
        },
        {
            "author": "Mark Miller",
            "body": "Okay, now its as fast, if not a bit faster. I was doing the priority queue n*readers, as part of getting tests to pass early. Left it after fixing things elsewhere, and boom - explains all the lessthan nonsense in the profiling. Whoops.\n\nLooks good now though - still  need to investigate failure of last sort test.",
            "date": "2008-12-11T00:11:42.428+0000",
            "id": 20
        },
        {
            "author": "Michael McCandless",
            "body": "Exellent!  That was a sneaky one.\n\nI attached a tiny change to the patch, which is to set the docBase in MultiReaderTopFieldDocCollector; this saves the lookup into starts in each collect call.\n",
            "date": "2008-12-11T01:56:43.412+0000",
            "id": 21
        },
        {
            "author": "Michael McCandless",
            "body": "\nOK, I ran a quick perf test on a 100 segment index with 1 million docs\n(10K docs per segment), for a single TermQuery (\"text\"), and I'm\nseeing 11.1% speedup (best of 4: 20.36s -> 18.11s) with this patch, on\nMac OS X.  On Linux I see 6.3% speedup (best of 4: 23.31s -> 21.84s).\n\nSingle segment index shows no difference, as expected.\n\nI think the speedup is due to avoiding the extra method call plus 2nd\npass through the int docs[] to add in the doc base, in\nMultiSegmentReader.MultiTermDocs.read(int[] docs, int[] freqs).\n\nThis is a nice \"side effect\", ie in addition to getting faster reopen\nperformance (the original goal here), we get a bump in single term\nsearch performance.\n\nI think given this, we should cutover other search methods\n(sort-by-relevance, custom HitCollector) to this approach?  Maybe if\nwe add a new Scorer.score method that can accept a \"docBase\" which it\nadds into the doc() before calling collect()?  In fact, if we do that,\nwe may not even need the new MultiReaderTopFieldDocCollector at all?\n\nHmm, though, a Scorer may override that score(HitCollector), eg\nBooleanScorer does.  Maybe we have to make a wrapper HitCollector that\nsimply adds in the docBase and then invokes the real\nHitCollector.collect after shifting the docBase?  Though that costs us\nan extra method call per collect().\n\nHere's the alg I used (slight modified from the one above):\n{code}\nmerge.factor=1000\ncompound=false\n\nanalyzer=org.apache.lucene.analysis.standard.StandardAnalyzer\ndirectory=FSDirectory\n#directory=RamDirectory\n\ndoc.tokenized=true\ndoc.term.vector=false\ndoc.add.log.step=100000\nmax.buffered=10000\nram.flush.mb=1000\n\nwork.dir = /lucene/work\n\ndoc.maker=org.apache.lucene.benchmark.byTask.feeds.SortableSimpleDocMaker\n\nquery.maker=org.apache.lucene.benchmark.byTask.feeds.FileBasedQueryMaker\nfile.query.maker.file = test.queries\n\ntask.max.depth.log=2\n\nlog.queries=true\n\n{ \"Populate\"\n  -CreateIndex\n  { \"MAddDocs\" AddDoc(100) > : 1000000\n  -CloseIndex\n}\n    \n{ \"Rounds\"\n  { \"Run\"\n    { \"TestSortSpeed\"\n      OpenReader  \n      { \"LoadFieldCacheAndSearch\" SearchWithSort(sort_field:int) > : 1 \n      { \"SearchWithSort\" SearchWithSort(sort_field) > : 500\n      CloseReader \n    }\n    NewRound\n  } : 4\n} \n\nRepSumByPrefRound SearchWithSort\n{code}\n\nIt creates the index once, then does 4 rounds of searching with the\nsingle query \"text\" in test.queries (SimpleQueryMaker was creating\nother queries that were getting 0 or 1 hits).\n\nI'm running with \"java -Xms1024M -Xmx1024M -Xbatch -server\"; java is\n1.6.0_07 on Mac Pro OS X 10.5.5 and 1.6.0_10-rc on 2.6.22.1 linux\nkernel.\n",
            "date": "2008-12-11T12:01:05.920+0000",
            "id": 22
        },
        {
            "author": "Mark Miller",
            "body": "Thanks Mike.\n\nAre we going to be screwed with this filter stuff though? I'm looking into the last sort test failing - my first thought is that a filter with say 8 docs, is getting pushed down onto 4 searches with 2 docs in each reader type of thing. A filter that allows the 8th doc wont do very well on a bunch of 2 docs searches...or hopefully I don't know what I'm talking about. Looking to see if I can figure my way around it now.\n",
            "date": "2008-12-11T12:01:50.599+0000",
            "id": 23
        },
        {
            "author": "Mark Miller",
            "body": "Hmmm...well this makes the test pass (I subtract the base from the filter doc id)...\n\nLet me know if I'm all wet on this...\n\n*EDIT*\n\nthat cant be quite right...I'll try making a different test.",
            "date": "2008-12-11T12:13:06.675+0000",
            "id": 24
        },
        {
            "author": "Michael McCandless",
            "body": "One thing to fix is ParalellReader: it currently defines a getSubReaders method, but, this won't work for searching (because ParallelReader's sub-readers are not \"concatenated\").  I think we need a more specific name than \"getSubReaders\" (there's some initial discussion of this in LUCENE-1475).  Maybe getConcatenatedReaders?  getSequentialReaders?  Something else...?",
            "date": "2008-12-11T12:17:45.886+0000",
            "id": 25
        },
        {
            "author": "Mark Miller",
            "body": "bq. I think given this, we should cutover other search methods (sort-by-relevance, custom HitCollector) to this approach? Maybe if we add a new Scorer.score method that can accept a \"docBase\" which it adds into the doc() before calling collect()? In fact, if we do that, we may not even need the new MultiReaderTopFieldDocCollector at all?\n\nI like this idea. I'd love to figure out how 'outside' systems could get the reopen benefit as well (solr caches and such, beyond internal sorting). This seems like a first step towards that possibility (though I admittedly don't see a clear path yet).\n\nbq. Hmm, though, a Scorer may override that score(HitCollector), eg BooleanScorer does. Maybe we have to make a wrapper HitCollector that simply adds in the docBase and then invokes the real HitCollector.collect after shifting the docBase? Though that costs us an extra method call per collect().\n\nWell, we might as well bench and see what we lose...",
            "date": "2008-12-11T12:36:21.071+0000",
            "id": 26
        },
        {
            "author": "Michael McCandless",
            "body": "Maybe, we should add \"setDocBase\" to HitCollector.  Then, fix all core/contrib HitCollectors to respect this.  Then add a method \"supportsDocBase()\" which returns false in default impl in HitCollector.  Then, in search() if we are dealing w/ a HitCollector that does not supportDocBase() we have to wrap?\n\nAlternatively, we could throw an UnsupportedOperationException in setDocBase() by default, catch that, and fallback to wrapping.\n\nThis way we avoid the extra collect() method call in the common cases (builtin HitCollectors).  Also, we save an add when the doc is not competitive.",
            "date": "2008-12-11T13:28:11.875+0000",
            "id": 27
        },
        {
            "author": "Michael McCandless",
            "body": "You shouldn't need to subtract base from the filter's docID, since the filter is operating in the docID space of the sub-reader.\n\nIs it TestSort.testTopDocScores that you see failing (that's what I see)?\n\nUnfortunately, the filter in that test is assuming that the IndexReader it's passed in is equal to the \"full\" IndexReader, because it references docs1.scoreDocs[0].doc, which is the docID space of the full reader.\n\nI would say the test is buggy (it's making an assumption about the API that happens to be true but was not guaranteed).  However, this could mean similar filters \"out there\" think they can grab docIDs from the top-level IndexReader, cache them, and then assign them inside the getDocIdSet method.",
            "date": "2008-12-11T13:44:51.680+0000",
            "id": 28
        },
        {
            "author": "Mark Miller",
            "body": "A filter fix thats closer to correct and a new test. ",
            "date": "2008-12-11T13:47:15.326+0000",
            "id": 29
        },
        {
            "author": "Mark Miller",
            "body": "bq. Is it TestSort.testTopDocScores that you see failing (that's what I see)?\n\nright\n\nbq. Unfortunately, the filter in that test is assuming that the IndexReader it's passed in is equal to the \"full\" IndexReader, because it references docs1.scoreDocs[0].doc, which is the docID space of the full reader.\n\nright, its using the full  id space - isnt that legal though? It did work.\n\nbq. I would say the test is buggy (it's making an assumption about the API that happens to be true but was not guaranteed). However, this could mean similar filters \"out there\" think they can grab docIDs from the top-level IndexReader, cache them, and then assign them inside the getDocIdSet method.\n\nThat was my first thought - are they aloud to build the filter this way? But it worked to do it right? I like your assumption thought though - suits my lazy side :)\n\nWhat if someone made a filter that is supposed to only allow the first doc? So it is set for 0...all of the first docs of each sub reader would match. That seemed to be supported before right?\n\n*EDIT*\n\nnm, I guess that still fits the 'assumption' thing. Feels odd changing this behavior still though - I guess you have this same issue over multisearchers though ...\n\nHow about those keeping their own reader to filter cache or something? A single filter could correctly apply against a single MultiReader before...now you would need a different filter for each subreader right?\n",
            "date": "2008-12-11T13:53:32.897+0000",
            "id": 30
        },
        {
            "author": "Michael McCandless",
            "body": "bq. How about those keeping their own reader to filter cache or something? A single filter could correctly apply against a single MultiReader before...now you would need a different filter for each subreader right?\n\nSuch cases would then be caching by sub-reader, right?  That's the benefit of this approach.  EG I had been thinking we'd need to fix the recently added FieldCacheRangeFilter to also \"understand\" when it's dealing w/ concatenated sub-readers, but in fact with this change that filter is only given the sub-readers, one at a time, and so it only asks FieldCache per sub-reader, and we automatically get faster reopen performance \"for free\" (no change to FieldCacheRangeFilter required).\n\nStill, I agree this is probably dangerous to suddenly change, since there could easily be filters out there that are [illegally] using a docID not belonging/corresponding to the reader that was passed in.  So maybe we should provide a migration path.  EG, add \"allowSubReaders\" to Filter, defaulting to \"return false\" so that any external Filter impls still get passed the Multi*Reader, and then fix all core/contrib filters to return true from that method?",
            "date": "2008-12-11T14:13:28.964+0000",
            "id": 31
        },
        {
            "author": "Mark Miller",
            "body": "Okay, I follow now. If you did things correctly, you'll always be passed the right segmentreader through a hook. Nice. I think we really do want to do this for the other search methods.\n\nbq. Still, I agree this is probably dangerous to suddenly change, since there could easily be filters out there that are [illegally] using a docID not belonging/corresponding to the reader that was passed in. So maybe we should provide a migration path. EG, add \"allowSubReaders\" to Filter, defaulting to \"return false\" so that any external Filter impls still get passed the Multi*Reader, and then fix all core/contrib filters to return true from that method?\n\nThis seems reasonable. I am following your [illegal] argument better now though, so I wouldn't feel so bad leaving it out. If its unsupported behavior, I like the idea of adding backward compat cruft much less. I had it in my head that you might be caching things based on the top level multireader, but it looks like now, that you always should be using the reader provided by a hook - which will be the single seg reader.",
            "date": "2008-12-11T14:33:53.100+0000",
            "id": 32
        },
        {
            "author": "Mark Miller",
            "body": "I think this is almost there: added the new logic to relevance and hitcollector search as well.",
            "date": "2008-12-11T16:30:15.917+0000",
            "id": 33
        },
        {
            "author": "Mark Miller",
            "body": "That actually needed a couple of tweaks.",
            "date": "2008-12-11T17:01:05.362+0000",
            "id": 34
        },
        {
            "author": "Michael McCandless",
            "body": "Looks good!  Do we really need IndexReader.supportsSequentialReaders?  Because the default impl (return length 1 array of itself) seems sufficient?\n\nAlso, I don't think ParallelReader needs to throw UnsupportedOperationException in that method -- it can fallback to the default?\n\nIt would be nice to somehow deprecate \"supportsDocBase\" so that all outside HitCollectors would need to support it on upgrading to 3.0, but, I'm not sure how to cleanly do that.  (Ie I'd rather not have that method continue to exist in 3.0).\n\nIt's a delightfully small patch now!",
            "date": "2008-12-11T17:14:32.814+0000",
            "id": 35
        },
        {
            "author": "Michael McCandless",
            "body": "Also, back compat tests fail to compile because we renamed Multi*Reader.getSubReaders --> getSequentialSubReaders.  So when committing this be sure to also fix the test-tag branch!",
            "date": "2008-12-11T17:21:47.917+0000",
            "id": 36
        },
        {
            "author": "Mark Miller",
            "body": "bq. Looks good! Do we really need IndexReader.supportsSequentialReaders? Because the default impl (return length 1 array of itself) seems sufficient? \n\nLet me investigate. If you try using the default impl, and you change the parralellreaderreopen test to use getSequintialReaders rather than getSubReaders, the test will throw a stack trace overflow on checking if the reader is closed. I put the illegal in there to make sure I wasnt calling it, because upon switching to getSubReaders, problem goes away. Seemed fair enough, but I'll I guess have to understand what was going on to really respond.\n\nbq. It would be nice to somehow deprecate \"supportsDocBase\" so that all outside HitCollectors would need to support it on upgrading to 3.0, but, I'm not sure how to cleanly do that. (Ie I'd rather not have that method continue to exist in 3.0).\n\n+1. I dont see what we can do but release it deprecated with a note explaining. Fair enough for 3.0 I think.\n\nbq. It's a delightfully small patch now!\n\nYeah, this one had the great feeling of the multiterm patch - rolled right up into something nice. Goto love the Lucene API, flaws or not. ",
            "date": "2008-12-11T17:29:38.457+0000",
            "id": 37
        },
        {
            "author": "Michael McCandless",
            "body": "bq. If you try using the default impl, and you change the parralellreaderreopen test to use getSequintialReaders rather than getSubReaders\n\nBut you shouldn't change that test (it should continue to call ParalellReader.getSubReaders).\n\nbq. I dont see what we can do but release it deprecated with a note explaining. Fair enough for 3.0 I think.\n\nThe problem is this doesn't create a the right sequence.  Ie, if we mark supportsDocBase as deprecated, then some ExternalHitCollector won't see the deprecation warning (they have not overridden supportsDocBase), and so then we can't remove it in 3.0 since their code will then silently break.  I think the only thing to do would be deprecate collect() in favor of another method.  Or, deprecate HitCollector entirely in favor of new class DocBaseHitCollector (don't like that name).  Sigh...\n\nbq. Yeah, this one had the great feeling of the multiterm patch - rolled right up into something nice. Goto love the Lucene API, flaws or not.\n\nI love this kind :)",
            "date": "2008-12-11T17:47:33.423+0000",
            "id": 38
        },
        {
            "author": "Mark Miller",
            "body": "So I don't know what that stackover flow was, but I just put things to how they should be and all tests pass.\n\nSo very close now. I'm not ready to commit myself though. I do most of my thinking after the work :)",
            "date": "2008-12-11T17:49:05.898+0000",
            "id": 39
        },
        {
            "author": "Michael McCandless",
            "body": "Oh one more thing: I think we don't need both supportsDocBase and setDocBase throwing UOE by default?  How about just the 2nd one, and you fix search to catch the UOE and wrap in DocBaseCollector?",
            "date": "2008-12-11T17:49:41.799+0000",
            "id": 40
        },
        {
            "author": "Mark Miller",
            "body": "bq. But you shouldn't change that test (it should continue to call ParalellReader.getSubReaders).\n\nRight, I was coming at it from the wrong angle. I had refactored in the change with eclipse, and seeing that ParalellReader.getSuquentialReaders could cause a statckoverflow, thats why i put in the isSequentialSuported check. Guess its not a concern though. I didn't take much time to understand it.\n\nbq. The problem is this doesn't create a the right sequence. Ie, if we mark supportsDocBase as deprecated, then some ExternalHitCollector won't see the deprecation warning (they have not overridden supportsDocBase), and so then we can't remove it in 3.0 since their code will then silently break. I think the only thing to do would be deprecate collect() in favor of another method. Or, deprecate HitCollector entirely in favor of new class DocBaseHitCollector (don't like that name). Sigh...\n\nThis depends right? Don't we have a lot of latitude with 3.0? I would think we could require that you read some upgrade notes on changes...3.0 is our hope to change some things we couldn't normally get away with I thought :) I agree we should be friendly, like 1 to 2, but its tempting to use 3.0 to do some things more cleanly rather than less.",
            "date": "2008-12-11T17:55:00.214+0000",
            "id": 41
        },
        {
            "author": "Mark Miller",
            "body": "bq. Oh one more thing: I think we don't need both supportsDocBase and setDocBase throwing UOE by default? How about just the 2nd one, and you fix search to catch the UOE and wrap in DocBaseCollector?\n\nIf you'd like...I'm not a fan of control with exceptions. I am also not a fan of of isSupported methods though...I was leaning that way over exceptions...sounds like you lean the other way...? I guess it has its appeal in this case...",
            "date": "2008-12-11T17:58:15.750+0000",
            "id": 42
        },
        {
            "author": "Doug Cutting",
            "body": "Could we add a new class like\n\n{code}\npublic abstract class Hitable {\n  public abstract void setBase(int base);\n  public abstract void hit(int doc, float score);\n}\n{code}\n\nupgrade everything in trunk to use this, and change HitCollector to:\n\n{code}\n/** @deprecated */\npublic abstract class HitCollector extends Hitable {\n  public abstract void setBase() { throw new UOE(); }\n}\n{code}\n\nthen, for back-compatiblity, wrap anything that extends HitCollector to rebase?\n\nThen you'd have neither an isSupported method nor use exceptions for control.\n",
            "date": "2008-12-11T20:11:33.652+0000",
            "id": 43
        },
        {
            "author": "Mark Miller",
            "body": "Thats a great idea, I'll try that route.\n\nAnother tiny win in this is that MuliSearcher doesn't have to use a doubled up hitcollector anymore.",
            "date": "2008-12-11T21:05:28.917+0000",
            "id": 44
        },
        {
            "author": "Mark Miller",
            "body": "bq. upgrade everything in trunk to use this, \n\n If users are using a HitCollector as a ref to a trunk HitCollector that becomes a Hitable, won't their code break? I really like this idea, but does it get around back compat? ",
            "date": "2008-12-11T22:13:07.783+0000",
            "id": 45
        },
        {
            "author": "Doug Cutting",
            "body": "> If users are using a HitCollector as a ref to a trunk HitCollector that becomes a Hitable, won't their code break?\n\nLucene never passes someone a HitCollector that they didn't create.  So all the classes that folks create may need to remain subclasses of HitCollector, but classes used internally do not need to, and we can deprecate all public HitCollector implementations and provide new versions that extend Hitable.\n\nhttp://lucene.apache.org/java/2_4_0/api/org/apache/lucene/search/class-use/HitCollector.html\n\nDoes that address your concern?\n\nI'm not too fond of Hitable, but can't think of anything better.  With that name, the method might better be called hit() than collect(), but that's a more invasive change.  DocCollector?  Collector?",
            "date": "2008-12-11T23:35:43.983+0000",
            "id": 46
        },
        {
            "author": "Mark Miller",
            "body": "Okay, so subclasses of HitCollector stay subclasses until 3, and then they extend Hitable? Sounds good.\n*EDIT*\nNo that wont work and I read your comment wrong - we have to provide new impls, and old impls will be wrapped. Got it. Patch coming.\n\nI kind of like Hitable myself. You are collecting a 'hit' with a Hittable object. A hit is a doc and score. Any other opinions? I'm less fond of other Collector variations. hit() could be better than collect(), but collect() is not such a stretch in my mind.\n\n*EDIT*\n\nOne further thought, if we are replacing TopDocCollector, what would it become? TopDocDocCollector, TopDocHitable? I'm liking these names less...",
            "date": "2008-12-12T00:26:16.671+0000",
            "id": 47
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> I'm not a fan of control with exceptions. I am also not a fan of of isSupported methods though...I was leaning that way over exceptions...sounds like you lean the other way...? I guess it has its appeal in this case...\n{quote}\n\nI agree, though I leaned towards using an exception because 1) no new\nAPI needing future deprecation would then have been added, and 2) the\nexpectation (but not forced, and this is a problem) is that over time\nall HitCollector subclasses would implement setBase, so the exception\nwould be the exception (heh) not the rule.\n\nBut I like Doug's proposal instead, since on upgrading to 2.9 you'll\nsee your code is deprecated, which then allows us to drop it in 3.0.\nI have a slight preference for DocCollector.\n\nThis means any methods that accept a HitCollector would also be\ndeprecated, and we'd add a new method that takes DocCollector instead,\nand change the deprecated one to wrap a DocBaseCollector around the\nHitCollector and invoke the new method.\n\n{quote}\n> we can deprecate all public HitCollector implementations and provide new versions that extend Hitable\n{quote}\n\nCould we leave (eg) TopDocCollector extending HitCollector in 2.9, and\nthen in 3.0 change it to directly extend DocCollector (Hitable)?\n(This saves having to deprecate TopDocCollector and at least 2\nothers).\n\n{quote}\n> Don't we have a lot of latitude with 3.0?\n{quote}\n\nI think in 3.0, when changing APIs, we are only allowed to remove\ndeprecated APIs from 2.9?  Ie we can't do more drastic changes.\n",
            "date": "2008-12-12T00:45:11.183+0000",
            "id": 48
        },
        {
            "author": "Mark Miller",
            "body": "bq. Could we leave (eg) TopDocCollector extending HitCollector in 2.9, and then in 3.0 change it to directly extend DocCollector (Hitable)? (This saves having to deprecate TopDocCollector and at least 2 others).\n\nIf we do that, I don't think we can do our check to use base or not by checking for HitCollector right?\n\n",
            "date": "2008-12-12T00:49:21.067+0000",
            "id": 49
        },
        {
            "author": "Mark Miller",
            "body": "Is that right? We better get going on java5 conversion then...\n",
            "date": "2008-12-12T01:00:45.726+0000",
            "id": 50
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> If we do that, I don't think we can do our check to use base or not by checking for HitCollector right?\n{quote}\n\nAhh right, so if a user outside creates a TopDocCollector & passes it in, we can't tell that it can handle setBase natively.  Or we could test & catch the UOE (since HitCollector is deprecated, using an exception here will go away in 3.0).",
            "date": "2008-12-12T01:04:03.119+0000",
            "id": 51
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Is that right? We better get going on java5 conversion then... \n{quote}\n\nAhh right, that too :)  But, as of 3.0 we can start accepting/making changes to Lucene that require 1.5 JRE, but still we can't just swap out APIs w/o going through deprecation first?",
            "date": "2008-12-12T01:42:15.213+0000",
            "id": 52
        },
        {
            "author": "Mark Miller",
            "body": "I thought there were some that wanted to change some of the API to java \n5 for the 3.0 release, cause I thought back compat was less restricted \n2-3. I guess mabye that won't end up happening, if it was going to, it \nseems we'd want to deprecate what will be changed in 2.9.\n\n- Mark\n\n\n",
            "date": "2008-12-12T01:48:45.328+0000",
            "id": 53
        },
        {
            "author": "Mark Miller",
            "body": "I think its almost there. I still want to spend a little time looking it over, but I think its looking good.",
            "date": "2008-12-12T02:56:16.074+0000",
            "id": 54
        },
        {
            "author": "Hoss Man",
            "body": "I haven't been following this issue too closely (or truthfully: at all) but if there's talk of  deprecating HItCollector and introducing a new superclass to replace it, would it also make sense to revist the idea of adding a return type to the collect/hit method? ... ie: an enum style result indicating \"OK\" or \"ABORT\" (with the potential of adding additional constants later ala FieldSelectorResult)\n\nI remember this coming up as a \"wish list\" back when TimeLimitedCollector was added (but i don't really remember if it was decided that the current implementation was actually better then if collect() did have a return value)\n\nAnyway, just something to ponder...\n\n{code}\npublic abstract class Hitable {\n  public abstract void setBase(int base);\n  public abstract HitStatus hit(int doc, float score);\n}\n/** @deprecated */\npublic abstract class HitCollector extends Hitable {\n  public abstract void collect(int doc, float score);\n  public void setBase(int base) { throw new UOE(); }\n  public HitStatus hit(int doc, float score) { \n    collect(doc, score); \n    return HitStatus.OK;\n  }\n}\n{code}",
            "date": "2008-12-12T05:20:53.594+0000",
            "id": 55
        },
        {
            "author": "Michael McCandless",
            "body": "Mark, I got on hunk (HitCollector) failed on applying the patch -- looks like it's the $Id$ issue again (your area doesn't expand $Id$ tags).  No problem -- I just applied it manually.",
            "date": "2008-12-12T10:22:07.085+0000",
            "id": 56
        },
        {
            "author": "Michael McCandless",
            "body": "bq. adding a return type to the collect/hit method? ... ie: an enum style result indicating \"OK\" or \"ABORT\" (with the potential of adding additional constants later ala FieldSelectorResult)\n\nI think we should consider this, though this then implies an if stmt checking the return result & doing something, on each hit, so we should test the cost of doing so vs the cost of throwing an exception instead (eg we could define a typed exception in this new interface which means \"abort the search now\" and maybe another to mean \"stop searching & return the results you got so far\", etc.).",
            "date": "2008-12-12T10:28:35.904+0000",
            "id": 57
        },
        {
            "author": "Uwe Schindler",
            "body": "{quote}bq. adding a return type to the collect/hit method? ... ie: an enum style result indicating \"OK\" or \"ABORT\" (with the potential of adding additional constants later ala FieldSelectorResult)\n\nI think we should consider this, though this then implies an if stmt checking the return result & doing something, on each hit, so we should test the cost of doing so vs the cost of throwing an exception instead (eg we could define a typed exception in this new interface which means \"abort the search now\" and maybe another to mean \"stop searching & return the results you got so far\", etc.).{quote}\n\nThis looks like a really good idea. Currently to stop a iterator, I use an exception class that extends RuntimeException (to have it unchecked) to cancel a search. Very nice if you support it directly.",
            "date": "2008-12-12T10:39:35.982+0000",
            "id": 58
        },
        {
            "author": "Michael McCandless",
            "body": "Duh: I just realized that when we switched back to a single pqueue for\ngathering results across the N subreaders, we lost the original\nintended \"benefit\" for this issue.  Hard to keep the forrest in mind\nwhen looking at all the trees....\n\nIe, we are now (again) creating a single FieldSortedHitQueue, which\npulls the FieldCache for the entire MultiReader, not per-segment.  So\nwarming time is still slow, when sorting by fields.\n\nReally we've \"stumbled\" on 2 rather different optimizations:\n\n  # Run Scorer at the \"sub reader\" level: this gains performance\n    because you save the cost of going through a MultiReader.  This\n    requires the new DocCollector class, so we can setDocBase(...).\n  # Do collection (sort comparison w/ pqueue) at the \"sub reader\"\n    level: this gains warming performance because we only ask for\n    FieldCache for each subreader.  But, it seems to hurt search\n    performance (pqueue comparison & insertion cost went up), so it's\n    no longer a no-brainer tradeoff (by default at least).\n\nGiven that #1 has emerged as a tentatively fairly compelling gain, I\nnow think we should decouple it from #2.  Even though #2 was the\noriginal intent here, let's now morph this issue into addressing #1\n(since that's what current patch does), and I'll open a new issue for\n#2?\n",
            "date": "2008-12-12T11:37:52.536+0000",
            "id": 59
        },
        {
            "author": "Mark Miller",
            "body": "Ugg...you know I was afraid of that when I was making the change, but I easily convinced myself that FieldSortedHitQueue was just taking that Reader for AUTO detect and didnt really relook. It also makes the comparators. Bummer. I guess lets open a new issue if we can't easily deal with it here (I've got to look at it some more).",
            "date": "2008-12-12T11:55:46.457+0000",
            "id": 60
        },
        {
            "author": "Mark Miller",
            "body": "I've got a quick idea I want to try to fix it.",
            "date": "2008-12-12T12:28:23.260+0000",
            "id": 61
        },
        {
            "author": "Mark Miller",
            "body": "Bah. You can't share that queue and get the reopen benefit without jumping too many hoops. All of a sudden you can't use ordinals, comparators need to know how to compare across comparators, and it just breaks down fast. How disappointing.",
            "date": "2008-12-12T12:57:53.700+0000",
            "id": 62
        },
        {
            "author": "Michael McCandless",
            "body": "\nYeah, ugg.  This is the nature of \"progress\"!  It's not exactly a\nstraight line from point A to B :) Lots of fits & starts, dead ends,\njumps, etc.\n\nWe could simply offer both (\"collect into single pqueue but pay high\nwarming cost\" or \"collect into separate pqueues, then merge, and pay\nlow warming cost\"), but that sure is an annoying choice to have to\nmake.\n\nOh, here's another idea: do separate pqueues (again!), but after the\nfirst segment is done, grab the values for the worst scoring doc in\nthe pqueue (assuming the queue filled up to its numHits) and use this\nas the \"cutoff\" before inserting into the next segment's pqueue.\n\nIn grabbing that cutoff we'd have to 1) map ord->value for segment 1,\nthen 2) map value->ord for segment 2, then 3) use that cutoff for\nsegment 2.  (And likewise for all segment N -> N+1).\n\nI think this'd greatly reduce the number of inserts & comparisons done\nin subsequent queues because it mimics how a single pqueue behaves:\nyou don't bother re-considering hits that won't be globally\ncompetitive.\n\nWe could also maybe merge after each segment is processed; that way\nthe cutoff we carry to the next segment is \"true\" so we'd reduce\ncomparisons even further.\n\nWould this work?  Let's try to think hard before writing code :)\n",
            "date": "2008-12-12T13:42:51.772+0000",
            "id": 63
        },
        {
            "author": "Mark Miller",
            "body": "bq. We could simply offer both (\"collect into single pqueue but pay high warming cost\" or \"collect into separate pqueues, then merge, and pay low warming cost\"), but that sure is an annoying choice to have to make.\n\nAgreed. I really hope we don't have to settle for this.\n\nbq. Oh, here's another idea:\n\nGood one! Keep those ideas coming.\n\nbq. Would this work?\n\nIt sounds like you've nailed it to me, but I'll let it float around in my head for a bit while I work on some other things.\n\nbq. Let's try to think hard before writing code :)\n\nNow theres a new concept for me. My brain will work itself to death trying to avoid real work :)",
            "date": "2008-12-12T13:58:15.652+0000",
            "id": 64
        },
        {
            "author": "Doug Cutting",
            "body": ">   public abstract void setBase(int base);\n\nIt occurred to me last night that this really has no place in HitCollector.  We're forcing applications to handle an implementation detail that they really shouldn't have to know about.  It would be better to pass the base down to the scorer implementations and have them add it on before they call collect(), no?\n",
            "date": "2008-12-12T17:25:08.535+0000",
            "id": 65
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> It would be better to pass the base down to the scorer implementations and have them add it on before they call collect(), no?\n{quote}\n\nSo we'd add Scorer.setDocBase instead?\n\nThe only downside I can think of here is that often you will perform the addition when it wasn't necessary.\n\nIe, if the score is not competitive at all, then you wouldn't need to create the full docID and so you'd save one add opcode.\n\nAdmittedly, this is a very small (tiny) cost, and I do agree that making HitCollector know about docBase is really an abstraction violation...",
            "date": "2008-12-12T17:42:34.994+0000",
            "id": 66
        },
        {
            "author": "Mark Miller",
            "body": "bq. Oh, here's another idea: do separate pqueues (again!), but after the first segment is done, grab the values for the worst scoring doc in the pqueue (assuming the queue filled up to its numHits) and use this as the \"cutoff\" before inserting into the next segment's pqueue.\n\nWe've got to try it. Whats the hard part in this? Converting a value to an ord?\n\n*EDIT*\n\nOkay, I see, we can just find our place by running through new value Comparables.\n\nAn added cost for going back to per reader is that all doc id values (not ords) also need to be adjusted (for the multisearcher).",
            "date": "2008-12-12T18:14:11.307+0000",
            "id": 67
        },
        {
            "author": "Michael McCandless",
            "body": "OK, here's another tweak on the last proposal: maybe we could,\ninstead, take the pqueue produced by segment 1 and \"convert\" it into\nthe ords matching segment 2, and then do normal searching for segment\n2 using that single pqueue (and the same for all seg N -> N+1\ntransitions)?\n\nFor all numeric fields, the conversion is a no-op (their ord is\ncurrently the actual numeric byte, short, int, etc. value, though\nconceivably that could change in the future); only String fields, and\ncustom (hmm) would need to do something.\n\nThis should be more efficient than the cutoff approach because it'd\nresult in less comparisons/inserts.  Ie, it's exactly a single pqueue\nagain, just with some \"conversion\" between segments.  The conversion\ncost is near zero for numeric fields, and for string fields it'd be\nO(numHits*log2(numValue)), where numValue is number of unique string\nvalues in next segment for that sort field.  I think for most cases\n(many more docs than numHits requested) this would be faster than the\ncutoff approach.\n\nWould that work?",
            "date": "2008-12-12T19:47:36.013+0000",
            "id": 68
        },
        {
            "author": "Yonik Seeley",
            "body": "segment 1 has terms:  apple, banana, orange\nsegment 2 has terms: apple, orange\n\nWhat is the ord of banana in segment2?",
            "date": "2008-12-12T19:54:29.592+0000",
            "id": 69
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> What is the ord of banana in segment2?\n{quote}\n\nHow about 0.5?\n\nIe, we just need an ord that means it's in-between two ords for the current segment.\n\nOn encountering that, we'd also need to record it's real value so that subsequent segments could look it up properly (or, if it survives until the end, to return the correct value \"banana\").",
            "date": "2008-12-12T20:01:36.654+0000",
            "id": 70
        },
        {
            "author": "Mark Miller",
            "body": "Okay, but how am I going to squeeze between two customs? I guess you'd have to store as a compare against either side?\n\n*EDIT*\n\nThere is also the problem that all compares are done based on ScoreDocs that index into a single ord array by doc. The previous pq's ScoreDocs will not compare right - they won't index into the ord array for the current Reader - they are indexes into the array for the previous Reader. This is what made me give up on single pq earlier.\n\n*EDIT*\n\nI guess we put them on the ScoreDoc like we do the values for multisearcher? Then we could use a PQ like FieldDocPQ that used ords rather than vals?\n\n*EDIT*\n\nHmmm...How do I get at the ordinals though? The value is exposed, but the ordinals are hidden behind a compare method...",
            "date": "2008-12-13T00:10:42.291+0000",
            "id": 71
        },
        {
            "author": "Mark Miller",
            "body": "Okay, in a pinch I guess we just grab the ordinals straight from the field cache and violate the comparator abit. But we don't have the score docs until after running the collector, so we cant perch stuff on them.\n\nHmm - we need something like the current hits work with the standard get ord mechanism (which has its own probs cause we compare, we don't look at ords) and the last hits work with an ord on the scoredoc or something. Its all ugly stuff in my head.",
            "date": "2008-12-13T13:28:01.692+0000",
            "id": 72
        },
        {
            "author": "Michael McCandless",
            "body": "I'm exploring one possible approach, with a new Comparator API that's told when to switch to the next subReader (which gives it the chance to translate the ords in the queue).  Not sure it'll work out yet though...",
            "date": "2008-12-13T14:31:36.126+0000",
            "id": 73
        },
        {
            "author": "Mark Miller",
            "body": "Thats were I don't follow though - its not ords in the queue right? Its ScoreDocs. Thats whats getting me at the moment.",
            "date": "2008-12-13T16:53:56.973+0000",
            "id": 74
        },
        {
            "author": "Michael McCandless",
            "body": "Attached initial patch (derived from one of the earlier patches).\nAlot of work remains.  TestSort (and likely others) fail.\n\n{quote}\n> Thats were I don't follow though - its not ords in the queue right? Its ScoreDocs. Thats whats getting me at the moment. \n{quote}\n\nExactly -- so I built first cut at the alternative \"copy value\"\napproach, where the comparator (new FieldComparator abstract class) is\nresponsible for holding the values it needs for docs inserted into the\nqueue.  I also added TopFieldValueDocCollector (extends DocCollector),\nand ByValueFieldSortedHitQueue (extends PriorityQueue) that interacts\nwith the FieldComparators.  (We can change these names...).  I updated\nIndexSearcher to use this new queue for field sorting.\n\nThis patch only handles SortField.{DOC,SCORE,INT} now, but I think the\napproach has early surprising promise: I'm seeing a sizable\nperformance gain for the \"sort by int field\" case (13.76 sec vs 17.95\nsec for 300 queries getting top 100 hits from 1M results) --> 23%\nfaster.  I verified for the test sort alg (above) it's producing the\nright results (at least top 40 docs match).\n\nI didn't expect such performance gain (I was hoping for not much\nperformance loss, actually).  I think it may be that although the\ninitial value copy adds some cost, the within-queue comparsions are\nthen faster because you don't have to deref back to the fieldcache\narray.  It seems we keep accidentally discovering performance gains\nhere :)\n\nIf we go forward with this approach I think it'd mean deprecating\nFieldSortedHitQueue & ScoreDocComparator, because I think there's no\nback-compatible way to migrate forward.  I also like that this\napproach means we only need an iterator interface to FieldCache\nvalues (for LUCENE-831).\n\nMark can you look this over and see if it makes sense and maybe try to\ntackle the other sort types?  String will be the most interesting but\nI think very doable.\n",
            "date": "2008-12-13T21:44:06.080+0000",
            "id": 75
        },
        {
            "author": "Mark Miller",
            "body": "Fantastic Mike! I've started working through the tests and I've corrected a small ordering problem and added most of the other basic types. This is great stuff I think, but I need some more time to digest it all.  Still looks like String will be the interesting piece. I think we have to fill fields for the multisearcher as well, which is annoying, because the multisearcher will have to let the indexsearcher know to do it, or we may do it for no reason. Then we just have to clear up the setbase stuff. Light at the end of the tunnel!",
            "date": "2008-12-14T15:43:58.048+0000",
            "id": 76
        },
        {
            "author": "Mark Miller",
            "body": "It seems there are a few hoops to jump through with strings beyond what I was thinking. We don't have the full array of unique terms now, but rather a bunch of smaller arrays of unique terms, with overlap. That makes converting Strings to ords very difficult right? We almost have to create the full array. Also, we still have to do some fancy foot work to get a proper ord. Then we have to juggle and track things so that we can return the String value in getValue (we are more concerned with ords, so its not fun). It seems a lot of spinning/tracking unless we go back to a full StringIndex. Perhaps its just as good to just compare by String value and give up on ord? It really seems that by the time we jump through every hoop to create ords from Strings on a bunch of smaller StringIndexes, we will have at least eaten as much as it costs to do String.compare? Not a conclusion really though, I am still mucking...\n\nAny insight?",
            "date": "2008-12-14T17:37:11.198+0000",
            "id": 77
        },
        {
            "author": "Mark Miller",
            "body": "I was off on the fillFields stuff, I forgot we are back to a single hit collector. EDIT - can't even follow my own thoughts - I wasn't off, you are just already handling the adjustment that needs to be made. I'd like to avoid filling fields unless we are in a multisearcher still though...\n\nI've got everything working except custom and locale stuff, in a suboptimal way anyway. String values rather than ords, and there is plenty that can probably be improved.\n\n4 tests still fail (3 with custom, 1 with locale). Still trying to lock down the best way to deal with String ords/values.",
            "date": "2008-12-14T18:17:55.126+0000",
            "id": 78
        },
        {
            "author": "Michael McCandless",
            "body": "\n{quote}\n> I've started working through the tests and I've corrected a small ordering problem and added most of the other basic types.\n{quote}\n\nGreat!\n\n{quote}\n> Then we just have to clear up the setbase stuff.\n{quote}\n\nYeah I think we should remove that (and use setNextReader instead).\n\n{quote}\n> That makes converting Strings to ords very difficult right? \n{quote}\n\nRight (this was the challenging example Yonik brought up above).\n\nHow about something like this: at any given time, the slots are filled\nwith an instance that has 1) the ord (that \"matches\" the current\nreader) and 2) the actual value.  When transitioning readers you have\nto remap all ords to the new reader (but keep the value unchagned):\nfor each slot, you take its String value look it up in the new reader\nw/ binary search.  If it's present, assign it the corresponding ord.\nIf it's not present, it must fall between ord X and X+1 so assign it\nan ord of X+0.5.\n\nThen proceed like normal, since all ords are now \"matched\" to your\ncurrent reader.  You compare with ords, never with values.\n\nThe one caveat is... we have to take care with precision.  A float\nX+0.5 won't be precise enough.  We could use double, or, we could use\nlong and \"remap\" all valid ords to be 2X (even) their value, and all\n\"in between\" ords (carried over from previous reader) to be odd\nvalues.  I think we'd need long for this since in the worst case, if\nyou have max number of docs and each doc has unique string you would\nhave 2^31 unique ords to represent.\n\n",
            "date": "2008-12-14T18:28:18.445+0000",
            "id": 79
        },
        {
            "author": "Uwe Schindler",
            "body": "You do not need to map to long, if you would use negative integers as marker for in between. So doc 0 has -1, doc 1 has -2, doc 2 has -3,..., doc (2^31-1 == Integer.MAX_VALUE) would have (-2^32 == Integer.MIN_VALUE)\n\nJust an idea.",
            "date": "2008-12-14T18:40:26.627+0000",
            "id": 80
        },
        {
            "author": "Uwe Schindler",
            "body": "Sorry that does not work because of comparing, but you could substract 2^31 form doc number and multiply by two.",
            "date": "2008-12-14T18:41:58.375+0000",
            "id": 81
        },
        {
            "author": "Mark Miller",
            "body": "bq. How about something like this:\n\nOkay, I actually got a ways down that path before I gave up...it was clearer in my head before I got the new code - that had me trying to map one ord at a time (my fault, not the code of course) - but right, I'd have to map them all on reader change. Clears up the haze a bit.\n\nLocale is in, custom coming. That will make all tests pass. Then I'll get back on this String stuff (switch to ord from the value stuff I have going now). Then cleanup. Very awesome stuff , thanks Mike.",
            "date": "2008-12-14T18:47:09.275+0000",
            "id": 82
        },
        {
            "author": "Mark Miller",
            "body": "What do we do about the old SortComparatorSource et al? I can't figure out a way to make old custom implementations work with this - they implement logic that compares ScoreDocs and I cant see how I can make a new comparator that works based on custom SortComparators.",
            "date": "2008-12-14T20:36:00.534+0000",
            "id": 83
        },
        {
            "author": "Mark Miller",
            "body": "bq. You compare with ords, never with values.\n\nBut I still have to implement getValue for fillFields. That means either storing the value along with ords (at each slot), or storing the orig ord plus the orig StringIndex is came out of for each slot...right?\n\n*EDIT*\n\nOkay, that answer is in your earlier comment anyway - we have to track value by slot as well. I'm almost there...",
            "date": "2008-12-14T20:42:32.608+0000",
            "id": 84
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> You do not need to map to long, if you would use negative integers as marker for in between\n{quote}\nActually a variation on this would work: we could logically do the even/odd ord mapping, but shift it down into negative numbers to make use of the full int range.  That'd give us enough precision.",
            "date": "2008-12-14T20:56:53.553+0000",
            "id": 85
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> What do we do about the old SortComparatorSource et al?\n{quote}\nI think we have to deprecate SortComparatorSource and ScoreDocComparator (in favor of FieldComparator and we should add a FieldComparatorSource, too I guess).  Ie, custom sort implementations would need to migrate to the new API?",
            "date": "2008-12-14T21:00:47.528+0000",
            "id": 86
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Sorry that does not work because of comparing, but you could substract 2^31 form doc number and multiply by two. \n{quote}\nAhh I missed that (I said the same thing 4 comments later... moving fast here!).",
            "date": "2008-12-14T21:02:16.038+0000",
            "id": 87
        },
        {
            "author": "Mark Miller",
            "body": "Does this have to wait for 3 then? How can we back compatibly tell everyone they have to write new custom comparator implementations?",
            "date": "2008-12-14T21:17:23.781+0000",
            "id": 88
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Does this have to wait for 3 then? How can we back compatibly tell everyone they have to write new custom comparator implementations?\n{quote}\nIf we deprecate old and introduce new in 2.9, then we can remove old in 3.0, right?",
            "date": "2008-12-14T21:45:07.757+0000",
            "id": 89
        },
        {
            "author": "Mark Miller",
            "body": "But if you are using the old one it wont work with the new Searcher methods? I guess I'll have to think about it some more.\n\nI've got the String stuff working (I think) except for one issue...if a bunch of ords already in the queue map to the same index, they need to be adjusted to be in order (eg when you convert a value, its not in the terms list for the next binary search). I tried some naive tricks to adjust the number based on the old ord, but no real progress yet...",
            "date": "2008-12-14T21:49:44.272+0000",
            "id": 90
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> But if you are using the old one it wont work with the new Searcher methods? I guess I'll have to think about it some more. \n{quote}\n\nI think the search methods, on seeing that there is a SortField.CUSTOM type and then seeing that it's a SortComparatorSource in there, would fallback to the current impl, but all other Sorts would use the new one?\n\n{quote}\n> if a bunch of ords already in the queue map to the same index, they need to be adjusted to be in order \n{quote}\n\nHmmm!  Perhaps on comparing two \"odd\" values that are the same we could fallback to a true String.compareTo (I don't like that added if, though, it should be rare).  Or, better, we could add a \"subord\" to break the tie.  That subord'd have to be computed by gathering all String values that sorted to the same \"odd ord\" and sorting them to assign subords.",
            "date": "2008-12-14T22:35:54.341+0000",
            "id": 91
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. If it's not present, it must fall between ord X and X+1 so assign it an ord of X+0.5.\n\nI went down this thought path in the past... float doesn't have the precision, double might, could use long and left shift to make space for \"inbetween\", etc.\n\nOne problem is that putting an ord \"inbetween\" isn't good enough since you may be mapping many values.  At that point, one starts wondering if it's worth getting an ord, and what is solved or optimized by using ords.\n\nWhy are ords useful:\n (a) fast comparison when reordering the priority queue (insertion/removal of items)\n (b) fast comparison to determine if something should be inserted into the priority queue\n (c) other (non sorting) usage, using term numbers instead of term values.\n\nUsing ords for (a) seems expensive, as all ords in the queue must be translated.\nUsing ords for (b) means calculating an ord only for the smallest element of the priority queue.\n\nWhen doing a large search with a diverse set of keys to sort by, there are many more checks to see if an item should be inserted into the queue than are actually inserted.  Also, when using an ord for (b), it doesn't have to be exact - it can be rounded since it's purpose isn't an exact comparison, but just an optimization to determine if insertion into the priority queue can be skipped.\n",
            "date": "2008-12-14T22:35:57.568+0000",
            "id": 92
        },
        {
            "author": "Mark Miller",
            "body": "bq. One problem is that putting an ord \"inbetween\" isn't good enough since you may be mapping many values. \n\nbq. I don't like that added if, though, it should be rare\n\nNot rare right? Let say there are 20 values in the queue, and now the new reader has 2 values. Lots will map to the same index.\n\nI'm still digesting the rest of what yonik said. I don't have this String ord stuff working 100%, but I have it working sort of (seems to sort pieces right, but then the pieces are out of order). I don't think the precision exists to do what I'm doing anyway, but since it kind of works, I could prob bench the diff of using values rather than ords.",
            "date": "2008-12-14T22:57:51.403+0000",
            "id": 93
        },
        {
            "author": "Mark Miller",
            "body": "> But if you are using the old one it wont work with the new Searcher methods? I guess I'll have to think about it some more. \n\n>>I think the search methods, on seeing that there is a SortField.CUSTOM type and then seeing that it's a SortComparatorSource in there, would fallback to the current impl, but all other Sorts would use the new one?\n\nAhhh...I was afraid of the ugliness. All right.",
            "date": "2008-12-14T22:59:55.592+0000",
            "id": 94
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Not rare right? Let say there are 20 values in the queue, and now the new reader has 2 values. Lots will map to the same index.\n{quote}\n\nTrue, not rare in that case, but then the added cost will be tiny since the new segment has relatively so few hits.",
            "date": "2008-12-14T23:01:44.615+0000",
            "id": 95
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> At that point, one starts wondering if it's worth getting an ord, and what is solved or optimized by using ords.\n{quote}\n\nI agree: all this complexity may not be worth it, if simple\ncompare-by-value in fact performs well enough.  I think we should\nbenchmark both.\n\nMark if you get things to a semi-stable state & post a patch we\ncan do some benching.  You could actually just have two SortField\ntypes (STRING and STRING_ORD) then we could easily swap\nback & forth.",
            "date": "2008-12-14T23:26:52.167+0000",
            "id": 96
        },
        {
            "author": "Mark Miller",
            "body": "bq. Or, better, we could add a \"subord\" to break the tie. That subord'd have to be computed by gathering all String values that sorted to the same \"odd ord\" and sorting them to assign subords.\n\nThat seems like a bit or work to manage. What if I just kept a separate double subords that holds the old mapping? If two slots are equal, we can fall down to that? We would have the whole new array, but the other way we have to track what maps to the same index, sort that, and then have a map or another array anyway. What do we save? We could have an int[] rather than a double[]? But a lot more juggling...\n\n*EDIT*\nNm...that logic doesnt quite work...\n\n*EDIT*\n\nOr it does...man I have a scatterbrain and a half. I got it to work (at least partially - the tests pass). I'll now work on getting something up for you to test with. My main worry at this point is that I'm doing things inefficiently enough that its not a fair test :)",
            "date": "2008-12-14T23:31:40.137+0000",
            "id": 97
        },
        {
            "author": "Mark Miller",
            "body": "Quick question: what should I use for the value version...Strings or StringIndex? StringIndex takes less mem, but requires two array lookups.",
            "date": "2008-12-15T00:24:32.878+0000",
            "id": 98
        },
        {
            "author": "Mark Miller",
            "body": "Here you go. I'm sorry I've made everything so messy :) I'll clean later.\n\nThere is now SortField.STRING_VAL and STRING_ORD.\n\nSTRING uses StringIndex,\nSTRING_VAL uses Strings[]\nSTRING_ORD uses ordinals.\n\nI havn't benched anything yet myself.\n\nThere is still a lot of cleanup to do beyond this String stuff  (and the old comparators still don't work)\n\nI havn't gotten over everything post scramble yet: hope I'm not doing anything too stupid. Sort tests pass other than custom comparator.",
            "date": "2008-12-15T00:52:09.176+0000",
            "id": 99
        },
        {
            "author": "Mark Miller",
            "body": "One small error:\n\n+    public int sortType() {\n+      return SortField.STRING_VA;\n+    }\n\nshould be\n\n+    public int sortType() {\n+      return SortField.STRING_VAL;\n+    }",
            "date": "2008-12-15T01:07:31.023+0000",
            "id": 100
        },
        {
            "author": "Mark Miller",
            "body": "That actually had a system.out as well. Another patch that takes care of the above error and the system.out, and a manual fix of the HitCollector $id.",
            "date": "2008-12-15T12:19:07.533+0000",
            "id": 101
        },
        {
            "author": "Michael McCandless",
            "body": "Thanks Mark.  FWIW, when I generate a patch (with \"svn diff\") that is near the $Id$ tag, I too cannot apply the patch.  So it seems like \"svn diff\" has some \"smarts\" whereby it un-expands a keyword, thus screwing up patch.  We really need that \"svn patch\" command... (which IIRC is coming in an upcoming svn release).",
            "date": "2008-12-15T12:22:34.186+0000",
            "id": 102
        },
        {
            "author": "Mark Miller",
            "body": "Some more quick comments:\n\nthe StringIndex value version does two much array derefing, so I'd fix that, or just use the String version.\n\nI'm dong ordinals by keeping a second Double subord array. Everytime ords are mapped to the new IndexReader, if an ord doesnt map directly onto the new terms array, if the subord is not 0, I multiply the old ord mapping into the sub ord and give it the new ord eg the subord becomes the old ord times the current subord and the ord is updated. When comparing, if two ords are the same, we drop to the subord.\n\nI havn't though about precision issues (it prob doesn't work, but I don't know), but it works for the tests.",
            "date": "2008-12-15T12:28:52.206+0000",
            "id": 103
        },
        {
            "author": "Michael McCandless",
            "body": "BTW, one important difference w/ the new TopFieldValueDocCollector is it does not track the max score -- we probably need to add that back in, until Hits is removed in 3.0 (is it needed beyond that?).",
            "date": "2008-12-15T16:40:00.361+0000",
            "id": 104
        },
        {
            "author": "Michael McCandless",
            "body": "There's something wrong w/ the SortField.STRING_ORD case -- I'm trying \"sort by title\" w/ a Wikipedia index, and while I see the same results in a clean checkout vs STRING_VAL, I get different (wrong) results for STRING_ORD.\n\nClean checkout & STRING_VAL get:\n{code}\nhit 0: docID=1974521 title=\"Born into Trouble as the Sparks Fly Upward.\"\nhit 1: docID=688913 title=\"Into The Open\" Exhibition\nhit 2: docID=1648 title=\"Love and Theft\"\nhit 3: docID=599545 title=\"Repent, Harlequin!\" Said the Ticktockman\nhit 4: docID=349499 title=\"The Spaghetti Incident?\"\n{code}\n\nbut STRING_ORD gets this:\n{code}\nhit 0: docID=599545 title=\"Repent, Harlequin!\" Said the Ticktockman\nhit 1: docID=688913 title=\"Into The Open\" Exhibition\nhit 2: docID=1974521 title=\"Born into Trouble as the Sparks Fly Upward.\"\nhit 3: docID=992439 title='Abd al-Malik II\nhit 4: docID=1951563 title='Auhelawa language\n{code}\n\nI haven't tried to track it down yet...",
            "date": "2008-12-15T16:43:02.200+0000",
            "id": 105
        },
        {
            "author": "Mark Miller",
            "body": "bq. haven't tried to track it down yet...\n\nI wouldn't. Well the method I am using passes the tests, its not likely viable (maybe even on a smaller scale than i would have guessed based on what your seeing). But since its close, I figure a benchmark of it against using values should tell us a lot about whether it makes sense to keep pushing with ord. Ord will no doubt end up a little slower if its to work properly, but comparing them now should give us a gauge of using values instead. Thats what we were looking for right?\n\nI still have tons I want to look at in this patch (and hopefully some ideas/suggestions). I havn't looked at it at all in that context yet though. I merely sat down and made the tests pass one by one with little consideration for anything else. ",
            "date": "2008-12-15T16:56:36.645+0000",
            "id": 106
        },
        {
            "author": "Mark Miller",
            "body": "Another thing I'll do is added another sort test - the tests may not hit all of the edge cases - i dont think they hit compare(ord, doc, score) at all for one (if i am remembering right).",
            "date": "2008-12-15T17:35:20.350+0000",
            "id": 107
        },
        {
            "author": "Mark Miller",
            "body": "I just made a quick new test for what im doing with ords - it seems once i add more than about 500 docs, one or two are out of order - that problem compounds as the number goes up. Special case I am missing, or precision issues.",
            "date": "2008-12-15T19:24:51.726+0000",
            "id": 108
        },
        {
            "author": "Michael McCandless",
            "body": "\nOK I ran an initial test, though since the ord approach is a \"bit\"\nbuggy we can't be sure how well to trust these results.\n\nI indexed first 2M docs from Wikipedia, into 101 segment index, then\nsearch for \"text\" (hits 97K results), sort by title, pulling best 100\nhits.  I do the search 1000 times in each round.\n\nCurrent trunk (best 107.1 searches/sec):\n{code}\nOperation            round   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\nXSearchWarm              0        1            1          0.0       93.64   463,373,760  1,029,046,272\nXSearchWithSort_1000 -   0 -  -   1 -  -  - 1000 -  -   100.6 -  -   9.94 - 463,373,760  1,029,046,272\nXSearchWithSort_1000     1        1         1000        107.1        9.34   572,969,344  1,029,046,272\nXSearchWithSort_1000 -   2 -  -   1 -  -  - 1000 -  -   105.5 -  -   9.48 - 572,969,344  1,029,046,272\nXSearchWithSort_1000     3        1         1000        106.2        9.41   587,068,928  1,029,046,272\n{code}\n\nPatch STRING_ORD (best 102.0 searches/sec):\n{code}\nOperation            round   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\nXSearchWarm              0        1            1          0.5        2.16   384,153,600  1,029,046,272\nXSearchWithSort_1000 -   0 -  -   1 -  -  - 1000 -  -  - 94.1 -  -  10.63 - 439,173,824  1,029,046,272\nXSearchWithSort_1000     1        1         1000        100.7        9.93   439,173,824  1,029,046,272\nXSearchWithSort_1000 -   2 -  -   1 -  -  - 1000 -  -   101.9 -  -   9.81 - 573,822,208  1,029,046,272\nXSearchWithSort_1000     3        1         1000        102.0        9.81   573,822,208  1,029,046,272\n{code}\n\nPatch STRING_VAL (best 34.6 searches/sec):\n{code}\nXSearchWarm              0        1            1          0.4        2.24   368,201,088  1,029,046,272\nXSearchWithSort_1000 -   0 -  -   1 -  -  - 1000 -  -  - 34.6 -  -  28.94 - 415,107,648  1,029,046,272\nXSearchWithSort_1000     1        1         1000         33.9       29.54   415,107,648  1,029,046,272\nXSearchWithSort_1000 -   2 -  -   1 -  -  - 1000 -  -  - 33.9 -  -  29.46 - 545,339,904  1,029,046,272\nXSearchWithSort_1000     3        1         1000         34.0       29.40   545,339,904  1,029,046,272\n{code}\n\n\nNotes:\n\n  * Populating the field cache on trunk for MultiReader is\n    fantastically costly (94 sec).  The IO cache was already hot so\n    this isn't IO latency.  I think MultiTermEnum/Docs behaves badly\n    for this use case (single unique term (title) per doc).  We really\n    need to switch to column-stride fields, not un-invert, for this.\n\n  * For this case at least STRING_ORD is still quite a bit faster than\n    STRING_VAL; however, it's still buggy.  Maybe a smaller queue size\n    (eg 10 or 20) would make them closer.\n\n  * STRING_ORD is still a bit slower than trunk's sort; hopefully once\n    tuned it'll be closer.\n\nI think we now need to fix the STRING_ORD bug & retest.\n",
            "date": "2008-12-15T19:55:08.639+0000",
            "id": 109
        },
        {
            "author": "Mark Miller",
            "body": "Thanks Mike. Yup - that says enough for me. We have to get ords working. I don't think ords will get faster though (you wouldnt surprise me though), I think they will get slower. Certainly they should stay much faster than value though - what a dog. But who knows - we can test fall back to value compare instead of subords as well. My naive ords attempt now is keeping previous mapping ords order by multiplying it as we move to new readers - thats going to explode into some very large numbers pretty fast, and I don't expect we can get by so easily. Either fall back to value will be good enough, or we will prob have to map to new ords rather than simple multiplying to retain each stages ording.\n\nI'll keep playing with the ord on my end though - i only got it to pass those tests moments before that patch went up. I try to keep a frantic pace because I never know if my spare cycles will go away - I have juggled a defensive plate for a while :) No doubt I'll squeeze some more hours tonight though. ",
            "date": "2008-12-15T20:04:01.127+0000",
            "id": 110
        },
        {
            "author": "Mark Miller",
            "body": "I'm starting to think fall back to value wont be so bad. I'll give you another cut that does fall back to value and whatever I have to do to get correct subord stuff right.",
            "date": "2008-12-15T21:57:10.197+0000",
            "id": 111
        },
        {
            "author": "Michael McCandless",
            "body": "\nWe should definitely try fallback compare-by-value.\n\nBut, sort by title (presumably unique key) is actually a worst case\nfor us, because all values in the queue will not exist in the next\nsegment.  So it's a good test ;) We should also test sorting by an\nenum field (\"country\", \"state\").\n\nThinking more about how to compute subords... I think we could store\nord & subord each as int, and then efficiently translate them to the\nnext segment with a single pass through the queue, in sort key order.\nThis would ensure we hit all the dups (different Strings that map to\nthe same ord in the next segment, but different subords) in one\ncluster.  And, the subord could be easily computed by simply\nincrementing (starting with 1) in key sort order, until the cluster is\ndone.\n\nIt should be simple to step through the pqueue's heap in sort order\nmin->max (w/o removing the entries which is the \"normal\" heapsort way\nto sort the elements); you'd need to maintain some sort of queue to\nkeep track of the \"frontier\" as you walk down the heap.  But I haven't\nfound a cookbook example yet...  It should be fast since we can use\nthe ord/subords in the queue for all within-queue comparisons.\n\nWe could also save time on the binary search by bounding the search by\nwhere we just found the last key.  It may be worth tracking the max\nvalue in the queue, to bound the other end of the search.  For a big\nsearch the queue should have a fairly tight bound.\n",
            "date": "2008-12-16T01:18:47.053+0000",
            "id": 112
        },
        {
            "author": "Mark Miller",
            "body": "bq. We should also test sorting by an enum field (\"country\", \"state\").\n\nI'm actually trying on random data that I am creating, and I'm getting different results. Oddly, many cases where Values seem to beat Trunk.\n\nbq. We could also save time on the binary search by bounding the search by\nwhere we just found the last key. It may be worth tracking the max\nvalue in the queue, to bound the other end of the search. For a big\nsearch the queue should have a fairly tight bound.\n\nRight, I've been thinking of ways to cut that down too. Its def binary searching much more then it needs to. That seems to be a big ord slowdown from what I can tell  - fallback to compare by value is actually appearing slower than by value. I've made a couple small optimizations, but theirs def more.\n\nbq. Thinking more about how to compute subords...\n\nCool. Great idea to think about. My main search has been to get subord as an int. Getting both to int would certainly be optimal. Everything I've come up with seems too expensive though - I'll try to run with that idea.",
            "date": "2008-12-16T01:50:15.869+0000",
            "id": 113
        },
        {
            "author": "Michael McCandless",
            "body": "Ugh -- that approach won't work, because the pqueue in the collector\nis not necessarily sorted primarily by our field (eg if the String\nsort field is not the first SortField).  So we don't have a fast way\nto visit the keys in sorted order.\n",
            "date": "2008-12-16T01:51:44.611+0000",
            "id": 114
        },
        {
            "author": "Mark Miller",
            "body": "Okay, I just full on did it inefficiently, and maybe I can work backwards a little. Seems to be solid.\n\nI just collect the old ords by making a map with the mapped to index as the key. The map has List values and when a list gets more than one entry, the entry is added to a morethanone set. After mapping all the ords, i go through the morethanone set and sort each list - each subord is then set based on its index in the sorted list.\n\nWe already knew that was easy enough - I just think its probably on the terribly inefficient side. Now to think about whacking pieces off. It just makes me not very hopeful to start at something so slow. And still the double ords :( Perhaps the negative int could still come into play though. \n\nWay too many little objects being made...",
            "date": "2008-12-16T03:32:23.440+0000",
            "id": 115
        },
        {
            "author": "Michael McCandless",
            "body": "\nCan you post your inefficient remapping version?\n\nI too created the fallback version (just set subord to -1 when value\nisn't found in the new index & respect that in the two compare\nmethods).  I confirmed it gives correct top 50 results.  This then\nbrings ord perf to 97.6 searches/sec (vs trunk 107.1 searches/sec), so\nthat's our number to beat since it seems to be bug-free.\n\nThen I ran \"MatchAllDocsQuery\" (to test a much larger result set --\nthis returns 2M hits but previous query \"text\" returned ~97K hits),\nsorting by title, queue size=100.  Trunk still has unbelievely slow\nwarming (95 sec), and then gets 7.6 searches/sec.  Patch ord search\n(with fallback) gets 30.7 searches/sec.\n\nThis is very interesting and odd -- I can't explain why ord searching\nw/ fallback is so much faster than current trunk when the number of\nhits is large (2M).  I think this is very important because it's the\nbig slow queries that are most important to improve here, even if it's\nat some cost to the queries that are already fast.\n\nIe, we still need to do more tests, but if this result holds (and we\nneed to explain the difference), I think it's a strong vote for the\nord+fallback approach.  Not to mention, it also sidesteps the absurdly\nslow warming time of FieldCache.StringIndex on a Multi*Reader.",
            "date": "2008-12-16T11:38:39.114+0000",
            "id": 116
        },
        {
            "author": "Michael McCandless",
            "body": "When I run MatchAllDocsQuery (2M hits), with a queue size of 10 instead of 100, trunk still gets 7.6 searches/sec and ord w/ fallback gets 33.1 searches/sec.",
            "date": "2008-12-16T14:47:24.679+0000",
            "id": 117
        },
        {
            "author": "Michael McCandless",
            "body": "I tested the query \"1\", which gets 384K hits.  Trunk gets 48.1 searches/sec and ord w/ fallback gets 55.0.\n\nSo somehow as the result set gets larger, with a crossover somewhere between 97K hits (query \"text\") and 384K hits (query \"1\"), the ord w/ fallback becomes faster and then gets much faster as the result set gets quite large (2M hits).",
            "date": "2008-12-16T14:55:57.871+0000",
            "id": 118
        },
        {
            "author": "Mark Miller",
            "body": "Okay, here is the super inefficient ords version.\n\n    SortField.STRING_VAL:   sort by val\n    SortField.STRING_ORD: sort by ord and subord\n    SortField.STRING_ORD_VAL: sort by ord fallback to val\n\nThose multireader fieldcache loading times blow me away...crazy.",
            "date": "2008-12-16T15:10:30.982+0000",
            "id": 119
        },
        {
            "author": "Mark Miller",
            "body": "bq. I too created the fallback version (just set subord to -1 when value\nisn't found in the new index & respect that in the two compare\nmethods).\n\nYours may be better than my then - i got rid of the subord array for fallback, and if they are equal ords, i do a compare on the values.",
            "date": "2008-12-16T15:14:27.671+0000",
            "id": 120
        },
        {
            "author": "Mark Miller",
            "body": "bq. This is very interesting and odd - I can't explain why ord searching w/ fallback is so much faster than current trunk when the number of hits is large (2M).\n\nI was testing with randomly created data (just random number of digits (2-8), each digit randomly 0-9) and a lot of what I was doing, straight values seemed to handily beat straight ords! It depended on how many docs I was making and how segmented I made it I think. Wasn't very official, and the test was somewhat short, but I ran it over and over...seemed odd.\n",
            "date": "2008-12-16T15:30:27.243+0000",
            "id": 121
        },
        {
            "author": "Mark Miller",
            "body": "I guess I can't get away with my new index calculation either:  ords[i] = ((-index << 1) - 3) / 2.0d;\n\nIndex is an int, so its going to overflow.\n\nEDIT\n\nWait...thats based on unique terms per reader not possible number of docs...guess it can stay.",
            "date": "2008-12-16T15:39:55.273+0000",
            "id": 122
        },
        {
            "author": "Mark Miller",
            "body": "Or can it? Over int.max/2 unique ids and then sort on id would be broke right? Okay, it would be kind of nuts to try and sort on that many unique terms, but in the future?...\n\n*EDIT*\n\nActually, one seg would need int.max /2, but you know what i mean...\n\n*EDIT*\n\nOkay, I guess my argument with JIRA cleared up - you'd have to have the second segment or later with over int.max/2 terms. Do we care about such an insane possibility?",
            "date": "2008-12-16T19:46:41.493+0000",
            "id": 123
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> I was testing with randomly created data (just random number of digits (2-8), each digit randomly 0-9)\n{quote}\n\nCan you post a patch for this?  Seems handy to fix contrib/benchmark to be able to generate such a field...\n\n{quote}\n> straight values seemed to handily beat straight ords!\n{quote}\n\nI'll try to test this case too; we need to understand why natural data (Wiki titles) shows one thing but synthetic data shows the opposite.  And we still need to test the enum case.\n",
            "date": "2008-12-16T20:16:46.202+0000",
            "id": 124
        },
        {
            "author": "Michael McCandless",
            "body": "\n{quote}\n> I guess I can't get away with my new index calculation either: ords[i] = ((-index << 1) - 3) / 2.0d; \n{quote}\n\nI think you can use an int for the ords?  Now that we have subord,\nwhen you get negative index back from binary search, you can set ord\nto -index-1 which is the \"lower bound\", and then as long as subord is\nat least 1 it should compare correctly.\n\nAlso, in your 2nd pass, if the list is length 1 then you can\nimmediately set subord to 1 and move on.\n\nIn your first pass, in the \"else\" clause (when the value was found in\nthe next segment) don't you need to set subord to 0?",
            "date": "2008-12-16T22:46:01.669+0000",
            "id": 125
        },
        {
            "author": "Mark Miller",
            "body": "bq. I think you can use an int for the ords? Now that we have subord, when you get negative index back from binary search, you can set ord to -index-1 which is the \"lower bound\", and then as long as subord is at least 1 it should compare correctly.\n\nAh, indeed - no need for in the middle if you can fall to the subord. I think I may have been thinking it would be nice not to fall through the ords so much, but surly its worth losing double and doing the average. Seems to like -2  not  -1  though, then I start the subords at 1 rather than 0...I'll bring real thought to it later, but thats generating some good looking results.\n\n*EDIT*\n\nArg - with -2 one tests fails, with -1 it passes, but reverse sort fails :) Prob is 1 one then, and I've got a small issue elsewhere.\n\nbq. In your first pass, in the \"else\" clause (when the value was found in the next segment) don't you need to set subord to 0?\n\nhmm...I had that commented out as I was playing...let me think - if you don't set it and multiple numbers don't map to clean new ords and they are the same, it will fall to subords...so right, you wouldn't want an old subord around.\n\nI'm hoping there is a lot more optimization we can do to the pure ords case, but frankly I have low hopes for it - it should be a bit more competitive though.\n\nI'm going to take some time to finish up some other pieces and then come back again I think.  I've polished up the comparators a bit, so once I get some other work in ill put up another rev.",
            "date": "2008-12-16T23:51:27.054+0000",
            "id": 126
        },
        {
            "author": "Mark Miller",
            "body": "bq. Admittedly, this is a very small (tiny) cost, and I do agree that making HitCollector know about docBase is really an abstraction violation...\n\nI'm not sold either way. Push to scorer?",
            "date": "2008-12-17T00:18:47.057+0000",
            "id": 127
        },
        {
            "author": "Michael McCandless",
            "body": "But, with this new approach (single pqueue that \"knows\" when we transition to the next segment) aren't we back to HitCollector not only knowing the doc base but also the IndexReader we are now advancing to?  (We should remove the setDocBase call).\n\nOr I guess we could pre-add the doc (in Scorer) so that collect is called with the full docID.\n\nStill that \"tiny\" performance cost nags at me ;)  Most of the time the add would not have been necessary since the number of inserts into the pqueue should be a small percentage for a large number of hits.  And this is the hotspot of searching for Lucene, so maybe we should not add on this cost even if it's tiny?  And we can always wrap a collector that doesn't implement setIndexReader and pre-add the docId for it.  It's like an \"expert\" DocCollector API vs the normal one.",
            "date": "2008-12-17T00:37:59.207+0000",
            "id": 128
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Prob is 1 one then, and I've got a small issue elsewhere.\n{quote}\n\nI think we want ord to be the lower bound.  EG if seg 1 has:\n\n  apple -> 0\n  banana -> 1\n  orange -> 2\n\nand then seg 2 has just apple & orange, then banana should map to ord 0 subord 1, meaning it's between ord 0 & 1, I think?\n\nAnd an exact match (apple & orange in this case) should have subord 0.\n\n{quote}\n> I'm hoping there is a lot more optimization we can do to the pure ords case, but frankly I have low hopes for it - it should be a bit more competitive though.\n{quote}\n\nI think the perf gains are very compelling, already, for the ord fallback case & title sorting.  Small result sets are slower, but large result sets are substantially faster, than current trunk.  Not to mention much faster warming time (side stepping the weirdness with Multi*Reader, and, only loading FieldCache for new segments).",
            "date": "2008-12-17T00:47:18.036+0000",
            "id": 129
        },
        {
            "author": "Mark Miller",
            "body": "Okay, I guess thats fair enough. I was going to push down the fall back sorted search (with the old Custom's) to a single reader too, but thats not actually worth keeping setdocbase for (or needed now that I think about it). So setNextReader brings the same abstraction argument though. But what can you do I guess - the benefits are clearly worth it, and those comparators need access to current subreader.\n",
            "date": "2008-12-17T00:54:24.341+0000",
            "id": 130
        },
        {
            "author": "Mark Miller",
            "body": "\n\nbq. I think the perf gains are very compelling, already, for the ord fallback case & title sorting. Small result sets are slower, but large result sets are substantially faster, than current trunk. \n\nOh, I agree there - I think this patch still makes perfect sense - its brings lot of gains. I just don't think that ords without fallback is going to get very good. I'm wondering if we should even try too hard if ord with val fallback does so well.",
            "date": "2008-12-17T01:01:29.266+0000",
            "id": 131
        },
        {
            "author": "Mark Miller",
            "body": "bq. and then seg 2 has just apple & orange, then banana should map to ord 0 subord 1, meaning it's between ord 0 & 1, I think?\n\napple -> 0\norange ->1\n\nthe binary search gives back -insertionpoint - 1, the insertion point for banana is 1, so -1 -1 = -2. So I reverse that and subtract 2 to get 0 right? It lands on apple. Then on sort, apple comes first for 0, 1 and then orange is 0, 2.\n\n(I dont remember off hand why subord has to start at 1 not 0, but i remember it didnt work otherwise)\n",
            "date": "2008-12-17T04:18:43.475+0000",
            "id": 132
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> the binary search gives back -insertionpoint - 1, the insertion point for banana is 1, so -1 -1 = -2. So I reverse that and subtract 2 to get 0 right? It lands on apple.\n{quote}\nHmm -- I didn't realize binarySearch is returning the insertion point on a miss.  So your logic (negate then subtract 2) makes perfect sense now.\n\nJust be sure... maybe you should temporarily add asserts when a negative index is returned that values[-index-2].compareTo(newValue) < 0 and values[-index-1] > 0 (making sure those array accesses are in bounds)?\n\n{quote}\n> (I dont remember off hand why subord has to start at 1 not 0, but i remember it didnt work otherwise)\n{quote}\n\nThis is very important -- that 1 is \"equivalent\" to the original 0.5 proposal, ie, think of subord as the 2nd digit in a 2-digit number.  That 2nd digit being non zero is how we know that even though banana's ord landed on apple's, banana is in fact *not* equal to apple (because the subord for banana is > 0) and is instead *between* apple and orange.",
            "date": "2008-12-17T10:03:38.391+0000",
            "id": 133
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> I just don't think that ords without fallback is going to get very good. I'm wondering if we should even try too hard if ord with val fallback does so well.\n{quote}\n\nMaybe we can try a bit more (I'll run perf tests on your next iteration here?) and then start wrapping things up?  Progress not perfection!  We can further improve this later.",
            "date": "2008-12-17T10:05:10.434+0000",
            "id": 134
        },
        {
            "author": "Mark Miller",
            "body": "I'm on board with whatever you think is best. \n\nI'll keep playing with ords.\n\nI spent some time last night putting in most of the rest of the cleaup/finishup that was left outside of the comparators. Theres a handful of non SortTest classes tests that still fail though, so I still have to fix those. I'll do that, give ords a little play time, and then I think the patch will be fairly close. Then we can take it in and bench on a fairly close to done version.",
            "date": "2008-12-17T14:18:11.541+0000",
            "id": 135
        },
        {
            "author": "Uwe Schindler",
            "body": "I have still one question: Why do we need the new DocCollector? Is this really needed? Would it be not OK to just add the offset before calling collect()?",
            "date": "2008-12-17T14:26:45.045+0000",
            "id": 136
        },
        {
            "author": "Mark Miller",
            "body": "bq. I have still one question: Why do we need the new DocCollector? Is this really needed? Would it be not OK to just add the offset before calling collect()?\n\nIf its not needed, lets get rid of it. We don't want to deprecate HitCollector if we don't have to. The main reason I can see that we are doing it at the moment is that the TopFieldValueDocCollector needs that hook so that it can set the next IndexReader for each Comparator. The Comparator needs it to create the fieldcaches and map ords from one reader to the next. Also, it lets us do the docBase stuff, which is nice because you add the docBase less often if done in the collector.",
            "date": "2008-12-17T14:37:10.856+0000",
            "id": 137
        },
        {
            "author": "Michael McCandless",
            "body": "\n{quote}\n> Why do we need the new DocCollector? Is this really needed? Would it be not OK to just add the offset before calling collect()?\n{quote}\n\nI'd like to allow for 'expert' cases, where the collector is told when\nwe advance to the next sequential reader and can do something at that\npoint (like our sort-by-field collector does).\n\nBut then still allow for 'normal' cases, where the collector is\nunchanged with what we have today (ie it receives the \"real\" docID).\n\nThe core collectors would use the expert API to eke out all\nperformance; external collectors can use either, but the 'normal' one\nwould be simplest (and match back compat).\n\nSo then how to \"implement\" this approach... I would actually be fine\nwith keeping HitCollector, adding a default \"setNextReader\" method,\nthat either throws UOE or (if we are strongly against exceptions)\nreturns \"false\" indicating it cannot handle sequential readers.\n\nThen when we run searches we simply check if the collector is an\n\"expert\" one (does not throw UOE or return false from setNextReader)\nand if it isn't we wrap it with DocBaseCollector (which adds the doc\nbase for every collect() call).\n",
            "date": "2008-12-17T14:37:34.940+0000",
            "id": 138
        },
        {
            "author": "Mark Miller",
            "body": "Hmmm...we had a reason for deprecating HitCollector though. At first it was to do the capability check (instance of HitCollector would be wrapped), but that didn't pan out. I think we also liked it because people got deprecation warnings though - so that they would know to implement that method for 3.0 when we would take out the wrapper.",
            "date": "2008-12-17T14:46:20.860+0000",
            "id": 139
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> so that they would know to implement that method for 3.0 when we would take out the wrapper.\n{quote}\nRight but the new insight (for me at least) is it's OK for external collectors to not code to the expert API.\n\nIe previously we wanted to force migration to the expert API, but now I think it's OK to allow normal API and expert API to exist together.",
            "date": "2008-12-17T14:50:46.377+0000",
            "id": 140
        },
        {
            "author": "Mark Miller",
            "body": "Okay, I hate the idea of leaving in the wrapper, but it is true thats too difficult of a method for HitCollector (to be required anyway).  setReader is a jump in understanding above setDocBase, which was bad enough.",
            "date": "2008-12-17T15:02:19.396+0000",
            "id": 141
        },
        {
            "author": "Mark Miller",
            "body": "Hey Mike how about this one? BooleanScorer can collect hits out of order if you force it (against the contract). I think its an issue with basedoc type stuff.\n\nActually I'll clarify that - I think its an issue with the multple reader mojo - didnt mean to put it solely on adding bases in particular yet.",
            "date": "2008-12-17T16:54:36.562+0000",
            "id": 142
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> BooleanScorer can collect hits out of order if you force it (against the contract).\n{quote}\nHmmm... right.  You mean if you pass in allowDocsOutOfOrder=true (defaults to false).\n\nI think this should not be a problem?  (Though, I really don't fully understand BooleanScorer!).  Since we are running scoring per-segment, each segment might collect its docIDs out of order, but all such docs are still within the current segment.  Then when we advance to the new segment, the collector can do something if it needs to, and then collection proceeds again on the next segment's docs, possibly out of order.  Ie, the out-of-orderness never jumps across a segment and then back again?\n\nBut this is a challenge for LUCENE-831, if we go with a primarily iterator-driven API.",
            "date": "2008-12-17T17:25:15.184+0000",
            "id": 143
        },
        {
            "author": "Mark Miller",
            "body": "I didnt think it should be a problem either, since we just push everything to one reader; But it seems to be - the only test not passing involves allowDocsOutOfOrder=true. Do the search with it true, do the same search with it false, gets 3 and 4 docs. 2 or 3 tests involving that fail. I don't have time to dig in till tonight though - thought you might shortcut me to the answer :)",
            "date": "2008-12-17T17:30:58.528+0000",
            "id": 144
        },
        {
            "author": "Doug Cutting",
            "body": "bq. I would actually be fine with keeping HitCollector, adding a default \"setNextReader\" method, that either throws UOE or (if we are strongly against exceptions) returns \"false\" indicating it cannot handle sequential readers.\n\nCould we instead add a new HitCollector subclass, that adds the setNextReader, then use 'instanceof' to decide whether to wrap or not?\n\nbq. I really don't fully understand BooleanScorer!\n\nThe original version of BooleanScorer uses a ~16k array to score windows of docs.  So it scores docs 0-16k first, then docs 16-32k, etc. For each window it iterates through all query terms and accumulates a score in table[doc%16k].  It also stores in the table a bitmask representing which terms contributed to the score.  Non-zero scores are chained in a linked list.  At the end of scoring each window it then iterates through the linked list and, if the bitmask matches the boolean constraints, collects a hit.  For boolean queries with lots of frequent terms this can be much faster, since it does not need to update a priority queue for each posting, instead performing constant-time operations per posting.  The only downside is that it results in hits being delivered out-of-order within the window, which means it cannot be nested within other scorers.  But it works well as a top-level scorer.  The new BooleanScorer2 implementation instead works by merging priority queues of postings, albeit with some clever tricks.  For example, a pure conjunction (all terms required) does not require a priority queue.  Instead it sorts the posting streams at the start, then repeatedly skips the first to to the last.  If the first ever equals the last, then there's a hit.  When some terms are required and some terms are optional, the conjunction can be evaluated first, then the optional terms can all skip to the match and be added to the score.  Thus the conjunction can reduce the number of priority queue updates for the optional terms.  Does that help any?\n",
            "date": "2008-12-17T18:07:43.184+0000",
            "id": 145
        },
        {
            "author": "Mark Miller",
            "body": "bq. Could we instead add a new HitCollector subclass, that adds the setNextReader, then use 'instanceof' to decide whether to wrap or not?\n\nWoah! Don't make me switch all that again! I've got wrist injuries here :) The reason I lost the instanceof is that we would have to deprecate the HitCollector implementations because they need to extend HitCollector. Mike seemed against deprecating those if we could get away with it, so I've since dropped that. I've already gone back and forth - whats it going to be ? Ill admit I don't like using the exception trap I am now, but I dont much like the return true/false method either...\n\n\n*Edit*\n\nAh, I see, you have a new tweak on this time. Extend HitCollector rather then HitCollector extending the new type...\n\nNice, I think this is the way to go.",
            "date": "2008-12-17T18:23:34.118+0000",
            "id": 146
        },
        {
            "author": "Doug Cutting",
            "body": "> Woah! Don't make me switch all that again!\n\nSorry, I'm just tossing out ideas.  Don't take me too seriously...\n\n> The reason I lost the instanceof is that we would have to deprecate the HitCollector implementations because they need to extend HitCollector.\n\nWould we?  I was suggesting that, if we're going to have two APIs, one expert and one non-expert, then we could make the expert API a subclass and not deprecate or otherwise alter HitCollector.  I do not like using exceptions for normal control flow.  Instanceof is better, but not ideal.  A default implementation of an expert method that returns 'false', as Mike suggested, isn't bad and might be best.  It requires neither deprecation, exceptions nor instanceof.  Would we have a subclass that overrides this that's used as a base class for optimized implementations?\n",
            "date": "2008-12-17T18:40:56.238+0000",
            "id": 147
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Would we have a subclass that overrides this that's used as a base class for optimized implementations?\n{quote}\n\nIf we do this, I don't think we need a new base class for \"expert\" collectors; they can simply subclass HitCollector & override the setNextReader method?\n\nThough one downside of this approach is the \"simple\" HitCollector API is polluted with this advanced method, and HitCollector's collect method gets different args depending on what that method returns.  It's a somewhat confusing API.\n\nI guess Id' actually prefer subclassing HitCollector (SequentialHitCollector?  AdvancedHitCollector?  SegmentedHitCollector?), adding setNextReader only to that subclass, and using instanceof to wrap HitCollector subclasses.",
            "date": "2008-12-17T18:53:44.355+0000",
            "id": 148
        },
        {
            "author": "Mark Miller",
            "body": ">> Woah! Don't make me switch all that again!\n\n>Sorry, I'm just tossing out ideas. Don't take me too seriously...\n\nSame here. If you guys have a 100 ideas, id do it 100 times. No worries. Just wrist frustration :) I misunderstood you anyways.\n\nbq. It requires neither deprecation, exceptions nor instanceof. \n\nOkay, fair points. I guess my main dislike was having to call it, see what it returns, and then maybe call it again. That turned me off as much as instanceof. I'm still liking the suggestion you just made myself...\n\nMike?",
            "date": "2008-12-17T18:54:09.001+0000",
            "id": 149
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Does that help any?\n{quote}\nYes, thanks!  So much so that I'm going to go add that blurb to the javadocs...",
            "date": "2008-12-17T18:54:34.668+0000",
            "id": 150
        },
        {
            "author": "Mark Miller",
            "body": "bq. I guess Id' actually prefer subclassing HitCollector (SequentialHitCollector? AdvancedHitCollector? SegmentedHitCollector?), adding setNextReader only to that subclass, and using instanceof to wrap HitCollector subclasses.\n\nThats actually what I prefer as well (and what I tried). I used MultiReaderHitCollector. Still thinking about the name...",
            "date": "2008-12-17T19:06:06.613+0000",
            "id": 151
        },
        {
            "author": "Michael McCandless",
            "body": "I like MultiReaderHitCollector!",
            "date": "2008-12-17T19:17:28.842+0000",
            "id": 152
        },
        {
            "author": "Mark Miller",
            "body": "{quote}Hmmm... right. You mean if you pass in allowDocsOutOfOrder=true (defaults to false).\n\nI think this should not be a problem? (Though, I really don't fully understand BooleanScorer!). Since we are running scoring per-segment, each segment might collect its docIDs out of order, but all such docs are still within the current segment. Then when we advance to the new segment, the collector can do something if it needs to, and then collection proceeds again on the next segment's docs, possibly out of order. Ie, the out-of-orderness never jumps across a segment and then back again?{quote}\n\nI was off base with my guess - its actually only using one reader for that test (3 or 4 docs). Gotto be the HitCollector that the out of order scorer uses needs to be tweaked. Last tests to fix.\n",
            "date": "2008-12-17T22:05:29.626+0000",
            "id": 153
        },
        {
            "author": "Mark Miller",
            "body": "Hmmm...working more with ints as ords rather than double...it gives us ints but it complicates things a bit. Before, the only ords that had to be sorted and suborded were ones that didn't map on the new Reader exactly. With an int ord, *everything* you add is going to collide, and you need the ords in the queue added to the double lists and you need to fall down to the subord much more often...\n\ninteresting...\n\nI guess I'll go with it for now though...",
            "date": "2008-12-17T22:37:46.295+0000",
            "id": 154
        },
        {
            "author": "Michael McCandless",
            "body": "Hang on -- if the value carries over to the new segment (and you set subord to 0) then you don't need to add those ords to the double lists?",
            "date": "2008-12-17T22:51:25.264+0000",
            "id": 155
        },
        {
            "author": "Mark Miller",
            "body": "Yeah - sorry. I actually realized that as I just finished it off, but I'm trying not too spam the dev list so much (not winning that war). But it does drop more often :) Ignore those concerns. Ill put up a patch in a minute.",
            "date": "2008-12-17T22:58:16.494+0000",
            "id": 156
        },
        {
            "author": "Mark Miller",
            "body": "This patch is entering the finishing stages I think. This one is pretty much functionally complete and all tests should pass.\n\nThere is still a bunch of polish to be done though.\n\nThere are still the following sort types: SortField.STRING_VAL, STRING_ORD, STRING_ORD_VAL, and STRING is currently set to straight ord.\n\nI think the ord case is still pretty slow, I'm sure there are still a few optimizations left, but it would be nice to see where its at.\n\nThere is still an issue with custom FieldComparators - they are currently passed the top level reader in the hook - this still needs to be addressed somehow. We also need a test for one.\n\n- Mark\n\n(ignore the couple setDocBases you see in contrib - ive got em)",
            "date": "2008-12-17T23:17:47.483+0000",
            "id": 157
        },
        {
            "author": "Mark Miller",
            "body": "bq. Hang on - if the value carries over to the new segment (and you set subord to 0) then you don't need to add those ords to the double lists? \n\nWhat was actually happening: I noticed it wasn't quite working right after switching ords to ints from double, and I realized the problem was that there was always going to be a collision for the sort list, whereas before, there was only a sortable collision when more than one mapped-from ord collided. So I thought that out wrong and figured you needed to sort the current ord as well, but in fact, of course you don't: I just needed to assume there is always a collision that adds to the sort list, not wait for 2 mapped-from ords to collide.",
            "date": "2008-12-17T23:48:06.939+0000",
            "id": 158
        },
        {
            "author": "Michael McCandless",
            "body": "Patch is looking good!  All tests, and back-compat tests, pass.  I'm\ngoing to run a round of perf tests...\n\nSome minor things I noticed:\n\n  * Fix indent on FieldComparatorSource.java to 2 spaces\n\n  * Leftover \"check val\" print in FieldComparator.java\n\n  * Do we need to track maxScore in TopFieldValueDocCollector (but\n    mark as deprecated)?  (Because Hits isn't removed yet).\n\n  * Got some \"nocommit\" comments to resolve still\n\n  * I think StringComparatorLocale should call FieldCache.getStrings\n   (as it does on trunk now when you do String sort w/ Locale), not\n   getStringIndex.  Then the queue should just hold the String[]\n   values, not StringIndex[]?\n.\n   (Aside: we could fix StringIndex computation to take a Locale,\n   which'd give better performance, but that's a separate issue).\n\n  * I think you can improve the ord fallback comparator a bit, by\n    keeping separate \"equals\" array that's just like subord but is\n    instead a boolean.  Equals is true when the ord is present in the\n    new segment and false if the string could not be found in the new\n    segment.  Then only fallback to String.compareTo when equals is\n    false.  I think this is important for enum fields because the two\n    segments will not have the same String object when they are equal.\n",
            "date": "2008-12-18T12:01:18.419+0000",
            "id": 159
        },
        {
            "author": "Mark Miller",
            "body": "bq. Fix indent on FieldComparatorSource.java to 2 spaces\n\nRoger.\n\nbq. Leftover \"check val\" print in FieldComparator.java\n\nI'll be sure to get all of this...i also have a ton of System.outs commented out that I'll remove.\n\nbq. Do we need to track maxScore in TopFieldValueDocCollector (but mark as deprecated)? (Because Hits isn't removed yet).\n\nYou know it.\n\nbq. Got some \"nocommit\" comments to resolve still\n\nRight - time to start looking at these, names, and design changes that might make sense I think.\n\nbq. I think StringComparatorLocale should call FieldCache.getStrings (as it does on trunk now when you do String sort w/ Locale), not getStringIndex. Then the queue should just hold the String[] values, not StringIndex[]?\n\nI swear I looked at trunk twice and saw it was using a StringIndex - just looked again ands its not. I love that.\n\nbq. I think you can improve the ord fallback comparator a bit...\n\nLets see if its in even in the ballpark yet...if it is, ill tweak it all we can.\n\n\n\n",
            "date": "2008-12-18T13:12:25.204+0000",
            "id": 160
        },
        {
            "author": "Michael McCandless",
            "body": "One question: do you think we should provide a simple \"legacy fallback\" option, deprecated, so that in case we messed something up here, people can force the sort to use the current approach?  We already have automatic \"legacy\" computation (if the old CUSTOM sort is in use) but we could eg add a deprecated \"setLegacy\" to SortField or some such?  As an insurance policy...",
            "date": "2008-12-18T13:20:14.277+0000",
            "id": 161
        },
        {
            "author": "Mark Miller",
            "body": "Yeah, that seems like a great idea. Will help debugging a lot if someone reports an oddity...",
            "date": "2008-12-18T13:30:16.441+0000",
            "id": 162
        },
        {
            "author": "Mark Miller",
            "body": "How about names?\n\n TopFieldValueDocCollector\n\nI'm not digging this one at the moment. I didn't dig TopFieldDocCollector either though. TopDocCollector makes sense, but shouldnt these be more like TopFieldSortedDocCollector or something?\n\nByValueFieldSortedHitQueue\n\nHow about maybe FieldValueSortedHitQueue?",
            "date": "2008-12-18T13:42:21.918+0000",
            "id": 163
        },
        {
            "author": "Michael McCandless",
            "body": "How about ByValueFieldSortedHitQueue --> FieldValueHitQueue (the \"sorted\" seems redundant?)\n\nHow about TopFieldValueDocCollector --> TopFieldCollector (I actually don't mind the current name TopFieldDocCollector, but, we can't use that name, so I dropped the Doc part).\n\n",
            "date": "2008-12-18T14:08:09.516+0000",
            "id": 164
        },
        {
            "author": "Mark Miller",
            "body": "bq. How about ByValueFieldSortedHitQueue --> FieldValueHitQueue (the \"sorted\" seems redundant?) \n\nFair enough, and shorter is better.\n\nbq. How about TopFieldValueDocCollector --> TopFieldCollector (I actually don't mind the current name TopFieldDocCollector, but, we can't use that name, so I dropped the Doc part).\n\nOkay...shorter better again, so agreed. I find TopFieldDocCollector confusing myself - I'd rather it be easier to know, this sorts by relevance, this sorts by field value, and those names don't say that to a non lucene user (or more fairly, they didn't say that to me). I think, what the heck is a FieldDoc? Moot point though, I agree with both suggestions.\n\n*edit*\n\nHmm...I guess that its not just fields, but also doc id and relevance if you want, that complicates things for that name...I guess in that way I also prefer TopFieldDocCollector over TopFieldCollector - ah well. ",
            "date": "2008-12-18T14:20:02.566+0000",
            "id": 165
        },
        {
            "author": "Michael McCandless",
            "body": "Can you change DocComparator to just return doc1-doc2?  (instead of having if that translates that into -1/1)?  I think that eeks performance.  (And we should fix javadoc saying \"any neg number\" and \"any pos number\" is OK; oh I see a nocommit asking for that already).",
            "date": "2008-12-18T14:50:32.105+0000",
            "id": 166
        },
        {
            "author": "Mark Miller",
            "body": "DocComparator? Its not doing the if's...\n\nDo you mean relevance? That doesn't work right when you can have negatives does it? This is what I have for Doc (I don't think I've touched it from what you did):\n\n{code}\n  public static final class DocComparator extends FieldComparator {\n\n    // nocommit -- maybe \"setcurrentscoredoc\"?\n\n    private final int[] docIDs;\n    private int docBase;\n    private int readerMaxDoc;\n\n    DocComparator(int numHits) {\n      docIDs = new int[numHits];\n    }\n\n    public int compare(int slot1, int slot2) {\n      return docIDs[slot1] - docIDs[slot2];\n    }\n\n    public int compare(int slot, int doc, float score) {\n      return docIDs[slot] - docBase - doc;\n    }\n\n    public void copy(int slot, int doc, float score) {\n      docIDs[slot] = docBase + doc;\n    }\n\n    public void setNextReader(IndexReader reader) {\n      // TODO: can we \"map\" our docIDs to the current\n      // reader? saves having to then subtract on every\n      // compare call\n      docBase += readerMaxDoc;\n      readerMaxDoc = reader.maxDoc();\n    }\n\n    public int sortType() {\n      return SortField.DOC;\n    }\n\n    public Comparable value(int slot) {\n      return new Integer(docIDs[slot]);\n    }\n  };\n{code}",
            "date": "2008-12-18T14:58:55.059+0000",
            "id": 167
        },
        {
            "author": "Michael McCandless",
            "body": "Woops, you're right, sorry, I was looking at an old version...",
            "date": "2008-12-18T15:04:18.166+0000",
            "id": 168
        },
        {
            "author": "Mark Miller",
            "body": "I left a doubled set in the ords comparator thats no longer needed. We can just use map.values() instead. I'm sure there are small win tricks we can do too - if its anywhere near competitive.",
            "date": "2008-12-18T15:16:35.464+0000",
            "id": 169
        },
        {
            "author": "Mark Miller",
            "body": "A slightly improved setNextReader for the ords case:\n\n{code}\n   public void setNextReader(IndexReader reader) throws IOException {\n      \n      // Map ords in queue to ords in reader\n      \n      StringIndex currentReaderValues = ExtendedFieldCache.EXT_DEFAULT\n          .getStringIndex(reader, field);\n      \n      lookup = currentReaderValues.lookup;\n      order = currentReaderValues.order;\n\n      if (lookup.length == 0) {\n        return;\n      }\n      \n//      for (int i = 0; i < lookup.length; i++) {\n//        System.out.println(\"i:\" + i + \" \" + lookup[i]);\n//      }\n\n      Map map = new HashMap();\n      for (int i = 0; i < slot + 1; i++) {\n        String val = values[i];\n        if (val == null) {\n          continue;\n        }\n\n        int index = binarySearch(lookup, val);\n\n        if (index < 0) {\n          int ord = -index - 2;\n          Integer intOrd = Integer.valueOf(ord);\n          List slotVals = (List) map.get(intOrd);\n          if (slotVals == null) {\n            slotVals = new ArrayList();\n            slotVals.add(new SlotValPair(i, val));\n            map.put(intOrd, slotVals);\n          } else {\n            slotVals.add(new SlotValPair(i, val));\n          }\n\n          ords[i] = ord;\n        } else {\n          ords[i] = index;\n          subords[i] = 0;\n        }\n      }\n\n      Iterator dit = map.values().iterator();\n      while (dit.hasNext()) {\n        List list = (List) dit.next();\n        if (list.size() > 1) {\n          Collections.sort(list);\n\n          for (int i = 0; i < list.size(); i++) {\n            SlotValPair svp = (SlotValPair) list.get(i);\n            subords[svp.i] = i+1;\n          }\n        } else {\n          SlotValPair svp = (SlotValPair) list.get(0);\n          subords[svp.i] = 1;\n        }\n      }\n\n    }\n{code}",
            "date": "2008-12-18T15:44:49.949+0000",
            "id": 170
        },
        {
            "author": "Michael McCandless",
            "body": "\nOK I ran a bunch of sort perf tests, on trunk & with the patch.\n(Attached the two Python sources for doing this... though they require\nsome small local mods to run properly).\n\nEach alg is run with \"java -Xms1024M -Xmx1024M -Xbatch -server\" on OS\nX 10.5.5, java 1.6.0_07-b06-153.\n\nI use two indexes, each with 2M docs.  One is docs from Wikipedia\n(labeled \"wiki\"), the other is SortableSimpleDocMaker docs augmented\nto include a random country field (labeled \"simple\").  For each I\ncreated 1-segment, 10-segment and 100-segment indices.  I sort by\nscore, doc, string (val, ord = true ord+subord, ordval = ord +\nfallback).  Queue size is 10.\n\nI ran various queries... query \"147\" hits ~5k docs, query \"text\" hits\n~97K docs, query \"1\" hits 386K docs and alldocs query hits 2M docs.  qps\nis queries per sec and warm is time for first warmup query, from\ntrunk.  qpsnew & warmnew are with patch.  pctg shows % gain in\nqps performance:\n\n||numSeg||index||sortBy||query||topN||meth||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|wiki|score|147|10| |   4984|   0.2|5717.6|   0.2|5627.5| -1.6%|\n|1|wiki|score|text|10| |  97191|   0.3| 340.9|   0.3| 348.8|  2.3%|\n|1|wiki|score|1|10| | 386435|   0.3|  86.7|   0.3|  89.3|  3.0%|\n|1|wiki|doc|147|10| |   4984|   0.3|4071.7|   0.3|4649.0| 14.2%|\n|1|wiki|doc|text|10| |  97191|   0.3| 225.4|   0.3| 253.7| 12.6%|\n|1|wiki|doc|1|10| | 386435|   0.3|  56.9|   0.3|  65.8| 15.6%|\n|1|wiki|doc|<all>|10| |2000000|   0.1|  23.0|   0.1|  38.6| 67.8%|\n|1|simple|int|text|10| |2000000|   0.7|  10.7|   0.7|  13.5| 26.2%|\n|1|simple|int|<all>|10| |2000000|   0.6|  21.1|   0.6|  34.7| 64.5%|\n|1|simple|country|text|10|ord|2000000|   0.6|  10.7|   0.6|  13.2| 23.4%|\n|1|simple|country|text|10|ordval|2000000|   0.6|  10.7|   0.6|  13.3| 24.3%|\n|1|simple|country|<all>|10|ord|2000000|   0.5|  20.7|   0.6|  32.5| 57.0%|\n|1|simple|country|<all>|10|ordval|2000000|   0.5|  20.7|   0.6|  34.6| 67.1%|\n|1|wiki|title|147|10|ord|   4984|   2.1|3743.8|   2.0|4210.5| 12.5%|\n|1|wiki|title|147|10|ordval|   4984|   2.1|3743.8|   2.0|4288.2| 14.5%|\n|1|wiki|title|text|10|ord|  97191|   2.1| 144.2|   2.1| 160.3| 11.2%|\n|1|wiki|title|text|10|ordval|  97191|   2.1| 144.2|   2.1| 163.5| 13.4%|\n|1|wiki|title|1|10|ord| 386435|   2.1|  51.2|   2.1|  63.2| 23.4%|\n|1|wiki|title|1|10|ordval| 386435|   2.1|  51.2|   2.1|  64.6| 26.2%|\n|1|wiki|title|<all>|10|ord|2000000|   2.1|  21.1|   2.1|  33.2| 57.3%|\n|1|wiki|title|<all>|10|ordval|2000000|   2.1|  21.1|   2.1|  35.4| 67.8%|\n||numSeg||index||sortBy||query||topN||meth||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|wiki|score|147|10| |   4984|   0.3|4228.3|   0.3|4510.6|  6.7%|\n|10|wiki|score|text|10| |  97191|   0.3| 294.7|   0.3| 341.5| 15.9%|\n|10|wiki|score|1|10| | 386435|   0.4|  75.0|   0.4|  87.0| 16.0%|\n|10|wiki|doc|147|10| |   4984|   0.3|3332.2|   0.3|4033.9| 21.1%|\n|10|wiki|doc|text|10| |  97191|   0.4| 217.0|   0.4| 277.0| 27.6%|\n|10|wiki|doc|1|10| | 386435|   0.4|  54.6|   0.4|  70.5| 29.1%|\n|10|wiki|doc|<all>|10| |2000000|   0.1|  12.7|   0.1|  38.6|203.9%|\n|10|simple|int|text|10| |2000000|   1.2|  10.3|   0.6|  13.5| 31.1%|\n|10|simple|int|<all>|10| |2000000|   1.1|  11.8|   0.8|  34.6|193.2%|\n|10|simple|country|text|10|ord|2000000|   0.7|  10.4|   0.5|  13.2| 26.9%|\n|10|simple|country|text|10|ordval|2000000|   0.7|  10.4|   0.5|  13.3| 27.9%|\n|10|simple|country|<all>|10|ord|2000000|   0.7|  11.5|   0.5|  32.5|182.6%|\n|10|simple|country|<all>|10|ordval|2000000|   0.7|  11.5|   0.5|  34.1|196.5%|\n|10|wiki|title|147|10|ord|   4984|  12.5|3004.5|   2.1|3124.0|  4.0%|\n|10|wiki|title|147|10|ordval|   4984|  12.5|3004.5|   2.1|3353.5| 11.6%|\n|10|wiki|title|text|10|ord|  97191|  12.7| 139.4|   2.1| 156.7| 12.4%|\n|10|wiki|title|text|10|ordval|  97191|  12.7| 139.4|   2.1| 160.9| 15.4%|\n|10|wiki|title|1|10|ord| 386435|  12.7|  50.3|   2.1|  62.3| 23.9%|\n|10|wiki|title|1|10|ordval| 386435|  12.7|  50.3|   2.1|  64.1| 27.4%|\n|10|wiki|title|<all>|10|ord|2000000|  12.7|  11.4|   2.1|  33.1|190.4%|\n|10|wiki|title|<all>|10|ordval|2000000|  12.7|  11.4|   2.1|  35.3|209.6%|\n||numSeg||index||sortBy||query||topN||meth||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|wiki|score|147|10| |   4984|   0.3|1282.2|   1.7|1162.3| -9.4%|\n|100|wiki|score|text|10| |  97191|   0.4| 232.4|   1.3| 275.6| 18.6%|\n|100|wiki|score|1|10| | 386435|   0.4|  65.1|   1.4|  80.4| 23.5%|\n|100|wiki|doc|147|10| |   4984|   0.4|1170.0|   0.4|1132.0| -3.2%|\n|100|wiki|doc|text|10| |  97191|   0.4| 171.7|   0.4| 230.1| 34.0%|\n|100|wiki|doc|1|10| | 386435|   0.4|  46.7|   0.4|  67.9| 45.4%|\n|100|wiki|doc|<all>|10| |2000000|   0.2|   7.8|   0.1|  41.6|433.3%|\n|100|simple|int|text|10| |2000000|   3.3|   8.9|   4.0|  11.0| 23.6%|\n|100|simple|int|<all>|10| |2000000|   3.4|   7.7|   1.1|  36.5|374.0%|\n|100|simple|country|text|10|ord|2000000|   1.0|   8.8|   0.6|  10.8| 22.7%|\n|100|simple|country|text|10|ordval|2000000|   1.0|   8.8|   0.6|  11.0| 25.0%|\n|100|simple|country|<all>|10|ord|2000000|   1.0|   7.6|   0.5|  35.0|360.5%|\n|100|simple|country|<all>|10|ordval|2000000|   1.0|   7.6|   0.5|  36.3|377.6%|\n|100|wiki|title|147|10|ord|   4984|  94.6|1066.9|   2.1| 583.7|-45.3%|\n|100|wiki|title|147|10|ordval|   4984|  94.6|1066.9|   2.1| 750.1|-29.7%|\n|100|wiki|title|text|10|ord|  97191|  94.9| 110.2|   2.1| 122.7| 11.3%|\n|100|wiki|title|text|10|ordval|  97191|  94.9| 110.2|   2.1| 128.4| 16.5%|\n|100|wiki|title|1|10|ord| 386435|  94.3|  47.9|   2.1|  58.2| 21.5%|\n|100|wiki|title|1|10|ordval| 386435|  94.3|  47.9|   2.1|  60.1| 25.5%|\n|100|wiki|title|<all>|10|ord|2000000|  94.6|   7.8|   2.5|  35.6|356.4%|\n|100|wiki|title|<all>|10|ordval|2000000|  94.6|   7.8|   2.4|  37.0|374.4%|\n\nIt's a ridiculous amount of of data to digest... but here are some\ninitial thoughts:\n\n  * These are only single term queries; I'd expect for multi term\n    queries the gain would be less since net/net less %tg of the time\n    is spent collecting.\n\n  * Ord + val fallback (ordval) is generally faster than pure\n    ord/subord.  I think for now we should run with ord + val\n    fallback?  (We can leave ord + subord commented out?).\n\n  * It's great that we see decent speedups for \"sort by score\" which\n    is presumably the most common sort used.\n\n  * We do get slower in certain cases (neg pctg in the rightmost\n    column): all not-in-the-noise slowdowns were with query \"147\" on\n    the 100 segment index.  This query hits relatively few docs (~5K)\n    So, this is expected, because the new approach spends some time\n    updating its queue for each subreader.  If the time spent\n    searching is relatively tiny then this queue update time becomes\n    relatively big.  I think with larger queue size the slowdown will\n    be worse.  However, I think this is an acceptable tradeoff.\n\n  * The gains for field sorting on a single segment (optimized) index\n    are impressive.  Generally, the more hits encountered the better\n    the gains.  It's amazing that we see ~67.8% gain sorting by docID,\n    country, and title for alldocs query.  My only guess for this is\n    better cache hit rate (because we gain locality by copying values\n    to local compact arrays).\n\n  * Across the board the alldocs query shows very sizable (5X faster\n    for 100 segment index; 3X faster for 10 segment index)\n    improvements.\n\n  * I didn't break out %tg difference, but warming time with the patch\n    is waaaay faster than trunk when index has > 1 segment.  Reopen\n    time should also be fantastically faster (we are sidestepping\n    something silly happing w/ FieldCache on a Multi*Reader).  Warming\n    on trunk takes ~95 seconds with the 100 segment index!\n",
            "date": "2008-12-18T19:43:11.030+0000",
            "id": 171
        },
        {
            "author": "Mark Miller",
            "body": "Awesome results Mike, thanks! You are a wizard.",
            "date": "2008-12-18T20:28:19.532+0000",
            "id": 172
        },
        {
            "author": "Michael McCandless",
            "body": "I set the queue size to 1000 and reran the tests:\n\n||numSeg||index||sortBy||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|wiki|score|147|1000|   4984|   0.3|1356.8|   0.3|1361.3|  0.3%|\n|1|wiki|score|text|1000|  97191|   0.3| 224.0|   0.3| 223.0| -0.4%|\n|1|wiki|score|1|1000| 386435|   0.3|  73.6|   0.3|  72.8| -1.1%|\n|1|wiki|doc|147|1000|   4984|   0.3|1527.0|   0.3|1475.0| -3.4%|\n|1|wiki|doc|text|1000|  97191|   0.3| 182.5|   0.3| 235.4| 29.0%|\n|1|wiki|doc|1|1000| 386435|   0.3|  50.6|   0.3|  67.7| 33.8%|\n|1|wiki|doc|<all>|1000|2000000|   0.1|  22.1|   0.1|  37.8| 71.0%|\n|1|simple|int|text|1000|2000000|   0.7|  10.1|   0.7|  12.8| 26.7%|\n|1|simple|int|<all>|1000|2000000|   0.6|  19.0|   0.6|  30.5| 60.5%|\n|1|simple|country|text|1000|2000000|   0.9|  10.1|   0.7|  12.5| 23.8%|\n|1|simple|country|<all>|1000|2000000|   0.9|  19.5|   0.6|  29.1| 49.2%|\n|1|wiki|title|147|1000|   4984|   4.0| 733.1|   2.0| 732.2| -0.1%|\n|1|wiki|title|text|1000|  97191|   4.1| 109.1|   2.1| 114.7|  5.1%|\n|1|wiki|title|1|1000| 386435|   4.1|  47.1|   2.1|  55.4| 17.6%|\n|1|wiki|title|<all>|1000|2000000|   4.1|  19.4|   2.1|  30.5| 57.2%|\n||numSeg||index||sortBy||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|wiki|score|147|1000|   4984|   0.3|1259.4|   0.3|1274.0|  1.2%|\n|10|wiki|score|text|1000|  97191|   0.4| 215.2|   0.4| 220.0|  2.2%|\n|10|wiki|score|1|1000| 386435|   0.4|  69.6|   0.4|  72.0|  3.4%|\n|10|wiki|doc|147|1000|   4984|   0.3|1409.0|   0.3|1394.7| -1.0%|\n|10|wiki|doc|text|1000|  97191|   0.4| 192.0|   0.4| 232.5| 21.1%|\n|10|wiki|doc|1|1000| 386435|   0.4|  53.0|   0.4|  66.3| 25.1%|\n|10|wiki|doc|<all>|1000|2000000|   0.1|  11.9|   0.1|  37.5|215.1%|\n|10|simple|int|text|1000|2000000|   1.2|   9.8|   0.6|  12.8| 30.6%|\n|10|simple|int|<all>|1000|2000000|   1.2|  11.0|   0.8|  30.2|174.5%|\n|10|simple|country|text|1000|2000000|   1.1|   9.8|   0.6|  12.4| 26.5%|\n|10|simple|country|<all>|1000|2000000|   1.1|  11.0|   0.5|  29.1|164.5%|\n|10|wiki|title|147|1000|   4984|  26.0| 655.2|   2.1|  84.7|-87.1%|\n|10|wiki|title|text|1000|  97191|  26.3| 100.4|   2.2|  77.8|-22.5%|\n|10|wiki|title|1|1000| 386435|  26.0|  42.3|   2.6|  48.4| 14.4%|\n|10|wiki|title|<all>|1000|2000000|  26.1|  10.9|   2.6|  28.5|161.5%|\n||numSeg||index||sortBy||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|wiki|score|147|1000|   4984|   0.4| 704.1|   0.5| 677.5| -3.8%|\n|100|wiki|score|text|1000|  97191|   0.4| 169.5|   0.5| 186.0|  9.7%|\n|100|wiki|score|1|1000| 386435|   0.4|  56.5|   0.5|  67.9| 20.2%|\n|100|wiki|doc|147|1000|   4984|   0.4| 785.0|   0.4| 724.0| -7.8%|\n|100|wiki|doc|text|1000|  97191|   0.4| 159.9|   0.4| 204.7| 28.0%|\n|100|wiki|doc|1|1000| 386435|   0.4|  44.9|   0.4|  64.8| 44.3%|\n|100|wiki|doc|<all>|1000|2000000|   0.2|   7.8|   0.1|  40.4|417.9%|\n|100|simple|int|text|1000|2000000|   3.3|   8.4|   1.4|  10.3| 22.6%|\n|100|simple|int|<all>|1000|2000000|   3.4|   7.4|   1.1|  32.4|337.8%|\n|100|simple|country|text|1000|2000000|   1.4|   8.6|   0.7|  10.0| 16.3%|\n|100|simple|country|<all>|1000|2000000|   1.5|   7.3|   0.6|  28.6|291.8%|\n|100|wiki|title|147|1000|   4984| 189.0| 446.3|   2.4|  19.8|-95.6%|\n|100|wiki|title|text|1000|  97191| 188.5|  87.7|   2.3|  27.5|-68.6%|\n|100|wiki|title|1|1000| 386435| 190.4|  41.1|   2.7|  24.6|-40.1%|\n|100|wiki|title|<all>|1000|2000000| 189.2|   7.4|   3.0|  18.4|148.6%|\n\nPerformance clearly gets worse for queries not hitting many docs, and\nwith a large queue, against an index with a large number of\nsegments, and sorting by a unique String field (like title).\n\nThe slowdown for \"147\" at 100 segments is quite bad.\n\nSo... I wonder how often users of Lucene set a very large queue size\n(to do some sort of post filtering, which could be more efficiently\ndone as a real Filter, but...).  I think it may a non-trivial number,\nso... what to do?\n\nEG we could offer a different collector that's better optimized\ntowards collecting a large topN (probably doing the toplevel\nFieldCache that's done today)?  Or, we could explore a hybrid approach\nwhereby a slot is only switched to the current segment when it's first\nvisited again (instead of updating all of them on switching readers)?\nOr... something else?",
            "date": "2008-12-18T21:53:17.648+0000",
            "id": 173
        },
        {
            "author": "Michael McCandless",
            "body": "One more small thing: StringOrdValComparator.compare uses double ord1 and double ord2 when comparing 2 slots, but in fact they should just be ints?",
            "date": "2008-12-19T13:24:20.313+0000",
            "id": 174
        },
        {
            "author": "Mark Miller",
            "body": "Yeah, wow. I've actually fixed that (though I didn't notice doing so). I've made a half dozen little tweaks trying to eek out some speed and maybe trigger some ideas. Nothing thats made much of a difference yet. We can subtract instead of compare and other tiny in the noise stuff - hoping I trigger a bigger idea though.",
            "date": "2008-12-19T13:36:11.253+0000",
            "id": 175
        },
        {
            "author": "Michael McCandless",
            "body": "Another fix to do: in StringOrdValComparator.compare (the one that takes slot, doc, score), it does not fallback to String value comparison.",
            "date": "2008-12-19T14:42:59.299+0000",
            "id": 176
        },
        {
            "author": "Mark Miller",
            "body": "Thanks. I've got a convert on demand version to give a try too.",
            "date": "2008-12-19T15:06:24.461+0000",
            "id": 177
        },
        {
            "author": "Michael McCandless",
            "body": "OK wanna post a new patch w/ all these fixes?  I'll re-test, and add on-demand queue.  If perf cost of that one is still too high, we may want to offer a queue that pulls MultiReader's FieldCache values, but uses the slot-based pqueue (we would have to fix this insanely slow warm time if we do that...).  I bet for very large queue sizes that'd give the best performance, at the obvious expense of reopen cost.",
            "date": "2008-12-19T16:27:48.349+0000",
            "id": 178
        },
        {
            "author": "Mark Miller",
            "body": "Escaped back to the computer. Here is the latest. I went down a few dead ends trying to improve things, and I don't think I found anything significant.\n\nThere are the following String sort types:\n\nSortField.STRING_VAL : by value\n\nSortField.STRING_ORD: by ordinal fall back to subord\n\nSortField.STRING_ORD_VAL: by ordinal fall back to value\n\nSortField.STRING_ORD_VAL_DEM: by ordinal fall back to value, convert on demand\n\nand just for kicks:\n\nSortField.STRING_ORD_VAL_DEM_WIN: by ordinal fall back to value, convert a window of 20 in each direction of n on demand\n\nSortField.STRING is set to STRING_ORD_VAL",
            "date": "2008-12-21T15:36:23.356+0000",
            "id": 179
        },
        {
            "author": "Mark Miller",
            "body": "Again with the two $id issues fixed.",
            "date": "2008-12-21T15:40:42.577+0000",
            "id": 180
        },
        {
            "author": "Mark Miller",
            "body": "Was just thinking about the window convert (which I doubt is worth considering anyway) - I wouldnt bench it...I forgot to make it check for conversion as its working on the window. It just checks the window pivot point. Creates lots of extra work.",
            "date": "2008-12-21T21:13:35.929+0000",
            "id": 181
        },
        {
            "author": "Michael McCandless",
            "body": "New patch attached:\n\n  * Made IndexWriter.getSegmentCount package protected again\n\n  * Fixed StringOrdComparator to use no doubles\n\n  * Added \"API is experimental\" warnings to the new APIs\n\n  * Deprecated FieldValueHitQueue.getMaxScore -- I think in 3.0 we\n    should remove this (with Hits)?\n\n  * Tweaked StringOrdValOnDemComparator to avoid Arrays.fill in\n    setNextReader \n\n  * Fixed FieldValueHitQueue to actually pull the right \"on demand\"\n    comparator (it was incorrectly pulling StringOrdValComparator)\n\nI re-ran perf tests:\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|1000|2000000|   0.9|  10.0|   0.8|  11.1| 11.0%|\n|1|simple|country|ord|text|1000|2000000|   0.9|  10.0|   0.7|  13.0| 30.0%|\n|1|simple|country|ordval|text|1000|2000000|   0.9|  10.0|   0.7|  12.5| 25.0%|\n|1|simple|country|orddem|text|1000|2000000|   0.9|  10.0|   0.7|  12.5| 25.0%|\n|1|wiki|title|val|147|1000|   4984|   2.1| 740.6|   2.4| 375.7|-49.3%|\n|1|wiki|title|ord|147|1000|   4984|   2.1| 740.6|   2.1| 811.7|  9.6%|\n|1|wiki|title|ordval|147|1000|   4984|   2.1| 740.6|   2.1| 806.6|  8.9%|\n|1|wiki|title|orddem|147|1000|   4984|   2.1| 740.6|   2.1| 207.6|-72.0%|\n|1|wiki|title|val|text|1000|  97191|   2.1| 108.7|   2.4|  32.5|-70.1%|\n|1|wiki|title|ord|text|1000|  97191|   2.1| 108.7|   2.1| 121.4| 11.7%|\n|1|wiki|title|ordval|text|1000|  97191|   2.1| 108.7|   2.1| 119.1|  9.6%|\n|1|wiki|title|orddem|text|1000|  97191|   2.1| 108.7|   2.1|  90.9|-16.4%|\n|1|wiki|title|val|1|1000| 386435|   2.1|  46.2|   2.4|  12.8|-72.3%|\n|1|wiki|title|ord|1|1000| 386435|   2.1|  46.2|   2.1|  58.6| 26.8%|\n|1|wiki|title|ordval|1|1000| 386435|   2.1|  46.2|   2.1|  55.7| 20.6%|\n|1|wiki|title|orddem|1|1000| 386435|   2.1|  46.2|   2.1|  50.1|  8.4%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|1000|2000000|   0.8|   9.7|   0.7|  11.0| 13.4%|\n|10|simple|country|ord|text|1000|2000000|   0.8|   9.7|   0.6|  13.0| 34.0%|\n|10|simple|country|ordval|text|1000|2000000|   0.8|   9.7|   0.6|  12.4| 27.8%|\n|10|simple|country|orddem|text|1000|2000000|   0.8|   9.7|   0.6|  12.5| 28.9%|\n|10|wiki|title|val|147|1000|   4984|  12.7| 664.2|   2.5| 383.8|-42.2%|\n|10|wiki|title|ord|147|1000|   4984|  12.7| 664.2|   2.1|  86.2|-87.0%|\n|10|wiki|title|ordval|147|1000|   4984|  12.7| 664.2|   2.1| 104.0|-84.3%|\n|10|wiki|title|orddem|147|1000|   4984|  12.7| 664.2|   2.1|  77.0|-88.4%|\n|10|wiki|title|val|text|1000|  97191|  12.6| 100.4|   2.4|  33.3|-66.8%|\n|10|wiki|title|ord|text|1000|  97191|  12.6| 100.4|   2.2|  80.0|-20.3%|\n|10|wiki|title|ordval|text|1000|  97191|  12.6| 100.4|   2.2|  90.3|-10.1%|\n|10|wiki|title|orddem|text|1000|  97191|  12.6| 100.4|   2.1|  72.1|-28.2%|\n|10|wiki|title|val|1|1000| 386435|  12.7|  42.4|   2.5|  14.7|-65.3%|\n|10|wiki|title|ord|1|1000| 386435|  12.7|  42.4|   2.6|  50.2| 18.4%|\n|10|wiki|title|ordval|1|1000| 386435|  12.7|  42.4|   2.2|  51.3| 21.0%|\n|10|wiki|title|orddem|1|1000| 386435|  12.7|  42.4|   2.2|  47.3| 11.6%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|simple|country|val|text|1000|2000000|   1.0|   8.5|   2.1|   9.2|  8.2%|\n|100|simple|country|ord|text|1000|2000000|   1.0|   8.5|   0.6|  10.7| 25.9%|\n|100|simple|country|ordval|text|1000|2000000|   1.0|   8.5|   0.6|  10.3| 21.2%|\n|100|simple|country|orddem|text|1000|2000000|   1.0|   8.5|   0.6|  10.2| 20.0%|\n|100|wiki|title|val|147|1000|   4984|  93.8| 442.8|   3.6| 238.8|-46.1%|\n|100|wiki|title|ord|147|1000|   4984|  93.8| 442.8|   2.3|  19.9|-95.5%|\n|100|wiki|title|ordval|147|1000|   4984|  93.8| 442.8|   2.2|  28.0|-93.7%|\n|100|wiki|title|orddem|147|1000|   4984|  93.8| 442.8|   2.2|  54.1|-87.8%|\n|100|wiki|title|val|text|1000|  97191|  93.4|  88.0|   3.1|  33.1|-62.4%|\n|100|wiki|title|ord|text|1000|  97191|  93.4|  88.0|   2.3|  27.8|-68.4%|\n|100|wiki|title|ordval|text|1000|  97191|  93.4|  88.0|   2.2|  40.9|-53.5%|\n|100|wiki|title|orddem|text|1000|  97191|  93.4|  88.0|   2.2|  53.3|-39.4%|\n|100|wiki|title|val|1|1000| 386435|  92.8|  41.0|   3.2|  14.7|-64.1%|\n|100|wiki|title|ord|1|1000| 386435|  92.8|  41.0|   2.7|  25.3|-38.3%|\n|100|wiki|title|ordval|1|1000| 386435|  92.8|  41.0|   2.2|  33.8|-17.6%|\n|100|wiki|title|orddem|1|1000| 386435|  92.8|  41.0|   2.2|  42.7|  4.1%|\n  \nHaven't digested these results yet...\n",
            "date": "2008-12-22T20:46:01.015+0000",
            "id": 182
        },
        {
            "author": "Michael McCandless",
            "body": "Sorry, disregard those results above... I think there's a bug in the on-demand comparator.",
            "date": "2008-12-22T21:06:22.980+0000",
            "id": 183
        },
        {
            "author": "Michael McCandless",
            "body": "\nOK new patch attached:\n\n  * Fixed the bug (I had added) in StringOrdValOnDemComparator that\n    was doing too much work on first segment (especially skewed\n    1-segment index results).\n\n  * Removed \"this.slot = slot\" from StringOrdComparator,\n    StringOrdValComparator and StringOrdValOnDemWinComparator.  I\n    think this was a bug that was causing setNextReader to not convert\n    enough of the queue in my tests.  Unfortunately, this makes\n    performance worse for these classes.\n\n  * Tweaked null checks for string values to be tiny bit faster if there\n     are nulls.\n\nNew benchmark results for topN=1000;\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|1000|2000000|   0.9|  10.0|   0.7|  11.1| 11.0%|\n|1|simple|country|ord|text|1000|2000000|   0.9|  10.0|   0.7|  13.3| 33.0%|\n|1|simple|country|ordval|text|1000|2000000|   0.9|  10.0|   0.7|  12.7| 27.0%|\n|1|simple|country|orddem|text|1000|2000000|   0.9|  10.0|   0.6|  12.5| 25.0%|\n|1|wiki|title|val|147|1000|   4984|   2.1| 740.6|   2.3| 369.3|-50.1%|\n|1|wiki|title|ord|147|1000|   4984|   2.1| 740.6|   2.1| 808.1|  9.1%|\n|1|wiki|title|ordval|147|1000|   4984|   2.1| 740.6|   2.0| 815.7| 10.1%|\n|1|wiki|title|orddem|147|1000|   4984|   2.1| 740.6|   2.1| 731.7| -1.2%|\n|1|wiki|title|val|text|1000|  97191|   2.1| 108.7|   2.4|  32.6|-70.0%|\n|1|wiki|title|ord|text|1000|  97191|   2.1| 108.7|   2.1| 121.1| 11.4%|\n|1|wiki|title|ordval|text|1000|  97191|   2.1| 108.7|   2.1| 119.0|  9.5%|\n|1|wiki|title|orddem|text|1000|  97191|   2.1| 108.7|   2.1| 114.8|  5.6%|\n|1|wiki|title|val|1|1000| 386435|   2.1|  46.2|   2.4|  12.7|-72.5%|\n|1|wiki|title|ord|1|1000| 386435|   2.1|  46.2|   2.1|  58.5| 26.6%|\n|1|wiki|title|ordval|1|1000| 386435|   2.1|  46.2|   2.1|  56.7| 22.7%|\n|1|wiki|title|orddem|1|1000| 386435|   2.1|  46.2|   2.1|  55.2| 19.5%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|1000|2000000|   0.8|   9.7|   0.6|  11.0| 13.4%|\n|10|simple|country|ord|text|1000|2000000|   0.8|   9.7|   0.6|  13.1| 35.1%|\n|10|simple|country|ordval|text|1000|2000000|   0.8|   9.7|   0.6|  12.5| 28.9%|\n|10|simple|country|orddem|text|1000|2000000|   0.8|   9.7|   0.6|  12.5| 28.9%|\n|10|wiki|title|val|147|1000|   4984|  12.7| 664.2|   2.4| 382.9|-42.4%|\n|10|wiki|title|ord|147|1000|   4984|  12.7| 664.2|   2.2|  57.9|-91.3%|\n|10|wiki|title|ordval|147|1000|   4984|  12.7| 664.2|   2.1|  71.5|-89.2%|\n|10|wiki|title|orddem|147|1000|   4984|  12.7| 664.2|   2.1|  91.1|-86.3%|\n|10|wiki|title|val|text|1000|  97191|  12.6| 100.4|   2.4|  33.4|-66.7%|\n|10|wiki|title|ord|text|1000|  97191|  12.6| 100.4|   2.2|  62.9|-37.4%|\n|10|wiki|title|ordval|text|1000|  97191|  12.6| 100.4|   2.2|  75.9|-24.4%|\n|10|wiki|title|orddem|text|1000|  97191|  12.6| 100.4|   2.2|  79.6|-20.7%|\n|10|wiki|title|val|1|1000| 386435|  12.7|  42.4|   2.4|  14.7|-65.3%|\n|10|wiki|title|ord|1|1000| 386435|  12.7|  42.4|   2.7|  45.2|  6.6%|\n|10|wiki|title|ordval|1|1000| 386435|  12.7|  42.4|   2.1|  48.5| 14.4%|\n|10|wiki|title|orddem|1|1000| 386435|  12.7|  42.4|   2.2|  50.2| 18.4%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|simple|country|val|text|1000|2000000|   1.0|   8.5|   0.7|   9.2|  8.2%|\n|100|simple|country|ord|text|1000|2000000|   1.0|   8.5|   0.6|  10.1| 18.8%|\n|100|simple|country|ordval|text|1000|2000000|   1.0|   8.5|   0.6|   9.7| 14.1%|\n|100|simple|country|orddem|text|1000|2000000|   1.0|   8.5|   0.6|  10.3| 21.2%|\n|100|wiki|title|val|147|1000|   4984|  93.8| 442.8|   2.3| 240.7|-45.6%|\n|100|wiki|title|ord|147|1000|   4984|  93.8| 442.8|   2.3|  12.3|-97.2%|\n|100|wiki|title|ordval|147|1000|   4984|  93.8| 442.8|   2.2|  18.4|-95.8%|\n|100|wiki|title|orddem|147|1000|   4984|  93.8| 442.8|   2.1|  57.7|-87.0%|\n|100|wiki|title|val|text|1000|  97191|  93.4|  88.0|   2.3|  33.3|-62.2%|\n|100|wiki|title|ord|text|1000|  97191|  93.4|  88.0|   2.3|  17.7|-79.9%|\n|100|wiki|title|ordval|text|1000|  97191|  93.4|  88.0|   2.2|  27.8|-68.4%|\n|100|wiki|title|orddem|text|1000|  97191|  93.4|  88.0|   2.2|  54.4|-38.2%|\n|100|wiki|title|val|1|1000| 386435|  92.8|  41.0|   2.4|  14.8|-63.9%|\n|100|wiki|title|ord|1|1000| 386435|  92.8|  41.0|   2.7|  16.6|-59.5%|\n|100|wiki|title|ordval|1|1000| 386435|  92.8|  41.0|   2.2|  27.9|-32.0%|\n|100|wiki|title|orddem|1|1000| 386435|  92.8|  41.0|   2.2|  43.2|  5.4%|\n",
            "date": "2008-12-22T22:48:02.943+0000",
            "id": 184
        },
        {
            "author": "Michael McCandless",
            "body": "Results with topN=10:\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|10|2000000|   0.6|  10.7|   0.7|  11.7|  9.3%|\n|1|simple|country|ord|text|10|2000000|   0.6|  10.7|   0.6|  13.8| 29.0%|\n|1|simple|country|ordval|text|10|2000000|   0.6|  10.7|   0.6|  13.3| 24.3%|\n|1|simple|country|orddem|text|10|2000000|   0.6|  10.7|   0.7|  13.0| 21.5%|\n|1|wiki|title|val|147|10|   4984|   2.1|3743.8|   2.3|2441.8|-34.8%|\n|1|wiki|title|ord|147|10|   4984|   2.1|3743.8|   2.0|4426.2| 18.2%|\n|1|wiki|title|ordval|147|10|   4984|   2.1|3743.8|   2.1|4352.7| 16.3%|\n|1|wiki|title|orddem|147|10|   4984|   2.1|3743.8|   2.0|4063.6|  8.5%|\n|1|wiki|title|val|text|10|  97191|   2.1| 144.2|   2.3|  39.1|-72.9%|\n|1|wiki|title|ord|text|10|  97191|   2.1| 144.2|   2.1| 164.5| 14.1%|\n|1|wiki|title|ordval|text|10|  97191|   2.1| 144.2|   2.1| 162.6| 12.8%|\n|1|wiki|title|orddem|text|10|  97191|   2.1| 144.2|   2.1| 157.3|  9.1%|\n|1|wiki|title|val|1|10| 386435|   2.1|  51.2|   2.4|  13.6|-73.4%|\n|1|wiki|title|ord|1|10| 386435|   2.1|  51.2|   2.1|  65.7| 28.3%|\n|1|wiki|title|ordval|1|10| 386435|   2.1|  51.2|   2.1|  64.7| 26.4%|\n|1|wiki|title|orddem|1|10| 386435|   2.1|  51.2|   2.1|  60.4| 18.0%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|10|2000000|   0.7|  10.4|   0.6|  11.6| 11.5%|\n|10|simple|country|ord|text|10|2000000|   0.7|  10.4|   0.6|  13.6| 30.8%|\n|10|simple|country|ordval|text|10|2000000|   0.7|  10.4|   0.6|  13.1| 26.0%|\n|10|simple|country|orddem|text|10|2000000|   0.7|  10.4|   0.6|  13.1| 26.0%|\n|10|wiki|title|val|147|10|   4984|  12.5|3004.5|   2.5|1732.9|-42.3%|\n|10|wiki|title|ord|147|10|   4984|  12.5|3004.5|   2.1|3067.2|  2.1%|\n|10|wiki|title|ordval|147|10|   4984|  12.5|3004.5|   2.1|3283.5|  9.3%|\n|10|wiki|title|orddem|147|10|   4984|  12.5|3004.5|   2.1|3237.9|  7.8%|\n|10|wiki|title|val|text|10|  97191|  12.7| 139.4|   2.4|  38.6|-72.3%|\n|10|wiki|title|ord|text|10|  97191|  12.7| 139.4|   2.1| 159.5| 14.4%|\n|10|wiki|title|ordval|text|10|  97191|  12.7| 139.4|   2.1| 160.5| 15.1%|\n|10|wiki|title|orddem|text|10|  97191|  12.7| 139.4|   2.1| 154.0| 10.5%|\n|10|wiki|title|val|1|10| 386435|  12.7|  50.3|   2.5|  15.6|-69.0%|\n|10|wiki|title|ord|1|10| 386435|  12.7|  50.3|   2.1|  64.8| 28.8%|\n|10|wiki|title|ordval|1|10| 386435|  12.7|  50.3|   2.1|  64.0| 27.2%|\n|10|wiki|title|orddem|1|10| 386435|  12.7|  50.3|   2.1|  59.4| 18.1%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|simple|country|val|text|10|2000000|   1.0|   8.8|   2.8|   9.4|  6.8%|\n|100|simple|country|ord|text|10|2000000|   1.0|   8.8|   0.6|  11.1| 26.1%|\n|100|simple|country|ordval|text|10|2000000|   1.0|   8.8|   0.6|  10.7| 21.6%|\n|100|simple|country|orddem|text|10|2000000|   1.0|   8.8|   0.6|  10.7| 21.6%|\n|100|wiki|title|val|147|10|   4984|  94.6|1066.9|   3.3| 454.8|-57.4%|\n|100|wiki|title|ord|147|10|   4984|  94.6|1066.9|   2.1| 519.2|-51.3%|\n|100|wiki|title|ordval|147|10|   4984|  94.6|1066.9|   2.1| 692.5|-35.1%|\n|100|wiki|title|orddem|147|10|   4984|  94.6|1066.9|   2.1| 778.1|-27.1%|\n|100|wiki|title|val|text|10|  97191|  94.9| 110.2|   2.7|  38.9|-64.7%|\n|100|wiki|title|ord|text|10|  97191|  94.9| 110.2|   2.1| 122.8| 11.4%|\n|100|wiki|title|ordval|text|10|  97191|  94.9| 110.2|   2.1| 126.3| 14.6%|\n|100|wiki|title|orddem|text|10|  97191|  94.9| 110.2|   2.1| 124.7| 13.2%|\n|100|wiki|title|val|1|10| 386435|  94.3|  47.9|   2.8|  15.8|-67.0%|\n|100|wiki|title|ord|1|10| 386435|  94.3|  47.9|   2.1|  59.1| 23.4%|\n|100|wiki|title|ordval|1|10| 386435|  94.3|  47.9|   2.2|  58.9| 23.0%|\n|100|wiki|title|orddem|1|10| 386435|  94.3|  47.9|   2.2|  54.9| 14.6%|\n",
            "date": "2008-12-22T23:46:11.503+0000",
            "id": 185
        },
        {
            "author": "Mark Miller",
            "body": "Hmm...I'm going to have to break down and think hard about the slot issue. You have switched it to values.length - here is what I'm thinking: In the case where 3 hits come from a Reader, but you ask for 1000 back, that will run through that loop 1000 times, but you only need to convert 3 right? This is what I was attempting - what test are you running to see the failure? The idea for me was that if you only have 20 hits so far on a top 1000 search, you only need to hit that loop to convert 20 values to the new Reader, rather 1000 everytime (though you spin fast hitting the ==null). I'm not sure - xmas shopping has burned my whats left of my brain cells. I'll let it stew, perhaps run some code, and come back.",
            "date": "2008-12-23T03:44:01.941+0000",
            "id": 186
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> In the case where 3 hits come from a Reader, but you ask for 1000 back, that will run through that loop 1000 times, but you only need to convert 3 right?\n{quote}\n\n\nWell, it's tricky... and indeed all tests pass with the bug (which is\nspooky -- I think we need to add cases to TestSort where 1) the index\nhas many segments, and 2) the number of hits is much greater than the\nqueue size), but I'm pretty sure it's a bug.\n\nYou're right: it'd be nice to only visit the \"used\" slots in the queue\non advancing to each reader.  During the \"startup transient\" (when\ncollector has not yet seen enough hits to fill its queue), the slot\nindeed increases one at a time, and you could at that point use it to\nefficiently visit only the used slots.\n\nHowevever, after startup transient, the pqueue will then track the\nweakest entry in the queue, which can occur in any of the slots, and\nwhen a hit that beats that weakest entry arrives, it will call copy()\ninto that slot.\n\nSo the slot passed to copy is now a \"relatively random\" value.  For a\n1000 sized queue whose slots are full, you might get a copy into slot\n242.  In this case we were incorrectly setting \"this.slot\" to 242 and\nthen only converting the first 242 entries.\n\nIf we changed to to track the maxSlot it should work... but I'm not\nsure this is worthwhile, since it only speeds up already super-fast\nsearches and slightly hurts slow searches.\n",
            "date": "2008-12-23T10:01:39.793+0000",
            "id": 187
        },
        {
            "author": "Michael McCandless",
            "body": "\nNew patch attached:\n\n  * I moved maxScore tracking up into TopFieldCollector to save a\n    method call per collect().\n\n  * Deprecated TopDocs.get/setMaxScore()\n\n  * Inlined the common \"only 1 comparator\" case\n\n  * Some small optimizations\n\n  * Fixed a bug in reverse sorting & short-circuit testing\n\n  * Renamed a few attrs\n\nIn addition to fixing TestSort to test multi-segment index where\ntotalHits is much greater than topN, we should include reverse sorting\n(to tickle the bug I just found) as well as sorting by 2 or more\nfields.  Mark do you want to take a stab at this?  Given how many\nsneaky bugs we're uncovering just by staring at the code (for long\nenough) I'd like to increase test coverage....\n\nHere're the topN=10 results with this patch:\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|10|2000000|   0.6|  10.7|   0.7|  11.9| 11.2%|\n|1|simple|country|ord|text|10|2000000|   0.6|  10.7|   0.6|  14.2| 32.7%|\n|1|simple|country|ordval|text|10|2000000|   0.6|  10.7|   0.6|  14.3| 33.6%|\n|1|simple|country|orddem|text|10|2000000|   0.6|  10.7|   0.6|  13.4| 25.2%|\n|1|wiki|title|val|147|10|   4984|   2.1|3743.8|   2.4|2451.8|-34.5%|\n|1|wiki|title|ord|147|10|   4984|   2.1|3743.8|   2.1|4459.4| 19.1%|\n|1|wiki|title|ordval|147|10|   4984|   2.1|3743.8|   2.1|4478.2| 19.6%|\n|1|wiki|title|orddem|147|10|   4984|   2.1|3743.8|   2.0|4233.9| 13.1%|\n|1|wiki|title|val|text|10|  97191|   2.1| 144.2|   2.4|  38.9|-73.0%|\n|1|wiki|title|ord|text|10|  97191|   2.1| 144.2|   2.1| 165.0| 14.4%|\n|1|wiki|title|ordval|text|10|  97191|   2.1| 144.2|   2.1| 159.9| 10.9%|\n|1|wiki|title|orddem|text|10|  97191|   2.1| 144.2|   2.1| 161.4| 11.9%|\n|1|wiki|title|val|1|10| 386435|   2.1|  51.2|   2.4|  13.5|-73.6%|\n|1|wiki|title|ord|1|10| 386435|   2.1|  51.2|   2.1|  67.1| 31.1%|\n|1|wiki|title|ordval|1|10| 386435|   2.1|  51.2|   2.1|  66.6| 30.1%|\n|1|wiki|title|orddem|1|10| 386435|   2.1|  51.2|   2.1|  64.7| 26.4%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|10|2000000|   0.7|  10.4|   0.7|  11.6| 11.5%|\n|10|simple|country|ord|text|10|2000000|   0.7|  10.4|   0.5|  13.9| 33.7%|\n|10|simple|country|ordval|text|10|2000000|   0.7|  10.4|   0.5|  14.0| 34.6%|\n|10|simple|country|orddem|text|10|2000000|   0.7|  10.4|   0.5|  13.2| 26.9%|\n|10|wiki|title|val|147|10|   4984|  12.5|3004.5|   2.6|1695.3|-43.6%|\n|10|wiki|title|ord|147|10|   4984|  12.5|3004.5|   2.1|3072.8|  2.3%|\n|10|wiki|title|ordval|147|10|   4984|  12.5|3004.5|   2.1|3328.7| 10.8%|\n|10|wiki|title|orddem|147|10|   4984|  12.5|3004.5|   2.1|3295.1|  9.7%|\n|10|wiki|title|val|text|10|  97191|  12.7| 139.4|   2.4|  38.7|-72.2%|\n|10|wiki|title|ord|text|10|  97191|  12.7| 139.4|   2.1| 158.9| 14.0%|\n|10|wiki|title|ordval|text|10|  97191|  12.7| 139.4|   2.1| 161.7| 16.0%|\n|10|wiki|title|orddem|text|10|  97191|  12.7| 139.4|   2.1| 157.7| 13.1%|\n|10|wiki|title|val|1|10| 386435|  12.7|  50.3|   2.5|  15.6|-69.0%|\n|10|wiki|title|ord|1|10| 386435|  12.7|  50.3|   2.1|  65.4| 30.0%|\n|10|wiki|title|ordval|1|10| 386435|  12.7|  50.3|   2.1|  66.4| 32.0%|\n|10|wiki|title|orddem|1|10| 386435|  12.7|  50.3|   2.1|  63.5| 26.2%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|simple|country|val|text|10|2000000|   1.0|   8.8|   3.1|   9.5|  8.0%|\n|100|simple|country|ord|text|10|2000000|   1.0|   8.8|   0.6|  11.4| 29.5%|\n|100|simple|country|ordval|text|10|2000000|   1.0|   8.8|   0.6|  11.3| 28.4%|\n|100|simple|country|orddem|text|10|2000000|   1.0|   8.8|   0.6|  11.0| 25.0%|\n|100|wiki|title|val|147|10|   4984|  94.6|1066.9|   3.7| 456.8|-57.2%|\n|100|wiki|title|ord|147|10|   4984|  94.6|1066.9|   2.1| 522.2|-51.1%|\n|100|wiki|title|ordval|147|10|   4984|  94.6|1066.9|   2.1| 667.1|-37.5%|\n|100|wiki|title|orddem|147|10|   4984|  94.6|1066.9|   2.1| 781.7|-26.7%|\n|100|wiki|title|val|text|10|  97191|  94.9| 110.2|   2.8|  38.4|-65.2%|\n|100|wiki|title|ord|text|10|  97191|  94.9| 110.2|   2.1| 123.0| 11.6%|\n|100|wiki|title|ordval|text|10|  97191|  94.9| 110.2|   2.2| 127.3| 15.5%|\n|100|wiki|title|orddem|text|10|  97191|  94.9| 110.2|   2.2| 126.8| 15.1%|\n|100|wiki|title|val|1|10| 386435|  94.3|  47.9|   2.8|  15.8|-67.0%|\n|100|wiki|title|ord|1|10| 386435|  94.3|  47.9|   2.1|  59.8| 24.8%|\n|100|wiki|title|ordval|1|10| 386435|  94.3|  47.9|   2.2|  60.8| 26.9%|\n|100|wiki|title|orddem|1|10| 386435|  94.3|  47.9|   2.2|  59.0| 23.2%|\n",
            "date": "2008-12-23T12:03:10.669+0000",
            "id": 188
        },
        {
            "author": "Mark Miller",
            "body": "Just as a reminder to myself - we also need a custom comparator test.",
            "date": "2008-12-23T13:11:21.984+0000",
            "id": 189
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> If we changed to to track the maxSlot it should work... but I'm not\n> sure this is worthwhile, since it only speeds up already super-fast\n> searches and slightly hurts slow searches.\n{quote}\nOK I realized we could do this with very little added cost, by passing in \"numFilledSlots\" to FieldComparator.setNextReader.  I'm attaching the patch with this.",
            "date": "2008-12-23T13:56:53.884+0000",
            "id": 190
        },
        {
            "author": "Michael McCandless",
            "body": "Current results with topN=1000:\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|1000|2000000|   0.9|  10.0|   0.8|  11.4| 14.0%|\n|1|simple|country|ord|text|1000|2000000|   0.9|  10.0|   0.6|  13.7| 37.0%|\n|1|simple|country|ordval|text|1000|2000000|   0.9|  10.0|   0.6|  13.3| 33.0%|\n|1|simple|country|orddem|text|1000|2000000|   0.9|  10.0|   0.7|  13.1| 31.0%|\n|1|wiki|title|val|147|1000|   4984|   2.1| 740.6|   2.3| 381.8|-48.4%|\n|1|wiki|title|ord|147|1000|   4984|   2.1| 740.6|   2.1| 905.2| 22.2%|\n|1|wiki|title|ordval|147|1000|   4984|   2.1| 740.6|   2.1| 906.4| 22.4%|\n|1|wiki|title|orddem|147|1000|   4984|   2.1| 740.6|   2.1| 834.5| 12.7%|\n|1|wiki|title|val|text|1000|  97191|   2.1| 108.7|   2.4|  32.9|-69.7%|\n|1|wiki|title|ord|text|1000|  97191|   2.1| 108.7|   2.1| 124.6| 14.6%|\n|1|wiki|title|ordval|text|1000|  97191|   2.1| 108.7|   2.1| 123.7| 13.8%|\n|1|wiki|title|orddem|text|1000|  97191|   2.1| 108.7|   2.1| 119.9| 10.3%|\n|1|wiki|title|val|1|1000| 386435|   2.1|  46.2|   2.4|  12.6|-72.7%|\n|1|wiki|title|ord|1|1000| 386435|   2.1|  46.2|   2.1|  60.3| 30.5%|\n|1|wiki|title|ordval|1|1000| 386435|   2.1|  46.2|   2.1|  59.3| 28.4%|\n|1|wiki|title|orddem|1|1000| 386435|   2.1|  46.2|   2.1|  57.9| 25.3%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|1000|2000000|   0.8|   9.7|   0.7|  11.2| 15.5%|\n|10|simple|country|ord|text|1000|2000000|   0.8|   9.7|   0.6|  13.5| 39.2%|\n|10|simple|country|ordval|text|1000|2000000|   0.8|   9.7|   0.6|  13.0| 34.0%|\n|10|simple|country|orddem|text|1000|2000000|   0.8|   9.7|   0.6|  12.8| 32.0%|\n|10|wiki|title|val|147|1000|   4984|  12.7| 664.2|   2.4| 417.3|-37.2%|\n|10|wiki|title|ord|147|1000|   4984|  12.7| 664.2|   2.2|  58.3|-91.2%|\n|10|wiki|title|ordval|147|1000|   4984|  12.7| 664.2|   2.1|  72.2|-89.1%|\n|10|wiki|title|orddem|147|1000|   4984|  12.7| 664.2|   2.1|  92.5|-86.1%|\n|10|wiki|title|val|text|1000|  97191|  12.6| 100.4|   2.4|  33.5|-66.6%|\n|10|wiki|title|ord|text|1000|  97191|  12.6| 100.4|   2.3|  65.3|-35.0%|\n|10|wiki|title|ordval|text|1000|  97191|  12.6| 100.4|   2.2|  78.7|-21.6%|\n|10|wiki|title|orddem|text|1000|  97191|  12.6| 100.4|   2.2|  79.8|-20.5%|\n|10|wiki|title|val|1|1000| 386435|  12.7|  42.4|   2.5|  14.6|-65.6%|\n|10|wiki|title|ord|1|1000| 386435|  12.7|  42.4|   2.7|  46.2|  9.0%|\n|10|wiki|title|ordval|1|1000| 386435|  12.7|  42.4|   2.1|  51.1| 20.5%|\n|10|wiki|title|orddem|1|1000| 386435|  12.7|  42.4|   2.1|  51.5| 21.5%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|simple|country|val|text|1000|2000000|   1.0|   8.5|   1.3|   9.2|  8.2%|\n|100|simple|country|ord|text|1000|2000000|   1.0|   8.5|   0.6|  10.3| 21.2%|\n|100|simple|country|ordval|text|1000|2000000|   1.0|   8.5|   0.6|  10.0| 17.6%|\n|100|simple|country|orddem|text|1000|2000000|   1.0|   8.5|   0.6|  10.6| 24.7%|\n|100|wiki|title|val|147|1000|   4984|  93.8| 442.8|   2.9| 245.2|-44.6%|\n|100|wiki|title|ord|147|1000|   4984|  93.8| 442.8|   2.3|  12.0|-97.3%|\n|100|wiki|title|ordval|147|1000|   4984|  93.8| 442.8|   2.2|  18.0|-95.9%|\n|100|wiki|title|orddem|147|1000|   4984|  93.8| 442.8|   2.1|  58.2|-86.9%|\n|100|wiki|title|val|text|1000|  97191|  93.4|  88.0|   2.5|  33.5|-61.9%|\n|100|wiki|title|ord|text|1000|  97191|  93.4|  88.0|   2.3|  17.6|-80.0%|\n|100|wiki|title|ordval|text|1000|  97191|  93.4|  88.0|   2.2|  29.8|-66.1%|\n|100|wiki|title|orddem|text|1000|  97191|  93.4|  88.0|   2.2|  56.6|-35.7%|\n|100|wiki|title|val|1|1000| 386435|  92.8|  41.0|   2.6|  14.9|-63.7%|\n|100|wiki|title|ord|1|1000| 386435|  92.8|  41.0|   2.7|  16.5|-59.8%|\n|100|wiki|title|ordval|1|1000| 386435|  92.8|  41.0|   2.2|  28.6|-30.2%|\n|100|wiki|title|orddem|1|1000| 386435|  92.8|  41.0|   2.2|  44.1|  7.6%|\n",
            "date": "2008-12-23T13:58:10.374+0000",
            "id": 191
        },
        {
            "author": "Michael McCandless",
            "body": "\nGiven how different the results are, depending on how many segments\nindex has, queue size, how many hits search gets, etc., I think we\nneed a dynamic solution, meaning in certain situations (many hits,\nsmall queue depth, small number of large segments) you use ORD but\nother times you use ORDDEM.\n\nSo I'm thinking setNextReader should return a new comparator?  Often\nit would simply return itself, but if it deems it worthwhile to switch\neg from ORD to ORDDEM it would switch to ORDDEM and return that.\n\nEG for real-time search we may have a tail of a zillion small\nsegments...\n\nThen I also thought of a wild possible change: when doing searching,\nit'd be best to visit the segments from largest to smallest, doing ORD\nin the beginning and switching to ORDDEM at some point.  So, could we\ndo this?  I think we only \"require\" in-order docs within a segment, so\ncould we switch up segment order.  We'd need to fix setNextReader API\nto take in reader & docBase.  Would that work?\n\n",
            "date": "2008-12-26T14:17:11.375+0000",
            "id": 192
        },
        {
            "author": "Mark Miller",
            "body": "{quote}\nGiven how different the results are, depending on how many segments\nindex has, queue size, how many hits search gets, etc., I think we\nneed a dynamic solution, meaning in certain situations (many hits,\nsmall queue depth, small number of large segments) you use ORD but\nother times you use ORDDEM.\n{quote}\n\nSounds interesting...\n\n{quote}\nSo I'm thinking setNextReader should return a new comparator? Often\nit would simply return itself, but if it deems it worthwhile to switch\neg from ORD to ORDDEM it would switch to ORDDEM and return that.\n{quote}\n\nI like that I think. Only other option I see off hand is a comparator that can do both, but not as clean and probably adds a check in tightly looped code.\n\n{quote}\nThen I also thought of a wild possible change: when doing searching,\nit'd be best to visit the segments from largest to smallest, doing ORD\nin the beginning and switching to ORDDEM at some point. So, could we\ndo this? I think we only \"require\" in-order docs within a segment, so\ncould we switch up segment order. We'd need to fix setNextReader API\nto take in reader & docBase. Would that work?\n{quote}\n\nI think this could work well. Since you are likely to have a few large segments, ord would be fastest, then as you moved through the many small segments, orddem would likely work best. Is largest to smallest best though? You do get to map onto smaller term[] arrays as you go, but that causes more fallback. You are also likely to be carrying more hits in the queue into the nextreader right? From smallest to largest you likely have fewer hits to map as you hit the big segments, and more room to fit in for less fallback. So the question is, what obvious piece am I missing :)\n\nLargest to smallest, you fill the queue faster earlier. So more to convert as you hit all the other segments - but I guess that will be heavily mitigated by on demand.. You will convert slot.min, and if nothing beats it, I guess thats it...so not so bad actually. And if you go smallest to largest, I guess the queue wont be full, so there will be more 'wins' into the queue, which will cause more conversions over the small segments...in which case for a ton of them and a big queue, largest to smallest seems better. Still feel like I'm missing something, but I guess I have convinced myself largest to smallest is the way to go.\n\nI'm probably not the first to wish there were more hours in the day...\n\nI'll put up a patch with the better testing soon just in case.\n\n\n\n",
            "date": "2008-12-27T17:56:29.875+0000",
            "id": 193
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Only other option I see off hand is a comparator that can do both, but not as clean and probably adds a check in tightly looped code.\n{quote}\nRight, I wanted to avoid inner-loop check by swapping out the comparator in between segments.  Though, modern CPUs are quite good when an if-statement consistently goes one way, so it could be a single comparator that does internal switching might perform fine.  Still, if we fix the API to return a new comparator, we can then allow both options.\n\nI think in some cases we'd even fall back to VAL comparison.\n\n{quote}\n>  Is largest to smallest best though?\n{quote}\n\nGood question; it's not obvious.  We should try both, and perhaps allow for the collector to optionally specify the order.\n\nMy thinking was the first large segment using ORD is \"free\" (because ORD is only costly on switching segments).  If there are many hits, likely the queue has done most of the work it'll do (ie, the majority of the total # insertions will have been done), unless search is \"degenerate\".  Perhaps the second segment, if large, warrants ORD, but them sometime soonish you'd switch to ORDDEM or VAL.\n\nThe \"long tail\" of tiny segments would then normally be zipped through w/ hardly any insertions, so a higher insertion cost (with zero segment transition cost) is OK.\n\nBut you're right: if we do the tiny segments first, then the queue would be small so transition cost is lower.\n\nWe should make it simple to override a method to implement your own \"search plan\", and then provide a default heuristic that decides when to switch comparators.  Probably that default heuristic should be based on how often compare was actually invoked for the segment.  EG if the String sort is secondary to a numeric sort then even if there are many hits, if the numeric sort mostly wins (doesn't have many compare(...) == 0's) then the String sort should probably immediately switch to VAL after the first segment.",
            "date": "2008-12-28T14:37:38.036+0000",
            "id": 194
        },
        {
            "author": "Mark Miller",
            "body": "Nice Mike! Definitely what needs to be done and very cool. Pluggable policy sounds great. You should be able to ride the right turns often enough to really reduce some of those losses. Ord with no transition cost on the largest segment should be a nice win on its own. I think thats what I was missing - if you come from smallest, you have to map on the ord switch.",
            "date": "2008-12-28T15:23:43.283+0000",
            "id": 195
        },
        {
            "author": "Mark Miller",
            "body": "I was playing with this late last night and I got some of the work moving. I've got it so you can work the readers in any order (sorting by size at the moment, largest to smallest), but in doing so, straight ord no longer works. This is likely because the testing has gotten a little better, but I am not sure whats up. The other comparators work fine. Got a little of the return a new comparator type stuff in too, but nothing finished.\n\nKind of got caught up on ord  - when thats fixed I'll put up a patch though.",
            "date": "2008-12-30T16:31:25.162+0000",
            "id": 196
        },
        {
            "author": "Mark Miller",
            "body": "Alright, my new years gift to myself is going to be to work on this a bit.\n\nI've got part of the straight ord problem - if multiple queue entries clashed on conversion, and they were indeed not just clashes but clashes with the same oringal value, they were still getting an incremented subord when they should get an identical subord. So I've taken care of that, but something still fails. Looking.\n\nOn a side note though, we probably want another straight ords comparator that does not fall back to subords. Then we can use that as the first comparator on a large segment, and equal values wont have to needlessly fallback to subords for a worthless 0 on 0 check.\n\n",
            "date": "2009-01-01T19:45:00.158+0000",
            "id": 197
        },
        {
            "author": "Mark Miller",
            "body": "Cool, got the other one. When copying the doc into a slot (FieldComparator.copy), the subord had to be set to 0 so that it didnt retain a stale value. Straight ord looks good now as do the rest, so I'll try and get a custom comparator policy in there so we can benchmark a couple strategies.\n\nRather than a new Comparator for a pure ord that doesnt fall to subord, perhaps the policy could return an overridden straight ord if its first and on the first index reader...",
            "date": "2009-01-01T20:18:43.975+0000",
            "id": 198
        },
        {
            "author": "Mark Miller",
            "body": "Still pretty ugly, but this patch has a working ord I think, allows readers in any order (giving largest to smallest now), and has a hackey ComparatorPolicy that can alter the comparators being used. Right now there is an ugly little one for ORD that switches to ORD_DEM after the first segment. The rest just use the same comparator throughout.\n\nAlso added something we may take out - an option to not fill fields (which we cant use for back compat, but a user could). If you are not using a MultiSearcher, its kind of a waste of time to fill fields.\n\nMuch to do, but fully functional I think.",
            "date": "2009-01-01T22:26:05.624+0000",
            "id": 199
        },
        {
            "author": "Mark Miller",
            "body": "So what looks like a promising strategy?\n\nOff the top I am thinking something as simple as:\n\nstart with ORD with no fallback on the largest.\nif the next segments are fairly large, use ORD_VAL\nif the segments get somewhat smaller, move to ORD_DEM\n\nOddly, I've seen VAL perform well in certain situations, so maybe it has its place, but I don't know where yet.\n\n*edit*\n\nOh, yeah, queue size should also play a roll in the switching ",
            "date": "2009-01-02T14:22:56.874+0000",
            "id": 200
        },
        {
            "author": "Michael McCandless",
            "body": "\nPatch looks great!  I will run some perf tests once I'm back at home\nbase (still on vacation now, far away from home!).  Some comments:\n\n  * The comment \"use multiple queues\" in IndexSearcher.java isn't\n    right -- it should be \"use single reader\"?\n\n  * I think FieldValueHitQueue.getComparatorPolicy should receive\n    subreaders?  EG when there's only one sub-reader, straight ORD is\n    best.  And possibly its order in the sort?  We may want to move\n    getComparatorPolicy into SortField so that one may override for\n    \"expert\" cases?  But we could do this later.\n\n  * We should fix sorting of sub-readers by maxDoc() to be done once,\n    not per query?\n\n  * I think we should sort sub-readers by numDocs() not maxDoc()?\n\n  * We should fix javadocs of MultiReaderHitCollector to explain that\n    sub-readers are visited not-in-order.  (And other javadoc fixes,\n    but this can wait for the \"polishing\" phase...).\n\n  * I like the \"don't fill fields\" option\n\n",
            "date": "2009-01-03T14:08:00.765+0000",
            "id": 201
        },
        {
            "author": "Mark Miller",
            "body": "I'll put up another patch soon with those changes. All look correct. I wasn't sure about maxdoc or numdoc (not that I spent much time thinking about it) because the fieldcache loads up all the deleted docs - for things like the terms array to be mapped to, that depends on maxdoc. But then how many hits are likely to end up in the queue is more related to numdocs. Switched it to numdocs.\n\nStill have to wrap up the custom comparator, but a comparatorpolicy changes things there. If you can set a custom comparatorpolicy (move it to sort?), than you can easily put in any custom comparators.\n\n- Mark",
            "date": "2009-01-03T15:18:42.070+0000",
            "id": 202
        },
        {
            "author": "Mark Miller",
            "body": "Less ugly, but still some finishing work to do, including some intelligent ComparatorPolicies.",
            "date": "2009-01-04T01:56:43.518+0000",
            "id": 203
        },
        {
            "author": "Mark Miller",
            "body": "No real work, but some more necessary cleanup.",
            "date": "2009-01-04T15:01:21.085+0000",
            "id": 204
        },
        {
            "author": "Michael McCandless",
            "body": "Mark, I see 3 testcase failures in TestSort if I \"pretend\" that SortField.STRING means STRING_ORD -- do you see that?\n\nI think we should fix TestSort so that it runs N times, each time using a different STRING sort method, to make sure we are covering all these methods?",
            "date": "2009-01-06T14:10:40.508+0000",
            "id": 205
        },
        {
            "author": "Michael McCandless",
            "body": "I prototyped a rough change to the FieldComparator API, whereby\nTopFieldCollector calls setBottom to notify the comparator which slot\nis the bottom of the queue (whenever it changes), and then calls\ncompareBottom (which replaces compare(int slot, int doc, float\nscore)).  This seems to offer decent perf. gains so I think we should\nmake this change for real?\n\nI think it gives good gains because 1) compare to bottom is very\nfrequent for a search that has many hits, and where the queue fairly\nquickly converges to the top N, 2) it allows the on-demand comparator\nto pre-cache the bottom's ord, and 3) it saves one array deref.\n\nTopFieldCollector would guarantee that compareBottom is not called\nunless setBottom was called; during the startup transient, setBottom\nis not called until the queue becomes full.\n\n",
            "date": "2009-01-06T14:13:30.552+0000",
            "id": 206
        },
        {
            "author": "Michael McCandless",
            "body": "On what ComparatorPolicy to use by default... I think we should start\nwith ORD, but gather counters of number of compares vs number of\ncopies, and based on those counters (and comparing to numDocs())\ndecide \"how aggressively\" to switch comparators?  That determination\nshould also take into account the queue size.\n\nAn optimized index would always use ORD (w/o gathering counters),\nwhich is fastest.\n\nIn the future... we could imagine allowing the query to dictate the\norder that segments are visited.  EG if the query can roughly estimate\nhow many hits it'll get on a given segment, we could order by that\ninstead of simply numDocs().\n\nThe query could also choose an appropriate ComparatorPolicy, eg, if it\nestimates it'll get very few hits, VAL is best right from the start,\nelse start with ORD.\n\nAnother future fix would be to implement ORDSUB with a single pass\nthrough the queue, using a reused secondary pqueue to do the full sort\nof the queue.  This would let us assign subords much faster, I think.\n\nBut I don't think we should pursue these optimizations as part of this\nissue... we need to bring closure here; we already have some solid\ngains to capture.  I think we should wrapup now...\n\n",
            "date": "2009-01-06T14:15:11.900+0000",
            "id": 207
        },
        {
            "author": "Mark Miller",
            "body": "bq. Mark, I see 3 testcase failures in TestSort if I \"pretend\" that SortField.STRING means STRING_ORD - do you see that?\n\nYeah, sorry. That STRING_ORD custom comparator policy is just a joke really, so I only really tested it on the StringSort test. It's just not initing the ords along with the values on switching. Making ords package private so that it can be changed (and changing it) fixes things. Not sure about new constructors or package private for that part of the switch...\n\nbq. I think we should fix TestSort so that it runs N times, each time using a different STRING sort method, to make sure we are covering all these methods?\n\nYeah, this makes sense in any case. I just keep switching them by hand as I work on them.",
            "date": "2009-01-06T14:52:01.812+0000",
            "id": 208
        },
        {
            "author": "Mark Miller",
            "body": "There are other little conversion steps that have to be considered as well I think. Like when you switch to ord dem, you won't have the ReaderIndex array filled in properly, etc. (probably an issue with that example policy in there beyond the ords copy)\n\nDepending on what you come from and what you go to, a couple little hoops have to be jumped.",
            "date": "2009-01-06T15:11:19.254+0000",
            "id": 209
        },
        {
            "author": "Mark Miller",
            "body": "Here is what that example policy has to be essentially. We just have to create a good way to do the right conversion I guess. I'll work on whatever you don't put up when you share your latest optimizations.\n\n\n{code}\n    case SortField.STRING_ORD:\n      return new ComparatorPolicy(){\n        private FieldComparator comparator = new FieldComparator.StringOrdComparator(numHits, field);\n        private boolean first = true;\n        private boolean second = true;\n        public FieldComparator nextComparator(FieldComparator oldComparator,\n            IndexReader reader, int numHits, int numSlotsFull)\n            throws IOException {\n          if(first) {\n            first = false;\n            return comparator;\n          } else if(second){\n            StringOrdValOnDemComparator comp = new FieldComparator.StringOrdValOnDemComparator(numHits, field);\n            comp.values = ((FieldComparator.StringOrdComparator)comparator).values;\n            comp.ords = ((FieldComparator.StringOrdComparator)comparator).ords;\n            comp.currentReaderIndex = 1;\n            comparator = comp;\n            second = false;\n            return comp;\n          }\n          return comparator;\n        }};\n{code}",
            "date": "2009-01-06T18:27:53.369+0000",
            "id": 210
        },
        {
            "author": "Ryan McKinley",
            "body": "Any estimates on how far along this is?\n\nIs it close enough that the reasonably simple patch in LUCENE-1304 should wait?  Or do you think it is worth waiting for this? \n\nI'm trying to get local lucene and solr to play nice (SOLR-773).  The hoops you have to jump through to avoid memory leaks make the final code too strange and not reusable.",
            "date": "2009-01-06T19:05:17.654+0000",
            "id": 211
        },
        {
            "author": "Mark Miller",
            "body": "I think we are wrapping up, but it may make sense to do 1304 anyway. That code will be deprecated, but if you use a custom comparator, it will use the deprecated code. The custom comparator will be removed in 3.0 I think, and you'd have to make a new comparator or comparator policy.\n\nSo its probably best to do 1304 if we want it, just for the 2.9 release.\n\n- Mark",
            "date": "2009-01-06T19:18:22.626+0000",
            "id": 212
        },
        {
            "author": "Michael McCandless",
            "body": "Attached prototype changes to switch to \"setBottom\" and \"compareBottom\" API for FieldComparator, but, I only included the few files I modified over the last patch, and it does not pass TestSort when I switch to it (fails the same tests ORD fails on).\n\nMark can you switch the comparators to this new API (and remove the compare(int, int, float) method) and fix the test failures?  Once that passes tests, I'll re-run perf test and we can tune the default policy.  I think we are close!",
            "date": "2009-01-06T20:16:43.741+0000",
            "id": 213
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Not sure about new constructors or package private for that part of the switch...\n{quote}\nCould we just make ctors on each comparator that take the other comparator and copy over what they need?  This way we can make attrs \"private final\" again, in case that helps the JRE optimize.",
            "date": "2009-01-06T20:18:11.751+0000",
            "id": 214
        },
        {
            "author": "Michael McCandless",
            "body": "\n{quote}\n> I'm trying to get local lucene and solr to play nice (SOLR-773). The hoops you have to jump through to avoid memory leaks make the final code too strange and not reusable.\n{quote}\n\nWith this patch we are changing how custom sorting works.\n\nPreviously, Lucene would iterate the terms for you, asking you to\nproduce a Comparable for each one.  With this patch, we are asking you\nto implement FieldComparator, which compares docs/slots directly and\nmust be aware of switching sub-readers during searching.\n\nRyan, can you have a look at FieldComparator to see if it \"works\" for\nlocal lucene (and any other feedback on it)?\n\nI think the best outcome here would be to get this issue done, and\nthen get local lucene switched over to this new API (so local lucene\nsees the benefits of the new API, and sidesteps the memory leak in\nLUCENE-1304).\n\nWe may still need to do LUCENE-1304 in case others hit the memory leak\nof the old custom sort API.\n",
            "date": "2009-01-06T20:42:06.938+0000",
            "id": 215
        },
        {
            "author": "Mark Miller",
            "body": "bq. Could we just make ctors on each comparator that take the other comparator and copy over what they need? This way we can make attrs \"private final\" again, in case that helps the JRE optimize.\n\nRight, good idea.\n\nI'll get everything together and put up a patch.",
            "date": "2009-01-06T20:47:46.310+0000",
            "id": 216
        },
        {
            "author": "Mark Miller",
            "body": "Can't seem to use the partial patch, but I'll try to put in by hand. Just gotta remember to make sure I don't miss anything.",
            "date": "2009-01-07T00:45:32.014+0000",
            "id": 217
        },
        {
            "author": "Mark Miller",
            "body": "bq.     I think we should fix TestSort so that it runs N times, each time using a different STRING sort method, to make sure we are covering all these methods?\n\nbq. Yeah, this makes sense in any case. I just keep switching them by hand as I work on them.\n\nIn thinking about this, we are going to drop those other sort types though right? I figured we would still just have String, and the comparator policy for String would pick the right comparators rather than the sort type?",
            "date": "2009-01-07T01:04:56.326+0000",
            "id": 218
        },
        {
            "author": "Mark Miller",
            "body": "Merged everything and put Sort.ORD back the way it was (using ORD_SUBORD).\n\nAdded two new types, STRING_POLICY and STRING_POLICY2. Nothing good, but something to get started with I suppose.\n\nThe first will just use straight ord and then switch to ordval on demand after the first reader.\n\nThe second will start with straight ord, go to ordval if the next readers have over 1000 docs (or is 5000?), and then finally move to ordvaldem.\n\nWhats left:\n\nPolish (mostly javadoc at this point I think)\nA good default String policy\nCustom FieldComparator test\nTests for each of the new String comparators (not sure how yet if we remove the new SortField types - perhaps we do leave them after all?)\nRemove the new SortField types that are being used for testing\n",
            "date": "2009-01-07T02:42:17.967+0000",
            "id": 219
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Can't seem to use the partial patch\n{quote}\nWoops, sorry -- did I miss a file I had changed?  I just quickly pulled together the files I thought I had changed.  I *really* want the \"svn patch\" command....\n\n{quote}\n> In thinking about this, we are going to drop those other sort types though right? \n{quote}\nTrue, I think.  Or, we may keep some of them around for \"expert\" usage.  I still think it'd be very helpful if one could alter a static array or something in TestSort to list the STRING sort methods to test out, and TestSort runs entirely with each method; then if one is making a private method one could stick it into the test to make sure it works.  Making a functionally correct STRING sort method is proving to be quite a challenge!\n\nOK I'll test the new patch... thanks Mark!",
            "date": "2009-01-07T12:01:45.855+0000",
            "id": 220
        },
        {
            "author": "Michael McCandless",
            "body": "Attached full patch (though you'll get failed hunks because of the\nannoying $Id$ expansion problem).\n\nI fixed various small issues, and added a new TestStressSort test.  It\nruns legacy vs new sort and asserts that they are the same.\n\nIt is currently failing... but I haven't spent any time digging into\nwhy.\n\nMark could you dig and try to figure out why it's failing?  I think we\nshould resolve it before running (or, trusting) perf tests.\n\nAlso: I wonder if we can remove the null checking in the compare\nmethods for String*Comparator?  EG maybe we need a new\nFieldCache.getString{s,Index} methods that optionally take a\n\"fillNulls\" param, and if true nulls are replaced with empty string?\nHowever... that would unfortunately cause a difference whereby \"\"\nwould be equal to null (whereas now null sorts ahead of \"\"), which is\nnot back compatible.  I guess we could make a \"non-null\" comparator\nand use it whenever it's known there are no nulls in the FieldCache\narray.  It may not be worth the hassle.  If the value is never null,\ncpu will guess the right branch path every time, so penalty should\nbe small (yet non-zero!).\n",
            "date": "2009-01-08T16:33:29.829+0000",
            "id": 221
        },
        {
            "author": "Mark Miller",
            "body": "bq. It runs legacy vs new sort and asserts that they are the same.\n\nClever. Very good idea.\n\nI'll fix it up. Also, if you have any ideas about what Policies you want to start with, I'd be happy to push those around a bit too.",
            "date": "2009-01-08T16:40:47.449+0000",
            "id": 222
        },
        {
            "author": "Mark Miller",
            "body": "Its the ORDSUBORD again (which I don't think we will use) and the two Policies. Odd because its the last hit of  10 that fails for all 3. I'll ferret it out tonight.\n\n- Mark\n\n*EDIT*\n\nyup...always the last entry thats wrong no matter the queue size - for all 3, which is odd because ORD_SUBORD doesnt have too much of a relationship to the two policies. Will be a fun one.",
            "date": "2009-01-08T17:01:39.584+0000",
            "id": 223
        },
        {
            "author": "Mark Miller",
            "body": "Still coming. Heavily side tracked for a bit with other stuff unfortunately, but I did fix the ORD_SUBORD issue last night (had to return -1 for the subord comparison rather than 1, something you had caught and left a 'is this wrong?' comment about).\n\nThe two policy problems are trickier, and must have something to do with the switch from one comparator to another. I see you straightened out some of the setbottom stuff that had to go on, but I can't find what else is off yet. Like I said, busy time for me for another week or two, but I'll find some time this weekend I hope.\n\nI still find it odd that it always the last hit thats off (at least from a couple quick tests) - somehow theres a clue there...\n\n- Mark",
            "date": "2009-01-09T14:29:55.303+0000",
            "id": 224
        },
        {
            "author": "Michael McCandless",
            "body": "OK new patch attached.  TestStressSort now passes -- there were a\nnumber of silly small bugs I had to fix.  Next up I'll run some perf\ntests...\n",
            "date": "2009-01-13T16:23:14.158+0000",
            "id": 225
        },
        {
            "author": "Mark Miller",
            "body": "What was causing the two policies to miss, even though the individual comparators passed? Was it more set bottom stuff messing up the transition between comparators? I couldn't see a transition problem last week. I see some of you other tweaks, but in terms of comparator transistion, I only see the readerGeneration rename there offhand (nice change). I actually think the generation can start with 0 rather than 1, as it normally starts at -1.\n\nI see that bottom optimization made the ordsubord bottomCompare more complicated as well - I'm surprised I saw everything passing with just a negative 1 rather than 1.\n\nVery much looking forward to the benchmark results! Wish I had more time to work on this, thanks for letting me in on so much of it.\n\n- Mark",
            "date": "2009-01-13T17:20:01.896+0000",
            "id": 226
        },
        {
            "author": "Michael McCandless",
            "body": "bq. What was causing the two policies to miss, even though the individual comparators passed?\n\nI think (not sure!) it was not correctly setting bottom* in one of the transition cases.  There were also a couple bugs in some of the setBottoms.",
            "date": "2009-01-13T18:24:00.010+0000",
            "id": 227
        },
        {
            "author": "Michael McCandless",
            "body": "OK here are the current results:\n\nQueue size 10:\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|10|2000000|   0.6|  10.7|   0.7|  12.4| 15.9%|\n|1|simple|country|ordsub|text|10|2000000|   0.6|  10.7|   0.6|  14.7| 37.4%|\n|1|simple|country|ordval|text|10|2000000|   0.6|  10.7|   0.6|  14.5| 35.5%|\n|1|simple|country|orddem|text|10|2000000|   0.6|  10.7|   0.6|  14.6| 36.4%|\n|1|simple|country|policy|text|10|2000000|   0.6|  10.7|   0.6|  14.5| 35.5%|\n|1|simple|country|policy2|text|10|2000000|   0.6|  10.7|   0.6|  14.6| 36.4%|\n|1|wiki|title|val|147|10|   4984|   2.1|3743.8|   2.3|2557.4|-31.7%|\n|1|wiki|title|ordsub|147|10|   4984|   2.1|3743.8|   2.0|4561.8| 21.8%|\n|1|wiki|title|ordval|147|10|   4984|   2.1|3743.8|   2.0|4551.4| 21.6%|\n|1|wiki|title|orddem|147|10|   4984|   2.1|3743.8|   2.0|4569.4| 22.1%|\n|1|wiki|title|policy|147|10|   4984|   2.1|3743.8|   2.0|4551.8| 21.6%|\n|1|wiki|title|policy2|147|10|   4984|   2.1|3743.8|   2.1|4526.6| 20.9%|\n|1|wiki|title|val|text|10|  97191|   2.1| 144.2|   2.4|  38.9|-73.0%|\n|1|wiki|title|ordsub|text|10|  97191|   2.1| 144.2|   2.1| 166.3| 15.3%|\n|1|wiki|title|ordval|text|10|  97191|   2.1| 144.2|   2.1| 166.1| 15.2%|\n|1|wiki|title|orddem|text|10|  97191|   2.1| 144.2|   2.1| 168.3| 16.7%|\n|1|wiki|title|policy|text|10|  97191|   2.1| 144.2|   2.1| 165.3| 14.6%|\n|1|wiki|title|policy2|text|10|  97191|   2.1| 144.2|   2.1| 165.1| 14.5%|\n|1|wiki|title|val|1|10| 386435|   2.1|  51.2|   2.4|  13.6|-73.4%|\n|1|wiki|title|ordsub|1|10| 386435|   2.1|  51.2|   2.1|  68.8| 34.4%|\n|1|wiki|title|ordval|1|10| 386435|   2.1|  51.2|   2.1|  68.9| 34.6%|\n|1|wiki|title|orddem|1|10| 386435|   2.1|  51.2|   2.1|  69.3| 35.4%|\n|1|wiki|title|policy|1|10| 386435|   2.1|  51.2|   2.1|  66.5| 29.9%|\n|1|wiki|title|policy2|1|10| 386435|   2.1|  51.2|   2.1|  66.3| 29.5%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|10|2000000|   0.7|  10.4|   0.5|  12.2| 17.3%|\n|10|simple|country|ordsub|text|10|2000000|   0.7|  10.4|   0.5|  14.6| 40.4%|\n|10|simple|country|ordval|text|10|2000000|   0.7|  10.4|   0.5|  14.7| 41.3%|\n|10|simple|country|orddem|text|10|2000000|   0.7|  10.4|   0.5|  14.7| 41.3%|\n|10|simple|country|policy|text|10|2000000|   0.7|  10.4|   0.5|  14.0| 34.6%|\n|10|simple|country|policy2|text|10|2000000|   0.7|  10.4|   0.5|  14.0| 34.6%|\n|10|wiki|title|val|147|10|   4984|  12.5|3004.5|   2.6|1735.7|-42.2%|\n|10|wiki|title|ordsub|147|10|   4984|  12.5|3004.5|   2.1|3077.2|  2.4%|\n|10|wiki|title|ordval|147|10|   4984|  12.5|3004.5|   2.1|3415.4| 13.7%|\n|10|wiki|title|orddem|147|10|   4984|  12.5|3004.5|   2.1|3537.0| 17.7%|\n|10|wiki|title|policy|147|10|   4984|  12.5|3004.5|   2.1|3463.8| 15.3%|\n|10|wiki|title|policy2|147|10|   4984|  12.5|3004.5|   2.1|3356.7| 11.7%|\n|10|wiki|title|val|text|10|  97191|  12.7| 139.4|   2.5|  38.5|-72.4%|\n|10|wiki|title|ordsub|text|10|  97191|  12.7| 139.4|   2.1| 164.0| 17.6%|\n|10|wiki|title|ordval|text|10|  97191|  12.7| 139.4|   2.1| 164.8| 18.2%|\n|10|wiki|title|orddem|text|10|  97191|  12.7| 139.4|   2.1| 164.7| 18.1%|\n|10|wiki|title|policy|text|10|  97191|  12.7| 139.4|   2.1| 163.1| 17.0%|\n|10|wiki|title|policy2|text|10|  97191|  12.7| 139.4|   2.1| 162.9| 16.9%|\n|10|wiki|title|val|1|10| 386435|  12.7|  50.3|   2.5|  15.2|-69.8%|\n|10|wiki|title|ordsub|1|10| 386435|  12.7|  50.3|   2.1|  67.4| 34.0%|\n|10|wiki|title|ordval|1|10| 386435|  12.7|  50.3|   2.1|  68.4| 36.0%|\n|10|wiki|title|orddem|1|10| 386435|  12.7|  50.3|   2.1|  68.4| 36.0%|\n|10|wiki|title|policy|1|10| 386435|  12.7|  50.3|   2.1|  65.7| 30.6%|\n|10|wiki|title|policy2|1|10| 386435|  12.7|  50.3|   2.1|  66.2| 31.6%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|simple|country|val|text|10|2000000|   1.0|   8.8|   4.0|   9.5|  8.0%|\n|100|simple|country|ordsub|text|10|2000000|   1.0|   8.8|   0.6|  11.5| 30.7%|\n|100|simple|country|ordval|text|10|2000000|   1.0|   8.8|   0.6|  11.7| 33.0%|\n|100|simple|country|orddem|text|10|2000000|   1.0|   8.8|   0.6|  11.8| 34.1%|\n|100|simple|country|policy|text|10|2000000|   1.0|   8.8|   0.6|  11.4| 29.5%|\n|100|simple|country|policy2|text|10|2000000|   1.0|   8.8|   0.6|  11.3| 28.4%|\n|100|wiki|title|val|147|10|   4984|  94.6|1066.9|   4.6| 450.6|-57.8%|\n|100|wiki|title|ordsub|147|10|   4984|  94.6|1066.9|   2.1| 480.8|-54.9%|\n|100|wiki|title|ordval|147|10|   4984|  94.6|1066.9|   2.1| 624.2|-41.5%|\n|100|wiki|title|orddem|147|10|   4984|  94.6|1066.9|   2.1| 703.3|-34.1%|\n|100|wiki|title|policy|147|10|   4984|  94.6|1066.9|   2.1| 724.1|-32.1%|\n|100|wiki|title|policy2|147|10|   4984|  94.6|1066.9|   2.1| 638.5|-40.2%|\n|100|wiki|title|val|text|10|  97191|  94.9| 110.2|   3.2|  37.9|-65.6%|\n|100|wiki|title|ordsub|text|10|  97191|  94.9| 110.2|   2.1| 118.1|  7.2%|\n|100|wiki|title|ordval|text|10|  97191|  94.9| 110.2|   2.2| 121.6| 10.3%|\n|100|wiki|title|orddem|text|10|  97191|  94.9| 110.2|   2.1| 123.4| 12.0%|\n|100|wiki|title|policy|text|10|  97191|  94.9| 110.2|   2.1| 123.1| 11.7%|\n|100|wiki|title|policy2|text|10|  97191|  94.9| 110.2|   2.1| 121.9| 10.6%|\n|100|wiki|title|val|1|10| 386435|  94.3|  47.9|   3.2|  14.7|-69.3%|\n|100|wiki|title|ordsub|1|10| 386435|  94.3|  47.9|   2.1|  61.8| 29.0%|\n|100|wiki|title|ordval|1|10| 386435|  94.3|  47.9|   2.1|  62.5| 30.5%|\n|100|wiki|title|orddem|1|10| 386435|  94.3|  47.9|   2.1|  63.3| 32.2%|\n|100|wiki|title|policy|1|10| 386435|  94.3|  47.9|   2.1|  61.8| 29.0%|\n|100|wiki|title|policy2|1|10| 386435|  94.3|  47.9|   2.1|  61.2| 27.8%|\n\n\nQueue size 1000:\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|1000|2000000|   0.9|  10.0|   0.7|  12.0| 20.0%|\n|1|simple|country|ordsub|text|1000|2000000|   0.9|  10.0|   0.6|  14.1| 41.0%|\n|1|simple|country|ordval|text|1000|2000000|   0.9|  10.0|   0.6|  14.0| 40.0%|\n|1|simple|country|orddem|text|1000|2000000|   0.9|  10.0|   0.6|  13.8| 38.0%|\n|1|simple|country|policy|text|1000|2000000|   0.9|  10.0|   0.7|  13.8| 38.0%|\n|1|simple|country|policy2|text|1000|2000000|   0.9|  10.0|   0.6|  13.7| 37.0%|\n|1|wiki|title|val|147|1000|   4984|   2.1| 740.6|   2.3| 385.0|-48.0%|\n|1|wiki|title|ordsub|147|1000|   4984|   2.1| 740.6|   2.1| 970.0| 31.0%|\n|1|wiki|title|ordval|147|1000|   4984|   2.1| 740.6|   2.1| 938.0| 26.7%|\n|1|wiki|title|orddem|147|1000|   4984|   2.1| 740.6|   2.1| 839.3| 13.3%|\n|1|wiki|title|policy|147|1000|   4984|   2.1| 740.6|   2.1| 938.4| 26.7%|\n|1|wiki|title|policy2|147|1000|   4984|   2.1| 740.6|   2.1| 924.4| 24.8%|\n|1|wiki|title|val|text|1000|  97191|   2.1| 108.7|   2.4|  33.1|-69.5%|\n|1|wiki|title|ordsub|text|1000|  97191|   2.1| 108.7|   2.1| 127.8| 17.6%|\n|1|wiki|title|ordval|text|1000|  97191|   2.1| 108.7|   2.1| 125.9| 15.8%|\n|1|wiki|title|orddem|text|1000|  97191|   2.1| 108.7|   2.1| 122.8| 13.0%|\n|1|wiki|title|policy|text|1000|  97191|   2.1| 108.7|   2.1| 125.7| 15.6%|\n|1|wiki|title|policy2|text|1000|  97191|   2.1| 108.7|   2.1| 125.4| 15.4%|\n|1|wiki|title|val|1|1000| 386435|   2.1|  46.2|   2.4|  12.8|-72.3%|\n|1|wiki|title|ordsub|1|1000| 386435|   2.1|  46.2|   2.1|  62.0| 34.2%|\n|1|wiki|title|ordval|1|1000| 386435|   2.1|  46.2|   2.1|  61.3| 32.7%|\n|1|wiki|title|orddem|1|1000| 386435|   2.1|  46.2|   2.1|  60.6| 31.2%|\n|1|wiki|title|policy|1|1000| 386435|   2.1|  46.2|   2.1|  60.0| 29.9%|\n|1|wiki|title|policy2|1|1000| 386435|   2.1|  46.2|   2.1|  60.4| 30.7%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|1000|2000000|   0.8|   9.7|   0.5|  11.9| 22.7%|\n|10|simple|country|ordsub|text|1000|2000000|   0.8|   9.7|   0.5|  13.8| 42.3%|\n|10|simple|country|ordval|text|1000|2000000|   0.8|   9.7|   0.6|  13.7| 41.2%|\n|10|simple|country|orddem|text|1000|2000000|   0.8|   9.7|   0.6|  13.7| 41.2%|\n|10|simple|country|policy|text|1000|2000000|   0.8|   9.7|   0.6|  13.5| 39.2%|\n|10|simple|country|policy2|text|1000|2000000|   0.8|   9.7|   0.6|  13.5| 39.2%|\n|10|wiki|title|val|147|1000|   4984|  12.7| 664.2|   2.3| 411.8|-38.0%|\n|10|wiki|title|ordsub|147|1000|   4984|  12.7| 664.2|   2.2|  58.3|-91.2%|\n|10|wiki|title|ordval|147|1000|   4984|  12.7| 664.2|   2.1|  71.1|-89.3%|\n|10|wiki|title|orddem|147|1000|   4984|  12.7| 664.2|   2.1|  89.9|-86.5%|\n|10|wiki|title|policy|147|1000|   4984|  12.7| 664.2|   2.1|  89.8|-86.5%|\n|10|wiki|title|policy2|147|1000|   4984|  12.7| 664.2|   2.1|  71.2|-89.3%|\n|10|wiki|title|val|text|1000|  97191|  12.6| 100.4|   2.4|  33.4|-66.7%|\n|10|wiki|title|ordsub|text|1000|  97191|  12.6| 100.4|   2.3|  68.4|-31.9%|\n|10|wiki|title|ordval|text|1000|  97191|  12.6| 100.4|   2.2|  80.6|-19.7%|\n|10|wiki|title|orddem|text|1000|  97191|  12.6| 100.4|   2.2|  84.6|-15.7%|\n|10|wiki|title|policy|text|1000|  97191|  12.6| 100.4|   2.2|  84.6|-15.7%|\n|10|wiki|title|policy2|text|1000|  97191|  12.6| 100.4|   2.2|  79.7|-20.6%|\n|10|wiki|title|val|1|1000| 386435|  12.7|  42.4|   2.4|  14.3|-66.3%|\n|10|wiki|title|ordsub|1|1000| 386435|  12.7|  42.4|   2.7|  47.8| 12.7%|\n|10|wiki|title|ordval|1|1000| 386435|  12.7|  42.4|   2.2|  52.9| 24.8%|\n|10|wiki|title|orddem|1|1000| 386435|  12.7|  42.4|   2.2|  54.3| 28.1%|\n|10|wiki|title|policy|1|1000| 386435|  12.7|  42.4|   2.2|  53.0| 25.0%|\n|10|wiki|title|policy2|1|1000| 386435|  12.7|  42.4|   2.2|  51.9| 22.4%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|100|simple|country|val|text|1000|2000000|   1.0|   8.5|   0.6|   9.4| 10.6%|\n|100|simple|country|ordsub|text|1000|2000000|   1.0|   8.5|   0.6|  10.5| 23.5%|\n|100|simple|country|ordval|text|1000|2000000|   1.0|   8.5|   0.6|  10.3| 21.2%|\n|100|simple|country|orddem|text|1000|2000000|   1.0|   8.5|   0.6|  10.6| 24.7%|\n|100|simple|country|policy|text|1000|2000000|   1.0|   8.5|   0.7|  10.3| 21.2%|\n|100|simple|country|policy2|text|1000|2000000|   1.0|   8.5|   0.7|  10.0| 17.6%|\n|100|wiki|title|val|147|1000|   4984|  93.8| 442.8|   2.2| 243.4|-45.0%|\n|100|wiki|title|ordsub|147|1000|   4984|  93.8| 442.8|   2.8|  12.5|-97.2%|\n|100|wiki|title|ordval|147|1000|   4984|  93.8| 442.8|   2.2|  19.0|-95.7%|\n|100|wiki|title|orddem|147|1000|   4984|  93.8| 442.8|   2.2|  58.4|-86.8%|\n|100|wiki|title|policy|147|1000|   4984|  93.8| 442.8|   2.1|  58.6|-86.8%|\n|100|wiki|title|policy2|147|1000|   4984|  93.8| 442.8|   2.2|  18.7|-95.8%|\n|100|wiki|title|val|text|1000|  97191|  93.4|  88.0|   2.3|  32.1|-63.5%|\n|100|wiki|title|ordsub|text|1000|  97191|  93.4|  88.0|   2.4|  15.9|-81.9%|\n|100|wiki|title|ordval|text|1000|  97191|  93.4|  88.0|   2.2|  27.4|-68.9%|\n|100|wiki|title|orddem|text|1000|  97191|  93.4|  88.0|   2.2|  46.6|-47.0%|\n|100|wiki|title|policy|text|1000|  97191|  93.4|  88.0|   2.2|  46.8|-46.8%|\n|100|wiki|title|policy2|text|1000|  97191|  93.4|  88.0|   2.2|  27.1|-69.2%|\n|100|wiki|title|val|1|1000| 386435|  92.8|  41.0|   2.3|  13.2|-67.8%|\n|100|wiki|title|ordsub|1|1000| 386435|  92.8|  41.0|   2.8|  15.9|-61.2%|\n|100|wiki|title|ordval|1|1000| 386435|  92.8|  41.0|   2.2|  26.6|-35.1%|\n|100|wiki|title|orddem|1|1000| 386435|  92.8|  41.0|   2.2|  37.3| -9.0%|\n|100|wiki|title|policy|1|1000| 386435|  92.8|  41.0|   2.2|  37.3| -9.0%|\n|100|wiki|title|policy2|1|1000| 386435|  92.8|  41.0|   2.2|  25.9|-36.8%|\n",
            "date": "2009-01-13T18:30:37.876+0000",
            "id": 228
        },
        {
            "author": "Mark Miller",
            "body": "Ha, how disappointing. I suppose not entirely unexpected though. I wouldn't expect one segment as straight ord would be much of a gain, but I am surprised it doesn't at least edge out the transition cost. Policy 2 is even worse - likely the arbitrary switch to on demand is not very useful - on the large queues it appears better to just orddem the whole thing. Perhaps it should switch sooner, or use a better heuristic. You gave some good ideas for that above, but I don't think thats a quick get.\n\nNeed to try and re micro bench little experiments to get an idea of what to do I think...\n\nI hope something smarter can eek out more gains than that.",
            "date": "2009-01-13T19:38:39.978+0000",
            "id": 229
        },
        {
            "author": "Mark Miller",
            "body": "Disregarding any missing gains with those simple policies, the rest of those numbers actually look pretty good! Still some problems here and there (large queue size still sticky), but overall some solid gains as well.\n\norddem seems to be best in most cases currently - maybe we can tweak that a little more somehow. Where its not better, or not much worse, is with a single segment. That result is interesting, because both policies beat it nicely, and its because they simpely use straight ord on the first segment. But ordsubord seems to outperform the policies. That doesn't make sense. Its largely the same, but should be a tad slower if anything. Other results match up so nicely, it seems like it might not be noise, in which case, weird.",
            "date": "2009-01-14T02:55:18.207+0000",
            "id": 230
        },
        {
            "author": "Michael McCandless",
            "body": "I agree, ORDDEM looks overall best.  I'm going to try to tune it a bit...",
            "date": "2009-01-14T14:38:55.425+0000",
            "id": 231
        },
        {
            "author": "Mark Miller",
            "body": "Any ideas on why ORDSUBORD would beat the policies with 1 segment and 1000 queue size? That technically boils down to ORD VS ORDSUBORD, and ORD should edge out or be about the same - but ORDSUBORD clearly wins by a few percent each time. Does this point to some funky policy problem or something?",
            "date": "2009-01-14T14:54:14.548+0000",
            "id": 232
        },
        {
            "author": "Michael McCandless",
            "body": "I was wondering the same thing.  ORD (policy/policy2 on a 1 seg index) ought to be faster than ORDSUB, always, but it's not.  Somthing is amiss.  I'll try running under YourKit to see if something stands out.",
            "date": "2009-01-14T15:00:58.281+0000",
            "id": 233
        },
        {
            "author": "Michael McCandless",
            "body": "OK new patch finally:\n\n  * Fixed a few small things YourKit uncovered, eg the private\n    binarySearch() method was inserting extra run-time access check\n    method so I changed it to package protected.\n\n  * I changed ComparatorPolicy.nextComparator -> nextReader, making it\n    that method's job to possibly switch comparators as well as call\n    setNextReader internally.  This allows us to pass in the\n    sub-reader when we init a new comparator.\n\n  * Improved TestStressSort some more.\n\n  * I made a new ORDDEM2 that does not convert slots when comparing,\n    but does convert the bottom slot.  So it uses ORD in\n    compareBottom, and ORD comparison between slots if the slots have\n    the same gen, else compare-by-value.  Also, when converting, it\n    bounds the binarySearch by using bottomOrd.  This seems to give\n    better performance in the high-segment-count, large-queue-size,\n    few hits cases, and comparable performance in other cases.\n\nI think for a custom sort we should allow user to pass in a ComparatorPolicy?\n",
            "date": "2009-01-16T20:10:28.735+0000",
            "id": 234
        },
        {
            "author": "Michael McCandless",
            "body": "I decided to change the wiki indexes I use for perf. testing.  Previously\nthe 10 and 100 segment indexes all had fix-sized segments, which is\nnot natural -- normally segments have a logarithmic size distribution.\nSo I created new 10 and 36 segment indexes from Wikipedia, with 2M\ndocs that are more \"natural\", and re-ran tests on them.\n\nI think net/net ORDDEM2 makes a good default policy!\n\nqueue=1000\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|1000|2000000|   0.9|  10.0|   0.7|  12.0| 20.0%|\n|1|simple|country|ordsub|text|1000|2000000|   0.9|  10.0|   0.6|  13.6| 36.0%|\n|1|simple|country|ordval|text|1000|2000000|   0.9|  10.0|   0.6|  13.9| 39.0%|\n|1|simple|country|orddem|text|1000|2000000|   0.9|  10.0|   0.7|  13.8| 38.0%|\n|1|simple|country|orddem2|text|1000|2000000|   0.9|  10.0|   0.6|  13.9| 39.0%|\n|1|wiki|title|val|147|1000|   4984|   2.1| 739.1|   2.3| 379.7|-48.6%|\n|1|wiki|title|ordsub|147|1000|   4984|   2.1| 739.1|   2.1| 954.7| 29.2%|\n|1|wiki|title|ordval|147|1000|   4984|   2.1| 739.1|   2.1| 951.3| 28.7%|\n|1|wiki|title|orddem|147|1000|   4984|   2.1| 739.1|   2.1| 858.8| 16.2%|\n|1|wiki|title|orddem2|147|1000|   4984|   2.1| 739.1|   2.1| 860.7| 16.5%|\n|1|wiki|title|val|text|1000|  97191|   2.1| 109.5|   2.4|  33.1|-69.8%|\n|1|wiki|title|ordsub|text|1000|  97191|   2.1| 109.5|   2.1| 125.8| 14.9%|\n|1|wiki|title|ordval|text|1000|  97191|   2.1| 109.5|   2.1| 126.1| 15.2%|\n|1|wiki|title|orddem|text|1000|  97191|   2.1| 109.5|   2.1| 123.4| 12.7%|\n|1|wiki|title|orddem2|text|1000|  97191|   2.1| 109.5|   2.1| 124.5| 13.7%|\n|1|wiki|title|val|1|1000| 386435|   2.1|  46.5|   2.4|  12.7|-72.7%|\n|1|wiki|title|ordsub|1|1000| 386435|   2.1|  46.5|   2.1|  60.7| 30.5%|\n|1|wiki|title|ordval|1|1000| 386435|   2.1|  46.5|   2.1|  61.3| 31.8%|\n|1|wiki|title|orddem|1|1000| 386435|   2.1|  46.5|   2.1|  61.0| 31.2%|\n|1|wiki|title|orddem2|1|1000| 386435|   2.1|  46.5|   2.1|  60.8| 30.8%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|1000|2000000|   0.8|   9.7|   0.6|  11.7| 20.6%|\n|10|simple|country|ordsub|text|1000|2000000|   0.8|   9.7|   0.6|  13.4| 38.1%|\n|10|simple|country|ordval|text|1000|2000000|   0.8|   9.7|   0.6|  13.6| 40.2%|\n|10|simple|country|orddem|text|1000|2000000|   0.8|   9.7|   0.6|  13.6| 40.2%|\n|10|simple|country|orddem2|text|1000|2000000|   0.8|   9.7|   0.6|  13.5| 39.2%|\n|10|wiki|title|val|147|1000|   4984|  12.6| 659.2|   2.3| 406.4|-38.3%|\n|10|wiki|title|ordsub|147|1000|   4984|  12.6| 659.2|   2.7|  68.6|-89.6%|\n|10|wiki|title|ordval|147|1000|   4984|  12.6| 659.2|   2.1|  86.4|-86.9%|\n|10|wiki|title|orddem|147|1000|   4984|  12.6| 659.2|   2.1| 117.8|-82.1%|\n|10|wiki|title|orddem2|147|1000|   4984|  12.6| 659.2|   2.1| 288.0|-56.3%|\n|10|wiki|title|val|text|1000|  97191|  12.7| 101.2|   2.4|  33.9|-66.5%|\n|10|wiki|title|ordsub|text|1000|  97191|  12.7| 101.2|   2.7|  68.8|-32.0%|\n|10|wiki|title|ordval|text|1000|  97191|  12.7| 101.2|   2.2|  83.1|-17.9%|\n|10|wiki|title|orddem|text|1000|  97191|  12.7| 101.2|   2.2|  87.4|-13.6%|\n|10|wiki|title|orddem2|text|1000|  97191|  12.7| 101.2|   2.2| 100.8| -0.4%|\n|10|wiki|title|val|1|1000| 386435|  12.7|  42.3|   2.5|  14.5|-65.7%|\n|10|wiki|title|ordsub|1|1000| 386435|  12.7|  42.3|   2.7|  46.4|  9.7%|\n|10|wiki|title|ordval|1|1000| 386435|  12.7|  42.3|   2.2|  53.0| 25.3%|\n|10|wiki|title|orddem|1|1000| 386435|  12.7|  42.3|   2.2|  54.7| 29.3%|\n|10|wiki|title|orddem2|1|1000| 386435|  12.7|  42.3|   2.2|  57.4| 35.7%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|36|wiki|title|val|147|1000|   4984|  42.1| 609.6|   2.3| 358.5|-41.2%|\n|36|wiki|title|ordsub|147|1000|   4984|  42.1| 609.6|   2.7|  37.6|-93.8%|\n|36|wiki|title|ordval|147|1000|   4984|  42.1| 609.6|   2.2|  58.2|-90.5%|\n|36|wiki|title|orddem|147|1000|   4984|  42.1| 609.6|   2.1| 113.6|-81.4%|\n|36|wiki|title|orddem2|147|1000|   4984|  42.1| 609.6|   2.1| 258.2|-57.6%|\n|36|wiki|title|val|text|1000|  97191|  42.4|  98.5|   2.4|  34.1|-65.4%|\n|36|wiki|title|ordsub|text|1000|  97191|  42.4|  98.5|   2.7|  39.1|-60.3%|\n|36|wiki|title|ordval|text|1000|  97191|  42.4|  98.5|   2.2|  65.1|-33.9%|\n|36|wiki|title|orddem|text|1000|  97191|  42.4|  98.5|   2.2|  85.9|-12.8%|\n|36|wiki|title|orddem2|text|1000|  97191|  42.4|  98.5|   2.2|  94.9| -3.7%|\n|36|wiki|title|val|1|1000| 386435|  42.0|  44.2|   2.4|  14.5|-67.2%|\n|36|wiki|title|ordsub|1|1000| 386435|  42.0|  44.2|   2.7|  30.7|-30.5%|\n|36|wiki|title|ordval|1|1000| 386435|  42.0|  44.2|   2.2|  47.6|  7.7%|\n|36|wiki|title|orddem|1|1000| 386435|  42.0|  44.2|   2.3|  54.9| 24.2%|\n|36|wiki|title|orddem2|1|1000| 386435|  42.0|  44.2|   2.2|  56.8| 28.5%|\n\n\nqueue=10\n\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|1|simple|country|val|text|10|2000000|   0.6|  10.6|   0.7|  12.4| 17.0%|\n|1|simple|country|ordsub|text|10|2000000|   0.6|  10.6|   0.6|  14.5| 36.8%|\n|1|simple|country|ordval|text|10|2000000|   0.6|  10.6|   0.6|  14.6| 37.7%|\n|1|simple|country|orddem|text|10|2000000|   0.6|  10.6|   0.6|  14.6| 37.7%|\n|1|simple|country|orddem2|text|10|2000000|   0.6|  10.6|   0.6|  14.6| 37.7%|\n|1|wiki|title|val|147|10|   4984|   2.1|3727.4|   2.3|2546.8|-31.7%|\n|1|wiki|title|ordsub|147|10|   4984|   2.1|3727.4|   2.0|4537.5| 21.7%|\n|1|wiki|title|ordval|147|10|   4984|   2.1|3727.4|   2.0|4568.1| 22.6%|\n|1|wiki|title|orddem|147|10|   4984|   2.1|3727.4|   2.1|4552.5| 22.1%|\n|1|wiki|title|orddem2|147|10|   4984|   2.1|3727.4|   2.0|4537.5| 21.7%|\n|1|wiki|title|val|text|10|  97191|   2.1| 143.4|   2.3|  39.2|-72.7%|\n|1|wiki|title|ordsub|text|10|  97191|   2.1| 143.4|   2.1| 165.5| 15.4%|\n|1|wiki|title|ordval|text|10|  97191|   2.1| 143.4|   2.1| 167.7| 16.9%|\n|1|wiki|title|orddem|text|10|  97191|   2.1| 143.4|   2.1| 167.7| 16.9%|\n|1|wiki|title|orddem2|text|10|  97191|   2.1| 143.4|   2.1| 168.2| 17.3%|\n|1|wiki|title|val|1|10| 386435|   2.1|  51.8|   2.4|  13.7|-73.6%|\n|1|wiki|title|ordsub|1|10| 386435|   2.1|  51.8|   2.1|  66.3| 28.0%|\n|1|wiki|title|ordval|1|10| 386435|   2.1|  51.8|   2.1|  69.5| 34.2%|\n|1|wiki|title|orddem|1|10| 386435|   2.1|  51.8|   2.1|  69.5| 34.2%|\n|1|wiki|title|orddem2|1|10| 386435|   2.1|  51.8|   2.1|  69.5| 34.2%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|10|simple|country|val|text|10|2000000|   0.7|  10.2|   0.5|  12.2| 19.6%|\n|10|simple|country|ordsub|text|10|2000000|   0.7|  10.2|   0.5|  14.2| 39.2%|\n|10|simple|country|ordval|text|10|2000000|   0.7|  10.2|   0.5|  14.5| 42.2%|\n|10|simple|country|orddem|text|10|2000000|   0.7|  10.2|   0.5|  14.4| 41.2%|\n|10|simple|country|orddem2|text|10|2000000|   0.7|  10.2|   0.5|  14.4| 41.2%|\n|10|wiki|title|val|147|10|   4984|  12.5|2943.0|   2.3|1761.1|-40.2%|\n|10|wiki|title|ordsub|147|10|   4984|  12.5|2943.0|   2.1|3035.3|  3.1%|\n|10|wiki|title|ordval|147|10|   4984|  12.5|2943.0|   2.1|3325.2| 13.0%|\n|10|wiki|title|orddem|147|10|   4984|  12.5|2943.0|   2.1|3481.8| 18.3%|\n|10|wiki|title|orddem2|147|10|   4984|  12.5|2943.0|   2.1|3574.1| 21.4%|\n|10|wiki|title|val|text|10|  97191|  12.6| 139.2|   2.4|  39.3|-71.8%|\n|10|wiki|title|ordsub|text|10|  97191|  12.6| 139.2|   2.1| 161.7| 16.2%|\n|10|wiki|title|ordval|text|10|  97191|  12.6| 139.2|   2.2| 165.2| 18.7%|\n|10|wiki|title|orddem|text|10|  97191|  12.6| 139.2|   2.1| 165.4| 18.8%|\n|10|wiki|title|orddem2|text|10|  97191|  12.6| 139.2|   2.1| 166.3| 19.5%|\n|10|wiki|title|val|1|10| 386435|  12.6|  50.4|   2.4|  15.5|-69.2%|\n|10|wiki|title|ordsub|1|10| 386435|  12.6|  50.4|   2.1|  65.8| 30.6%|\n|10|wiki|title|ordval|1|10| 386435|  12.6|  50.4|   2.1|  68.1| 35.1%|\n|10|wiki|title|orddem|1|10| 386435|  12.6|  50.4|   2.1|  67.9| 34.7%|\n|10|wiki|title|orddem2|1|10| 386435|  12.6|  50.4|   2.2|  67.8| 34.5%|\n||numSeg||index||sortBy||method||query||topN||hits||warm||qps||warmnew||qpsnew||pctg||\n|36|wiki|title|val|147|10|   4984|  42.0|2137.0|   2.3|1143.0|-46.5%|\n|36|wiki|title|ordsub|147|10|   4984|  42.0|2137.0|   2.1|1641.5|-23.2%|\n|36|wiki|title|ordval|147|10|   4984|  42.0|2137.0|   2.1|2046.0| -4.3%|\n|36|wiki|title|orddem|147|10|   4984|  42.0|2137.0|   2.1|2203.9|  3.1%|\n|36|wiki|title|orddem2|147|10|   4984|  42.0|2137.0|   2.1|2215.3|  3.7%|\n|36|wiki|title|val|text|10|  97191|  42.2| 135.2|   2.4|  39.8|-70.6%|\n|36|wiki|title|ordsub|text|10|  97191|  42.2| 135.2|   2.1| 149.9| 10.9%|\n|36|wiki|title|ordval|text|10|  97191|  42.2| 135.2|   2.1| 154.9| 14.6%|\n|36|wiki|title|orddem|text|10|  97191|  42.2| 135.2|   2.1| 154.9| 14.6%|\n|36|wiki|title|orddem2|text|10|  97191|  42.2| 135.2|   2.2| 155.0| 14.6%|\n|36|wiki|title|val|1|10| 386435|  41.9|  49.7|   2.4|  15.7|-68.4%|\n|36|wiki|title|ordsub|1|10| 386435|  41.9|  49.7|   2.2|  65.9| 32.6%|\n|36|wiki|title|ordval|1|10| 386435|  41.9|  49.7|   2.2|  67.4| 35.6%|\n|36|wiki|title|orddem|1|10| 386435|  41.9|  49.7|   2.1|  67.9| 36.6%|\n|36|wiki|title|orddem2|1|10| 386435|  41.9|  49.7|   2.2|  67.7| 36.2%|\n\n\n",
            "date": "2009-01-16T20:11:46.631+0000",
            "id": 235
        },
        {
            "author": "Mark Miller",
            "body": "Nice Mike! Those results look great. Do we want to keep the policy idea if we don't end up using any that switch comparators? I'd also like to see if sorting readers by size really does any good.\n\n>>I think for a custom sort we should allow user to pass in a ComparatorPolicy?\n\nYeah def. If we keep the policies, we should rip out the custom comparator and allow for a custom policy.",
            "date": "2009-01-16T20:34:17.526+0000",
            "id": 236
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Do we want to keep the policy idea if we don't end up using any that switch comparators?\n\nGood question.  I think we should not keep it -- all our attempts to use it to improve performance have not succeeded.  And then we can stick with FieldComparatorSource for custom sorting.  I'll make this change.\n\nbq. I'd also like to see if sorting readers by size really does any good. \n\nI think this likely does help, because if you visit the largest segment first, your queue will tend to quickly get most of its inserts out of the way.  ORDDEM2 is fastest on the first segment because all ORDs are comparable.  I think this'll matter most for indexes that have many deletions, such that the old large segments contain many deletes (in which case they are sorted later).",
            "date": "2009-01-16T20:42:01.797+0000",
            "id": 237
        },
        {
            "author": "Michael McCandless",
            "body": "New patch w/ ComparatorPolicy removed.",
            "date": "2009-01-16T22:17:15.267+0000",
            "id": 238
        },
        {
            "author": "Michael McCandless",
            "body": "Woops, last one had compilation errors in contrib/benchmark... this one should work.",
            "date": "2009-01-16T22:24:47.520+0000",
            "id": 239
        },
        {
            "author": "Mark Miller",
            "body": "Re: The FieldCache loading problem with MultiSegmentReader\n\nI think this is just the overhead cost associated with how we currently handle this.\n\nTo load a FieldCache for a single segment we get a SegmentTermDocs and just keep calling next, which basically just calls readbyte and readint over and over on the index. Pretty efficient. Do it for each term to be loaded.\n\nTo load a FieldCache for multiple segments we get a MultiSegmentReader to get  MultiTermDocs. As we call next on MultiTermDocs it will get a TermDocs for each Reader and call seek to get to the Term. The seek appears pretty slow, and we do it for the number of Readers x the number of Terms to be loaded. \n\nUnder seek, TermInfosReader.get looks slow with SegmentTermeEnum.scanTo looking to be the worst offender under it.\n\nAll in all though, there is just a big difference in whats going on, that compounds with more segments.\n\n- Mark\n",
            "date": "2009-01-17T23:34:05.581+0000",
            "id": 240
        },
        {
            "author": "Mark Miller",
            "body": "Or put in another way:\n\nthe single segment version, with about 20000 terms for a field will seek on one segment about 20,000 times, once for each term.\n\na multisegment version over 79 segments will seek about 1,580,000 times. The MultiSegment seek for each term is pretty much free, so I dont count that, but you seek on each term for each individual segment as you call next on the TermDocs. If your terms are spread across all of the segments, its not even much cheaper on any given segment to do the seek.",
            "date": "2009-01-18T00:24:51.068+0000",
            "id": 241
        },
        {
            "author": "Mark Miller",
            "body": "Cool - this problem affects other things too, like SpanQueries. This will be a good boost for them as well if you have more than a few segments. Same with the multi term queries I think (enumeration should be faster). This patch is going to be dope for performance all around.",
            "date": "2009-01-18T02:45:17.278+0000",
            "id": 242
        },
        {
            "author": "Mark Miller",
            "body": "Whoops. As usual, getting ahead of myself. Perhaps there won't be big gains with those other queries.\n\nWhile there is  a big difference between searching a single segment vs multisegments for these things, we already knew about that - thats why you optimize.\n\nEven when we search each individual indexsearcher with a single hit queue (this patch), we have to load the field cache for each segment and do a seek, the same as the old method with the multireader. One seek for each reader for each term.\n\nHowever, it still appears that we get to do WAY fewer seeks this way - for my last example, maybe like 40000 seeks. Quite a bit better than 1.5 million. But why?\n\nPerhaps its because we can use only the terms from each segment. Then, rather than num readers X total unique terms seeks, you have the sum of unique terms per index seeks. That could count for a lot of saved seeks, but I am not sure that it accounts for all of them (1.5 mil to 40,000 is quite the drop). Beyond all the saved seeks though, I imagine its more efficient to hit the same reader n times, than to hit each reader round robin n times. Something makes me think there is something else that allows us to avoid seeks, but not sure what yet...",
            "date": "2009-01-18T03:30:25.341+0000",
            "id": 243
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. As we call next on MultiTermDocs it will get a TermDocs for each Reader and call seek to get to the Term. The seek appears pretty slow, and we do it for the number of Readers x the number of Terms to be loaded.\n\nRight -- the uninverting we do to populate the FieldCache is very\ncostly through MultiReader for fields that are mostly unique String\n(eg a title field, or a \"primary key\" id field, etc.).\n\nEnum type fields (like country) don't have this problem (1.0 sec vs\n0.6 sec to populate FieldCache through MultiReader for the 100 segment\nindex).\n\nBut, with this change, we sidestep this problem for Lucene's core, but\nfor apps that directly load FieldCache for the MultiReader the problem\nis still there.\n\nOnce we have column stride fields (LUCENE-1231) it should then be far\nfaster to load the FieldCache for unique String fields.\n\nbq. While there is a big difference between searching a single segment vs multisegments for these things, we already knew about that - thats why you optimize.\n\nRight, but for realtime search you don't have the luxury of\noptimizing.  This patch makes warming time after reopen much faster\nfor a many-segment index for apps that use FieldCache with mostly unique String\nfields.\n",
            "date": "2009-01-18T11:11:09.081+0000",
            "id": 244
        },
        {
            "author": "Mark Miller",
            "body": "I think its pretty costly even for non id type fields. In your enum case, their are what, 50 unique  values? Even still, you are seeing like a 40% diff, but small enough times to not matter.\n\nMy test example has 20,000 unique terms for 600,000 documents (lots of overlap, 2-8 char strings, 1-9, I think), so quite a bit short of a primary key - but it still was WAY faster with the new method.\n\nOld method non optimized, 79 segments - 1.5 million seeks, WAY slow.\nOld method, optimized, 1 segment - 20,000 seeks, pretty darn fast.\nNew method, non optimized, 79 segments - 40,000 seeks, pretty darn fast.\n\n\nbq.    While there is a big difference between searching a single segment vs multisegments for these things, we already knew about that - thats why you optimize.\n\n{quote}Right, but for realtime search you don't have the luxury of\noptimizing. This patch makes warming time after reopen much faster\nfor a many-segment index for apps that use FieldCache with mostly unique String\nfields.{quote}\n\nRight, I got you - I know we can't optimize. I was just realizing that explaining why 100 segments was so slow was not explaining why the new method on 100 segments was so fast. I still don't think I fully have why that is. I don't think getting to use the unique terms at each segment saves enough seeks for what I am seeing. Especially in this test case, the terms should be pretty evenly distributed across segments...\n",
            "date": "2009-01-18T14:06:30.851+0000",
            "id": 245
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. Even still, you are seeing like a 40% diff, but small enough times to not matter. \n\nRight, good point.\n\nI think the massive slowness of iterating through all terms & docs\nfrom a MultiTermEnum/Docs may come from asking the N-1 SegmentReaders\nto seek to a non-existent (for them) term.\n\nIe when we ask MultiTermDocs to seek to a unique title X, only the\nparticular segment that title X comes from actually has it, whereas\nthe others do a costly seek to the index term just before it then scan\nto look for the non-existent term, and then repeat that for the next\ntitle, etc.\n\nIn fact this probably causes the underlying buffer in\nBufferedIndexReader to get reloaded many times whenever we cross a\nboundary (ie, we keep flipping between buffer N and N+1, then back to\nN then N+1 again, etc.) -- maybe that's the source massive slowness?\n\nBTW I think this change may also speed up Range/PrefixQuery as well.\n",
            "date": "2009-01-18T16:36:50.388+0000",
            "id": 246
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. think the massive slowness of iterating through all terms & docs from a MultiTermEnum/Docs may come from asking the N-1 SegmentReaders to seek to a non-existent (for them) term.\n\nI've seen cases where the MultiTermEnum was the bottleneck (compared to the MultiTermDocs) when iterating over all docs for all terms in a field.  But quickly looking at the code, MultiTermEnum.next() looks pretty efficient.",
            "date": "2009-01-18T16:58:01.063+0000",
            "id": 247
        },
        {
            "author": "Mark Miller",
            "body": "My previous results had a few oddities going with them (I was loosely playing around). Being a little more careful, here is an example of the difference, and the hotspots. Timings are probably not completely comparable as my comp couldnt keep up profiling the second version very well - its much slower without profiling as well though:\n\nIndex is 600000 docs, 46 segments\n\nLoad the fieldcache on one multireader\n\n||method||time||invocations||\n|FieldCacheImpl.createValue|156536(98%)|1|\n|MultiTermDocs.next()|148499(93.5%)|621803|\n|MutliTermDocs(int)|140397(88.4%)|1002938|\n|SegmentTermDocs.seek(Term)|138332(87.1%)|1002938|\n\nload the fieldcache on each sub reader of the multireader, one at a time\n\n||method||time||invocations||\n|FieldCacheImpl.createValue|7815(80.4%)|46|\n|SegmentTermDocs.next()|3315(34.1%)|642046|\n|SegmentTermEnum.next()|1936(19.9%)|42046|\n|SegmentTermDocs.seek(TermEnum)|874(9%)|42046|\n\n\n*edit*\nwrong values\n\n\n\n",
            "date": "2009-01-18T17:20:20.829+0000",
            "id": 248
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nIn fact this probably causes the underlying buffer in\nBufferedIndexReader to get reloaded many times whenever we cross a\nboundary\n{quote}\nOK I was wrong about this -- there is logic in TermInfosReader.get to not go backwards to the last index term.  So we are in fact reading each tis file sequentially...",
            "date": "2009-01-18T18:04:58.676+0000",
            "id": 249
        },
        {
            "author": "Mark Miller",
            "body": "Okay, I think I have it. I tried to count the terms per segment by getting a term enum and looping through it for each sub reader, but something must have been off with that count. Taking a second look with checkindex, and all of the docs / terms are piled into the first couple segments - the rest are a long tail with few terms. So it makes sense then - for every segment with few terms in it, all of the unique terms for the whole index get checked against it. A segment with even 1 term will be hit against for every unique term in the whole index. Thats what was happening in this case, as its like a logarithmic drop. I'll try playing around some more with less of a thin tail end of segments, but I guess that is enough to explain the drop in seeks in this case.",
            "date": "2009-01-18T22:27:08.054+0000",
            "id": 250
        },
        {
            "author": "Michael McCandless",
            "body": "I'm working on another iteration of this patch, cleaning things up, adding javadocs, etc., in preparation for committing...",
            "date": "2009-01-19T11:24:48.446+0000",
            "id": 251
        },
        {
            "author": "Michael Busch",
            "body": "Mark and Mike,\n\nthis issue and the patch are amazingly long and catching up here after vacation is pretty hard. Maybe you could update the description of this issue with a summary (maybe a bullet list?) that describes the main goals and changes here? That would be great...",
            "date": "2009-01-19T22:13:48.402+0000",
            "id": 252
        },
        {
            "author": "Mark Miller",
            "body": "Here is a start at a better summary. It could be improved.",
            "date": "2009-01-19T22:48:40.770+0000",
            "id": 253
        },
        {
            "author": "Mark Miller",
            "body": "Okay, its not a handbook, but this should be a much better summary. Hopefully I didnt miss anything too major.",
            "date": "2009-01-19T23:15:28.229+0000",
            "id": 254
        },
        {
            "author": "Michael McCandless",
            "body": "\nOK I made a bunch of small fixes.\n\nWith this patch there is one back-compat test failing\n(TestScorerPerf), because it seems to assume that a searcher on an\nindex with 0 segments will call Scorer.collect(HitCollector).  We used\nto do so, but no longer as of this patch, and I don't think it's a\nreasonable assumption, so I plan to commit a small fix to the test on\nthe back compat branch (and trunk) to add a single empty doc to the\nindex.\n\nOne thing worries me: we changed TopDocCollector to subclass\nMultiReaderHitCollector instead of HitCollector, which means it\n(TopDocCollector) now tracks docBase.  But this means subclasses of\nTopDocCollector will suddenly see the not-rebased docID passed to\ntheir collect methods, resulting in a hard to detect bug for the app.\n\nMaybe we should leave TopDocCollector how it was, and make a new\nTopDocCollector (any name suggestion?) that subclasses from\nMultiReaderHitCollector?\n\nChanges:\n\n  * Renamed StringOrdValOnDem2Comparator --> StringOrdValComparator;\n    commented out the other String*Comparator except for StringVal\n\n  * Switched over to sorted sub-readers for all searching in\n    IndexSearcher\n\n  * Moved sub-reader sorting to IndexSearcher's ctor\n\n  * Also removed SortField.STRING* except for STRING (uses\n    StringOrdValComparator) and STRING_VAL (uses StringValComparator)\n\n  * Changed FieldComparatorSource from interface --> abstract class;\n    removed Serializable\n\n  * Moved the \"set legacy sort when using legacy custom sort\" logic\n    into SortField out of IndexSearcher\n\n  * Fixed TimeLimitedCollector, ParallelMultiSearcher, MultiSearcher\n    to \"pass down\" MultiReaderHitCollector if that's what they were\n    passed in, else wrap the HitCollector\n\n  * Added test in TestSort to test FieldComparatorSource (custom\n    sort)\n\n  * Addressed/removed all nocommits, removed dead code\n\n  * Added some javadocs; removed unused imports\n\n  * Fixed whitespace\n\n  * Added entries to CHANGES.txt\n",
            "date": "2009-01-21T20:14:00.132+0000",
            "id": 255
        },
        {
            "author": "Mark Miller",
            "body": "Nice work Mike - pretty polished. I've spent a little time looking it over, but I'm going to look more tonight. Everything looking pretty good to me.\n\nNot sure what to name that new class, but here are some ideas:\n\nTopScoreDocCollector\nTopHitCollector\nTopResultCollector\nTopMatchCollector\nTopCollector\nTopScoreCollector\n\nCould be a low score, so that last one is odd, but I guess the low would kind of be the top...\n*edit*\nnevermind...I was thinking lowest score could be considered top match, but it wouldnt be the case with this hitcollector implementation, so I guess it makes as much sense as any of the others.\n\n",
            "date": "2009-01-22T15:02:30.534+0000",
            "id": 256
        },
        {
            "author": "Michael McCandless",
            "body": "OK I named it \"TopScoreDocCollector\" and left TopDocCollector as it was.  New patch attached.\n\nI think this is finally ready to commit!  I'll wait a few days for any comments...",
            "date": "2009-01-23T11:59:28.687+0000",
            "id": 257
        },
        {
            "author": "Mark Miller",
            "body": "I went over all of the diffs for a while last night - I didn't see anything that seemed worth putting up a patch for. All of the tweaks, fixes, polish looks great to me. All tests also passing for me.\n\n+1 on committing in a few days barring any objections.\n",
            "date": "2009-01-23T13:24:06.630+0000",
            "id": 258
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Michael & Mike,\ngreat work. I patched my tree and compiled, no problems. One test failed with the following exception:\n{code}\n<testcase classname=\"org.apache.lucene.benchmark.quality.TestQualityRun\" name=\"testTrecQuality\" time=\"64.656\">\n  <error type=\"java.lang.NullPointerException\">java.lang.NullPointerException\n\tat org.apache.lucene.benchmark.byTask.feeds.ReutersDocMaker.getNextDocData(ReutersDocMaker.java:112)\n\tat org.apache.lucene.benchmark.byTask.feeds.BasicDocMaker.makeDocument(BasicDocMaker.java:98)\n\tat org.apache.lucene.benchmark.byTask.tasks.AddDocTask.setup(AddDocTask.java:61)\n\tat org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:89)\n\tat org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doSerialTasks(TaskSequence.java:141)\n\tat org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doLogic(TaskSequence.java:122)\n\tat org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:92)\n\tat org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doSerialTasks(TaskSequence.java:141)\n\tat org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doLogic(TaskSequence.java:122)\n\tat org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:92)\n\tat org.apache.lucene.benchmark.byTask.utils.Algorithm.execute(Algorithm.java:246)\n\tat org.apache.lucene.benchmark.byTask.Benchmark.execute(Benchmark.java:73)\n\tat org.apache.lucene.benchmark.byTask.TestPerfTasksLogic.execBenchmark(TestPerfTasksLogic.java:455)\n\tat org.apache.lucene.benchmark.quality.TestQualityRun.createReutersIndex(TestQualityRun.java:173)\n\tat org.apache.lucene.benchmark.quality.TestQualityRun.testTrecQuality(TestQualityRun.java:56)\n  </error>\n</testcase>\n{code}\nI am not sure if this failing test have anything to do with the patch.\n\nI then tested the resulting lucene-core.jar as a drop-in-replacement for my big portal (www.pangaea.de) - as we are waiting for the optimized reopen with sorted search results here since months. In my test environment I got no errors/exception etc. After tests, I set it online on my productive system (I will look into the error logs of the webserver for exceptions).\n\nThe speed increase of a sorted search after a reopen of the index (600,000 docs), that only added some documents into a new cfs segment, is incredible. In the past, the warmup for filling the field cache was about 3 seconds - now it shows up without any recognizable time. So no warmup after reopen is needed anymore.\n\nOne thing I noticed when compiling my code against the new lucene-core.jar:\nTop(Field)Docs deprecated the method getMaxScore(). Why is this so? To display search results with a score normalized to 1.0, you need to divide by the maximum score. The docs say, you should implement your own HitCollector (why that, I want to use TopDocs?), but why does TopDocs deprecate the maximum score? OK, for relevance/score sorted TopDocs, this is no problem, as the maximum score is in ScoreDoc[0], but for docs sorted by fields (which extends TopFieldDoc), you need the max score. If you have generic search code that does not distinguish between TopDocs and TopFieldDocs, the generic code is to divide by TopDocs.getMaxScore().\n\nI am happy, +1 for commiting. But let getMaxScore live after Lucene 3.0!",
            "date": "2009-01-23T15:54:43.127+0000",
            "id": 259
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. One test failed with the following exception: \n\nCould you try removing your contrib/benchmark/work directory and see\nif the test then passes?  I've seen similar exceptions in the past where\nsomehow the reuters docs weren't properly unpacked.\n\nbq. In my test environment I got no errors/exception etc. After tests, I set it online on my productive system (I will look into the error logs of the webserver for exceptions).\n\nThat's good to hear!  Please report back if you get excetpions in the\nproduction system... (and thanks for that vote of confidence!).\n\nbq. In the past, the warmup for filling the field cache was about 3 seconds - now it shows up without any recognizable time. So no warmup after reopen is needed anymore.\n\nExcellent!  This was the primary (original) goal here...\n\nSpeedup on warming should be even better when you sort by textual\nfields that have a highish number of unique terms.\n\nbq. OK, for relevance/score sorted TopDocs, this is no problem, as the maximum score is in ScoreDoc[0], but for docs sorted by fields (which extends TopFieldDoc), you need the max score. If you have generic search code that does not distinguish between TopDocs and TopFieldDocs, the generic code is to divide by TopDocs.getMaxScore().\n\nOK I agree we should un-deprecate this and keep it; I'll do that.\n\nThanks for reviewing this Uwe!\n",
            "date": "2009-01-23T16:15:50.509+0000",
            "id": 260
        },
        {
            "author": "Uwe Schindler",
            "body": "{quote}\nbq. One test failed with the following exception: \nCould you try removing your contrib/benchmark/work directory and see\nif the test then passes? I've seen similar exceptions in the past where\nsomehow the reuters docs weren't properly unpacked.\n{quote}\nTest passes now, sorry for the false alarm.\n\nbq. Speedup on warming should be even better when you sort by textual fields that have a highish number of unique terms.\nI was looking after the initial warmup, but noticed no difference. Maybe the string field I used was not distinct enough. What is a good number for a noticeable speed improve (50% distinct terms?).\n\nDuring reviewing my TrieRangeQuery/-Filter code, I noticed, that TrieRangeFilter.getDocIdSet() is executed separately for each segment now (this is clear to me). The test case should also return the number of terms visited during the split of the trie range on stdout. As each segment was searched separate, the statistics about terms was incorrect (because the range statistics were reset on each getDocIdSet() call). I changed the test case to optimize the index before testing the TrieRangeQuery to have only one segment, to show the real trie range split stats.",
            "date": "2009-01-23T16:55:30.052+0000",
            "id": 261
        },
        {
            "author": "Mark Miller",
            "body": "bq. I was looking after the initial warmup, but noticed no difference. Maybe the string field I used was not distinct enough. What is a good number for a noticeable speed improve (50% distinct terms?).\n\nHes not saying after the warm up, but that the warm up should be faster based on that.\n\nIts because of this:\n\nThe old way, if you had 5 segments with unique terms distributions of 50,000, 6000, 6000, 5, 5, then for the old way, we would try to load all 62,010 terms for every segment - 62,010 x 5 -310,050.\n\nWith the new way, we load 50,000 terms for the first, 6000 for the next, then 6000, then 5 and 5: total of 62,010.\n\nEven though most of the 62,010 wont be found in the 5 term segment, it still takes a long time to check them all. So the more unique terms and the more segments, the worse the problem got.\n\n*edit*\nlittle fix on those numbers",
            "date": "2009-01-23T17:05:42.107+0000",
            "id": 262
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. Hes not saying after the warm up, but that the warm up should be faster based on that.\nI meant not \"looking *after* the initial warmup\", I meant \"looking *for* the initial warmup\" :-). The speed difference for the initial warmup was neglectible for my index (not optimized). But I did not know, how many segments and terms the index really had. I can find this out for a better test-case here. I keep you informed.",
            "date": "2009-01-23T17:19:18.078+0000",
            "id": 263
        },
        {
            "author": "Michael McCandless",
            "body": "\nNew patch:\n\n  * Un-deprecate TopDocs.get/setMaxScore\n\n  * Made IndexSearcher.sortSubReaders protected so a subclass can\n    change it\n\n  * Added logic in IndexSearcher to recursively expand sub-readers, so\n    eg a MultiReader containing several MultiSegmentReaders would\n    visit the SegmentReaders one by one.\n\n  * Small javadoc fixes\n\n",
            "date": "2009-01-23T19:49:38.861+0000",
            "id": 264
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. Un-deprecate TopDocs.get/setMaxScore \n\nFine, now my code compiles without deprecation warnings.\n\nbq. Added logic in IndexSearcher to recursively expand sub-readers, so eg a MultiReader containing several MultiSegmentReaders would visit the SegmentReaders one by one. \n\nThis is even better, when I looked into the code, I was thinking about that, too. I have portals consisting of many separate indexes, concenated with MultiReader. With your new patch, the Searcher will use all readers downto the lowest, single segment of each index.\n\nBy the way: No warnings or exceptions here until now.",
            "date": "2009-01-23T21:56:18.805+0000",
            "id": 265
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi again,\nI found a small problem with getSequentialReaders() and your recursion. In my opinion, the whole problem is the way, how getSequentialReaders() is defined in IndexReader.\n\nFirst the problem:\nIf you create an MultiReader consisting of only one IndexReader (this can be the case if you supply 3 indexes in a user interface and the user can check them for searching. If the user only checks one, the MultiReader will contain one). The recursion in IndexSearcher.gatherSubReaders() stops, when the count is 1. If this one reader is a unoptimized index (a MultiSegmentReader), the sub-readers are not gathered.\n\nIn my opinion, I would do it in another way:\na) rename getSequentialReaders() into getSubReaders(). IndexReader.getSubReaders returns an empty array or null (because it has no sub readers). Multi(Segment)Reader returns the sub-readers.\nb) gatherSubReaders then looks like this:\n{code}\n  protected void gatherSubReaders(List allSubReaders, IndexReader r) {\n    IndexReader[] subReaders = r.getSubReaders();\n    if (subReaders == null || subReaders.length == 0) {\n      allSubReaders.add(r);\n    } else {\n      for(int i=0;i<subReaders.length;i++) {\n        gatherSubReaders(allSubReaders, subReaders[i]);\n      }\n    }\n  }\n{code}\n\nIn my opinion, this is the cleaner way. Returning a one-entry-array containing itsself in getSequentialReader() is not clean and can lead to endless loops if used wrongly.",
            "date": "2009-01-23T23:38:58.445+0000",
            "id": 266
        },
        {
            "author": "Michael McCandless",
            "body": "Excellent!  I like that solution.  I'll make that change.",
            "date": "2009-01-23T23:48:51.332+0000",
            "id": 267
        },
        {
            "author": "Michael McCandless",
            "body": "Though... I think I still like getSequentialReaders?  EG, some readers might have subreaders that are not \"sequential\", eg ParallelReader already defines getSubReaders() but we cannot treat them sequentially.",
            "date": "2009-01-23T23:50:16.094+0000",
            "id": 268
        },
        {
            "author": "Michael McCandless",
            "body": "And... if an empty list is returned I think that should mean this reader has no sub-readers, ie, it can be skipped?  EG a MultiSegmentReader with 0 segments.\n\nSo null --> I cannot be split into sub-readers; empty array --> I am a null reader; array.length > 0 --> I do have sequential sub-readers?",
            "date": "2009-01-23T23:54:27.905+0000",
            "id": 269
        },
        {
            "author": "Uwe Schindler",
            "body": "You are right, I noticed that when I started to prepared a patch and wondered about failed tests :-) The name-clash and backwards compatibility needs this. So getSequentialReaders() or getSequentialSubReaders() is ok. With the same name, a ParallelReader used in a IndexSearcher would crash the whole thing.",
            "date": "2009-01-23T23:56:44.458+0000",
            "id": 270
        },
        {
            "author": "Uwe Schindler",
            "body": "by the way: The package private method getSubReaders in MultiSegmentReader can be removed, it is not used in the test (which uses getSequentialReader).",
            "date": "2009-01-23T23:57:57.471+0000",
            "id": 271
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. So null --> I cannot be split into sub-readers; empty array --> I am a null reader; array.length > 0 --> I do have sequential sub-readers?\n\nThis is a good optimization. If a MultiReader would return null instead of an empty array, it wouldn't be a problem (the empty reader would be searched with no results). But returning an empty array is better in this case. So gatherSubReaders() should only check for (null) and then add the parent reader itsself to the List and in all other cases do the recursion.",
            "date": "2009-01-24T00:06:02.059+0000",
            "id": 272
        },
        {
            "author": "Michael McCandless",
            "body": "OK I will rename to getSequentialSubReaders, with the semantics above.\n\nbq. by the way: The package private method getSubReaders in MultiSegmentReader can be removed, it is not used in the test (which uses getSequentialReader).\n\nYeah, but then \"ant test-tag\" fails to compile.  But I agree, we should fix it (and I'll commit the fix to back-compat branch at the same time) and MultiReader's getSubReaders too.  Probably we should plant tags along the back-compat branch and reference that tag in build.xml, this way if others have a checkout ant run \"ant test-tag\" they won't see compile failures if they haven't yet updated this commit.  I'll do that.",
            "date": "2009-01-24T00:19:38.219+0000",
            "id": 273
        },
        {
            "author": "Michael McCandless",
            "body": "New patch.  I'm attaching the actual patch plus the \"back compat\"\nchanges patch.  In order to run with these patches you should 1) run\n\"ant test-tag\" so it checks out the back-compat branch under \"tags\",\n2) apply the main patch, 3) apply the back-compat patch on your\ntags/... sources, then run \"ant test test-tag\".\n\nChanges:\n\n  * Renamed to getSequentialSubReaders, which returns null (use me\n    directly), empty array (I am a null reader), or non-empty array (I\n    do have sub-readers)\n\n  * Removed the \"for testing\" package private\n    Multi*Reader.getSubReaders methods since they are the same as\n    getSequentialSubReaders.\n",
            "date": "2009-01-24T10:59:51.085+0000",
            "id": 274
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Mike,\n\nlooks good. I did not yet test the backwards compat one. I forget yesterday to add one other note:\nin sortSubReaders is an unneeded System.arraycopy(). This was needed before, when you did not have the List for collecting the subreaders. Now the array is coped by List.toArray() and then again copied by System.arraycopy:\n\n{code}\n    List subReadersList = new ArrayList();\n    gatherSubReaders(subReadersList, reader);\n    final IndexReader[] subReaders = (IndexReader[]) subReadersList.toArray(indexReaderZeroArray);\n    final int length = subReaders.length;\n    sortedSubReaders = new IndexReader[length];\n    System.arraycopy(subReaders, 0, sortedSubReaders, 0,\n                     length);\n    sortedStarts = new int[length];\n{code}\n\nMore efficient would be:\n\n{code}\n    List subReadersList = new ArrayList();\n    gatherSubReaders(subReadersList, reader);\n    sortedSubReaders = (IndexReader[]) subReadersList.toArray(indexReaderZeroArray);\n    final int length = sortedSubReaders.length;\n    sortedStarts = new int[length];\n{code}\n\nI did not create a patch, because I do not want to mix all changes alltogether with yours, I think it is simplier to change it at your checkout.\n\nAnd: the casts to MultiSegmentReader in the TestIndexReopen are not needed anymore, as every IndexReader has getSequentialSubReaders().\n\nI think, it is perfect now! +1 for commit!",
            "date": "2009-01-24T11:18:26.288+0000",
            "id": 275
        },
        {
            "author": "Michael McCandless",
            "body": "Excellent -- new patch with those fixes.  Thanks for reviewing Uwe!",
            "date": "2009-01-24T11:26:50.360+0000",
            "id": 276
        },
        {
            "author": "Uwe Schindler",
            "body": "Now, I cannot find any other improvements.\n\nJust a comment for discussion:\nIn principle, the MultiSearcher is obsolete now. Maybe we can deprecate it and remove it in 3.0. The hint is: Use IndexSearcher with a MultiReader instead.\n\nOnly ParallelMultiSearcher is of use now, but I am not sure how to keep it alive (maybe as a ParallelIndexSearcher inherited from IndexSearcher, that does the searches of the bigger segments in parallel. Parallel searching the smaller segments is of no use).",
            "date": "2009-01-24T12:19:55.265+0000",
            "id": 277
        },
        {
            "author": "Doug Cutting",
            "body": "> In principle, the MultiSearcher is obsolete now.\n\nIt's still useful with RemoteSearchable, no?  That was the original motivating case for MultiSearcher.  While the RMI-based RemoteSearchable might not be industrial-strength, it does serve as a placeholder for distributed search.  We'd like the Lucene APIs to be able to gracefully support distributed search, and I think that requires MultiSearcher.\n",
            "date": "2009-01-26T17:52:04.036+0000",
            "id": 278
        },
        {
            "author": "Uwe Schindler",
            "body": "Good comment, you are right! I forget the remote application. Nevertheless, for local-only applications, the new IndexSearcher is preferable over a MultiSearcher with separate IndexSearchers for each index.\n\nAn improvement of the current ParallelMultiSearcher could be, as mentioned before, to use the new sorting by doc count of all subreaders implemented by gatherSubReaders in the new IndexSearcher together with a maxThreads property. The new ParallelIndexSearcher could spawn max threads for the first (and biggest) n index readers in the list and one for the rest. The search could then done in parallel. This solves the problem of the current ParallelMultiSearcher spawning too many threads (because there is no limitation). The new one could only parallelize the search inside bigger indexes (this is just an idea). Note: This ParallelIndexSearcher would not get separate Searchables as c'tor parameter, but one IndexReader like IndexSearcher. The parallelization is only done based on all sub-readers. The only problem with parallelization is that the MultiReaderHitCollector must be synchronized in some way.",
            "date": "2009-01-26T18:30:36.245+0000",
            "id": 279
        },
        {
            "author": "Jason Rutherglen",
            "body": "{quote}\nUwe: \"An improvement of the current ParallelMultiSearcher\ncould be, as mentioned before, to use the new sorting by doc count of\nall subreaders implemented by gatherSubReaders\" \n{quote}\n\n+1 Parallelization is important as many applications are looking for\nreduced latency of queries, something parallelizing with multiple\nthreads guarantees (provided there is sufficient hardware).\n\n{quote}\nUwe: \"The only problem with parallelization is that the MultiReaderHitCollector must be synchronized in some way.\"\n{quote}\n\nTrue, thread locking (synchronization) definitely won't work for this.  \n",
            "date": "2009-01-27T02:07:28.002+0000",
            "id": 280
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Mike,\nsince last Friday, we had no problem with the new sort implementation. No exceptions from Lucene or any problems with Lucene. The sorting of results was (as far as I have seen) always correct (tested was SortField.INT, SortField.STRING). The index was updated each half hour and reopened, really great performance. There were also no errors after an optimize() and reopen again on Sunday (only that it took longer than to warmup the sorting).",
            "date": "2009-01-27T18:45:21.424+0000",
            "id": 281
        },
        {
            "author": "Uwe Schindler",
            "body": "Jason: We should open a new issue for that after this one is solved. Maybe we can create a good parallelized implementation after solving the problems with MultiReaderHitCollector (if more than one thread call setNextReader with collect calls inbetween, it would not work).",
            "date": "2009-01-27T18:54:46.612+0000",
            "id": 282
        },
        {
            "author": "Michael McCandless",
            "body": "bq. since last Friday, we had no problem with the new sort implementation.\n\nOK, excellent.  I will commit shortly!",
            "date": "2009-01-27T19:44:43.115+0000",
            "id": 283
        },
        {
            "author": "Michael McCandless",
            "body": "bq. The only problem with parallelization is that the MultiReaderHitCollector must be synchronized in some way.\n\nI think we'd have to collect to separate collectors and then merge\n(like ParallelMultiSearcher does today)?\n\nI think this (separate thread for the \"big\" segments, and one thread\nfor the \"long tail\") would be a good approach, except I don't like\nthat the performance would depend so much on the structure of the\nindex.  EG after you've optimized your index you'd suddenly get no\nconcurrency, and presumably worse performance than when you had a few\nbig segments.\n\nCould we instead divide the index into chunks and have each thread\nskipTo the start of its chunk?  EG if the index has N docs, and you\nwant to use M threads, each thread visits N/M docs.  If that can work\nit should be less dependent on the index structure.\n",
            "date": "2009-01-27T19:53:06.074+0000",
            "id": 284
        },
        {
            "author": "Michael McCandless",
            "body": "Committed revision 738219.  Thanks to everyone who helped out\nhere...and many thanks to Mark for working through so many iterations\nas we explored the different approaches here!\n",
            "date": "2009-01-27T20:17:41.597+0000",
            "id": 285
        },
        {
            "author": "Yonik Seeley",
            "body": "My previous comment:\n{quote}\nI tracked down how this patch was causing Solr failures:\n\nExternalFileField in Solr maps from a uniqueKey to a float value from a separate file.\nThere is a cache that is essentially keyed by (IndexReader,field) that gives back a float[].\n\nAny change in the index used to cause all values to be updated (cache miss because the MultiReader was a different instance). Now, since it's called segment-at-a-time, only new segments are reloaded from the file, leaving older segments with stale values.\n\nIt's certainly in the very gray area... but perhaps Solr won't be the only one affected by this - maybe apps that implement security filters, etc?\n{quote}\n\nbq. Yonik, why was the failure so intermittent? \n\nIt failed for others but not for me due to a Solr bug that prevented IndexReader.reopen() from being used on Windows.\nAs to why it reportedly worked for Mark when he built Lucene himself.... <shrug>... at this point perhaps testing error.\n\n[...]\n{quote}\nLucene implicitly assumes that a FieldCache's arrays do not change for\na given segment; this is normally safe since the arrays are derived\nfrom the postings in the field (which are write once).\n\nBut it sounds like Solr changed that assumption, and the values in the\n(Solr-subclass of) FieldCache's arrays are now derived from something\nexternal, which is no longer write once.\n{quote}\nRight... it used to hold in solr because nothing really operated below the MultiReader level.\nThe intention is that at the time when a new IndexReader is opened, the entire file is read.\nThis patch changes that up.\n\n{quote}\nHow do you plan to fix it with Solr? It seems like, since you are\nmaintaining a private cache, you could forcefully evict entries from\nthe cache for all SegmentReaders whenever the external file has\nchanged (or a new MultiSegmentReader had been opened)?\n{quote}\n\nIt's not so easy... the same segment could be associated with two different active MultiReaders (with a different set of values for each).  When the scorer is created, only the SegmentReader is passed with no other context.\n",
            "date": "2009-01-30T15:12:24.723+0000",
            "id": 286
        },
        {
            "author": "Michael McCandless",
            "body": "One immediate workaround would be to use the legacy searching (SortField.setUseLegacySearch) when sorting by an \"external file\" field?",
            "date": "2009-01-30T16:17:57.029+0000",
            "id": 287
        },
        {
            "author": "Yonik Seeley",
            "body": "How about an option to deliver docs in sorted order (basically, skip the segment sort)",
            "date": "2009-01-31T16:19:58.738+0000",
            "id": 288
        },
        {
            "author": "Yonik Seeley",
            "body": "As far as a Solr fix... the code needs more context than the IndexReader passed in.\n\nAfter a reopen, I could tear apart the MultiSegmentReader and create my own MultiReader, wrapping each reader.  The only real difference between the two is getVersion() and isCurrent(), right?",
            "date": "2009-01-31T17:57:03.920+0000",
            "id": 289
        },
        {
            "author": "Michael McCandless",
            "body": "You are using oal.function.ValueSource as the interface for loading values for \"external file\" fields, right?\n\nCould you maintain a separate FieldCacheImpl, newly created each time you reopen the reader, and extend *ValueSource so that they use that private FieldCache instead of the default one?  Then, when a ValueSourceQuery is created, you'd have to init it with the right private FieldCache instance corresponding to your MultiSegmentReader.  Would that work?",
            "date": "2009-01-31T19:55:47.456+0000",
            "id": 290
        },
        {
            "author": "Michael McCandless",
            "body": "bq. How about an option to deliver docs in sorted order (basically, skip the segment sort) \n\nWe could do that; would you add it to Query?",
            "date": "2009-01-31T19:57:45.248+0000",
            "id": 291
        },
        {
            "author": "Michael McCandless",
            "body": "bq. After a reopen, I could tear apart the MultiSegmentReader and create my own MultiReader, wrapping each reader. The only real difference between the two is getVersion() and isCurrent(), right?\n\nThat's a neat idea!  But there are other differences (eg you wouldn't be able to make changes, I think?  Because no IndexReader has the SegmentInfos?).",
            "date": "2009-01-31T19:59:51.644+0000",
            "id": 292
        },
        {
            "author": "Uwe Schindler",
            "body": "Some other idea:\nHow about adding a API to FieldCache/ExtendedFieldCache, that makes it possible to remove all cached values for a specific field name? It would remove the stale arrays of that field from each IndexReader's cache in the WeakHashMap. So it would not make a difference if the search uses one reader or each segment in separate. This would be a move forward to LUCENE-831.",
            "date": "2009-01-31T21:28:28.984+0000",
            "id": 293
        },
        {
            "author": "Yonik Seeley",
            "body": "> > How about an option to deliver docs in sorted order (basically, skip the segment sort) \n> We could do that; would you add it to Query?\n\nI wouldn't want to add another field on Query...I was thinking more along the lines of adding a flag to the IndexSearcher constructor: IndexSearcher(IndexReader, boolean sortSegments) or something",
            "date": "2009-01-31T22:40:09.754+0000",
            "id": 294
        },
        {
            "author": "Michael McCandless",
            "body": "bq. IndexSearcher(IndexReader, boolean sortSegments) or something\n\nBut isn't that too coarse?  (Ie, it's only very specific kinds of queries, against very specific fields, that are affected by visiting segments in reverse-size order)?\n\nActually, how would this help fix Solr's \"external file\" field (vs the private FieldCache approach)?",
            "date": "2009-02-01T11:15:41.612+0000",
            "id": 295
        },
        {
            "author": "Michael McCandless",
            "body": "bq. How about adding a API to FieldCache/ExtendedFieldCache, that makes it possible to remove all cached values for a specific field name?\n\nI think maybe that's too coarse -- there may be situations when you want to keep both the old and the new cache around (eg, while warming is taking place, but also in cases where you don't immediately retired the old reader once a new one is reopened).\n\nIt's really like Solr needs its own \"key\", combined with the SegmentReader, when retrieving entries from FieldCache, or the ability to use a private FieldCache for certain queries (which I think is a viable solution today for *ValueSource).",
            "date": "2009-02-01T11:19:01.045+0000",
            "id": 296
        },
        {
            "author": "Yonik Seeley",
            "body": ">> IndexSearcher(IndexReader, boolean sortSegments) or something\n\n> But isn't that too coarse? (Ie, it's only very specific kinds of queries, against very specific fields, that are affected by visiting segments in reverse-size order)?\n\nActually, I think a number of applications will probably be affected (those sensitive to doc order).\nThink about anyone using SortedVIntListBuilder, or anyone with their own hit collector that short-circuits too soon based on the assumption that docs often come in index order.  The worst thing is that they often will come in index order... and only break later on under certain circumstances.\n\nWe could add a flag to methods that take a hit collector, but that would require keeping two lists of Segments (sorted and original) and corresponding bases.  It seemes cleaner to just sort or not in the constructor..... people who want both behaviors can instantiate two IndexSearcher objects.\n\n> Actually, how would this help fix Solr's \"external file\" field (vs the private FieldCache approach)?\n\nIt's unrelated, I should have made that clearer.\n\n> It's really like Solr needs its own \"key\", combined with the SegmentReader\n\nYep.  No worries... I think I've got this one figured out.  There are numbers of options (including thread-local too), but I'm liking the sound of wrapping segment readers for general flexibility.",
            "date": "2009-02-01T15:38:25.426+0000",
            "id": 297
        },
        {
            "author": "Michael McCandless",
            "body": "bq. It seemes cleaner to just sort or not in the constructor\n\nOK, I agree... I'll work out a patch.",
            "date": "2009-02-02T01:20:06.723+0000",
            "id": 298
        },
        {
            "author": "Yonik Seeley",
            "body": "My initial thought was to just add it to the most expert level constructor (i.e. avoid adding flags to every constructor):\n  public IndexSearcher(IndexReader r, boolean sortSegments)  (or docsInOrder?)\n",
            "date": "2009-02-02T01:53:42.875+0000",
            "id": 299
        },
        {
            "author": "Michael McCandless",
            "body": "bq. public IndexSearcher(IndexReader r, boolean sortSegments) (or docsInOrder?)\n\nSounds good... I added an expert ctor that takes boolean docsInOrder (attached).",
            "date": "2009-02-02T12:02:40.025+0000",
            "id": 300
        },
        {
            "author": "Yonik Seeley",
            "body": "+1, thanks Mike!\n\njavadoc: maxDoc should be numDocs in \"in order of decreasing maxDoc()\"\n",
            "date": "2009-02-02T15:39:00.501+0000",
            "id": 301
        },
        {
            "author": "Michael McCandless",
            "body": "bq. javadoc: maxDoc should be numDocs in \"in order of decreasing maxDoc()\"\n\nWoops, right!  I'll fix & commit.  Thanks Yonik!",
            "date": "2009-02-02T16:18:11.415+0000",
            "id": 302
        },
        {
            "author": "Michael McCandless",
            "body": "Committed revision 740021.",
            "date": "2009-02-02T16:22:12.293+0000",
            "id": 303
        },
        {
            "author": "Michael McCandless",
            "body": "Hmm -- we didn't deprecate SortComparator/SortComparatorSource with this, but I think we should have?  Does that sound right?  If so I can work up a patch...",
            "date": "2009-02-20T18:57:32.203+0000",
            "id": 304
        },
        {
            "author": "Michael McCandless",
            "body": "OK I committed the missing deprecations (Committed revision 747019).",
            "date": "2009-02-23T14:00:15.125+0000",
            "id": 305
        },
        {
            "author": "Mark Miller",
            "body": "bq. OK I committed the missing deprecations.\n\n+1. Thanks.\n",
            "date": "2009-02-23T14:04:10.075+0000",
            "id": 306
        },
        {
            "author": "Jeremy Volkman",
            "body": "I'm trying to create a FieldValueHitQueue outside of an IndexSearcher. One part of my code collects all results in a fashion similar to http://www.gossamer-threads.com/lists/lucene/java-user/66362#66362. At the end of my collection, I used to pass the results through a FieldSortedHitQueue of the proper size to get sorted results. The problem now is that FieldValueHitQueue takes an array of subreaders instead of one IndexReader. As far as I can tell, there's no way for me to get a proper sorted array of subreaders for an IndexReader without copying and pasting the gatherSubReaders and sortSubReaders methods from IndexSearcher. This isn't desirable, so could IndexSearcher perhaps provide some sort of getSortedSubReaders() method? Either that, or extract this functionality out into a common utility method that IndexSearcher uses.",
            "date": "2009-04-03T21:05:23.513+0000",
            "id": 307
        },
        {
            "author": "Shai Erera",
            "body": "Hi Jeremy\n\nThis will be taken care of in 1575 by removing the IndexReader[] arg from TopFieldCollector. As a matter of fact, 1575 changes quite a bit the collector's API, so you might want to take a look there. Anyway, I've run into the same issue there and realized this arg can be safely removed from TopFieldCollector as well as FieldValueHitQueue.",
            "date": "2009-04-03T21:15:44.125+0000",
            "id": 308
        },
        {
            "author": "Uwe Schindler",
            "body": "This will be changed as part of LUCENE-1575",
            "date": "2009-04-03T21:18:11.679+0000",
            "id": 309
        },
        {
            "author": "Gunnar Wagenknecht",
            "body": "Hi,\n\nThis issue introduced SorterTemplate.java. Right in the header it says \"Borrowed from Cglib.\". Unfortunately, our IP team is not able to clarify provenance on CGLib. It seems that we can't get in touch with the authors. Any help is appreciated.\n\nIs it possible to exclude that file from this patch or replace it with an alternate implementation?\n",
            "date": "2009-12-02T20:18:48.710+0000",
            "id": 310
        },
        {
            "author": "Yonik Seeley",
            "body": "That's strange... looks like SorterTemplate isn't even used anywhere.  Mike, was this an accidental commit?",
            "date": "2009-12-02T20:30:09.233+0000",
            "id": 311
        },
        {
            "author": "Mark Miller",
            "body": "I originally borrowed to sort readers and starts at the same time - since then, we stopped doing that sort. We could drop it - though technically its a bw compat break now ;)",
            "date": "2009-12-02T20:59:57.178+0000",
            "id": 312
        },
        {
            "author": "Robert Muir",
            "body": "but isn't this code ok to borrow? http://cglib.cvs.sourceforge.net/viewvc/cglib/cglib/src/proxy/net/sf/cglib/util/SorterTemplate.java?revision=1.2&view=markup&pathrev=MAIN",
            "date": "2009-12-02T21:01:58.667+0000",
            "id": 313
        },
        {
            "author": "Mark Miller",
            "body": "Sure is - but IP teams are crazy :) Other stuff was likely borrowed in other cases, there just wasn't a trail like this left behind :) Even things that we have gotten software grants for don't have a trail thats easily followable always (or at all from the source code) - so essentially, we are being trusted in any case. But if you look at previous discussions that have come up about this type of thing, common sense won't win :)",
            "date": "2009-12-02T21:06:25.557+0000",
            "id": 314
        },
        {
            "author": "Michael McCandless",
            "body": "bq.  originally borrowed to sort readers and starts at the same time - since then, we stopped doing that sort. We could drop it - though technically its a bw compat break now\n\nI think, going forward, whenever we adopt some utility class like this, we should declare that it's for internal use by Lucene only, and we made it public only to use within different sub-packages in Lucene.  And that we reserve full future rights to break back compat -- change the APIs, change semantics of the methods, remove the class entirely.\n\nEG I've done this with DoubleBarrelLRUCache.\n\nIn this particular case, I'm inclined to simply make an exception to back compat, and simply remove the class, for 3.1.  Any objections?",
            "date": "2009-12-03T12:35:40.676+0000",
            "id": 315
        },
        {
            "author": "Mark Miller",
            "body": "bq.  we should declare that it's for internal use by Lucene only\n\n+1\n\nbq. Any objections?\n\nNot from me - the chances are slim to nil anyone is using it I bet - and if they are, they can copy it into their code base. We don't want to have to mange util classes we don't use.",
            "date": "2009-12-03T12:43:55.168+0000",
            "id": 316
        },
        {
            "author": "Michael McCandless",
            "body": "OK I just removed SorterTemplate.java",
            "date": "2009-12-03T17:25:45.206+0000",
            "id": 317
        },
        {
            "author": "Uwe Schindler",
            "body": "Reverted the removal of SorterTemplate, its now replaced by a better implementation, only inspired by CGLIB: LUCENE-2719",
            "date": "2010-10-27T15:18:21.324+0000",
            "id": 318
        }
    ],
    "component": "",
    "description": "This issue changes how an IndexSearcher searches over multiple segments. The current method of searching multiple segments is to use a MultiSegmentReader and treat all of the segments as one. This causes filters and FieldCaches to be keyed to the MultiReader and makes reopen expensive. If only a few segments change, the FieldCache is still loaded for all of them.\n\nThis patch changes things by searching each individual segment one at a time, but sharing the HitCollector used across each segment. This allows FieldCaches and Filters to be keyed on individual SegmentReaders, making reopen much cheaper. FieldCache loading over multiple segments can be much faster as well - with the old method, all unique terms for every segment is enumerated against each segment - because of the likely logarithmic change in terms per segment, this can be very wasteful. Searching individual segments avoids this cost. The term/document statistics from the multireader are used to score results for each segment.\n\nWhen sorting, its more difficult to use a single HitCollector for each sub searcher. Ordinals are not comparable across segments. To account for this, a new field sort enabled HitCollector is introduced that is able to collect and sort across segments (because of its ability to compare ordinals across segments). This TopFieldCollector class will collect the values/ordinals for a given segment, and upon moving to the next segment, translate any ordinals/values so that they can be compared against the values for the new segment. This is done lazily.\n\nAll and all, the switch seems to provide numerous performance benefits, in both sorted and non sorted search. We were seeing a good loss on indices with lots of segments (1000?) and certain queue sizes / queries, but the latest results seem to show thats been mostly taken care of (you shouldnt be using such a large queue on such a segmented index anyway).\n\n* Introduces\n** MultiReaderHitCollector - a HitCollector that can collect across multiple IndexReaders. Old HitCollectors are wrapped to support multiple IndexReaders.\n** TopFieldCollector - a HitCollector that can compare values/ordinals across IndexReaders and sort on fields.\n** FieldValueHitQueue - a Priority queue that is part of the TopFieldCollector implementation.\n** FieldComparator - a new Comparator class that works across IndexReaders. Part of the TopFieldCollector implementation.\n** FieldComparatorSource - new class to allow for custom Comparators.\n* Alters\n** IndexSearcher uses a single HitCollector to collect hits against each individual SegmentReader. All the other changes stem from this ;)\n* Deprecates\n** TopFieldDocCollector\n** FieldSortedHitQueue\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1483",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Change IndexSearcher multisegment searches to search each individual segment using a single HitCollector",
    "systemSpecification": true,
    "version": "2.9"
}