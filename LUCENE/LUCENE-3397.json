{
    "comments": [
        {
            "author": "Chris Male",
            "body": "Patch which adds state resetting to TokenStreams created in tests.  \n\nThe only other TSs which are not reusable are done so by design to test that something can handle non-reusable TSs.  When we made reuse mandatory, we can drop these tests and remove the non reusable TSs.",
            "date": "2011-08-24T12:53:55.909+0000",
            "id": 0
        },
        {
            "author": "Chris Male",
            "body": "Better patch which removes changing the state of a static variable.\n\nI'll commit this in day or so.",
            "date": "2011-08-24T13:25:11.374+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "looks good!",
            "date": "2011-08-24T13:37:51.881+0000",
            "id": 2
        },
        {
            "author": "Chris Male",
            "body": "Committed revision 1161488.\n\nI or someone else will get to back porting this at another stage.",
            "date": "2011-08-25T10:43:37.570+0000",
            "id": 3
        },
        {
            "author": "Chris Male",
            "body": "Found some more.",
            "date": "2011-08-25T11:16:18.218+0000",
            "id": 4
        },
        {
            "author": "Chris Male",
            "body": "Patch which addresses the remaining non-reusable TSs.\n\nPatch also takes a swing at the deprecated PatternAnalyzer's Tokenizers (even though they were neither Tokenizers, nor in tests).\n\n",
            "date": "2011-08-25T14:44:16.140+0000",
            "id": 5
        },
        {
            "author": "Chris Male",
            "body": "Committed revision 1161986.\n\nI understand Robert is backporting the changes.\n\nIf I find anymore, I'll address them in LUCENE-3396.",
            "date": "2011-08-26T04:17:43.114+0000",
            "id": 6
        },
        {
            "author": "Chris Male",
            "body": "Found another.  Okay I'm going to stop resolving this till I'm sure we're clear.",
            "date": "2011-08-26T04:57:10.707+0000",
            "id": 7
        },
        {
            "author": "Chris Male",
            "body": "Patch addresses the SynonymTokenizer (note, not a Tokenizer) in HighlighterTest which was only resetting its actual Tokenizer once.",
            "date": "2011-08-26T04:58:28.501+0000",
            "id": 8
        },
        {
            "author": "Chris Male",
            "body": "Committed revision 1161993.",
            "date": "2011-08-26T04:59:27.524+0000",
            "id": 9
        },
        {
            "author": "Simon Willnauer",
            "body": "thanks for all this cleanup work chris! this makes our codebase much cleaner and test real examples! Very very welcome work!",
            "date": "2011-08-26T11:16:52.321+0000",
            "id": 10
        },
        {
            "author": "Chris Male",
            "body": "All TokenStreams are now reusable.",
            "date": "2011-11-14T11:04:13.135+0000",
            "id": 11
        }
    ],
    "component": "modules/analysis",
    "description": "Many TokenStreams created in tests are not reusable.  Some do some really messy things which prevent their reuse so we may have to change the tests themselves.\n\nWe'll target back porting this to 3x.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3397",
    "issuetypeClassified": "OTHER",
    "issuetypeTracker": "",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Cleanup Test TokenStreams so they are reusable",
    "systemSpecification": true,
    "version": ""
}