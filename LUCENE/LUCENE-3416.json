{
    "comments": [
        {
            "author": "Simon Willnauer",
            "body": "Shay, can't you use a Input / Output wrapper on a RateLimitingDirectoryDelegate? With lucene 4.0 you get the IOContext when open / creating streams so you can decide based on this?",
            "date": "2011-09-06T10:19:56.547+0000",
            "id": 0
        },
        {
            "author": "Shay Banon",
            "body": "It is possible, but requires more work to do, and depends on overriding the createOutput method (as well as all the other methods in Directory). If rate limiting makes sense on the directory level to be exposed as a \"feature\", I think that this small change allows for greater control over it.",
            "date": "2011-09-06T14:07:59.008+0000",
            "id": 1
        },
        {
            "author": "Simon Willnauer",
            "body": "I see, I guess that is kind of overkill here. This patch looks fine to me though while I wonder why this needs to be synchronized since we don't read it from a synced block. if you want this to take immediate effect you should rather use volatile here? I doubt that this is necessary in this context - I'd rather not invalidate a cache line for each IndexOutput creation.",
            "date": "2011-09-06T19:18:25.629+0000",
            "id": 2
        },
        {
            "author": "Shay Banon",
            "body": "The only reason its synchronized is because the setMaxMergeWriteMBPerSec method is synchronized (I guess to protected from setting the rate limit concurrently). In practice, I don't see users changing it that often, so concerns about cache lines are not really relevant.",
            "date": "2011-09-07T17:52:06.286+0000",
            "id": 3
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. The only reason its synchronized is because the setMaxMergeWriteMBPerSec method is synchronized (I guess to protected from setting the rate limit concurrently). In practice, I don't see users changing it that often, so concerns about cache lines are not really relevant.\n\nthis make no sense to me. If you don't want to set this concurrently how does a lock protect you from this? I mean you if you have two threads accessing this you have either A B or B A. but this would happen without a lock too. if you want to have the changes to take effect immediately you need to either lock on each read on this var or make it volatile which is almost equivalent (a mem barrier). \n\nMy concern here was related to make this var volatile which would be a cacheline invalidation each time you read the var. I think we should get rid of the synchronized.",
            "date": "2011-09-07T17:58:40.851+0000",
            "id": 4
        },
        {
            "author": "Shay Banon",
            "body": "> this make no sense to me. If you don't want to set this concurrently how does a lock protect you from this? I mean you if you have two threads accessing this you have either A B or B A. but this would happen without a lock too. if you want to have the changes to take effect immediately you need to either lock on each read on this var or make it volatile which is almost equivalent (a mem barrier).\n\nNo, thats not correct. setMaxMergeWriteMBPerSec (not the method I added, the other one) is a complex method, and I think Mike wanted to protect from two threads setting the value concurrently. As for reading the value, I think Mike logic was that its not that importnat the have \"immediate\" visibility of the change to require a volatile field (which is understandable). So, since setMaxMergeWriteMBPerSec is synchronized, the method added in this patch has to be as well.\n\n> My concern here was related to make this var volatile which would be a cacheline invalidation each time you read the var. I think we should get rid of the synchronized.\n\nReading a volatile var in x86 is not a cache invalidation, though it does come with a cost. Its not relevant here based on what I explained before (and second guessing Mike :) )",
            "date": "2011-09-07T18:10:58.719+0000",
            "id": 5
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Reading a volatile var in x86 is not a cache invalidation, though it does come with a cost.\nyes unless you are reading and writing it. Yet since this is not intended here we don't need to get into details. Bottom line that synchronization doesn't make much sense here. we should try to control some order here that we can not control. if somebody sets either of those concurrently they should take care of synchronization. What should I expect if you set this concurrently? IMO we should craft those method to work without synchronization which is certainly possible. synchronized here buys us nothing and should be removed.",
            "date": "2011-09-07T18:45:51.118+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "I made setMaxMergeWriteMBPerSec sync'd because ie has tricky logic about creating a new RateLimiter or reusing an existing one (so current merges can see the change on a \"best effort\" basis) or clearing the current one... so I just wanted to be safe and have only one thread doing this at once; else eg you could get NPE I think.\n\nBut, probably we should in fact make mergeWriteRateLimiter volatile, just to make sure the unsync'd read sees the current value?  The minor added read cost should be negligible vs the overhead of creating / writing / closing files.",
            "date": "2011-09-07T18:54:41.214+0000",
            "id": 7
        },
        {
            "author": "Shay Banon",
            "body": "I agree with Mike, I think it should remain synchronized, it does safeguard concurrently calling setMaxMergeWriteMBPerSec from falling over itself (who \"wins\" the call is not really relevant). Since thats synchronized, the metod I added should be as well. Personally, I really don't think there is a need to make it thread safe without \"blocking\", since calling the \"setters\" is not something people do frequently at all, so the optimization is mute, and it will complicate the code.\n\nAs for making mergeWriteRateLimiter volatile, it can be done. Though, in practice, there really is no need to do it (there is a memory barrier when reading it before). But, I think that should go in a different issue? Just to keep changes clean and isolated?\n",
            "date": "2011-09-07T19:16:33.379+0000",
            "id": 8
        },
        {
            "author": "Simon Willnauer",
            "body": "what about something like that:\n\n{code}\n  public void setMaxMergeWriteMBPerSec(Double mbPerSec) {\n    final RateLimiter limiter = mergeWriteRateLimiter;\n    if (mbPerSec == null) {\n      if (limiter != null) {\n        limiter.setMaxRate(Double.MAX_VALUE);\n        mergeWriteRateLimiter = null;\n      }\n    } else if (limiter != null) {\n      limiter.setMaxRate(mbPerSec);\n    } else {\n      mergeWriteRateLimiter = new RateLimiter(mbPerSec);\n    }\n  }\n\n  /** See {@link #setMaxMergeWriteMBPerSec}.\n   *\n   * @lucene.experimental */\n  public Double getMaxMergeWriteMBPerSec() {\n    final RateLimiter limiter = mergeWriteRateLimiter;\n    return limiter == null ? null : limiter.getMaxRateMB();\n  }\n{code}\n\nI think we can make this simple without any synchronization which is totally unnecessary here.",
            "date": "2011-09-07T19:18:37.371+0000",
            "id": 9
        },
        {
            "author": "Michael McCandless",
            "body": "That change looks fine to me Simon.",
            "date": "2011-09-07T19:24:52.559+0000",
            "id": 10
        },
        {
            "author": "Shay Banon",
            "body": "I must say that I am at a lost in trying to understand why we need this \"optimization\", but it does not really matter to me as long as the ability to set the rate limiter instance gets in.",
            "date": "2011-09-07T20:23:55.765+0000",
            "id": 11
        },
        {
            "author": "Shay Banon",
            "body": "A new patch, remove synchronization. It also adds another field to RateLimiter to record the original mbPerSec value set, so we can easily get it back.",
            "date": "2011-09-08T07:37:00.872+0000",
            "id": 12
        },
        {
            "author": "Simon Willnauer",
            "body": "that looks good to me, thanks shay!",
            "date": "2011-09-08T07:41:04.571+0000",
            "id": 13
        },
        {
            "author": "Simon Willnauer",
            "body": "I am planning to commit this today, any objections?",
            "date": "2011-09-09T08:55:27.376+0000",
            "id": 14
        },
        {
            "author": "Simon Willnauer",
            "body": "committed to trunk. Thanks Shay",
            "date": "2011-09-09T20:35:49.565+0000",
            "id": 15
        }
    ],
    "component": "core/store",
    "description": "This can come in handy when running several Lucene indices in the same VM, and wishing to rate limit merge across all of them.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3416",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Allow to pass an instance of RateLimiter to FSDirectory allowing to rate limit merge IO across several directories / instances",
    "systemSpecification": true,
    "version": ""
}