{
    "comments": [
        {
            "author": "Robert Muir",
            "body": "Does consolidation include contrib/icu, too?\n\nOtherwise we still suffer from similar problems, such as you need this filter in contrib/icu to standardize your width differences in CJK text, \nGreekLowerCaseFilter and such that are not really necessary and can be satisfied with case folding, etc.\n(and really NFKC_Casefold in my opinion should just replace LowerCaseFilter in every single last one of these analyzers)\n",
            "date": "2010-04-22T20:16:16.047+0000",
            "id": 0
        },
        {
            "author": "DM Smith",
            "body": "Robert: +1",
            "date": "2010-04-22T20:24:25.418+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Does consolidation include contrib/icu, too?\n\n+1",
            "date": "2010-04-22T21:39:33.274+0000",
            "id": 2
        },
        {
            "author": "Steve Rowe",
            "body": "bq. Does consolidation include contrib/icu, too?\n\n+1\n\nEspecially if we really go the route of individually packaging artifacts for & releasing each component separately.",
            "date": "2010-04-23T16:31:51.197+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "I played with this issue enough already to realize its gonna be a pain, huge svn movements and lots of changes.\n\nso here's a patch that moves the PorterStemmer to contrib/analyzers... (under the 'en' pkg)... its a start.\n\nI would like to commit tomorrow unless anyone objects.",
            "date": "2010-05-02T20:41:58.153+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "+1 to doing this in as-baby-steps as we can :)",
            "date": "2010-05-03T09:50:46.217+0000",
            "id": 5
        },
        {
            "author": "Robert Muir",
            "body": "committed LUCENE-2413_porter.patch revision 940459.",
            "date": "2010-05-03T19:22:12.646+0000",
            "id": 6
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch to move ISOLatin1AccentFilter and ASCIIFoldingFilter to contrib (under miscellaneous).\n\nI hacked the analyzing queryparser's test to avoid a dependency \non contrib analyzers, but gonna need a 'TestAnalyzer' soon.\n\nwould like to commit soon unless there are objections",
            "date": "2010-05-03T19:25:35.277+0000",
            "id": 7
        },
        {
            "author": "Robert Muir",
            "body": "committed LUCENE-2413_folding.patch revision 940591.",
            "date": "2010-05-03T20:03:12.532+0000",
            "id": 8
        },
        {
            "author": "Uwe Schindler",
            "body": "Here my patch for LengthFilter and PerFieldAnalyzerWrapper.",
            "date": "2010-05-03T21:16:42.402+0000",
            "id": 9
        },
        {
            "author": "Robert Muir",
            "body": "Thanks Uwe, the help is appreciated!",
            "date": "2010-05-03T21:19:19.734+0000",
            "id": 10
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch for TeeSink, it moves it to contrib/analyzers/sinks\n\nI moved the test in TestIW (seems to really be unrelated to IW) as-is to \nthe TeeSinkTest, it appears from the JIRA issue etc that this is simply \ntesting that end() is implemented correctly in TeeSink, and there is \nalready a separate test for end() in TestIW.\n",
            "date": "2010-05-03T21:23:41.345+0000",
            "id": 11
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed LUCENE-2413-PFAW+LF.patch revision: 940632",
            "date": "2010-05-03T21:38:47.018+0000",
            "id": 12
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_teesink.patch revision 940633",
            "date": "2010-05-03T21:42:12.965+0000",
            "id": 13
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch that moves some high-level charfilter functionality to contrib/analyzers\nso MappingCharFilter,BaseCharFilter,NormalizeCharMap -> o.a.l.analysis.charfilter",
            "date": "2010-05-03T23:20:51.665+0000",
            "id": 14
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413-charfilter.patch revision 940676.",
            "date": "2010-05-03T23:37:11.293+0000",
            "id": 15
        },
        {
            "author": "Robert Muir",
            "body": "patch for commongrams(query)filter",
            "date": "2010-05-04T07:47:22.220+0000",
            "id": 16
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_commongrams.patch revision 940761.",
            "date": "2010-05-04T07:51:43.829+0000",
            "id": 17
        },
        {
            "author": "Robert Muir",
            "body": "htmlstripcharfilter -> o.a.l.charfilter.htmlstripcharfilter",
            "date": "2010-05-04T08:26:07.181+0000",
            "id": 18
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_htmlstrip.patch revision 940768.",
            "date": "2010-05-04T08:34:56.042+0000",
            "id": 19
        },
        {
            "author": "Robert Muir",
            "body": "worddelimiterfilter -> analysis.misc.WordDelimiterFilter",
            "date": "2010-05-04T09:01:24.555+0000",
            "id": 20
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_wdf.patch revision 940781.",
            "date": "2010-05-04T09:12:09.802+0000",
            "id": 21
        },
        {
            "author": "Robert Muir",
            "body": "removeDuplicatesTokenFilter -> misc/",
            "date": "2010-05-04T09:53:36.806+0000",
            "id": 22
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_removeDups.patch revision 940788.",
            "date": "2010-05-04T09:56:44.072+0000",
            "id": 23
        },
        {
            "author": "Robert Muir",
            "body": "this patch moves pattern-based components (PatternReplaceFilter, PatternTokenizer, PatternReplaceCharFilter)\nto analysis.pattern package.\n\nthe existing PatternAnalyzer in contrib is marked deprecated in favor of this.\n\nadditionally, i removed the commons dependency on PatternTokenizer and improved its performance by reusing a stringbuilder (instead of IOUtils.toString), and by not creating new strings for group-matching.\n",
            "date": "2010-05-04T11:06:54.408+0000",
            "id": 24
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_pattern.patch revision 940813",
            "date": "2010-05-04T11:58:21.487+0000",
            "id": 25
        },
        {
            "author": "Robert Muir",
            "body": "keepwordfilter,trimfilter,hyphenatedwordsfilter -> misc",
            "date": "2010-05-04T16:16:22.922+0000",
            "id": 26
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_keep_hyphen_trim.patch revision 940962.",
            "date": "2010-05-04T17:08:33.058+0000",
            "id": 27
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch to move synonymfilter/synonymmap into the analyzers module.\n\ndidn't deprecate the synonymfilter/synonymmap from contrib/wordnet quite yet.",
            "date": "2010-05-10T11:48:15.461+0000",
            "id": 28
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_synonym.patch revision 942827.",
            "date": "2010-05-10T17:38:51.804+0000",
            "id": 29
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch that creates a barebones _TestAnalyzer and _TestTokenizer in src/test\n\nThese can be used for running lucene tests, so that more analyzers can be moved to the analyzers module.\n\nI didn't convert all tests to use it, only the easy ones so far.",
            "date": "2010-05-11T17:18:06.890+0000",
            "id": 30
        },
        {
            "author": "Robert Muir",
            "body": "i renamed the test analyzer to MockAnalyzer/Tokenizer at hossman's suggestion...\n\nall tests pass",
            "date": "2010-05-11T18:36:34.564+0000",
            "id": 31
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_testanalyzer.patch revision 943288.\n\nBy the way, when reviewing I found some disabled queryparser tests: \n{noformat}\n-  public void tesStopwordsParsing() throws Exception {\n+  public void testStopwordsParsing() throws Exception {\n{noformat}\n\nI will re-enable these tests on the 3x branch too.",
            "date": "2010-05-11T21:05:12.897+0000",
            "id": 32
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch (LUCENE-2413_tests2.patcH) that adds a \"SIMPLE\" mode to MockAnalyzer.\nI cut over a lot of tests that were previously using SimpleAnalyzer/LowerCaseTokenizer etc to this.\n\nI also added some basic tests for the MockAnalyzer itself (one day we will want to free it from CharTokenizer, etc)",
            "date": "2010-05-15T16:11:16.655+0000",
            "id": 33
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_tests2.patch revision 944677",
            "date": "2010-05-15T16:42:29.323+0000",
            "id": 34
        },
        {
            "author": "Robert Muir",
            "body": "attached is some cleanup for the mock analyzers tests.\n\nadditionally i added a filter for testing, that removes any terms accepted by a DFA.\nSo you can use this to emulate stopfilter, keepfilter, lengthfilter, ...\nLots of tests need to test this sorta stuff with posIncs.",
            "date": "2010-05-16T19:40:14.054+0000",
            "id": 35
        },
        {
            "author": "Robert Muir",
            "body": "oops, i forgot to svn add.\nheres the corrected patch",
            "date": "2010-05-16T19:42:37.150+0000",
            "id": 36
        },
        {
            "author": "Uwe Schindler",
            "body": "Just thinking about MockFilter:\nMay this much faster than CharArraySet? If we build a DFA out of the stopwords, like done in the MockFilter, and also minimize it, will the checking for a hit not be much faster? e.g. if the first character of the termBuffer does not match the automaton it gets rejected. CAS always has to calculate the hashCode of the whole string first and then look it up.\nI would like to see a comparison with a minimized Automaton vs. CAS for StopFilter. OK, LengthFilter is more performant by just comparing TermLength, but the StopFilter should be much faster.\nI propose to pass a Set to the StopFilter and internally it converts it to a minimized Automaton similar to MockFilter.",
            "date": "2010-05-16T20:35:44.093+0000",
            "id": 37
        },
        {
            "author": "Robert Muir",
            "body": "bq. May this much faster than CharArraySet\n\nI ran indexing tests a while ago (reuters) with CharArraySet itself implemented with a DFA, and it was slightly faster, but not much. I think this is because english words are usually not very long (average length=5). For other languages this technique might save some cpu time, but there are some \"problems\" i imagine\n\n# building an automaton from a list of words is more expensive, although Dawid Weiss has implemented an addition to automaton that does this fast.\n# in general building automaton and runautomaton etc is more \"heavy\" i would think, but Mike Mccandless hacked away a lot of this heaviness when we converted to UTF-32.\n# the CharacterRunAutomaton is not optimized right now, we disabled the classmap[] for chars because it consume more RAM. I think if we were to care about performance on char[] we should make it classmap 0x0-0xffff and binary search the rest, or something similar. currently it binarysearches on each input character.\n\nSomewhat related, a while ago i tested this with CharArraySet as a DFA, and opened this issue: LUCENE-2227. But obviously this is not the only way, as this example shows filtering on the dfa itself (and not using chararrayset at all). \n\nSo in general, i have those concerns right now, but maybe in the future once some things are addressed we could at least make an optional stopfilter impl or something similar.\n\nOne thing i like about this filter personally, is that rejected terms always get (optionally) the posInc increased... I do not think our existing KeepWord or LengthFilters do this, but maybe i am wrong.\n",
            "date": "2010-05-16T20:47:46.433+0000",
            "id": 38
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_mockfilter.patch 944908.\n\nI think now we can move all tests to this framework and pull all the analyzers out.",
            "date": "2010-05-16T21:01:55.174+0000",
            "id": 39
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch that converts over some more tests... need a break and this was a good stopping point.",
            "date": "2010-05-16T21:54:23.002+0000",
            "id": 40
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch cutting over a lot more tests.",
            "date": "2010-05-17T04:01:00.028+0000",
            "id": 41
        },
        {
            "author": "Robert Muir",
            "body": "committed LUCENE-2413_tests3.patch revision 944925\ncommitted LUCENE-2413_test4.patch revision 944966",
            "date": "2010-05-17T04:39:05.370+0000",
            "id": 42
        },
        {
            "author": "Robert Muir",
            "body": "Attached patch (LUCENE-2413_icu.patch) folds contrib/icu into the analyzers module.\n\nSince it depends on an external lib, i set it up as analyzers-icu.jar",
            "date": "2010-05-20T02:08:13.512+0000",
            "id": 43
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_icu.patch revision 946590.",
            "date": "2010-05-20T10:47:33.872+0000",
            "id": 44
        },
        {
            "author": "Robert Muir",
            "body": "this patch (LUCENE-2413_keyword.patch) moves the keywordmarkerfilter out of core into the module.",
            "date": "2010-05-20T11:39:22.174+0000",
            "id": 45
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_keyword.patch revision 946621.",
            "date": "2010-05-20T13:23:55.827+0000",
            "id": 46
        },
        {
            "author": "Doron Cohen",
            "body": "contrib/benchmark's NewShingleAnalyzerTask depends on modules' o.a.l.analysis.shingle.ShingleAnalyzerWrapper - causing cyclic dependency between projects - e.g. when creating separate Eclipse projects for lucene and modules. ",
            "date": "2010-05-24T20:58:51.159+0000",
            "id": 47
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\ncontrib/benchmark's NewShingleAnalyzerTask depends on modules' o.a.l.analysis.shingle.ShingleAnalyzerWrapper - causing cyclic dependency between projects - e.g. when creating separate Eclipse projects for lucene and modules.\n{quote}\n\nHi, its not a cyclic dependency, as the analyzers module only depends on core lucene. \n\nIf you want to have separate projects I would make the contribs separate, too, or put everything in one eclipse project (this is what I prefer).\n",
            "date": "2010-05-24T21:04:38.953+0000",
            "id": 48
        },
        {
            "author": "Robert Muir",
            "body": "By the way, one idea could be to make benchmark a module itself (the benchmarking module for all lucene/solr related stuff).\n\nI noticed Solr lacks a standard benchmarking suite, and at the same time more benchmarks are being created even for\ncontribs/modules (highlighter, analyzers)\n",
            "date": "2010-05-24T21:13:27.024+0000",
            "id": 49
        },
        {
            "author": "Robert Muir",
            "body": "attached is a patch that pulls out the rest of lucene's concrete analyzers and puts them in the analyzers module.\n\nin order to do this, I had to rearrange demo. Instead i made it contrib/demo, and this really simplified the build system.\n",
            "date": "2010-05-25T18:36:43.935+0000",
            "id": 50
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_coreAnalyzers.patch revision 948195.",
            "date": "2010-05-25T20:18:06.078+0000",
            "id": 51
        },
        {
            "author": "Robert Muir",
            "body": "moves CharFilter, CharArraySet, and CharArrayMap",
            "date": "2010-05-25T21:36:55.938+0000",
            "id": 52
        },
        {
            "author": "Robert Muir",
            "body": "Committed LUCENE-2413_coreUtils.patch revision 948225",
            "date": "2010-05-25T22:28:49.662+0000",
            "id": 53
        },
        {
            "author": "Steve Rowe",
            "body": "I found an unchanged package name in a .alg file in contrib/benchmark, and went looking for more similar issues - this patch fixes the directory references and packages I found that were still pointing to the old locations.",
            "date": "2010-06-16T06:42:49.358+0000",
            "id": 54
        },
        {
            "author": "Robert Muir",
            "body": "Thanks Steven, committed revision 955203 of your patch.",
            "date": "2010-06-16T11:34:32.612+0000",
            "id": 55
        },
        {
            "author": "Robert Muir",
            "body": "patch that moves the phonetic, doublemetaphone, and capitalization filters to the analysis module.\n\nwith this patch, all concrete analysis components are consolidated and available to both lucene and solr users. \n\nI think i would like to close this issue and further, more complicated refactorings  (distancing analysis from indexing, moving factories/abstract classes etc) can be done on their own issues.\n",
            "date": "2010-06-23T04:55:19.133+0000",
            "id": 56
        },
        {
            "author": "Robert Muir",
            "body": "Committed revision 957162.",
            "date": "2010-06-23T11:26:33.890+0000",
            "id": 57
        }
    ],
    "component": "modules/analysis",
    "description": "We've been wanting to do this for quite some time now...  I think, now that Solr/Lucene are merged, and we're looking at opening an unstable line of development for Solr/Lucene, now is the right time to do it.\n\nA standalone module for all analyzers also empowers apps to separately version the analyzers from which version of Solr/Lucene they use, possibly enabling us to remove Version entirely from the analyzers.\n\nWe should also do LUCENE-2309 (decouple, as much as possible, indexer from the analysis API), but I don't think that issue needs to block this consolidation.\n\nOnce we do this, there is one place where our users can find all the analyzers that Solr/Lucene provide.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2413",
    "issuetypeClassified": "REFACTORING",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Consolidate all (Solr's & Lucene's) analyzers into modules/analysis",
    "systemSpecification": true,
    "version": ""
}