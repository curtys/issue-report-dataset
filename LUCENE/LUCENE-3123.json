{
    "comments": [
        {
            "author": "Doron Cohen",
            "body": "This is on Ubuntu btw.\n\nRun log:\n{noformat}\nNOTE: reproduce with: ant test -Dtestcase=TestIndexWriter -Dtestmethod=testBackgroundOptimize -Dtests.seed=-3981504507637360146:51354004663342240\nNOTE: reproduce with: ant test -Dtestcase=TestIndexWriter -Dtestmethod=testBackgroundOptimize -Dtests.seed=-3981504507637360146:51354004663342240\nThe following exceptions were thrown by threads:\n*** Thread: Lucene Merge Thread #0 ***\norg.apache.lucene.index.MergePolicy$MergeException: java.io.FileNotFoundException: /tmp/test4907593285402510583tmp/_51_0.sd (Too many open files)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler.handleMergeException(ConcurrentMergeScheduler.java:507)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:472)\nCaused by: java.io.FileNotFoundException: /tmp/test4907593285402510583tmp/_51_0.sd (Too many open files)\n\tat java.io.RandomAccessFile.open(Native Method)\n\tat java.io.RandomAccessFile.<init>(RandomAccessFile.java:233)\n\tat org.apache.lucene.store.SimpleFSDirectory$SimpleFSIndexInput$Descriptor.<init>(SimpleFSDirectory.java:69)\n\tat org.apache.lucene.store.SimpleFSDirectory$SimpleFSIndexInput.<init>(SimpleFSDirectory.java:90)\n\tat org.apache.lucene.store.SimpleFSDirectory.openInput(SimpleFSDirectory.java:56)\n\tat org.apache.lucene.store.FSDirectory.openInput(FSDirectory.java:337)\n\tat org.apache.lucene.store.MockDirectoryWrapper.openInput(MockDirectoryWrapper.java:402)\n\tat org.apache.lucene.index.codecs.mockrandom.MockRandomCodec.fieldsProducer(MockRandomCodec.java:236)\n\tat org.apache.lucene.index.PerFieldCodecWrapper$FieldsReader.<init>(PerFieldCodecWrapper.java:113)\n\tat org.apache.lucene.index.PerFieldCodecWrapper.fieldsProducer(PerFieldCodecWrapper.java:210)\n\tat org.apache.lucene.index.SegmentReader$CoreReaders.<init>(SegmentReader.java:131)\n\tat org.apache.lucene.index.SegmentReader.get(SegmentReader.java:495)\n\tat org.apache.lucene.index.IndexWriter$ReaderPool.get(IndexWriter.java:635)\n\tat org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:3260)\n\tat org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:2930)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:379)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:447)\nNOTE: test params are: codec=RandomCodecProvider: {field=MockRandom}, locale=nl_NL, timezone=Turkey\nNOTE: all tests run in this JVM:\n[TestIndexWriter]\nNOTE: Linux 2.6.32-31-generic i386/Sun Microsystems Inc. 1.6.0_20 (32-bit)/cpus=1,threads=2,free=26480072,total=33468416\n{noformat}",
            "date": "2011-05-19T12:56:01.842+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "Does that repro line reproduce the failure for you Doron?  It's odd because that test doesn't make that many fields... oh I see it makes a 100 segment index. I'll drop that to 50...\n\nThe nightly build also hits too-many-open-files every so often, I suspect because our random-per-field-codec is making too many codecs... I wonder if we should throttle it?  Ie if it accumulates too many codecs, to start sharing them b/w fields?",
            "date": "2011-05-19T17:21:51.763+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "I dropped it from 100 to 50 segs.  Can you test if that works in your env Doron?",
            "date": "2011-05-19T17:25:00.425+0000",
            "id": 2
        },
        {
            "author": "Doron Cohen",
            "body": "Yes, thanks, now it passes (trunk) - with this seed as well quite a few times without specifying a seed. \nI'll now verify on 3x.",
            "date": "2011-05-19T17:51:23.410+0000",
            "id": 3
        },
        {
            "author": "Doron Cohen",
            "body": "I fact in 3x this is not reproducible with same seed (expected as Robert once explained) and I was not able to reproduce it with no seed, tried with -Dtest.iter=100 as well (though I am not sure, would a new seed be created in each iteration? Need to verify this...)\nAnyhow in 3x the test passes also after svn up with this fix.\nSo I think this can be resolved...",
            "date": "2011-05-19T18:02:23.699+0000",
            "id": 4
        },
        {
            "author": "Doron Cohen",
            "body": "Fixed by Mike, thanks Mike!",
            "date": "2011-05-19T18:05:24.616+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "Thanks for raising it Doron!",
            "date": "2011-05-19T21:24:37.481+0000",
            "id": 6
        },
        {
            "author": "Robert Muir",
            "body": "Bulk closing for 3.2",
            "date": "2011-06-03T16:37:18.404+0000",
            "id": 7
        }
    ],
    "component": "core/index",
    "description": "Recreate with this line:\n\nant test -Dtestcase=TestIndexWriter -Dtestmethod=testBackgroundOptimize -Dtests.seed=-3981504507637360146:51354004663342240\n\nMight be related to LUCENE-2873 ?",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-3123",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "TestIndexWriter.testBackgroundOptimize fails with too many open files",
    "systemSpecification": true,
    "version": ""
}