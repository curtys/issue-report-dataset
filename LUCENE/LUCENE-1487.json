{
    "comments": [
        {
            "author": "Tim Sturge",
            "body": "FieldCacheTermsFilter  using OpenBitSet.fastGet()",
            "date": "2008-12-10T21:31:02.426+0000",
            "id": 0
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Would it be possible to reformat to use Lucene code style and add a bit of javadoc/unit test?  Eclipse and IDEA styles are at the bottom of http://wiki.apache.org/lucene-java/HowToContribute\n",
            "date": "2008-12-11T05:22:15.293+0000",
            "id": 1
        },
        {
            "author": "Tim Sturge",
            "body": "No problem at all. Should I assume this means that the idea is generally considered sound; the only question is getting something with sufficient tests/docs/level of finish?\n\nI was expecting to get comments about the implementation first; last time what ended up going in was very different (in good ways) from my initial submission. \n\n",
            "date": "2008-12-11T19:55:02.781+0000",
            "id": 2
        },
        {
            "author": "Mark Miller",
            "body": "Hold out Tim, your likely to get further comments before it goes in. I think Otis was just suggesting we start with those changes. Once your code is in the right format, your more likely to get a committer to spend some time with it. Sometimes we just reformat and add the tests ourselves depending on a host of factors, but in general, your more likely to get good comments  faster if that work has already been done.\n\nIts a fair question to ask if the idea is sound, but just posting the work doesn't necessarily imply that you are looking for that advice before putting more work into what you have done. And many times questions do go unanswered, they are missed, people don't have the time at the moment - so its best to supply all of this stuff, unless you are prepared for a wait if their is no current interest in going over the patch.",
            "date": "2008-12-11T20:10:37.754+0000",
            "id": 3
        },
        {
            "author": "Tim Sturge",
            "body": "I'm running a bit behind this week and I'm out most of next week so it may be a while before I get to this.\n\nOne thing I hope will be helpful in the interim is to repost here the java-dev exchange that lead to me posting this here; I suspect that many people who watch JIRA don't necessarily read java-dev as well and I hope the postings are informative.\n\nHere's the exchange:\n\nOn 12/10/08 1:13 PM, \"Tim Sturge\" <tsturge@hi5.com> wrote:\n\n> Yes (mostly). It turns those terms into an OpenBitSet on the term array.\n> Then it does a fastGet() in the next() and skipTo() loops to see if the term\n> for that document is in the set.\n> \n> The issue is that fastGet() is not as fast as the two inequalities in FCRF.\n> I didn't directly benchmark FCTF against FCRF because I had a different\n> application in mind for FCTF (location boxes). However it wasn't as\n> efficient in that case as directly realizing the bit sets. This was mostly\n> because in the application I had in mind there were a lot (>100K) of terms\n> with relatively low frequency and queries that needed only a few hundred\n> terms in the set.\n> \n> I tried a sorted list of terms and Arrays.binarySearch() but that is way\n> slower as is Set<Integer> (no surprise there). I was thinking about a custom\n> hash table implementation but I'm not hopeful; it increases cycle cost and\n> means \n> \n> So it is efficient but for a more limited set of cases than FCRF. My gut\n> feeling is that FCRF is a better solution for \"most\" range filters, whereas\n> FCTF is a better solution for \"some\" term set filters (versus creating\n> TermsFilter objects on the fly each time) It all depends on how common the\n> terms are and how large the sets of terms are. Lots of terms (or a few very\n> common terms) it wins. A few less common terms it loses.\n> \n> I'll open a JIRA issue for it.\n> \n> Tim\n> \n> On 12/10/08 12:45 PM, \"Michael McCandless\" <lucene@mikemccandless.com>\n> wrote:\n> \n>> \n>> It'd be great to get this into Lucene.\n>> \n>> Does FieldCacheTermsFilter let you specify a set of arbitrary terms to\n>> filter for, like TermsFilter in contrib/queries?  And it's space/time\n>> efficient once FieldCache is populated?\n>> \n>> Mike\n>> \n>> Tim Sturge wrote:\n>> \n>>> Mike, Mike,\n>>> \n>>> I have an implementation of FieldCacheTermsFilter (which uses field\n>>> cache to\n>>> filter for a predefined set of terms) around if either of you are\n>>> interested. It is faster than materializing the filter roughly when\n>>> the\n>>> filter matches more than 1% of the documents.\n>>> \n>>> So it's not better for a large set of small filters (which you can\n>>> materialize on the spot) but it is better for a small set (but more\n>>> than 32)\n>>> large filters.\n>>> \n>>> Let me know if you're interested and I'll send it in.\n>>> \n>>> Tim\n>>> \n>>> On 12/10/08 3:34 AM, \"Michael McCandless\"\n>>> <lucene@mikemccandless.com> wrote:\n>>> \n>>>> \n>>>> In your approach, roughly how many filters do you have cached?  It\n>>>> seems like it could be quite a few (one for each color, one for each\n>>>> type, etc)?\n>>>> \n>>>> You might be able to modify the new (on Lucene trunk)\n>>>> FieldCacheRangeFilter to achieve this same filtering without actually\n>>>> having to materialize the full bitset for each.\n>>>> \n>>>> Mike\n>>>> \n>>>> Michael Stoppelman wrote:\n>>>> \n>>>>> Yeah looks similar to what we've implemented for ourselves\n>>>>> (although I\n>>>>> haven't looked at the implementation). We've got quite a custom\n>>>>> version of\n>>>>> lucene at this point. Using Solr at this point really isn't a viable\n>>>>> option,\n>>>>> but thanks for pointing this out.\n>>>>> \n>>>>> M\n>>>>> \n>>>>> On Tue, Dec 9, 2008 at 1:47 AM, Michael McCandless <\n>>>>> lucene@mikemccandless.com> wrote:\n>>>>> \n>>>>>> \n>>>>>> This use case sounds alot like faceted navigation, which Solr\n>>>>>> provides.\n>>>>>> \n>>>>>> Mike\n>>>>>> \n>>>>>> \n>>>>>> Michael Stoppelman wrote:\n>>>>>> \n>>>>>> Hi all,\n>>>>>>> \n>>>>>>> I'm working on upgrading to Lucene 2.4.0 from 2.3.2 and was trying\n>>>>>>> to\n>>>>>>> integrate the new DodIdSet changes since\n>>>>>>> o.a.l.search.Filter#bits() method\n>>>>>>> is now depreciated. For our app we actually heavily rely on bits\n>>>>>>> from the\n>>>>>>> Filter to do post-query filtering (I explain why below).\n>>>>>>> \n>>>>>>> For example, if someone searches for product: \"ipod\" and then\n>>>>>>> filters a\n>>>>>>> type: \"nano\" (e.g. mini/nano/regular) AND color: \"red\" (e.g.\n>>>>>>> red/yellow/blue). In our current model the results are gathered in\n>>>>>>> the\n>>>>>>> following way:\n>>>>>>> \n>>>>>>> 1) \"ipod\" w/o attributes is run and the results are stored in a\n>>>>>>> hitcollector\n>>>>>>> 2) \"ipod\" results are now filtered for color=\"red\" AND type=\"mini\"\n>>>>>>> using\n>>>>>>> the\n>>>>>>> lucene Filters\n>>>>>>> 3) The filtered results are returned to the user.\n>>>>>>> \n>>>>>>> The reason that the attributes are filtered post-query is so that\n>>>>>>> we can\n>>>>>>> return the other types and colors the user can filter by in the\n>>>>>>> future.\n>>>>>>> Meaning the UI would be able to show \"blue\", \"green\", \"pink\",\n>>>>>>> etc... if we\n>>>>>>> pre-filtered results by color and type before hand we wouldn't\n>>>>>>> know what\n>>>>>>> the\n>>>>>>> other filter options would be there for a broader result set.\n>>>>>>> \n>>>>>>> Does anyone else have this use case? I'd imagine other folks are\n>>>>>>> probably\n>>>>>>> doing similar things to accomplish this.\n>>>>>>> \n>>>>>>> M\n>>>>>>> \n>>>>>> \n>>>>>> \n>>>>>> ---------------------------------------------------------------------\n>>>>>> To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org\n>>>>>> For additional commands, e-mail: java-user-help@lucene.apache.org\n>>>>>> \n>>>>>> \n>>>> \n>>>> \n>>>> ---------------------------------------------------------------------\n>>>> To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org\n>>>> For additional commands, e-mail: java-user-help@lucene.apache.org\n>>>> \n>>> \n>>> \n>>> ---------------------------------------------------------------------\n>>> To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org\n>>> For additional commands, e-mail: java-user-help@lucene.apache.org\n>>> \n>> \n>> \n>> ---------------------------------------------------------------------\n>> To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org\n>> For additional commands, e-mail: java-user-help@lucene.apache.org\n>> \n> \n> \n> ---------------------------------------------------------------------\n> To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org\n> For additional commands, e-mail: java-user-help@lucene.apache.org\n> \n",
            "date": "2008-12-12T01:50:30.124+0000",
            "id": 4
        },
        {
            "author": "Tim Sturge",
            "body": "Mark, Otis, looking back over the bug history I totally see where you are coming from; I do look like I've just dumped this here without explanation which wasn't my intention.\n\nHonestly I don't really know how useful this is; I think there's a set of cases where it works very well but how comparatively large that set is I am unsure. You can think of it as adding a level of indirection (from documents to terms) to filtering. \n\nThe alternative (at least as far as I can see) is to do a union by term of sorted docid lists (which is fundamentally what a DisjunctionQuery does I think). There may well be other options.\n\n",
            "date": "2008-12-12T02:00:38.848+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "I think this is a useful filter impl, and a nice companion to FCRF.\nI'd like to see it committed; formatting & test case are good next\nsteps.\n\nTermsFilter (in contrib/queries) does the same thing, but creates a\nbitset by docID up front by walking the TermDocs for each term.  An OR\nquery, wrapped in QueryWrapperFilter, is another way.\n\nThis impl uses FieldCache to create a bitset by term number and then\ndoes a scan by docID, so it has different performance tradeoffs: for\n\"enum\" fields (far more docs than unique terms -- like country, state,\netc.) it's fast to create this filter, and then applying the filter is\nO(maxDocs) with a small constant factor.\n\nI think for many apps it means you do not have to cache the filter\nbecause creating & using it \"on the fly\" is plenty fast.\n\n",
            "date": "2008-12-12T09:53:23.408+0000",
            "id": 6
        },
        {
            "author": "Yonik Seeley",
            "body": "I think the name should be different since it only works with single-valued fields, unlike other TermFilters and TermQueries.",
            "date": "2008-12-12T15:42:56.380+0000",
            "id": 7
        },
        {
            "author": "Tim Sturge",
            "body": "Reformatted version. I'm happy to change the name if that's the consensus but I can't think of any better alternatives right now.",
            "date": "2008-12-12T19:55:25.476+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "Yonik do you have any suggestions for a new name (I agree a new name would be better but can't think of one offhand).",
            "date": "2008-12-14T15:42:11.633+0000",
            "id": 9
        },
        {
            "author": "Yonik Seeley",
            "body": "FieldCacheStringFilter?\nFieldCacheValueFilter?\nFieldCacheMatchFilter?\n\nNot sure if any of those are better though.  Perhaps it's enough that \"FieldCache\" is in the name to indicate that it only works on single-valued indexed fields that are able to be cached by the FieldCache.\n",
            "date": "2008-12-14T16:25:15.226+0000",
            "id": 10
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n> Perhaps it's enough that \"FieldCache\" is in the name to indicate that it only works on single-valued indexed fields that are able to be cached by the FieldCache.\n{quote}\nThis'd be my vote (keep the name FieldCacheTermsFilter).\n\nTim, the new patch looks great!  Could you add some javadocs describing the tradeoffs with this filter, and maybe a unit test?  Thanks.",
            "date": "2008-12-16T15:05:01.057+0000",
            "id": 11
        },
        {
            "author": "Michael McCandless",
            "body": "Tim, are you still looking into this?  Or if you don't have the itch/time, does anyone else want to add javadocs & unit test for FieldCacheTermsFilter to move this forwards?",
            "date": "2009-01-28T11:05:45.567+0000",
            "id": 12
        },
        {
            "author": "Shalin Shekhar Mangar",
            "body": "Attached a patch on trunk\n\n# Adds Javadocs per the comments here and my understanding\n# TestFieldCacheTermsFilter is a simple unit test",
            "date": "2009-01-28T20:21:14.674+0000",
            "id": 13
        },
        {
            "author": "Michael McCandless",
            "body": "Fabulous, thanks Shalin!  I changed UN_TOKENIZED --> NOT_ANALYZED in the javadoc,\nand switched to MockRAMDirectory in the test.  I'll commit shortly.",
            "date": "2009-01-28T20:58:05.310+0000",
            "id": 14
        },
        {
            "author": "Michael McCandless",
            "body": "Committed revision 738622.  Thanks Tim & Shalin!",
            "date": "2009-01-28T21:06:40.281+0000",
            "id": 15
        },
        {
            "author": "Mark Miller",
            "body": "So the advantage appears to be that you can cache the field values and so calculate the filter faster for arbitrary terms, rather than having to calculate and cache a bitset for each set of terms if you used TermsFilter - Right? I think it should be easier to extract that info from the javadoc. And more clear on exactly what the tradeoffs are, and when I should choose which.\n\n* The FieldCacheTermsFilter is faster than building a TermsFilter each time.\n\nWhile I did figure it out eventually (if I figured it out right), I'm thinking it could be clearer. It could just be me though. I'm often a bit hazzy.\n\n",
            "date": "2009-01-28T21:40:56.984+0000",
            "id": 16
        },
        {
            "author": "Michael McCandless",
            "body": "I agree: the wording can be improved.  I'll take a stab at it.",
            "date": "2009-01-29T11:10:20.567+0000",
            "id": 17
        },
        {
            "author": "Michael McCandless",
            "body": "How about this:\n\n{code}\n/**\n * A {@link Filter} that only accepts documents whose single\n * term value in the specified field is contained in the\n * provided set of allowed terms.\n * \n * <p/>\n * \n * This is the same functionality as TermsFilter (from\n * contrib/queries), except this filter requires that the\n * field contains only a single term for all documents.\n * Because of drastically different implementations, they\n * also have different performance characteristics, as\n * described below.\n * \n * <p/>\n * \n * The first invocation of this filter on a given field will\n * be slower, since a {@link FieldCache.StringIndex} must be\n * created.  Subsequent invocations using the same field\n * will re-use this cache.  However, as with all\n * functionality based on {@link FieldCache}, persistent RAM\n * is consumed to hold the cache, and is not freed until the\n * {@link IndexReader} is closed.  In contrast, TermsFilter\n * has no persistent RAM consumption.\n * \n * \n * <p/>\n * \n * With each search, this filter translates the specified\n * set of Terms into a private {@link OpenBitSet} keyed by\n * term number per unique {@link IndexReader} (normally one\n * reader per segment).  Then, during matching, the term\n * number for each docID is retrieved from the cache and\n * then checked for inclusion using the {@link OpenBitSet}.\n * Since all testing is done using RAM resident data\n * structures, performance should be very fast, most likely\n * fast enough to not require further caching of the\n * DocIdSet for each possible combination of terms.\n * However, because docIDs are simply scanned linearly, an\n * index with a great many small documents may find this\n * linear scan too costly.\n * \n * <p/>\n * \n * In contrast, TermsFilter builds up an {@link OpenBitSet},\n * keyed by docID, every time it's created, by enumerating\n * through all matching docs using {@link TermDocs} to seek\n * and scan through each term's docID list.  While there is\n * no linear scan of all docIDs, besides the allocation of\n * the underlying array in the {@link OpenBitSet}, this\n * approach requires a number of \"disk seeks\" in proportion\n * to the number of terms, which can be exceptionally costly\n * when there are cache misses in the OS's IO cache.\n * \n * <p/>\n * \n * Generally, this filter will be slower on the first\n * invocation for a given field, but subsequent invocations,\n * even if you change the allowed set of Terms, should be\n * faster than TermsFilter, especially as the number of\n * Terms being matched increases.  If you are matching only\n * a very small number of terms, and those terms in turn\n * match a very small number of documents, TermsFilter may\n * perform faster.\n *\n * <p/>\n *\n * Which filter is best is very application dependent.\n */\n{code}",
            "date": "2009-01-29T13:39:36.019+0000",
            "id": 18
        },
        {
            "author": "Mark Miller",
            "body": "+1",
            "date": "2009-01-29T14:02:23.838+0000",
            "id": 19
        },
        {
            "author": "Shalin Shekhar Mangar",
            "body": "+1\n\nThis is much more clear. Thanks Michael.",
            "date": "2009-01-29T15:38:08.696+0000",
            "id": 20
        },
        {
            "author": "Uwe Schindler",
            "body": "Sorry, I reopened the wrong issue, the correct class is FieldCacheRangeFilter.\n\nClosing again.",
            "date": "2009-06-23T21:09:51.118+0000",
            "id": 21
        }
    ],
    "component": "core/search",
    "description": "This is a companion to FieldCacheRangeFilter except it operates on a set of terms rather than a range. It works best when the set is comparatively large or the terms are comparatively common.\n\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1487",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "FieldCacheTermsFilter",
    "systemSpecification": true,
    "version": "2.4"
}