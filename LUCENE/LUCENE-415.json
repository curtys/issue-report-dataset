{
    "comments": [
        {
            "author": "Otis Gospodnetic",
            "body": "Hi Daniel.  There is probably not much we can do without more information.  If\nyou can create a small index that causes this error, and put together some code\nthat we can run and see the error, then we can step through Lucene and find the\nsource of the problem.  Are you using Lucene 1.4.3?\n",
            "date": "2005-07-28T07:33:34.000+0000",
            "id": 0
        },
        {
            "author": "Daniel Quaroni",
            "body": "I'm using 1.4.3.  I'll give a try at re-indexing the data that caused the \nproblem.  I figured there wouldn't be much you can do - as I said, I've indexed \nabout 100 million records in different indexes several times and this is the \nfirst time I've seen this error.  It was the first time dealing with the \nparticular data that the error occurred on, too.\n\nAnyway, I'll give a try at reproducing it, and if I can, I'll let you know.",
            "date": "2005-07-28T22:51:56.000+0000",
            "id": 1
        },
        {
            "author": "Andy Hind",
            "body": "I have now seen a related issue twice:\n\njava.lang.IndexOutOfBoundsException: Index: 125, Size: 31\n\tat java.util.ArrayList.RangeCheck(ArrayList.java:547)\n\tat java.util.ArrayList.get(ArrayList.java:322)\n\tat org.apache.lucene.index.FieldInfos.fieldInfo(FieldInfos.java:155)\n\tat org.apache.lucene.index.FieldsReader.doc(FieldsReader.java:66)\n\tat org.apache.lucene.index.SegmentReader.document(SegmentReader.java:237)\n\tat org.apache.lucene.index.SegmentMerger.mergeFields(SegmentMerger.java:185)\n\tat org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:92)\n",
            "date": "2005-11-08T21:25:25.000+0000",
            "id": 2
        },
        {
            "author": "Andy Hind",
            "body": "And I can reproduce it .....on 1.4.3\n\nWhen FSDirectory.createFile creates a FSOutputStream the random access file may already exist and contain data. The content is not cleaned out.\n\nSo if segment merging is taking place to a new segment, and the merge has written data to this file ....and the machine crashes/app is terminated .... you can end up with a partial or full segment file that the segment infos knows nothing about. If you restart, then any merge will try to reuse the same file name...and the content it contains.....\n\nTo reproduce the issue I created the next segment file by copying one that already exists .... and bang....on the next merge\n\nI suggest that in FSOutputStream sets the file length to 0 on initialisation (as well as opening the channel to the file which can aslo produce some nasty deferred IO erorrs in windows XP a least)\n\nI am not sure of any side effect of this but will test it.\n\nWe are seeing this 2-3 times a day if under heavy load or single thread and killing the app at random, which may be in the procedss of a segment write... \n",
            "date": "2005-11-17T21:40:37.000+0000",
            "id": 3
        },
        {
            "author": "Andy Hind",
            "body": "We have tested the above solution pretty heavily since 18/11/2005 and would regard it as stable in 1.4.3.\n\nLooking at the 1.9 code stream the issue is likely to be present, unless there is some other code that checks if an index segment file already exists when not expected, or the next segement is generated based in the segments that actually exist in the directory.\n\nIn 1.4.3 ..... in FSDirectory\n\n......\nfinal class FSOutputStream extends OutputStream\n{\n    RandomAccessFile file = null;\n\n    public FSOutputStream(File path) throws IOException\n    {\n        file = new RandomAccessFile(path, \"rw\");\n        file.setLength(0);\n        file.getChannel();\n    }\n......\n\nwill sort this issue and some other file handle issues I have seen under XP\n\nSomething similar is likely to be required in FSIndexOutput  in the 1.9 code line\n\n",
            "date": "2006-03-22T03:03:07.000+0000",
            "id": 4
        },
        {
            "author": "Yonik Seeley",
            "body": "I'm not sure I understand... the new file will be the output or result of a merge, not the input, right?\nIs the problem that the output is appended to an existing file?  In that case, I can see the logic of the file.setLength(0) in your fix.\n\nCould you elaborate more on the effects of \"file.getChannel()\"?  Is it really needed?\n",
            "date": "2006-03-22T06:36:50.000+0000",
            "id": 5
        },
        {
            "author": "Andy Hind",
            "body": "The problem is that the output is going into a file that already exists. \nI assume it leaves and then finds old bits during random access and gets confused.\n\nIf a merge fails while it is writing its output segment file you have a segment file that contains rubbish.\nThis can occur if you are unlucky when you kill the JVM (and to repeat the problem, set a break point and kill the JVM just before the segment write completes). The next time a merge takes place it writes to the segment file that already exists - as the same file name is generated for the new segment file. It always blows with an error similar to that reported for this bug.\n\nThe file.getChannel() solved some fairly odd but repeatable issues with stale/invalid file handles under windows XP.\n\n",
            "date": "2006-03-22T15:39:51.000+0000",
            "id": 6
        },
        {
            "author": "Yonik Seeley",
            "body": "the fact that getChannel has side effects in Windows makes me a little uncomfortable about what other side effects it has on other platforms.  Is it only needed when truncating a previously existing file, or is it always needed to solve \"fairly odd but repeatable issues with stale/invalid file handles under windows XP\"?\n\nIf the former, we could do the following:\n\n    public FSOutputStream(File path) throws IOException\n    {\n        file = new RandomAccessFile(path, \"rw\"); \n        if (file.length()!=0) {\n          file.setLength(0);\n          file.getChannel().close();   // solved some fairly odd but repeatable issues with stale/invalid file handles under windows XP.\n       }\n    } ",
            "date": "2006-05-18T23:39:36.000+0000",
            "id": 7
        },
        {
            "author": "Andy Hind",
            "body": "file.getChannel() was added on windows.\nIt was *before* the truncating file issue was found and resolved.\nIt is possible the two are related.\nI have not verified and tested the same issue on linux.\nWe had just not seen it on other platforms.\n\n\nIt is possible   file.setLength(0)  also resolves the above issue.\nIt *certainly* solves some JVM crash/recovery issues.\n\n\n\n",
            "date": "2006-05-19T00:05:01.000+0000",
            "id": 8
        },
        {
            "author": "Yonik Seeley",
            "body": "Andy, how easy is it for you to replicate the problems that getChannel() solved?  Is it possible to check if the addition of setLength() alone solves the problem.  getChannel() really shouldn't be needed.\n\n(note: the close() on the fileChannel in my version isn't right since it will cause everything to be closed.)",
            "date": "2006-05-19T03:34:03.000+0000",
            "id": 9
        },
        {
            "author": "Yonik Seeley",
            "body": "Thanks Andy!  I've committed a patch to set the length to zero if it wasn't already.\n\nIf this doesn't also fix the \"some fairly odd but repeatable issues with stale/invalid file handles under windows XP. \" issue, please open a new bug.\n\nThis bug was imported from Bugzilla, doesn't have a status, and hence I can't resolve it.  Anyone else with higher JIRA perms?",
            "date": "2006-06-21T04:33:22.000+0000",
            "id": 10
        },
        {
            "author": "Volodymyr Bychkoviak",
            "body": "Yonik,\n\nis this right code?\n    if (file.length() == 0) {\n      // This can happen if there was a previous crash / unclean shutdown that\n      // left files around, then we end up re-using a segment name.\n      // If we have a logging framework in the future, a warning here might be\n      // a good idea.\n      file.setLength(0);\n    }\n\nmaybe it should be \n\n    if (file.length() != 0) {\n",
            "date": "2006-06-22T21:33:52.000+0000",
            "id": 11
        },
        {
            "author": "Volodymyr Bychkoviak",
            "body": "moreover\n\nFSDirectory.createDirectory() which calls FSIndexOutput constructor already has a check for file existance.",
            "date": "2006-06-22T21:38:51.000+0000",
            "id": 12
        },
        {
            "author": "Yonik Seeley",
            "body": "Thanks for catching that Volodymyr.\n\nI did a further search of the code, and FSIndexOutput is only instantiated in one place: createOutput()\nwhich already does a check if the file exists, and if so deletes it.  If it can't delete it, an exception is thrown.\n\nSo while this patch may have been valid for 1.4, it is no longer needed for Lucene 2.0\nDoes that look right?  If so, I'll revert it.",
            "date": "2006-06-22T21:53:25.000+0000",
            "id": 13
        },
        {
            "author": "Yonik Seeley",
            "body": "Closing (a jira bug prevented me from closing this earlier).",
            "date": "2006-10-17T21:05:07.000+0000",
            "id": 14
        }
    ],
    "component": "core/index",
    "description": "I've been batch-building indexes, and I've build a couple hundred indexes with \na total of around 150 million records.  This only happened once, so it's \nprobably impossible to reproduce, but anyway... I was building an index with \naround 9.6 million records, and towards the end I got this:\n\njava.lang.IndexOutOfBoundsException: Index: 54, Size: 24\n        at java.util.ArrayList.RangeCheck(ArrayList.java:547)\n        at java.util.ArrayList.get(ArrayList.java:322)\n        at org.apache.lucene.index.FieldInfos.fieldInfo(FieldInfos.java:155)\n        at org.apache.lucene.index.FieldInfos.fieldName(FieldInfos.java:151)\n        at org.apache.lucene.index.SegmentTermEnum.readTerm(SegmentTermEnum.java\n:149)\n        at org.apache.lucene.index.SegmentTermEnum.next\n(SegmentTermEnum.java:115)\n        at org.apache.lucene.index.SegmentMergeInfo.next\n(SegmentMergeInfo.java:52)\n        at org.apache.lucene.index.SegmentMerger.mergeTermInfos\n(SegmentMerger.java:294)\n        at org.apache.lucene.index.SegmentMerger.mergeTerms\n(SegmentMerger.java:254)\n        at org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:93)\n        at org.apache.lucene.index.IndexWriter.mergeSegments\n(IndexWriter.java:487)\n        at org.apache.lucene.index.IndexWriter.maybeMergeSegments\n(IndexWriter.java:458)\n        at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:310)\n        at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:294)",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-415",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Merge error during add to index (IndexOutOfBoundsException)",
    "systemSpecification": true,
    "version": "1.4"
}