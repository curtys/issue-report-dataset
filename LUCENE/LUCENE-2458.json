{
    "comments": [
        {
            "author": "Hoss Man",
            "body": "Robter: do you have a specific suggestion for what QueryParser should do if a single \"chunk\" of input causes the Analyzer to produce multiple tokens that are not at the same position (ie: the current case where QueryParser produces a PhraseQuery even if there are no quotes)\n\nIe: if the query parser is asked to parse... \n{code}fieldName:A-Field-Value{code}\n...and the Analyzer produces three tokens...\n * A (at position 0)\n * Field (at position 1)\n * Value (at position 2)\n\n...what should the resulting Query object be?",
            "date": "2010-05-11T21:22:14.715+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "bq. ...what should the resulting Query object be?\n\na Boolean Query formed with the default operator.\n",
            "date": "2010-05-11T21:38:46.108+0000",
            "id": 1
        },
        {
            "author": "Hoss Man",
            "body": "bq. a Boolean Query formed with the default operator.\n\nThat seems like equally bad default behavior -- lots of existing TokenFilters produce chains of tokens for situations where the user creating the query string clearly intended to be searching for a single \"word\" and has no idea that as an implementation detail multiple tokens were produced under the covers (ie: WordDelimiterFilter, Ngrams, etc...)\n\nI haven't thought this through very well, but perhaps this is an area where (the new) Token Attributes could be used to instruct QueryParser as to the intent behind a stream of multiple tokens?  A new Attribute could be used on each token to convey when that token should be combined with teh previous token, and in what way: as a phrase, as a conjunction or as a disjunction.  (this could still be orthogonal to the position, which would indicate slop/span type information like it does currently)\n\nStock Analysys components that produce multiple tokens could be modified to add this attribute fairly easily (it should be a relatively static value for any component that currently \"splits\" tokens) and QueryParser could have an option controlling what to do if  it encounters a token w/o this attribute (perhaps even two options: one for quoted input chunks and one for unquoted input chunks).\n\nthat way the default could still work in a back compatible way, but people using languages that don't use whitespace separation *and* are using older (or custom) analyzers that don't know about this attribute could set a simple query parser property to force this behavior.\n\nwould that make sense? (asks the man who only vaguely understands Token Attributes at this point)",
            "date": "2010-05-11T21:54:45.470+0000",
            "id": 2
        },
        {
            "author": "Robert Muir",
            "body": "bq. That seems like equally bad default behavior\n\nDo you have measurements to support this? Because they show its 10x better to use this operator for Chinese :)\n\nbq. I haven't thought this through very well, but perhaps this is an area where (the new) Token Attributes\n\nI disagree. Instead the queryparser should only form phrasequeries when you use double quotes, just like the documentation says.",
            "date": "2010-05-11T22:20:52.729+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "by the way hoss man you said it best yourself:\n\n{quote}\nlots of existing TokenFilters produce chains of tokens for situations where the user creating the query string clearly intended to be searching for a single \"word\" and has no idea that as an implementation detail multiple tokens were produced under the covers (ie: WordDelimiterFilter, Ngrams, etc...)\n{quote}\n\nUser clearly intended is wrong. WordDelimiterFilter will break tibetan text in a similar manner (it uses no spaces between words), yet no user \"clearly intended\" to form phrase queries.\n\nUsers clearly intend to form phrase queries only when they use the phrase query operator, thats how the query parser is documented to work, and its a bug that it doesnt work that way.",
            "date": "2010-05-11T22:38:03.285+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "This is sneaky behavior on QueryParser's part!  I didn't realize it did this.\n\nWhat are some real use-cases where this is \"good\"?  WordDelmiterFilter seems like a good example (eg, Wi-Fi -> Wi Fi).\n\nIt sounds like it's a very bad default for non-whitespace languages.\n\nIt seems like we should make it controllable, switch it under Version, and change the default going forward to not do this?\n\nbq. Token Attributes could be used to instruct QueryParser as to the intent behind a stream of multiple tokens?\n\nThis seems like a good idea (since we seem to have real-world cases where it's very useful and others where it's very bad)?  Could/should it be per-analyzer?  (ie, WDF would always do this but, say, ICUAnalyzer would never).  Or, per-token created?",
            "date": "2010-05-12T09:52:42.301+0000",
            "id": 5
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nWhat are some real use-cases where this is \"good\"? WordDelmiterFilter seems like a good example (eg, Wi-Fi -> Wi Fi).\nIt sounds like it's a very bad default for non-whitespace languages.\n{quote}\n\nIts a horrible bug! And to boot, i don't think it helps english much as a default either.\nHere's a comparison on an english test collection (Telegraph collection with standardAnalyzer + porter):\n\n||measure||T||TD||TDN||\n|% of queries affected|6%|14%|32%|\n|positionfilter improvement|+1.704%|+0.213%|+0.805%|\n\nSo, turning it off certainly doesn't hurt (I won't try to argue that this small \"improvement\" by turning it off means anything).\nFor chinese, its a 10x improvement on TREC5/TREC6: obviously the bug is horrible there because its generating phrase queries all the time.\n\n{quote}\nThis seems like a good idea (since we seem to have real-world cases where it's very useful and others where it's very bad)? Could/should it be per-analyzer? (ie, WDF would always do this but, say, ICUAnalyzer would never). Or, per-token created?\n{quote}\n\nI am strongly opposed to this. My tibetan example with WDF or whatever above is an easy example.\nI haven't seen any measured real-world example where this helps, subjectively saying \"I like this bug\" isnt convincing me.\n\nWe don't need to push \"what should be phrase query\" onto analysis, it doesn't know from unicode properties etc, what the user wanted.\nWe don't need to put hairy logic into things like StandardTokenizer, to determine if \"the user wanted a phrase query\" or not in certain contexts.\n\nInstead we should just do what the documentation says, and only issue phrase queries when the user asks for one!!!!!!\n",
            "date": "2010-05-12T13:01:02.823+0000",
            "id": 6
        },
        {
            "author": "Marvin Humphrey",
            "body": "I have mixed feelings about this for English.  It's a weakness of our engine\nthat we do not take position of terms within a query string into account.  At\ntimes I've tried to modify the scoring hierarchy to improve the situation, but\nI gave up because it was too difficult.  This behavior of QueryParser is a\nsneaky way of getting around that limitation by turning stuff which should\nalmost certainly be treated as phrase queries as such.  It's the one place \nwhere we actually exploit position data within the query string.\n\nMike's \"wi-fi\" example, though, wouldn't suffer that badly.  The terms \"wi\"\nand \"fi\" are unlikely to occur much outside the context of 'wi-fi/wi fi/wifi'.\nAnd treating \"wi-fi\" as a phrase still won't conflate results with \"wifi\" as\nit would ideally.  \n\nThe example I would use doesn't typically apply to Lucene.  Lucene's\nStandardAnalyzer tokenizes URLs as wholes, but KinoSearch's analogous analyzer\nbreaks them up into individual components.  As described in another recent\nthread, this allows a search for 'example.com' to match a document which\ncontains the URL 'http://www.example.com/index.html'.  It would suck if all of\na sudden a search for 'example.com' started matching every document that\ncontained 'com'. \n\nYou could, and theoretically should, address this problem with sophisticated\nanalysis.  But it does make it harder to write a good Analyzer.  You make it\nmore important to solve what Yonik calls the 'e space mail' problem by making\nit worse.",
            "date": "2010-05-12T15:32:39.583+0000",
            "id": 7
        },
        {
            "author": "Marvin Humphrey",
            "body": "> Because they show its 10x better to use this operator for Chinese\n\nAnother way to achieve this 10x improvement is to change how QP performs its\nfirst stage of tokenization, as you and I discussed at ApacheCon Oakland.\n\nRight now QP splits on whitespace.  If that behavior were customizable, e.g.\nvia a \"splitter\" Analyzer, then individual Han characters would get submitted\nto getFieldQuery() -- and thus getFieldQuery() would no longer turn long\nstrings of Han characters into a PhraseQuery.  It seems wrong to continue to\npush entire query strings from non-whitespace-delimited languages down into\ngetFieldQuery().",
            "date": "2010-05-12T16:01:29.948+0000",
            "id": 8
        },
        {
            "author": "Robert Muir",
            "body": "edit: s/control/contrib. I apologize for the typo.\n\n{quote}\nAs described in another recent\nthread, this allows a search for 'example.com' to match a document which\ncontains the URL 'http://www.example.com/index.html'. It would suck if all of\na sudden a search for 'example.com' started matching every document that\ncontained 'com'.\n{quote}\n\nYou could solve this with better analysis, for example recognizing the full URL and decomposing it into its parts (forming n-grams of them).\nThis would be more performant than the current \"english hacking\" anyway.\n\nI'm honestly having a tough time seeing where to proceed on this issue.\n\nLucene's queryparsing is completely broken for several languages due to this bug, and such language-specific hacking (heuristically forming phrase queries based on things that people subjectively feel helps for english) really doesn't belong in core lucene, but instead elsewhere, perhaps in some special optional pass to the contrib query parser.\n\nThe queryparser really should be language-independent and work well on average, this would fix it for several languages.\n\nHowever, given the *huge* english bias I see here, i have a tough time seeing what concrete direction (e.g. code) i can work on to try to fix it. I feel such work would only be rejected since so many people seem opposed to simplifying the query parser and removing this language-specific hack.\n\nIf someone brings up an issue with the query parser (for instance i brought up several language-specific problems at apachecon), then people are quick to say that this doesn't belong in the queryparser, but should be dealt with on a special case. Why isn't english treated this way too? I don't consider this bias towards english \"at all costs\" including preventing languages such as Chinese from working at all very fair, I think its a really ugly stance for Lucene to take.\n\n",
            "date": "2010-05-12T17:39:09.164+0000",
            "id": 9
        },
        {
            "author": "Ivan Provalov",
            "body": "Robert has asked me to post our test results on the Chinese Collection. We used the following data collection from TREC:\n\nhttp://trec.nist.gov/data/qrels_noneng/index.html\nqrels.trec6.29-54.chinese.gz\nqrels.1-28.chinese.gz\n\nhttp://trec.nist.gov/data/topics_noneng\nTREC-6 Chinese topics (.gz)\nTREC-5 Chinese topics (.gz)\n\nMandarin Data Collection\nhttp://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2000T52\n\nAnalyzer Name Plain analyzers Added PositionFilter (only at query time)\nChineseAnalyzer 0.028 0.264\nCJKAnalyzer 0.027 0.284\nSmartChinese 0.027 0.265\nIKAnalyzer 0.028 0.259\n\n(Note: IKAnalyzer has its own IKQueryParser which yields 0.084 for the average precision)\n\nThanks,\n\nIvan Provalov",
            "date": "2010-05-12T18:01:04.724+0000",
            "id": 10
        },
        {
            "author": "Marvin Humphrey",
            "body": "> I'm honestly having a tough time seeing where to proceed on this issue.\n\nChange the initial split on whitespace to be customizable.  Override the\nsplitting behavior for non-whitespace-delimited languages and feed\ngetFieldQuery() smaller chunks.\n\nThat solves your problem without removing behavior most people believe to be\nhelpful.  Insisting on that orthogonal change is what is holding things up.\n",
            "date": "2010-05-12T19:03:58.865+0000",
            "id": 11
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nChange the initial split on whitespace to be customizable. Override the\nsplitting behavior for non-whitespace-delimited languages and feed\ngetFieldQuery() smaller chunks.\n{quote}\n\nWhitespace doesn't separate words in the majority of the world's languages, including english.\n\nThe responsibility should be instead on english to do its language-specific processing, not on everyone else to dodge it.",
            "date": "2010-05-12T19:09:39.640+0000",
            "id": 12
        },
        {
            "author": "Hoss Man",
            "body": "bq. Instead the queryparser should only form phrasequeries when you use double quotes, just like the documentation says.\n\ni'll grant you that the documentation is wrong -- i view that as a bug in the documentation, not the code.  \n\nSaying that a PhraseQuery object should only ever be constructed if the user uses quotes is like saying that a BooleanQuery should only ever be constructed if the user specifies boolean operators -- there is no rule that the syntax must match the query structure, the same Query classes can serve multiple purposes.  The parser syntax should be what makes sense  for hte user, and the query structure constructed should be what makes sense for hte index, based on the syntax used by the user.\n\nIf i have built an index consisting entirely of ngrams, the end user shouldn't have to know that -- they shouldn't have to put every individual word in quotes to force a PhraseQuery to be constructed out of the ngram tokenstream produced by an individual word.\n\nbq. Why isn't english treated this way too? I don't consider this bias towards english \"at all costs\" including preventing languages such as Chinese from working at all very fair, I think its a really ugly stance for Lucene to take.\n\nI personally don't view it as an \"english bias\" ... to be it is a \"backwards compatibility bias\"  \n\nI'm totally happy to make things onfigurable, but if two diametrically opposed behaviors are both equally useful, and If there is a choice needs to be made between leaving the default configuration the way the current hardcoded behavior is, or make the default the exact opposite of what the current hardcoded behavior is, it is then i would prefer to leave the default alone -- especially since this beahior has been around for so long, and many Analyzers and TOkenFilters, have been written with this behavior specificly in mind (several examples of this are in the Lucene code base -- and if we have them in our own code, you can be sure they exist \"in the wild\" of client code that would break if this behavior changes by default)\n\nOnce again: if this is a problem that can be solved \"per instance\" with token attributes, then by all means let's make *all* of the TokenFIlters that come \"out of the box\" implement this appropriately (english and non-english alike) so that people who change the default settings on the queryparser get the \"correct\" behavior regardless of langauge.  but all other things being equal lets keep the behavior working the way it has to avoid suprises.\n\nbq. What are some real use-cases where this is \"good\"?\n\n * WordDelimiterFilter (\"wi-fi\" is a pathalogicaly bad example for this issue because as robert pointed out \"wi\" and \"fi\" don't tend to exist independently in english, but people tend to get anoyed when \"race-horse\" matches all docs containing \"race\" or \"horse\")\n * single word to multiword synonym expansion/transformation (particularly acronym expansion: GE => General Electric)\n * Ngram indexing for fuzzy matching (if someone searches for the word billionaire they're going to be surprised to get documents containing \"lion\")\n\n\n",
            "date": "2010-05-12T19:10:18.909+0000",
            "id": 13
        },
        {
            "author": "Robert Muir",
            "body": "bq. but all other things being equal lets keep the behavior working the way it has to avoid suprises.\n\nThis attitude makes me sick. The surprise is to the CJK users that get no results due to undocumented, english-specific hacks that people refuse to let go of.",
            "date": "2010-05-12T19:13:06.621+0000",
            "id": 14
        },
        {
            "author": "DM Smith",
            "body": "As I see it there are two issues:\n1) Backward compatibility. \n2) Correctness according to the syntax definition of a query.\n\nLet me preface the following by saying I have not studied the query parser in Lucene. Over 20 years ago I got an MS in compiler writing. I've been away from it for quite a while.\n\nSo, IMHO as a former compiler writer:\n\nMaybe I'm just not \"getting it\" but it should be trivial to define the grammar (w/ precedence for any ambiguity, if necessary) and implement it. The tokenizer for the parser should have the responsibility to break the input into sequences of meta and non-meta. This tokenizer should not be anything more than what the parser requires.\n\nThe non-meta reasonably is subject to further tokenization/analysis. This further analysis should be entirely under the user's control. It should not be part of the parser.\n\nRegarding the issue, I think it would be best if a quotation was the sole criteria for the determination of what is a phrase, not some heuristical analysis of the token stream.\n",
            "date": "2010-05-13T04:04:54.290+0000",
            "id": 15
        },
        {
            "author": "Michael McCandless",
            "body": "I'd like a solution that lets us have our cake and eat it too...\n\nIe, we clearly have to fix the disastrous out-of-the-box experience\nthat non-whitespace languages (CJK) now have with Lucene.  This is\nclear.\n\nBut, when an analyzer that splits English-like compound words (eg\ne-mail -> e mail) is used, I think this should also continue to create\na PhraseQuery, out-of-the-box.\n\nToday when a user searches for \"e-mail\", s/he will correctly see only\n\"email/e-mail\" hit & highlighted in the search results.  If we break\nthis behaviour, ie no longer produce a PQ out-of-the-box, suddenly\nhits with just \"mail\" will be returned, which is bad.\n\nSo a single setter on QueryParser w/ a global default is not a good\nenough solution -- it means either CJK or English-like compound words\nwill be bad.\n\nThis is why I like the token attr based solution -- those analyzers\nthat are doing \"English-like\" de-compounding can mark the tokens as\nsuch.  Then QueryParser can notice this attr and (if configured to do so, via\nsetter), create a PhraseQuery out of that sequence of tokens.\n\nThis then pushes the decision of which series of Tokens are produced\nvia \"English-like\" de-compounding.  EG I think WordDelimiterFilter\nshould be default mark its tokens as such (the majority of users use\nit this way).  When StandardAnalyzer splits a part-number-like token,\nit should do so as well.\n\nThis isn't a perfect solution: it's not easy, in general, for an\nanalyzer to \"know\" its splits are \"English-like\" de-compounding, but\nthis would still give us a solid step forward (progress not\nperfection).  And, since the decision point is now in the analyzer,\nper-token, it gives users complete flexibility to customize as needed.\n\nBTW, this appears to not be an English-only need; this page\n(http://www.seobythesea.com/?p=1206) lists these example languages as\nalso using \"English-like\" compound words: \"Some example languages that\nuse compound words include: Afrikaans, Danish, Dutch-Flemish, English,\nFaroese, Frisian, High German, Gutnish, Icelandic, Low German,\nNorwegian, Swedish, and Yiddish.\"\n\n",
            "date": "2010-05-13T09:38:05.895+0000",
            "id": 16
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nThis is why I like the token attr based solution\n{quote}\n\nI am, and will always be, -1 to this solution. Why can't we try to think about lucene from a proper internationalization architecture perspective? \n\nYou shouldnt design apis around \"e-mail\" phenomena in english, thats absurd.\n\n{quote}\nBTW, this appears to not be an English-only need; this page\n(http://www.seobythesea.com/?p=1206) lists these example languages as\nalso using \"English-like\" compound words: \"Some example languages that\nuse compound words include: Afrikaans, Danish, Dutch-Flemish, English,\nFaroese, Frisian, High German, Gutnish, Icelandic, Low German,\nNorwegian, Swedish, and Yiddish.\"\n{quote}\n\nPlease don't try to insinuate that phrases are the way you should handle compound terms in these languages unless you have some actual evidence that they should be used instead of \"normal decompounding\".\n\nThese languages have different syntax and word formation, and its simply not appropriate.\n",
            "date": "2010-05-13T11:29:57.174+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "Sorry for intervening,\n\nI am in the same opinion like Hoss:\nA lot of people are common to be able to create phrases in search engines by appending words with dashes (which StandardAnalyzer is perfectly doing with the current query parser impl). As quotes are slower to write, I e.g. always use this approach to search for phrases in Google this-is-a-phrase, which works always and brings identical results like \"this is a phrase\" (only ranking is sometimes slightly different in Google).\n\nSo we should have at least some possibility to switch the behavior on that creates phrase queries out of multiple tokens with posIncr>0 -- but I am +1 on fixing the problem for non-whitespace languages like cjk. Its also broken, that QueryParser parses whitespace in its javacc grammar, in my opinion, this should be done by the analyzer (and not partly by analyzer and QP grammar).\n\nIn addition: I just bring in again non-compounds like product ids...",
            "date": "2010-05-13T11:48:01.277+0000",
            "id": 18
        },
        {
            "author": "Robert Muir",
            "body": "bq. When StandardAnalyzer splits a part-number-like token, it should do so as well.\n\nI don't think StandardAnalyzer should do any such thing. Maybe in some screwed up search engine biased towards english and analyzers have to work around it, then EnglishAnalyzer would do this, but not StandardAnalyzer.\n\nAnd now you see why this is no solution at all, we will only then end up arguing about the toggle for this aweful hack in more places!\n\nInstead, the tokenizer used for English should tokenize English better, rather than hacking *the entire search engine* around it.",
            "date": "2010-05-13T12:25:01.239+0000",
            "id": 19
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. Instead the queryparser should only form phrasequeries when you use double quotes, just like the documentation says.\n\nWe're conflating high level user syntax and the underlying implementation.\n\n'text:Ready' says \"search for the word 'ready' in the field 'text'\"... the fact that an underlying term query of 'text:readi' (after lowercasing, stemming, etc) is not incorrect, it's simply the closest match to what the user is asking for given the details of analysis.  Likewise, a user query of 'text:ak-47'  may end up as a phrase query of \"ak 47\" because that's the closest representation in the index (the user doesn't necessarily know that the analysis of the field splits on dashes).\n\nLikewise, a user query of text:\"foo bar\" is a high level way of saying \"search for the word foo immediately followed by the word bar\".  It is *not* saying \"make a Lucene phrase query object with 2 terms\".  Synonyms, common grams, or other analysis methods may in fact turn this into a single term query.",
            "date": "2010-05-13T14:23:58.558+0000",
            "id": 20
        },
        {
            "author": "Yonik Seeley",
            "body": "bq This is why I like the token attr based solution\n\n+1\n\nAlthough I think it's more general than \"de-compounding\".\nAn attribute that says \"these tokens go together\" or \"these tokens should be considered one unit\" seems like nice generic functionality, and is unrelated to any specific language or search feature.\n",
            "date": "2010-05-13T14:37:48.269+0000",
            "id": 21
        },
        {
            "author": "Robert Muir",
            "body": "bq. We're conflating high level user syntax and the underlying implementation.\n\nThen you have no problem if we form phrase queries for all adjacent english words, like we do for chinese.\n\nPerhaps then you will aware of how wrong this is, this hack designed to make open compounds match hyphenated compounds in english, or whatever it is.\n\nYou are conflating english syntax and word formation into the query parser itself.\n",
            "date": "2010-05-13T14:40:07.764+0000",
            "id": 22
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nAn attribute that says \"these tokens go together\" or \"these tokens should be considered one unit\" seems like nice generic functionality, and is unrelated to any specific language or search feature.\n{quote}\n\nNo,  if they are one unit for search, they are one token.\n\nInstead the tokenizer should be fixed so that they are one token, instead of making all languages suffer for the lack of a crappy english tokenizer.\n",
            "date": "2010-05-13T14:47:24.783+0000",
            "id": 23
        },
        {
            "author": "Michael McCandless",
            "body": "OK mulling some more on this one...\n\nEven for english, the QP hack (pre-splitting on whitespace, then\nturning any text that analyzers to multiple tokens into a\nPhraseQuery), doesn't work right.\n\nEG, say I want ice-cream, ice cream and icecream to mean the same\nthing.  Really I should do this (handling compounds) during indexing\n-- I'll get better relevance and performance.  But say for some reason\nI'm doing it at search time...\n\nI would want an analyzer that detects all three forms and in turn\nexpands to all three forms in the query.\n\nBut there's no way to do this today, because QP pre-splits on\nwhitespace, for ice cream the analyzer would separately receive ice\nand cream, so it never has a chance to detect this form of the\ncompound.\n\nSo... first, I think we should fix QP to not pre-split on whitespace.\nQP really should be as language neutral as possible.  It should only\nsplit on syntax chars, and send the whole string in between syntax\nchars to the analyzer.\n\nAnd, second, the QP should not create PhraseQuery when it sees\nmultiple tokens come back.  This obliterates the OOTB experience for\nnon-whitespace languages.  And, it doesn't work right for\nenglish... so I think we should deprecate the option and default it to\n\"off\".\n\nReally the contrib queryparser is a better fit for doing rewrites like\nthis: it's able to operate on the abstract query tree, and can easily\ndo things like rewriting the query to add phrase queries...\n",
            "date": "2010-05-19T19:33:34.042+0000",
            "id": 24
        },
        {
            "author": "Robert Muir",
            "body": "Attached is a patch that addresses most of the issue:\n\nNOTE: I do not tackle the 'split on whitespace' issue as this is a larger change and would require changes to the actual grammar itself. We can open a separate JIRA issue for this. This issue is about not generating phrase queries based on how many terms come out of the hardcoded whitespace-tokenizer in QueryParser.\n\n* The bug is preserved based on both Version and subclassing, so previous subclasses overriding getFieldQuery work just fine as before.\n* All lucene/solr tests pass, the backwards/ still uses LUCENE_CURRENT so i had to add a TEST_VERSION_CURRENT there, so that it runs the tests as LUCENE_30 (this is a problem in general).\n* This fixes a host of issues for CJK, not only do we let normal queries work, but phrase/sloppy phrase work correctly too if you use the double quotes. (because if you use PositionFilter hack you disable these!)\n* Normal CJK queries also get coord(), which if you use the PositionFilter hack is disabled too, because it treates the entire query as synonyms. CJK users should get coord() too, like english users, thanks to Ivan for testing this (additional 12% relevance boost on their test collection).\n* Normal CJK queries are formed by the queryparser default operator, same as english queries.\n* English synonym queries (1 term followed by multiple positions) still get coord() disabled as they should.\n* I only migrated one subclass to the new API, the \"Extendable Query Parser\", and only because its TestExtendable actually extends TestQueryParser from core (so it had to be done).\n\nTODO:\n* The coord-disabled-BQ code for english synonyms need to be generalized in case CJK users use synonyms, single terms followed by posinc=0 terms should form coord-disabled-BQ's just like they do for english.\n* Add some nice explicit tests for CJK queries, phrase queries, sloppy phrase queries, CJK queries with synonyms, etc.\n* Cutover remaining queryparsers\n\nedit: by the way this patch is for 3x, not trunk yet, because 3x has back-compat tests enabled\n",
            "date": "2010-05-21T05:57:34.288+0000",
            "id": 25
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nBut there's no way to do this today, because QP pre-splits on\nwhitespace, for ice cream the analyzer would separately receive ice\nand cream, so it never has a chance to detect this form of the\ncompound.\n{quote}\n\nI completely agree with this... the hack hurts english too!\n\nBut i ask that we open a separate issue for this, \nas providing backwards compat for this separate problem seems like\nit might need \"sophisticated backwards layer\".\n\nSolving this first problem can be done without any grammar modifications.\n",
            "date": "2010-05-21T06:48:44.849+0000",
            "id": 26
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nBut i ask that we open a separate issue for this, \nas providing backwards compat for this separate problem seems like\nit might need \"sophisticated backwards layer\".\n{quote}\nI agree, let's handle this (\"QP should not pre-split on whitespace but instead leave that to the analyzer since it's language specific\") as a separate issue.",
            "date": "2010-05-21T10:40:35.290+0000",
            "id": 27
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks good Robert!\n\nYou've added a new \"boolean quoted\" param, to getFieldQuery.\n\nIt's true if the search has double quotes, to force a PhraseQuery.  But if there are no double quotes, it's true when Version < 31, else false.\n\nAnd, when it's not quoted, you also fixed coord to be enabled for the BQ created, and for the operator to be respected in the BQ that's created (for the \"Chinese\" cases).  The getFieldQuery method is now very scary :)  But I don't think we can improve that much (the logic is must implement is fundamentally hairy).\n\nSo users who want to emulate the English-optimized \"forced PhraseQuery even when user didn't say so explicitly\" can create QP with VERSION_30.\n",
            "date": "2010-05-21T10:58:24.430+0000",
            "id": 28
        },
        {
            "author": "Robert Muir",
            "body": "bq. But I don't think we can improve that much (the logic is must implement is fundamentally hairy).\n\nI do have some suggestions for the future (we could do when we can get rid of the deprecated behavior).\nBut I couldn't implement anything below, because this change I am working on is already hairy enough itself :)\n\nThe problem with getFieldQuery is that it does too much. One of the things it does is a bunch of query rewrites. \nI think a lot of this is silly, and I think if you search on \"foo\" its ok for the QP to call newPhraseQuery and return a 1-term PhraseQuery.\nThis is, after all, what the query was, and it should be closer to a simple parser.\nPhraseQuery already has its own code to later rewrite() to a single TermQuery in this case.\n\nThe other problem with this method is that it is trying to abuse a CachingTokenFilter to work with a TokenStream in 'extra dimensions' that it doesnt have.\nIn my opinion, instead of doing this, it should just put the terms from the TokenStream in a more suitable data structure that allows the code to be less hairy,\ninstead of using a CachingTokenFilter and reset()'ing it.\n\n",
            "date": "2010-05-21T12:46:13.660+0000",
            "id": 29
        },
        {
            "author": "Robert Muir",
            "body": "i added tests for CJK, and cut over all ? extends QueryParser classes.\n\nTODO still:\n* shouldnt depend on whitespace/term count for coord (so cjk synonyms work nice)\n* fix flexible and precedence queryparsers.\n",
            "date": "2010-05-21T22:07:53.323+0000",
            "id": 30
        },
        {
            "author": "Mark Miller",
            "body": "I still don't think this falls under bug territory myself - which leads me to thinking that Version is not the correct way to handle it.\n\nThe icecream example showing that this is not a 'perfect' solution even for english does not show its a bug in my opinion either. \n\nI still vote to make this an option. Or make another QueryParser that works with more languages, and I guess with less 'biased' english language operators. The whole idea of the new QP was to make that type of thing easy if I remember right.\n\nbq. So users who want to emulate the English-optimized \"forced PhraseQuery even when user didn't say so explicitly\" can create QP\n\nThis should be an option, not an emulation.",
            "date": "2010-05-22T20:59:24.529+0000",
            "id": 31
        },
        {
            "author": "Shai Erera",
            "body": "FWIW, I agree w/ Mark. I don't think it's a bug, but more of a user option. Whether it should be specified by a setter, or an extension of QP - I have no strong feelings for either of them, so either would be fine by me.\n\nAnd for what's it's also worth, we've once worked w/ a Japanese linguist, who suggested that we always convert queries like [abcd] to [abcd \"abcd\"] or just [\"abcd\"] because if someone had already bothered to write them like that, then phrase matching should contribute to the rank of the documents. IMO, if someone had gone even further by writing [field:abcd], then even if the query should be [field:a field:b field:c field:d], executing the query [field:\"abcd\"] is still important and better.\n\nSo .. I'm not trying to argue what should be the default behavior, because that is subject to personal flavor and apps requirements -- only to emphasize that there are many user cases out there, and we should cater for such scenarios.\n\nThe extension way is already supported, right? So perhaps we just need to document the current behavior, and not change anything? Or, introduce a setter, that will do the simple thing - either keep it as a phrase or break it down to terms. More sophisticated scenarios can be dealt through extension.",
            "date": "2010-05-23T04:37:55.174+0000",
            "id": 32
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. FWIW, I agree w/ Mark. I don't think it's a bug, but more of a user option\nI would rather agree with Shai and Mark here but it is also not the behavior I would expect if I come to lucene the first time and use query parser. I still don't understand why this should not be done by using version. Exactly stuff like that where the reason to introduce it. Using Version to change runtime behavior has been done before (see CharTokenizer, CharacterUtils, LowerCaseFilter). IMO this is a totally valid usage and makes people aware of that something has changed. I also figured that Version seriously got adopted in the Community, people start using and appreciating it which somewhat changed my mind on Version.\n\nbq. And for what's it's also worth, we've once worked w/ a Japanese linguist,\nThere will be tons of different opinions to that around linguists around the world but this parser is not for linguists in the first place. It should give the majority of users a good DEFAULT and has never aimed to be a perfect solution. I usually recommend to misplease everybody equally than being biased towards a certain usergroup when providing an API which is not super special purpose.\n\nIt seems to me making this behavior available with Version is the right way to go. I don't care if people call it a bug or a good default for US text - what count is to give people a good default no matter what they index or where they come from. (sounds like this is close to discriminating people - just kidding)\n\nAnother thing i wanna mention is that QueryParser should really be in contrib / modules rather than in core. I don't know how many parsers we have in the meanwhile but we should really consolidate them in a new module for 4.0. Get the stuff out there, make a copy of the current parser, name it \"SmartENBiasedAutomaticPhraseGeneratingQueryParser\", fix that in the other one and provide people a good default.\n\njust my $0.05",
            "date": "2010-05-23T09:08:07.962+0000",
            "id": 33
        },
        {
            "author": "Mark Miller",
            "body": "{quote}\nIt seems to me making this behavior available with Version is the right way to go. I don't care if people call it a bug or a good default for US text - what count is to give people a good default no matter what they index or where they come from. (sounds like this is close to discriminating people - just kidding)\n{quote}\n\nUsing Version or not is orthogonal to what the default is IMO though. That's why its important whether its considered a bug or an option - Version is not a good option selector at all.\n\nThis is part of the goodness of stable/unstable - default options can change in unstable. ",
            "date": "2010-05-23T09:25:31.710+0000",
            "id": 34
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Using Version or not is orthogonal to what the default is IMO though. That's why its important whether its considered a bug or an option - Version is not a good option selector at all.\n\nI disagree, if you upgrade to a new version of lucene and you already deal with version you wanna pass in the version you are upgradeing from and get the same behavior. On the other hand you wanna have a good default when you are new to lucene so Version >=3.1 should give you the new behavior. I guess having a hybrid approach where the given version sets the option sounds like a good compromise - or was that what you where alluding to? I am not saying that this should not be optional just wanna make sure we are consistent with what version is supposed to be used for.",
            "date": "2010-05-23T09:40:28.854+0000",
            "id": 35
        },
        {
            "author": "Shai Erera",
            "body": "bq. There will be tons of different opinions to that around linguists around the world but this parser is not for linguists in the first place.\n\nSure. I've pointed that out just to show there are different opinions around that particular problem.\n\nbq. It seems to me making this behavior available with Version is the right way to go\n\nI disagree (and agree w/ Mark). Version can only control default behavior. This particular issue should be a setter IMO. Irregardless of what the default behavior is, I may want to set it differently. It doesn't make sense to *guess* what Version should I use in order to get that behavior.\n\nThat's why I don't mind leaving the current behavior as default, and introduce a setter for whoever wants to change it. The current behavior is not applicable for just English - I bet there's a whole list of languages which would interpret that query the same (i.e. require a phrase to be generated).\n\nAnd I don't know the distribution of Lucene users around the world, but I'm not sure that CJK users are more common that say English ones, or other European languages. So who knows what a good default is? :)\n\nI suggest we leave the default as it is now, and introduce a setter. People have been working w/ the parser and that default for a long time. Why suddenly change it?",
            "date": "2010-05-23T10:37:52.062+0000",
            "id": 36
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Robert,\n\nI also agree with Mark (as you know). We can have both:\n- Version for a good default (3.1 will get the new non-phrase-query behavior)\n- A separate getsetter for this option (set/getCreatePhraseQueryOnConcenattedTerms or whatever)\n\nThis would give you the best from both worlds.",
            "date": "2010-05-23T14:59:18.974+0000",
            "id": 37
        },
        {
            "author": "Robert Muir",
            "body": "updated patch that cuts over the remaining two qps: the flexible queryparser and precedence queryparser",
            "date": "2010-05-24T19:16:36.573+0000",
            "id": 38
        },
        {
            "author": "Robert Muir",
            "body": "editing this issue to make it easier to understand.",
            "date": "2010-05-26T04:28:05.397+0000",
            "id": 39
        },
        {
            "author": "Robert Muir",
            "body": "This patch fixes the bug in all queryparsers. I plan to commit soon.\n\nIf desired, someone can make their own euro-centric queryparser in the contrib section and I have no objection, as long as its clearly documented that its unsuitable for many languages (just like the JDK does).",
            "date": "2010-05-26T04:35:03.043+0000",
            "id": 40
        },
        {
            "author": "Robert Muir",
            "body": "Committed revision 948326 (trunk) / 948325 (3x)",
            "date": "2010-05-26T05:43:12.411+0000",
            "id": 41
        },
        {
            "author": "Mark Miller",
            "body": "For all the debate around this change, that was a pretty fast commit IMO ...",
            "date": "2010-05-26T08:59:06.669+0000",
            "id": 42
        },
        {
            "author": "Mark Miller",
            "body": "I know there was more discussion on this in IRC, but I don't see consensus in the issue. I also don't see the issues brought up having been addressed or worked out.\n\nI've got to -1 this commit. I even think I may be convinced that making this an option will make future improvements we may want too difficult - but nothing has been hammered out in this JIRA issue. It looks like those that have brought up various points have just been ignored.\n\n-1.",
            "date": "2010-05-26T09:17:04.170+0000",
            "id": 43
        },
        {
            "author": "Uwe Schindler",
            "body": "Revert! Revert! Revert!\n\nBy the way, matchVersion should be final. I also like to have a separate setter for the auto-phrase functionality. That should be easy possible!",
            "date": "2010-05-26T09:18:55.794+0000",
            "id": 44
        },
        {
            "author": "Koji Sekiguchi",
            "body": "+1 to revert. Though I am a late comer (as always :(  ) and I just read the updated Description, the example behavior of QueryParser for CJK (abcd -> \"ab bc cd\") looks correct to me and I'm using QP with CJK as is.",
            "date": "2010-05-26T11:16:56.890+0000",
            "id": 45
        },
        {
            "author": "Robert Muir",
            "body": "bq. I've got to -1 this commit.\n\nAs mentioned on apache's website:\n{code}\nTo prevent vetos from being used capriciously, they must be accompanied by a technical justification showing why the change is bad (opens a security exposure, negatively affects performance, etc.). A veto without a justification is invalid and has no weight.\n{code}\n\nNo one has been able to provide any technical justifications, only subjective opinions.\n\nWhen standard test collections were used, it was shown that this behavior significant hurts CJK and delivers only 10% of standard IR techniques (not generating phrases but using boolean word/bigram queries). See Ivan's results above. This isn't surprising since CJK IR has been pretty well studied, there is nothing new here.\n\nAt the same time, when english test collections were used, there was no difference, on the contrary, it only tended to slightly improve relevance for english, too.\n\nWhy do we even bother trying to start an openrelevance project if people do not want to go with the scientific method but prefer subjective opinion?\n\n",
            "date": "2010-05-26T12:13:26.222+0000",
            "id": 46
        },
        {
            "author": "Mark Miller",
            "body": "I think we should continue working out what's best here.\n\nI don't think its wise to try and bully through contentious issues. There should be consensus before something happens here - barring that, some kind of vote makes sense IMO.\n\n\n",
            "date": "2010-05-26T13:16:55.887+0000",
            "id": 47
        },
        {
            "author": "Yonik Seeley",
            "body": "Let's remember that the bug is  \"queryparser makes all CJK queries phrase queries regardless of analyzer\".\nThe ability of an analysis chain to create phrase queries in conjunction with the query parser is a feature.\nThe obvious way to reconcile these opposing statements is to make it configurable.\nPer-parser is a bare minimum... per-field would be better... and per-token would be best.\n\nI won't repeat my previous comments in this thread - however those arguments are still valid.",
            "date": "2010-05-26T13:25:25.505+0000",
            "id": 48
        },
        {
            "author": "Michael McCandless",
            "body": "I think the latest patch is an OK step forward.  Yeah it's not\nperfect, but it's better than what we have today.  Progress not\nperfection.\n\nQP (and more generally all of Lucene's core) should aim to be language\nneutral, and it's not now.  This patch improves that (defaulting the\nauto-PhraseQuery to off, by version).\n\nYes, compound/syn handling in English should be available, but the way\nQP does this is really quite broken (the analyzer can't do multi-words\nsyns).\n\nThere are deep questions/ideas about how to properly do multi-words\nsyns/compounds (see LUCENE-1622 -- we really need to change the index,\nto store \"span\" of a token).  I'm no longer sure that having analyzer\nmark tokens that should be made into PhraseQuery is the right\napproach... eg with the contrib QP, a plugin could directly tweak the\nquery tree, instead of being forced to use a token stream to\ncommunicate this.\n",
            "date": "2010-05-26T19:40:40.577+0000",
            "id": 49
        },
        {
            "author": "Michael McCandless",
            "body": "How about making the setting (\"if analyzer returns more than 1 token for a\nsingle chunk of whitespace-separated text, make a PhraseQuery\")\nconfigurable (instead of hardwired according to Version)?  And defaulting it\nto off for Version >= 31 (so CJK, etc., work out of the box)?\n",
            "date": "2010-05-26T19:46:14.428+0000",
            "id": 50
        },
        {
            "author": "Mark Miller",
            "body": "{quote}\nHow about making the setting (\"if analyzer returns more than 1 token for a\nsingle chunk of whitespace-separated text, make a PhraseQuery\")\nconfigurable (instead of hardwired according to Version)? And defaulting it\nto off for Version >= 31 (so CJK, etc., work out of the box)?\n{quote}\n\nI think its pretty clear this would make most people happy.\n\nPersonally, I'm somewhat on board with Robert that this may really hamstring us when it comes to further fixes that are needed/wanted in the future.\n\nTo note though - I think in general, most who have commented on this issue are into making CJK work out of the box. But I really think we need to nail down more consensus on this first.\n\nAt a minimum, I think making the behavior configurable, while defaulting to CJK 'betterness' by default has pretty much everyone on board.\n\nBut I'd really like to discuss whether doing that will only lead to losing that option as we do things like stop qp from splitting on whitespace in the future...\n\nSomething I was thinking, and it might be more of a maintenance headache than its worth, but we could demote this queryparser from the core query parser, and rename it something like ClassicQueryParser (or whatever), and make a new QueryParser that is better for more languages across the board (originally basing it on the classic parser eg this patch to start). People that like the older more english biased QueryParser can still use it, and by default, new users will likely pick up the default QueryParser that works better with more languages out of the box?\n\nJust an idea.\n\nIn any event - I think this patch is a step forward too - but it looks to me like there are still open concerns and objections.",
            "date": "2010-05-26T21:38:02.273+0000",
            "id": 51
        },
        {
            "author": "Robert Muir",
            "body": "i would suggest the following, a combination of mike, mark's, and yonik's ideas:\n\n* in 3.1 we supply a patch that looks like this one, except, there is a toggle too. this toggle can be per-field.\n* in 4.0 we do the same thing, for now.\n\nwe open a separate issue where we replace the QP with something better (that does not split on whitespace \nat all and allows multi-word syns, n-gram tokenization, vietnamese, etc to work) \n\nas part of that issue take the existing one (with per-field toggle) and call it classicqueryparser or whatever.\n\ni think we should consider the second separate issue carefully and take more time. I personally would prefer\nif somehow we could \"tone down\" the flexible queryparser (as far as number of classes, attributes, etc) and \nuse that as a base. There are things about it I like, and things I don't like, but overall it seems to be a better\nstarting point for such a thing.\n",
            "date": "2010-05-28T15:21:18.356+0000",
            "id": 52
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. in 3.1 we supply a patch that looks like this one, except, there is a toggle too. this toggle can be per-field.\n\nThe easiest way might be to just make it configurable per-parser but changeable at any point in time (i.e. just a getter and a setter).\nPer-field can be handled via subclassing (same way per-field differences are handled for everything else with this QP).\n",
            "date": "2010-05-28T15:56:37.421+0000",
            "id": 53
        },
        {
            "author": "Uwe Schindler",
            "body": "+1 @ rmuir & yonik\n\nI tend to make the per field thing also only by subclassing. If we add a per field property here, we also need things like: switch on date format, numeric type per field.\n\nA new syntax for the parser in 4.0 is essential in my opinion!",
            "date": "2010-05-28T16:00:22.942+0000",
            "id": 54
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nThe easiest way might be to just make it configurable per-parser but changeable at any point in time (i.e. just a getter and a setter).\nPer-field can be handled via subclassing (same way per-field differences are handled for everything else with this QP).\n{quote}\n\nTrue, but I thought there was something about dealing with this via subclassing you didnt like?\n\nWith the current patch (with no option at all) you could do this per-field behavior with subclassing already:\n\n{code}\n@Override\npublic Query getFieldQuery(String field, String text, boolean quoted) {\n if (field.equals(\"foobar\"))\n   return super.getFieldQuery(field, text, true /* treat it as if it were quoted */ );\n else\n  return super.getFieldQuery(field, text, quoted);\n}\n{code}\n",
            "date": "2010-05-28T16:01:40.000+0000",
            "id": 55
        },
        {
            "author": "Yonik Seeley",
            "body": "{quote}\nTrue, but I thought there was something about dealing with this via subclassing you didnt like?\nWith the current patch (with no option at all) you could do this per-field behavior with subclassing already:\n{quote}\n\nTrue... I'm  fine with subclassing - I guess the only diff is if the default is configurable or set only via version.",
            "date": "2010-05-28T16:05:04.912+0000",
            "id": 56
        },
        {
            "author": "Robert Muir",
            "body": "bq. True... I'm fine with subclassing - I guess the only diff is if the default is configurable or set only via version.\n\nIn this case, too, you could override the default with subclassing.\n\n{code}\n@Override\npublic Query getFieldQuery(String field, String text, boolean quoted) {\n  return super.getFieldQuery(field, text, true /* treat it as if it were quoted */);\n}\n{code}\n\nbut we can add an explicit boolean option for those that don't subclass?",
            "date": "2010-05-28T16:07:02.812+0000",
            "id": 57
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. In this case, too, you could override the default with subclassing.\n\nTrue - but I think some were saying the default should be configurable w/o subclassing.\n\nbq. but we can add an explicit boolean option for those that don't subclass?\n\nRight.  I think everyone is essentially saying the same thing at this point (at the high level)?\nMake it configurable (per-parser), and allow the user to handle per-field variations via subclassing.\n",
            "date": "2010-05-28T16:14:23.024+0000",
            "id": 58
        },
        {
            "author": "Robert Muir",
            "body": "ok i revised the idea here:\n\nin 3.1 we supply a patch that looks like this one, except, there is a simple boolean toggle too. \nif you want per-field behavior or more explicit customization, you can subclass.\nthe simple toggle is for non-subclassers.\n\nin 4.0 we do the same thing, for now.\n\nwe open a separate issue where we replace the QP with something better (that does not split on whitespace \nat all and allows multi-word syns, n-gram tokenization, vietnamese, etc to work)\n\nas part of that issue take the existing one (with per-field toggle) and call it classicqueryparser or whatever.\n",
            "date": "2010-05-28T16:17:42.401+0000",
            "id": 59
        },
        {
            "author": "Uwe Schindler",
            "body": "+1 to latest proposal!",
            "date": "2010-05-28T16:21:02.193+0000",
            "id": 60
        },
        {
            "author": "Michael McCandless",
            "body": "+1",
            "date": "2010-05-28T16:28:53.953+0000",
            "id": 61
        },
        {
            "author": "Mark Miller",
            "body": "+1",
            "date": "2010-05-28T16:44:28.359+0000",
            "id": 62
        },
        {
            "author": "Robert Muir",
            "body": "attached is an updated patch, with the latest proposal (for 3x branch).\n\nA boolean option, getter, and setter is added, and it defaults to false only for >= 3.1\nAlso added a test for the toggle and some javadocs.\n\nall tests pass.\n",
            "date": "2010-05-31T13:29:59.361+0000",
            "id": 63
        },
        {
            "author": "Robert Muir",
            "body": "ok, will commit this in a few days.\n",
            "date": "2010-06-29T12:37:39.293+0000",
            "id": 64
        },
        {
            "author": "Robert Muir",
            "body": "Committed revision 965585 / 965592 (3x)",
            "date": "2010-07-19T19:25:33.307+0000",
            "id": 65
        },
        {
            "author": "Yonik Seeley",
            "body": "As Koji noticed, it looks like what was committed accidentally changed the default behavior of solr (i.e. the last attached patch didn't but what was committed did).\nA query of pdp-11 now results in text:pdp OR text:11 instead of text:\"pdp 11\"\n\nPerhaps we should switch the SolrQueryParser back to using version==LUCENE_24 (or LUCENE_29 would work too)?",
            "date": "2010-07-24T03:20:50.449+0000",
            "id": 66
        },
        {
            "author": "Robert Muir",
            "body": "The change is backwards compatible... it fully respects the version in solrconfig.xml (as it should)",
            "date": "2010-07-24T03:22:50.416+0000",
            "id": 67
        },
        {
            "author": "Robert Muir",
            "body": "bq. Perhaps we should switch the SolrQueryParser back to using version==LUCENE_24 (or LUCENE_29 would work too)?\n\nI dont think we should do this. the whole *point* of this issue was that this auto-generation is a bad default, e.g. *every* thai query is a phrase query.\nI agree with Koji's idea of adding a config hook for autoGeneratePhraseQueries for those that want it though, but i don't think it should be on by default either.\n",
            "date": "2010-07-24T03:35:17.045+0000",
            "id": 68
        },
        {
            "author": "Koji Sekiguchi",
            "body": "bq. I agree with Koji's idea of adding a config hook for autoGeneratePhraseQueries for those that want it though, but i don't think it should be on by default either.\n\nThanks. I'll open a ticket for it.\n",
            "date": "2010-07-24T03:41:17.845+0000",
            "id": 69
        },
        {
            "author": "Uwe Schindler",
            "body": "QP has now a public final void setAutoGeneratePhraseQueries(boolean value). The default value is the one coming from Version parameter, but you can easily change it (like e.g. me, often working with such type of product numbers but never CJK text) can easily use this behaviour. Lucene's problem is, that it does not take position for scoring into account, so documents where the tokens appear next to each other do not score higher (in contract to google, which supports those combined tokens).",
            "date": "2010-07-24T07:00:22.411+0000",
            "id": 70
        },
        {
            "author": "Robert Muir",
            "body": "bq. Lucene's problem is, that it does not take position for scoring into account, so documents where the tokens appear next to each other do not score higher (in contract to google, which supports those combined tokens).\n\nActually no, the problem is, this autogeneration never really worked anyway, it was broken from the beginning.\ne.g. http://www.lucidimagination.com/search/document/bacf34995067e3cb/worddelimiterfilter_and_phrase_queries\n",
            "date": "2010-07-24T11:55:24.553+0000",
            "id": 71
        },
        {
            "author": "Yonik Seeley",
            "body": "I've reverted just the change of default behavior to Solr's QP.\nThere are too many negative side-effects to change this given the way Solr is currently used (and documented to behave).\nWe need to work on (at a minimum) a per-field config for Solr, but it seems like per-token is still the right way long term.",
            "date": "2010-07-24T14:43:57.663+0000",
            "id": 72
        },
        {
            "author": "Robert Muir",
            "body": "Please revert.",
            "date": "2010-07-24T15:56:13.308+0000",
            "id": 73
        },
        {
            "author": "Yonik Seeley",
            "body": "The previous patches posted in this issue did not change Solr's default (else I would have objected earlier).\nFrom past discussions, it seems like a majority of people feel like the default should be the old behavior for Solr (this default matters much less for Lucene developers).\nWe need to find a way to enable the new behavior per-field (although I feel that's a bit of a hack too... it really should be per-token).",
            "date": "2010-07-24T16:04:20.104+0000",
            "id": 74
        },
        {
            "author": "Robert Muir",
            "body": "The patch doesnt change solr's default, it instead causes SolrQueryParser to respect the version parameter in the solrconfig in *both* ctors.\nBefore, one ctor used the version specified, the other hardcoded LUCENE_24.\n\nAs i said before, this shouldnt and cannot be \"per-token\" and such english centric hacks do not belong in the analysis api.\n\nSeparately, I think what Koji is doing on SOLR-2015 is the way to go, not hardcoding LUCENE_24 as a version despite what is in the config.\n\nI don't think this english-centric hack should be the default for Solr. It *does* completely respect old schemas and is completely backwards compatible,\nsuch that if you have no version in your schema it will be LUCENE_24 and get the old behavior, \nif you made your own queryparser and subclassed the old API, you get the old behavior, and it respects the version set in the solrconfig rather than overriding it to 2.4 in just one ctor.",
            "date": "2010-07-24T16:09:55.999+0000",
            "id": 75
        },
        {
            "author": "Uwe Schindler",
            "body": "I don't userstand the backwards issue. We did not change backwards, as the default for luceneMatchVersion is still 2.4 (so anybody using his old solrconfig will get exactly the same behaviour). New users are new and can use the new default. If they don't like it, they can change the default version or Koji's parameter.\n\nThe idea about having this in the TS is not bad, but in my opinion too special. But you are right, the tokenizer should report suche concenated words. But on the other hand, you can simply use another tokenizer, that does not split your product numbers.",
            "date": "2010-07-24T16:11:15.434+0000",
            "id": 76
        },
        {
            "author": "Yonik Seeley",
            "body": "bq.  Before, one ctor used the version specified, the other hardcoded LUCENE_24.\n\nAh.... and that constructor is the one that's used everywhere in Solr (leading me to believe that leaving Solr's default alone was deliberate).\n\nbq. As i said before, this shouldnt and cannot be \"per-token\" and such english centric hacks do not belong in the analysis api.\n\nThe ability of a filter to say \"this token is actually indexed as two adjacent tokens\" is fundamental and not related to any specific language.\nIt can be *used* for language specific hacks perhaps... but it is not a hack itself.\n\nI never mentioned issues of back compat, but of changes to Solr's default behavior, which I continue to think is the best.\nI think the best way forward is to add a CJK field to solr that defaults to the opposite behavior (i.e. treats split tokens as completely separate).",
            "date": "2010-07-24T16:35:03.661+0000",
            "id": 77
        },
        {
            "author": "Robert Muir",
            "body": "bq. I think the best way forward is to add a CJK field to solr that defaults to the opposite behavior (i.e. treats split tokens as completely separate).\n\nI think this is completely wrong (besides its way more than CJK affected)\n\nYou should consider a \"european\" field instead.\n\nFurthermore, you should check if its set to index with \"omitTF\" and not autogenerate in that case either.\nIn trunk I think phrasequery will actually throw an exception in this case instead of silently failing: \nso the autogenerated queries can be very dangerous even for english.\n",
            "date": "2010-07-24T16:40:16.491+0000",
            "id": 78
        },
        {
            "author": "Robert Muir",
            "body": "Please stop committing all these wrong changes.\n\nNow i have to go revert 2 more commits.",
            "date": "2010-07-24T16:54:30.858+0000",
            "id": 79
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. Furthermore, you should check if its set to index with \"omitTF\" and not autogenerate in that case either.\n\nSolr doesn't currently allow ommitting TF for text fields.\nIt's good to keep in mind if we ever enable that though.",
            "date": "2010-07-24T16:58:25.095+0000",
            "id": 80
        },
        {
            "author": "Yonik Seeley",
            "body": "Robert, it was your commit that changed the default behavior of Solr, and I disagree with that change.\nTechnically, I could VETO - but I don't believe I have ever done a code-change veto, and I don't want to start now.\nInstead, I'll try and be constructive by going to work on SOLR-2015 so we can at least configure it per-field.",
            "date": "2010-07-24T17:11:27.383+0000",
            "id": 81
        },
        {
            "author": "Uwe Schindler",
            "body": "It's a new major version! Even 2 steps major 1.5 -> 3.1 and three steps to 4.0",
            "date": "2010-07-24T17:14:26.958+0000",
            "id": 82
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nRobert, it was your commit that changed the default behavior of Solr, and I disagree with that change.\nTechnically, I could VETO - but I don't believe I have ever done a code-change veto, and I don't want to start now\n{quote}\n\nYonik, i would rather you just VETO than heavy-commit the wrong changes.\nFor example, if you said \"robert, its annoying that for users with LUCENE_31 version in their solrconfig, \nI don't feel they don't have enough flexibility yet without going setting version to LUCENE_30. I feel that\nthe parameter setting in SOLR-2015 should be incorporated into this issue\"\n\nI mean, thats completely constructive!\n\n{quote}\nInstead, I'll try and be constructive by going to work on SOLR-2015 so we can at least configure it per-field.\n{quote}\n\nMan, I am willing to help with that also (though, i am not particularly a solr queryparser expert, I think we\nshould expose these options to users that want them, instead of requiring them to depend on version-specific\ndefaults). Just let me know how I can help, I want constructive progress.\n",
            "date": "2010-07-24T17:17:23.873+0000",
            "id": 83
        },
        {
            "author": "Grant Ingersoll",
            "body": "Bulk close for 3.1",
            "date": "2011-03-30T15:50:22.710+0000",
            "id": 84
        }
    ],
    "component": "core/queryparser",
    "description": "The queryparser automatically makes *ALL* CJK, Thai, Lao, Myanmar, Tibetan, ... queries into phrase queries, even though you didn't ask for one, and there isn't a way to turn this off.\n\nThis completely breaks lucene for these languages, as it treats all queries like 'grep'.\n\nExample: if you query for f:abcd with standardanalyzer, where a,b,c,d are chinese characters, you get a phrasequery of \"a b c d\". if you use cjk analyzer, its no better, its a phrasequery of  \"ab bc cd\", and if you use smartchinese analyzer, you get a phrasequery like \"ab cd\". But the user didn't ask for one, and they cannot turn it off.\n\nThe reason is that the code to form phrase queries is not internationally appropriate and assumes whitespace tokenization. If more than one token comes out of whitespace delimited text, its automatically a phrase query no matter what.\n\nThe proposed patch fixes the core queryparser (with all backwards compat kept) to only form phrase queries when the double quote operator is used. \n\nImplementing subclasses can always extend the QP and auto-generate whatever kind of queries they want that might completely break search for languages they don't care about, but core general-purpose QPs should be language independent.\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2458",
    "issuetypeClassified": "OTHER",
    "issuetypeTracker": "BUG",
    "priority": "Blocker",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "queryparser makes all CJK queries phrase queries regardless of analyzer",
    "systemSpecification": true,
    "version": ""
}