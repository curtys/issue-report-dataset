{
    "comments": [
        {
            "author": "Yonik Seeley",
            "body": "bq. CMS sorts merges by segments size, doc-based and not bytes-based. Since the default MP is LogByteSizeMP, and I hardly believe people care about doc-based size segments anymore, I think we should switch the default impl.\n\nThat's probably a good idea.\nWe should also scale this by the number of deleted docs... so if a segment has 10,000 documents, is 10MB in size, and has 2000 deleted documents, then we should consider it as 8MB for the purposes of selecting to merge?",
            "date": "2010-11-11T14:04:30.274+0000",
            "id": 0
        },
        {
            "author": "Shai Erera",
            "body": "Right! Hence why I wrote it is best determined by MP. LogMP already does it by default (can be disabled).",
            "date": "2010-11-11T17:11:03.987+0000",
            "id": 1
        },
        {
            "author": "Shai Erera",
            "body": "Ok, so not calling IndexWriter.getNextMerge() before we know we can register that merge is problematic. The reason is we want to know if there is a next merge before we check if it can be registered. If not, the method returns immediately. Otherwise, we'll wait until any merge can be registered, just to discover there are no more merge.\n\nSo one solution can be to add to IW a hasMerges() and in CMS wait for room to become available only if there are merges.\n\nAnother solution is to do a larger change to CMS and introduce an ExecutorService - this has been raised in the past, so perhaps it's time to finally do it? By using a blocking queue, we don't need to implement any waiting logic - Java will do it for us.\n\nThe downside of that is that I'm not sure we can control which of the merges runs and which isn't. Perhaps we can hack this through - I'll need to start the process to tell for sure. This feature is important - today CMS guarantees the smaller merges run first - so it might be that a larger merge was registered before a smaller merge, and we'd still want to execute the smaller one before the larger.\n\nA third solution would be to not do anything and keep things as they are - namely let some merge be held by CMS until it can be executed.\n\nJust summarizing my thoughts for now.",
            "date": "2010-11-12T17:52:25.614+0000",
            "id": 2
        },
        {
            "author": "Shai Erera",
            "body": "I've looked into integrating an ExecutorService and I think it can really simplify things, as long as we can let go of CMS sorting merges by their size. And I think - why should it? What if we make it to MP's decision? Namely, if you care about which merges run first, have your MP sort them the way you want, before you return them. If we make OneMerge comparable, that should be a very trivial extension one has to make to MP (extend MP, override the methods, call super.method() and then sort accordingly).\n\nIf we do that, then SMS and CMS will work the same - execute the merges in the order returned by MP, only CMS will do so in parallel and SMS will do so synchronously. By reading that you can already see that later (in a separate issue), we can let go of SMS entirely - it will be a single-threaded ExecutorService, w/ an implementation to wait until the work competes (unlike CMS which returns immediately). But that's for another day.\n\nWhat do you think?",
            "date": "2010-11-14T09:25:04.557+0000",
            "id": 3
        },
        {
            "author": "Michael McCandless",
            "body": "Cutting over to ExecutorService and letting MergePolicy dictate how OneMerge compares sounds great!\n\nWill CMS still have the ability to pause running big merges in order to let smaller ones complete?  Seems like these changes should still allow that to work correctly.",
            "date": "2010-11-14T11:10:02.215+0000",
            "id": 4
        },
        {
            "author": "Earwin Burrfoot",
            "body": "Is there any reason at all to be concerned with merge execution order (not even starting about pausing)? Sounds like a fat bit of overengineering.\nMerging (with CMS) happens outside of index/search loop anyway so whatever the order, you're not affecting latencies.",
            "date": "2010-11-14T23:07:58.949+0000",
            "id": 5
        },
        {
            "author": "Shai Erera",
            "body": "The problem with ThreadPoolExecutor is that its submit() doesn't block on the queue, even if you pass a bounded ArrayBlockingQueue (which is really silly IMO). I was hoping we can super simplify CMS logic by letting a BlockingQueue throttle the number of merges we 'register' before CMS itself waits, and the ExecutorService instead of the MergeThreads and their management.\n\nUnfortunately this does not look to be the case. Here is an alternative solution which looks a nice workaround: http://stackoverflow.com/questions/2001086/how-to-make-threadpoolexecutors-submit-method-block-if-it-is-saturated.\n\nThe idea is to block the call to ExecutorService.execute() through a Semaphore. In that case, I think it's safe to not use a blocking queue at all, because the throttling will be handled by the Semaphore.\n\nAnother alternative is to use a CallerRunsPolicy as the rejection policy, which has many disadvantages (such as potentially starving the other threads if the caller gets to execute the heavy task, or risking running the tasks by N+1 threads etc.).\n\nEarwin - if we make OneMerge comparable, we give any MP the freedom to decide the order merges will run. In my case it is important because I'm getting a certain time frame to run index optimization, and prefer to reduce as many segments as possible, therefore I choose to run the smaller merges first. I think it's a reasonable decision anyway as a default, because even if you call close(false) (not waiting for merges), then it's better if some merges have already finished and committed, thereby you're making forward progress all the time, vs. if you run merges in arbitrary order you mind not finish any merge.\n\nI agree though that in some situations apps won't care, in which case sorting by merge size will be as good as random ordering.\n\nPausing large merges is something that I consider less important though, but I don't want to break back-compat behavior. IMO if a merge started - let it finish. You don't know how much work it has completed, how much work is left, and how much work does the 'smaller' merge has (what if say it's smaller by 1 byte/doc?). In different situations the best decision might be different, therefore IMO we shouldn't pause threads - rather let the MP decide up front the order of the merges (if it wants to) and then execute them in that order.",
            "date": "2010-11-15T15:07:23.452+0000",
            "id": 6
        },
        {
            "author": "Earwin Burrfoot",
            "body": "Whatever solution for block-on-add you employ, I think it is important to implement it as an Executor. I think, people can benefit from threading policy being pluggable.\n\nI'm not against sorting merges, it's so simple, even if useless. Though maybe it's better to use Comparator, so you can redefine the order? Pausing large merges is another issue - that's a freakload of complexity for zero gain.\n\nAnother issue to ponder - what about slightly uncluttering IW <-> MS interaction?\nWe drop IW.getNextMerge, MS.merge(IW), and replace them with MS.scheduleMerge(MP.OM), so instead of IW asking MS to pull all merges from itself, it simply pushes them.\nAlso, let's kill this weeeird IW.mergeInit that is called from CMS, but not SMS :)\n\n\nBut oh, well. With introduction of executors, and SMS being folded as a special case of CMS, we might as well drop MS completely and move what little code is left straight to IW, which will now accept an executor.",
            "date": "2010-11-15T17:55:45.306+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "bq. We drop IW.getNextMerge, MS.merge(IW), and replace them with MS.scheduleMerge(MP.OM), so instead of IW asking MS to pull all merges from itself, it simply pushes them.\n\nThat sounds like a great simplification!\n\nbq. I'm not against sorting merges, it's so simple, even if useless. Though maybe it's better to use Comparator, so you can redefine the order? Pausing large merges is another issue - that's a freakload of complexity for zero gain.\n\nPausing large merges is (unfortunately) important for full use of available concurrency.  Otherwise, when a laaarge merge is taking place, it causes to to fully stop your indexing threads unnecessarily.  Turn on infoStream when building a large index and you'll see...\n\nAn OS CPU scheduler will lower the priority of long-running CPU hogging processes, for the same reason (so that newly started CPU hog processes that are short running get nearly 100% of the CPU so they finish fast).  It's just that we don't have the \"freedom\" to allow an unbounded number of merges that we must \"approximate\" this by explicitly pausing the long running merges.\n\nbq. Also, let's kill this weeeird IW.mergeInit that is called from CMS, but not SMS\n\nThere was some reason why this needed to be called by CMS but not SMS but I can't remember why.  (It's re-called by IW.merge in case the MS didn't already call it).  But it'd be great to not call it from CMS if it's not necessary... I can't remember the reason.\n\nbq. With introduction of executors, and SMS being folded as a special case of CMS, we might as well drop MS completely and move what little code is left straight to IW, which will now accept an executor.\n\nThat's tempting... but people use MSs eg to schedule big merges at different times.  I don't think we should outright drop MS.",
            "date": "2010-11-15T19:36:33.440+0000",
            "id": 8
        },
        {
            "author": "Jason Rutherglen",
            "body": "A good feature for Solr could be the ability to via an HTTP call kick-off pending large merges.  They could then be scheduled via a cron job and based on other factors, such as whether or not other indexing tasks are running.",
            "date": "2010-11-15T20:33:30.572+0000",
            "id": 9
        },
        {
            "author": "Earwin Burrfoot",
            "body": "bq. There was some reason why this needed to be called by CMS but not SMS but I can't remember why.\nThat has something to do with assigning new segment names, if you believe the comments.\nBut IW.mergeInit does a freakload of other stuff! I think assigning names can happen in a separate place, before OneMerge is submitted to MS.\n\nbq. Otherwise, when a laaarge merge is taking place, it causes to to fully stop your indexing threads unnecessarily\nI still think this can be mitigated in more appropriate ways. Like allocating big enough pending merges queue to wait until the long one finishes.\nIndexing threads push merges into the queue (with CMS) and don't block.\nPlus to that, you can use nice policies like BalancedSegmentMergePolicy, that prevent UBER-merges from occuring at all.\n\nbq. That's tempting... but people use MSs eg to schedule big merges at different times. I don't think we should outright drop MS.\nThat exact use case is totally wrong. MergePolicy decides which merges should run NOW, MergeScheduler executes them.\nIf a certain big merge should run only within some specific timeframe, MergePolicy should not return it when asked for eligible merges.\n\nIn your sample, when decision-making is smeared across classes, the merges created by MP and deferred by MS are stale when their\ntime comes. If asked now, MP would include some additional segments in the merge that MS stalled around for ages.\n\nFor a glance of things done relatively right, take a look at BSMP - it has setPartialExpunge method, that alters its\nbehaviour to include some expensive housecleaning. It is supposed you do setPartialExpunge(true) at the beginning of your quiet period, and\nsetPartialExpunge(false) when it ends.\n\nbq. A good feature for Solr could be the ability to via an HTTP call kick-off pending large merges.  They could then be scheduled via a cron job and based on other factors, such as whether or not other indexing tasks are running.\nSame argument here. The place for such decisions is MergePolicy.",
            "date": "2010-11-15T21:09:55.504+0000",
            "id": 10
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nThat has something to do with assigning new segment names, if you believe the comments.\nBut IW.mergeInit does a freakload of other stuff! I think assigning names can happen in a separate place, before OneMerge is submitted to MS.\n{quote}\n\nIf indeed that's all then I agree, let's just assign the name up front and then CMS need not call mergeInit.\n\n{quote}\nbq. Otherwise, when a laaarge merge is taking place, it causes to to fully stop your indexing threads unnecessarily\n\nI still think this can be mitigated in more appropriate ways. Like allocating big enough pending merges queue to wait until the long one finishes.\nIndexing threads push merges into the queue (with CMS) and don't block.\n{quote}\n\nBut then you accumulate too many tiny merges, while waiting for the big one to finish?\n\nbq. Plus to that, you can use nice policies like BalancedSegmentMergePolicy, that prevent UBER-merges from occuring at all.\n\nMaybe we should move BSMP to core and make it the default?\n\nBut I don't fully understand how it chooses merges.  EG does it pick lopsided merges (where the segments differ substantially in size), as long as they are \"small\" segments?\n\n{quote}\nMergePolicy decides which merges should run NOW, MergeScheduler executes them.\nIf a certain big merge should run only within some specific timeframe, MergePolicy should not return it when asked for eligible merges.\n{quote}\n\nI agree there is ambiguity here, which is not good.  It is tempting to nuke MergeScheduler (absorb CMS into IW, w/ SMS a special case) and define MergePolicy to only return merges which should run right now... that would be a nice simplification.",
            "date": "2010-11-15T22:29:44.134+0000",
            "id": 11
        },
        {
            "author": "Earwin Burrfoot",
            "body": "bq. But then you accumulate too many tiny merges, while waiting for the big one to finish?\nYou say this, as if it was something terribly wrong. :)\nBig merges aren't heffalumps, they don't usually stalk IW in droves. Big merge ends sooner or later, and tiny ones go out in a flash.\n\nbq. Maybe we should move BSMP to core and make it the default?\nDunno. The index you end up with is larger than with LogWhateverMP.\nBut you get a nice benefit of having roughly equal-sized big segments, which is cool for running collection in parallel.\nEveryone has his own requirements.\n\nbq. But I don't fully understand how it chooses merges. EG does it pick lopsided merges (where the segments differ substantially in size), as long as they are \"small\" segments?\nDocs say small-sized segments are treated as with LogByteSizeMP.\n\n\n\nAnother thought I had looking through the code. We have seriously inefficient \"merge conflict\" resolution algorithm on our hands.\nWe just damn drop all new merges that have segments in common with the merges already queued (but not yet running!!).\nWhat does that mean?\n\nImagine we're producing a slew of mini-segments with decent speed and our MergeScheduler is lagging behind:\n* new seg1\n* new seg2\n* queue merge seg1+seg2\n* start merge seg1+seg2\n* new seg3\n* new seg4\n* queue merge seg3+seg4\n* new seg5\n* FAIL queue merge seg3+seg4+seg5\n* new seg6\n* FAIL queue merge seg3+seg4+seg5+seg6\n* finish merge seg1+seg2\n* start merge seg3+seg4\n\nBy that point we should really start merging of all four last segments (maybe together with the result of seg1+seg2).\nBut in reality we'll merge seg3+seg4, than seg5+seg6 and then all of three merge results together (provided no new mini-segments are added).\n\nIf we throw large merges into the loop (whether pausable or not) the situation is amplified.\n\nUgly solution - when MP suggests a merge that is a strict superset of a queued, but not yet running merge - drop the old one, use the new.\nBetter solution - instead of asking MP for all the merges it deems reasonable on current index, we only ask it for \"most important\" one.\nAnd we do it each time MS has an open slot for execution. This way each merge happening is the best merge possible at that moment.\n\nPlease, correct my wrongs, if any.",
            "date": "2010-11-15T23:54:42.952+0000",
            "id": 12
        },
        {
            "author": "Shai Erera",
            "body": "I have to say I totally agree w/ Earwin - in my mind, the MP should be the one deciding what merges to run, and in what order, the MS should be the one executing them. Hack, we should really call MS a MergeExecutor, since it doesn't really schedule anything, just does what it's told, based on the execution policy (parallel or blocking).\n\nIn my app, it's the MP which decides which merges to run, based on their sizes, time of the day and allotted time to run. I expect MS to faithfully do what it's told and don't play tricks on me (like pausing merges I've asked it to run), 'cause otherwise I'll need to write a MS too.\n\nAnother question that was brought up here is who should register the merges. Today there are two entities - one is the MS which repeatedly calls IW.getNextMerge() and in the CMS case, MergeThread does so too. The disadvantage of that is that IW.getNextMerge() (and mergeInit()) is called from two places, but the advantage is that it allows executing all of MP merges, even if they come in several rounds. Example, you have 4 segs of level 0 and 3 segs of level 1 (mergeFactor=4). MP returns a single merge (4 segs level 0), and IW.getNextMerge() returns null 'cause there are no merges left). However, after completing this merge, if asked, MP will return a follow on merge of 4 segs level 1. That will be picked up by the MergeThread that calls IW.getNextMerge().\n\nThe thing is - the second round of merges may only be detected by MP after most if not all of the merges from the previous round ended. Therefore, if we dim that functionality important (and I do), we must have the MergeThreads query MP as well.\n\nAbout mergeInit, I took a look too and discovered a 140 lines method, so I doubt it does only \"new segment name registration\". But perhaps I'm wrong and those are redundant 140 lines ...\n\nI think that having a MS entity (or MergeExecutor) is important - it still gives an app the ability to override things if it wants to. Also, putting the MS code inside IW will only add code to it, and I think that we should really start refactoring it down to smaller, more readable and focused, pieces. So I'm against adding more logic to it. For 3x we can choose to improve things internally, or leave them as they are. For 4.0 I'd suggest we do the following:\n* Create a new MergeExecutor entity receives an Executor(Service?) to run with, but also defaults to one (like CMS is today). That replaces CMS.\n** You can control the number of threads it runs with (1 for almost-SMS-like behavior and more for CMS).\n* We create a BlockingMergeExecutor, which regardless of how many threads you allow it to run with, blocks until all merges finish.\n** That is an improved SMS - I've always thought that blocking until merges finish is not related to how many threads you'd like to execute merges with. E.g., if you set CMS's # threads to 1, you get a sort of an SMS behavior, only the call is non-blocking.\n* We define MP as the one responsible for returning the merges in the order it wants, and provide the necessary support by making OneMerge comparable (Earwin, MP can still sort by using a custom Comparator, we only provide a default comparison method for merges). That definition will be mostly in javadocs.",
            "date": "2010-11-16T07:00:32.231+0000",
            "id": 13
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nbq. But then you accumulate too many tiny merges, while waiting for the big one to finish?\n\nYou say this, as if it was something terribly wrong. \nBig merges aren't heffalumps, they don't usually stalk IW in droves. Big merge ends sooner or later, and tiny ones go out in a flash.\n{quote}\n\nIn fact there is something wrong: without us explicitly scheduling the\nrunning merges (ie setting thread priorities, stopping the big merges\nwhen there are too many small ones), CMS will pause the incoming\nthreads.\n\nI first saw this happen when testing our NRT reopen perf (which is\nmerge intensive).  Normally the turnaround is very fast (eg 5 msec)\nbut if you're at your max merge count then CMS will stall you and the\nturnaround time easily becomes seconds, which is awful.\n\nIt's like an OS that refuses to schedule your \"ls\" command because\nthere's still some long running process...\n\nCMS's explicit thread scheduling fixes that problem -- a big merge no\nlonger causes seconds of delay in opening a new NRT reader.  That is,\nas long as net/net you've allocated enough CPUs (maxThreadCount) to do\nthe merging.  If merging is too slow vs indexing rate + reopen rate\nthen there's no hope: at some point reopen must be blocked (it's\na zero sum game).\n\nIn the ideal world the OS/JRE would do a better job scheduling, ie\nrealize that there are looong running threads and down prioritize them\n(like the OS does to processes), but in practice it's nowhere close to\ndoing this right for our use case, so I don't see a choice here.  If\nwe want to keep our fast NRT reopen time, we have to manually schedule\nour merge threads.\n\n{quote}\nbq. Maybe we should move BSMP to core and make it the default?\n\nDunno. The index you end up with is larger than with LogWhateverMP.\nBut you get a nice benefit of having roughly equal-sized big segments, which is cool for running collection in parallel.\nEveryone has his own requirements.\n{quote}\n\nFair enough...\n\n{quote}\nbq. But I don't fully understand how it chooses merges. EG does it pick lopsided merges (where the segments differ substantially in size), as long as they are \"small\" segments?\n\nDocs say small-sized segments are treated as with LogByteSizeMP.\n{quote}\n\nHmm... but then how does this differ from setting a maxMergeMB/Docs?\n\nbq. We have seriously inefficient \"merge conflict\" resolution algorithm on our hands.\n\nYou're right!  Though, I think this typically isn't a problem for\nLogMP since it doesn't normally pick future merges that conflict with\npast ones.\n\nAlso the problem is bounded by how long the merge takes to finish.\n\nBut I agree we should try to fix this... other MPs could conceivably\ndo this.\n\n{quote}\nUgly solution - when MP suggests a merge that is a strict superset of a queued, but not yet running merge - drop the old one, use the new.\nBetter solution - instead of asking MP for all the merges it deems reasonable on current index, we only ask it for \"most important\" one.\nAnd we do it each time MS has an open slot for execution. This way each merge happening is the best merge possible at that moment.\n{quote}\n\nThis seems dangerous: what's an \"important\" merge?\n\nHow about, instead, we let MP return all eligible merges (like it does\ntoday) but then we replace all previously buffered but not yet running\nmerges w/ the new merges it returned?  Hmm but this would probably\nrequire giving it access to the buffered-but-not-yet-running merge\nset...\n\n\nbq. About mergeInit, I took a look too and discovered a 140 lines method, so I doubt it does only \"new segment name registration\". But perhaps I'm wrong and those are redundant 140 lines ...\n\nRight -- it's doing lots of stuff.  But the question was whether CMS\nreally must be calling it itself vs leaving IW.merge to call it as SMS\ndoes.  Ideally only IW.merge should call it (and it becomes private),\nwhich if we take the name assignment out \"earlier\" seems feasible.\n",
            "date": "2010-11-16T14:36:22.744+0000",
            "id": 14
        },
        {
            "author": "Shai Erera",
            "body": "bq. Ideally only IW.merge should call it (and it becomes private),\n\nI wouldn't make it private. If I remember correctly, the Parallel Index overrode that method to synchronize merges across all parallels.\n\nbq. but if you're at your max merge count then CMS will stall you and the turnaround time easily becomes seconds, which is awful.\n\nBut Mike, if you hit your maxMergeCount with large merges, then you won't run tiny merges at all. It's only if you have room to run any merges, that this 'pausing' actually helps. I trust you when you say you've observed that not pausing those merges hurt performance, but I wonder in real life, how often does that happen, and whether we should incorporate that in our code. If it's a rare case, then perhaps apps that hit it should use another MS which pauses its threads?",
            "date": "2010-11-16T14:56:32.894+0000",
            "id": 15
        },
        {
            "author": "Michael McCandless",
            "body": "\n{quote}\nbq. Ideally only IW.merge should call it (and it becomes private),\n\nI wouldn't make it private. If I remember correctly, the Parallel Index overrode that method to synchronize merges across all parallels.\n{quote}\n\nAhh OK.\n\nbq. But Mike, if you hit your maxMergeCount with large merges, then you won't run tiny merges at all.\n\nSure, but that's uncommon.  Ie, large merges don't happen very\nfrequently.\n\nbq. It's only if you have room to run any merges, that this 'pausing' actually helps. I trust you when you say you've observed that not pausing those merges hurt performance, but I wonder in real life, how often does that happen, and whether we should incorporate that in our code. If it's a rare case, then perhaps apps that hit it should use another MS which pauses its threads?\n\nRemember it's not just pausing.  We also set thread priorities so that\nsmaller merges run with higher priority, and, all merges run with\nhigher priority than the indexing threads (by default).\n\nI don't think this is rare because eventually (assuming your index is\nbig enough) you'll hit a large merge and then you can fairly easily\nsee the merges stack up.  I've seen merges stack up in the non-NRT\ncase too.  Without this explicit thread scheduling we do, that large\nmerge can easily kill your NRT reopens, ie take many seconds to get a\nnew reader.  This is non-graceful degradation because at first NRT\nreopen time looks great but then as your index grows and you hit a\nlarge merge, suddenly it's many seconds.\n\nIf your app has costly merges (eg you store fields, term vectors, and\nyou use dynamic fields which means the stores cannot be bulk merged),\nand you're not on an SSD, and your OS is memory starved so it can't do\nas much readahead as it should be doing, your merges become far more\ncostly.  Worse, the default merge thread count (3) may in fact be too high\nfor most machines even with 4 or more cores.  There are many variables...\n\nThe scheduling can only do so much, of course.  Ie it enables us to\nsoak up the \"spare\" CPU cycles in between medium, little merges to let\nthe bit merge make progress.  But if those spare cycles aren't enough\nthen inevitably the best scheduling will still have to eventually\npause your reopens.\n\nStill I think the other improvements we've talked about here would be\ngreat steps forward.  It's just that we still need to explicitly\nschedule the merge threads.\n",
            "date": "2010-11-16T17:08:24.075+0000",
            "id": 16
        },
        {
            "author": "Earwin Burrfoot",
            "body": "Shai:\nbq. The thing is - the second round of merges may only be detected by MP after most if not all of the merges from the previous round ended. Therefore, if we dim that functionality important (and I do), we must have the MergeThreads query MP as well.\nDon't turn things upside down. MergeThreads are best hidden from view inside Executor, we just feed it chunks of work in the order we want it to be done. It's quite enough to have a single place that queries MP and feeds Executor.\n\nbq. About mergeInit, I took a look too and discovered a 140 lines method, so I doubt it does only \"new segment name registration\". But perhaps I'm wrong and those are redundant 140 lines ...\nThese are not redundant. But only a small number of them really need to be executed when a merge is added to CMS, everything else can wait until merge actually starts.\n\nbq. I think that having a MS entity (or MergeExecutor) is important - it still gives an app the ability to override things if it wants to.\nTentatively agree on this.\n\nbq. Also, putting the MS code inside IW will only add code to it, \nBut this is not true, with all the cruft thrown away, remaining code size is likely on par with current that invokes MS from within IW.\n\nbq. We define MP as the one responsible for returning the merges in the order it wants, and provide the necessary support by making OneMerge comparable\nYou contradict yourself here. If we make OneMerge comparable, we define order in its compareTo() method. MP can no longer return the merges in the order it wants. I suggest there's no Comparable, and MP does the sort itself and returns an ordered list of merges. Better yet - it returns only the first one of them, on each request.\n\n\n\nMike:\nbq. In fact there is something wrong: without us explicitly scheduling the running merges (ie setting thread priorities, stopping the big merges when there are too many small ones), CMS will pause the incoming threads.\nWhy?? Indexing threads can drop merges into a queue, and forget about them. The blocking happens only if you explicitly want to use the same thread for merging, or if merging threads are lagging - in such a case you're in for troubles anyway.\nAll further analogies with OS scheduling are broken because we're not running \"ls\", we're running background jobs, and don't really care which of them blocks which.\n\n{quote}\nbq.  Docs say small-sized segments are treated as with LogByteSizeMP.\nHmm... but then how does this differ from setting a maxMergeMB/Docs?\n{quote}\nBSMP doesn't keep your segments under certain size like maxMergeMB does. It ensures you have exactly N 'large' segments. How large they are - depends on total size of the index.\nIt also limits the maximum count of 'small' segments, the size distribution for them is the same as with LBSMP.\nI think the [docs|http://code.google.com/p/zoie/wiki/ZoieMergePolicy] are pretty good.\n\n{quote}\nThis seems dangerous: what's an \"important\" merge?\n\nHow about, instead, we let MP return all eligible merges (like it does\ntoday) but then we replace all previously buffered but not yet running\nmerges w/ the new merges it returned? Hmm but this would probably\nrequire giving it access to the buffered-but-not-yet-running merge\nset...\n{quote}\nWe already decided that merges should be sorted? And MP gives us a bunch of them. Sort the bunch, pick the first one - that's your \"important\" merge.\nBy calling this MP.giveMeNextImportantMerge() method repeatedly we free ourselves from tons of bookkeeping you just mentioned.\n\nHo-ho-ho! In fact, we don't need any queues, any buffering, no hard link between indexing and merging - no nothing at all :)\nHere's my proposal cleaned up and reiterated:\n\n* MP has a single method - getNextMerge() (I'm not taking optimize and friends into account now)\n** For current policies this method works as described before - MP decides on a list of eligible merges, sorts them by some criteria (i.e. smaller merges come first) and returns the first.\n* MS repeatedly polls MP for merges (in one or more threads) and executes them.\n** If getNextMerge() returns null, MS goes to sleep - null signifies that from MP's perspective index is already in ideal state.\n** When some index-changing events occur, eg - indexing thread adds some docs and creates a new segment, MS is woken up and resumes polling/merging.\n** rinse, repeat\n* In CMS-like scenario, indexing and merging threads are completely decoupled and even lack queues that could overflow. So if some lesser merges have to wait for the big one - that's not going to bite you at all.\n* In SMS-like scenario, polling happens within indexing thread, and everything works as it does now.\n\n{quote}\nStill I think the other improvements we've talked about here would be great steps forward.\nIt's just that we still need to explicitly schedule the merge threads.\n{quote}\nAs I just described - we don't have to :)\nAnd if you really want to preserve that monster of pausing and priority control (largely broken for java anyway), forget about Executors - they don't support this.",
            "date": "2010-11-16T17:53:42.428+0000",
            "id": 17
        },
        {
            "author": "Jason Rutherglen",
            "body": "bq. large merge can easily kill your NRT reopens\n\nWhen RT is implemented, these small segments (that require merging) go\naway because we'll be flushing relatively medium sized segments the size\nof the RAM buffer.\n\nI'd prefer to have more control of large merges from an external process\nso that they may be scheduled according to application demand, ie, during\nnon-peak hours. This is actually what I've implemented in production using\nthings like optimize num segments = 5 and/or expunge deletes during the\nearly morning hours. However the external control is doable today using an\nexisting merge policy such as LogByteSizeMergePolicy, where during the day\nfor example, the maximum segment size could be lower, and in the early\nmorning, it'd be set to something much higher, or nullified altogether. \n\nAlso the problems associated with merge interleaving only affects systems\nthat are not using replication because the merging is occurring on an\nindex-only server. The newly merged files are transferred over as is, and\nthat's something that can easily be interleaved with other IO processes.",
            "date": "2010-11-16T18:52:43.545+0000",
            "id": 18
        },
        {
            "author": "Shai Erera",
            "body": "bq. You contradict yourself here. If we make OneMerge comparable, we define order in its compareTo() method. \n\nI think it's convenient to have OneMerge comparable somehow. But we can have MP sort them using its own Comparator. By making them Comparable I intended to say 'this is the default order' - but we can have a DefaultComparator instead.\n\nIf we proceed w/ your proposal, that is basically the MS/ME polling MP, and not IW doing so, how would IW know about the running merges and pending ones? Today IW tracks those two lists so that if you need to abort merges, it knows which ones to abort.\n\nWe can workaround aborting the running merges by introducing a MS.abort()-like method. But what about MP? Now the lists are divided between too entities (MP and MS), and aborting a MP does not make sense (doable, but I don't think it belongs there). Maybe we can have MS.abort() poll MP for next merges until it returns null, and throwing all the returned ones away - that can be done. Aborting an Executor is easy, and I think can be faster than our current way of doing so.\n\nI would still love to see the merge code (as much as possible) going away from IW. This may not be doable now, but could be in the future, if we factor out a SegmentsMerger/IndexMerger entity which encapsulates the merge execution and policy inside. But this is for another day.\n\nBTW, MS.merge() takes an IW, as if you could call merge() w/ two IW instances and things will work ok. It does in SMS but doesn't in CMS. Should we, in the scope of this issue, make IW a required settable parameter on MS, like we do w/ MP?",
            "date": "2010-11-17T04:20:44.480+0000",
            "id": 19
        },
        {
            "author": "Earwin Burrfoot",
            "body": "{quote}\nIf we proceed w/ your proposal, that is basically the MS/ME polling MP, and not IW doing so, how would IW know about the running merges and pending ones? Today IW tracks those two lists so that if you need to abort merges, it knows which ones to abort.\n\nWe can workaround aborting the running merges by introducing a MS.abort()-like method. But what about MP? Now the lists are divided between too entities (MP and MS), and aborting a MP does not make sense (doable, but I don't think it belongs there). \n{quote}\nThere are no lists at all with my approach. At least no \"pending\" list, that one gets recalculated each time we poll MP and it never gets out, neither gets stored inside.\nThere's a kind of implicit \"in flight\" list - MS has the knowledge of its threads that are currently doing things. And if you want to go around aborting things, MS is probably the right place to do this.\n\nbq. Maybe we can have MS.abort() poll MP for next merges until it returns null, and throwing all the returned ones away - that can be done.\nSo, just I said - that's not needed. MP is empty, it has no state.\n\nbq. Should we, in the scope of this issue, make IW a required settable parameter on MS, like we do w/ MP?\nFor the love of God, no. I'd like to see it removed from MP too.\nIt's only natural to pass the same instance of Policy or Scheduler to different Writers, so they have the same behaviour and share Scheduler resources (insanely important if you have fifteen indexes like I do and don't want them to rape hardware with fifteen simultaneous merges).\nIt is against the nature to pass Writer to Policy. Does the Policy need to write anything on its own, when it decides to? No. It should advice, not act.",
            "date": "2010-11-17T08:52:36.446+0000",
            "id": 20
        },
        {
            "author": "Shai Erera",
            "body": "Earwin, the way CMS currently handles the writer instance makes it entirely not thread-safe. If you e.g. pass different writers to merge(), the class member changes, and MTs will start merging other segments, and in the worse case attempt to merge segments of a different writer.\n\nI myself thinks it's ok to have a MP and MS per writer, but I don't have too strong feelings for/against it - so if we want to allow this, we should fix CMS.\n\nAs for the other comments, I'll need to check more closely what IW does w/ those merges - as it checks all sorts of things (e.g. whether it's an optimize merge or not, see one of the latest bugs Mike resolved). So getting it entirely outside of IndexWriter and into MP/MS is risky - at least, I don't understand the code well enough (yet) to say whether it's doable at all and if we don't miss something.",
            "date": "2010-11-17T15:17:24.980+0000",
            "id": 21
        },
        {
            "author": "Shai Erera",
            "body": "There are several points addressed by this issue:\n* Refactor IW, MS and MP so that MS pulls merges directly from MP, instead from IW.\n* Rewrite CMS to take advantage of ThreadPoolExecutor instead of managing the threads on its own, in addition to using a blocking queue instead of us coding the blocking directly.\n* One should be able to reuse CMS across several IndexWriters, which is not possible today, to e.g., allow one controlling the total # of merges happening in the JVM.\n* Merges should be sorted by their size in bytes and not by their # of docs -- or actually, merges should be sorted by a criteria the MP determines.\n\nAll the while maintaining the following requirements, in no particular order:\n* MergeThreads' priority needs to be controllable - this is the current behavior of CMS that we'd like to keep.\n* When there are too many merges to execute, small ones should be preferred to large ones, and we need the ability to pause large merges in favor of small ones.\n* The user needs to be able to control:\n*# The max number of running merges\n*# The max number of merges, above which scheduling more merges should be blocked.\n* We should keep the sync() API, which lets the user wait for all scheduled merges to complete.\n* The MP needs to be aware of the type of merges that are requested (regular, optimize, expunge).\n* The user should be able to fast-close the index, aborting all merges (running and pending).\n* If there are cascading merges (i.e., a result of several other merges), they should all be executed following the call to MS.merge() -- that is, it could be that CMS itself, or its MergeThreads will encounter merges not returned by MP at first, but as a subsequent round due to changes done to the index.\n\nAfter investigating the code and going over the proposed plan, I feel that we cannot accomplish all that we'd like to do, given the above requirements. And just to be clear, those are not *any* application requirements, but the default ones we'd like Lucene to offer OOtB. One can still write a MS/MP which doesn't guarantee all that.\n\nUsing ThreadPoolExecutor looks like will only complicate CMS instead of simplifying it:\n# Because of all the requirements I've listed above, we'd need to trick TPE into starting more threads than we intend to run, while we pause some of them.\n# In order to set threads' priorities, we need to write our own ThreadFactory to pass to TPE, and inside it keep track of the allocated Threads and those that still run, so that we can control their priority.\n# There's no trivial way to impl sync(), as TPE does not provide API we can rely on (e.g. checking when all threads are done). There are ways to impl that, using Semaphore (see next bullet).\n# In order to block the app on too many merges being scheduled, we'd need to use a Semaphore, because even if we use a BlockingQueue w/ TPE, the submit() call won't block, but simply reject the item.\n# In order to execute cascading merges as well, we'd need the TPE threads (or the Runnable we submit) to poll getNextMerge() until null is returned. This breaks the concepts of Executors, where a task is submitted, done and that's it. I wouldn't mind if we did it still though.\n\nAll of these make me think that TPE, at this point at least, is not suitable for CMS. While it's doable, it's not going to make CMS code any simpler. And it looks more as if we'll enforce TPE in CMS, than it is really useful.\n\nRefactoring IW, MS and MP seems to not simplify anything, really:\n# We'd still need IW telling MP which merges are needed (optimize, regular or expunge), so the three findMergesForXYZ will need to remain.\n# The proposal will add a getNextMerge() to MP, instead of IW, which IMO will only complicate matters for MP implementers. E.g., what should MP do if findRegularMerges was called, then getNext() was called and then findOptimizeMerges is called? It's not a critical decision we leave in the MP developers, but IMO it's unnecessary. Today MP is a stateless object - it receives SegmentInfos and returns a MergeSpec. It doesn't need to 'remember' anything. But if we move the getNextMerge() to it, we make it stateful, for no good reasons\n# We don't really take IW outside the loop really - it would still need to instruct MP which merges to 'prepare', so that MS can take.\n# We'd need to introduce an abort/cancel() API on MS, which adds another responsibility for MS, but doesn't remove much from IW.\n\nAll in all, I don't think this refactoring simplifies IW-MS-MP communication a lot or allows custom MS and MPs have more control over what's going on. IW, as the mediator, is nothing but the mediator, which happens to know (as it should) which merges finish and if the state of the index changed, ask MP for more merges. That that it keeps track of pending and running merges, to me, is not a big deal. In fact, due to IW.waitForMerges() it either must continue to keep track of pending/running merges, or we add a sync() API to every MS.\n\nFixing CMS to allow sharing across multiple IndexWriter instances is important IMO, so I'll look into fixing it. To allow for MP dependent sort, I suggest we add to MP a getMergesComparator and use it in CMS. The default (to not break back-compat) can be ByDocsComparator and we override it in the existing MPs.\n\nI must say that the more I went over the details, the more I was convinced that the proposals made will change the current API for no great benefits. But I may have looked too deeply into the impl, that I lost the ability to think about it 'from above' - so I'd appreciate if someone can go over what I wrote and offer comments :-).",
            "date": "2010-11-24T14:03:30.372+0000",
            "id": 22
        },
        {
            "author": "Earwin Burrfoot",
            "body": "bq. Refactor IW, MS and MP so that MS pulls merges directly from MP, instead from IW.\nDirectly or through IW - this is not important. Important point is pulling merges one-by-one, when you have the resources to execute them.\n\nbq. Rewrite CMS to take advantage of ThreadPoolExecutor instead of managing the threads on its own, in addition to using a blocking queue instead of us coding the blocking directly.\nbq. Using ThreadPoolExecutor looks like will only complicate CMS instead of simplifying it:\nI ended up with same conclusion, while taking my first stabs. But for different reasons.\nThe philosphy of Executors is that you schedule (push) a number of tasks, and then some magic black box runs them for you, resolving threading issues itself.\nMy suggestion requires pulling tasks when computing resources become available, and that doesn't map on scheduling model at all.\nAll priority/pausing/breaking issues are largely irrelevant.\n\nbq. MergeThreads' priority needs to be controllable, and we need the ability to pause large merges in favor of small ones\nThese, and the likes - are not requirements.\nThese are but one of the possible solutions to our real requirements, which look like\n* don't run out of file handles on fast indexation\n* don't degrade search performance and NRT turnaround\n* don't kill the disk with too much random IOs.\n\nbq. If there are cascading merges (i.e., a result of several other merges), they should all be executed following the call to MS.merge() - that is, it could be that CMS itself, or its MergeThreads will encounter merges not returned by MP at first, but as a subsequent round due to changes done to the index.\nThis is trivially solved with my pulling model. We pull until nothing is left. Period. Instead of getting batches of merges from MP and then reconciling them with reality we do the same operation over and over again, until MP is satisfied - very simple.\n\nbq. The proposal will add a getNextMerge() to MP, instead of IW, which IMO will only complicate matters for MP implementers. E.g., what should MP do if findRegularMerges was called, then getNext() was called and then findOptimizeMerges is called? It's not a critical decision we leave in the MP developers, but IMO it's unnecessary. Today MP is a stateless object - it receives SegmentInfos and returns a MergeSpec. It doesn't need to 'remember' anything. But if we move the getNextMerge() to it, we make it stateful, for no good reasons\nbq. We don't really take IW outside the loop really - it would still need to instruct MP which merges to 'prepare', so that MS can take.\nThere will be, most probably, getNext(Normal/Optimize/Expunge)Merge() methods. findWhatever methods will be removed, noone needs to call them, so - no state, no 'preparations'.\nMP will recieve SegmentInfos and return OneMerge.\n\nbq. To allow for MP dependent sort, I suggest we add to MP a getMergesComparator and use it in CMS.\nMP should return merges sorted, that's all. Why do you need to expose its Comparator or whatever it uses for sorting?\n\n\nWhatever I didn't mention from your post - I either missed, or agree with :)\nI think I'll stop trying to explain it in Jira comments. It took great time discussing everything with Mike over IRC, and here it'll take ages.\nThe proper route is to take a handful of dirt and sticks and slap together some working code to illustrate my point. And that's what I'm gonna do.",
            "date": "2010-11-24T17:08:56.526+0000",
            "id": 23
        },
        {
            "author": "Shai Erera",
            "body": "Getting rid of the IndexWriter member in CMS is not trivial w/o API change. The IndexWriter member is used for verbosing purposes, which is accessed by some public/protected API, like sync() and doMerge(). So on 3x it'd mean to deprecate methods, which IMO does not justify it. On trunk it's easier.\n\nOn the other hand, we can consider two things:\n# Make IndexWriter ThreadLocal -- the thread who calls merge() will own its ThreadLocal, and if different threads index to different indexes, then it should work. But it won't help in case the indexing threads are taken from a pool.\n# Think whether we want CMS to be shareable across several IndexWriters at all. I haven't heard that requirement coming up on the list, and definitely if someone attempted to do it, things would break, so I guess no one really does it. Therefore maybe we should leave it to the users to develop something like that on their own, and maybe even contribute back. A MS which might even be simplified by not implementing all of CMS functionality today (controlling threads' priority, pause merge threads etc.).\n\nbq, The proper route is to take a handful of dirt and sticks and slap together some working code to illustrate my point. And that's what I'm gonna do.\n\nIt'd be great if you will do that ! Sometimes it's indeed easier to fight over a concrete example then theoretical \"can and can't work\" arguments.\n\nbq. MP will recieve SegmentInfos and return OneMerge.\n\nFrom whom will it receive it? In the case of cascading merges, the merge threads need to continuously pull MP for getNextMerge(MergeType), but they don't have the global picture IW holds about the existing segments (SegmentInfos). Also, IW keeps track of the segments that existed when you first called optimize() and doesn't allow the cascading merges to include segments that didn't exist at the time. Who will do that accounting now?",
            "date": "2010-12-02T09:11:12.999+0000",
            "id": 24
        },
        {
            "author": "Shai Erera",
            "body": "Patch includes some formatting changes and documentation addition. I'm not sure if eventually we will be able to refactor the whole MP-MS-IW interaction like we said. Earwin, if you still want to work on it, the I can keep the issue open and mark it 3.2 (unless you want to give it a try in 3.1).\n\nAnd I think those tiny mods/formatting are worth checking in, because they at least add some documentation to CMS.",
            "date": "2011-01-17T09:01:16.907+0000",
            "id": 25
        },
        {
            "author": "Earwin Burrfoot",
            "body": "bq. if you still want to work on it, the I can keep the issue open and mark it 3.2 (unless you want to give it a try in 3.1). \nI'll start another later, so please, go on.",
            "date": "2011-01-17T09:46:24.881+0000",
            "id": 26
        },
        {
            "author": "Shai Erera",
            "body": "Committed revision 1059904 (3x).\nCommitted revision 1059905 (trunk).",
            "date": "2011-01-17T12:49:53.548+0000",
            "id": 27
        },
        {
            "author": "Michael McCandless",
            "body": "The cosmetic change committed here accidentally reverted part of LUCENE-2820, which now causes CMS to deadlock!  Specifically the change in mergeThreadCount()...\n\nI'll fix shortly.",
            "date": "2011-01-18T16:05:55.899+0000",
            "id": 28
        },
        {
            "author": "Robert Muir",
            "body": "Mike, fyi it looks like we are hung again in hudson:\nhttps://hudson.apache.org/hudson/job/Lucene-Solr-tests-only-3.x/3866/\n\nNot sure if its the same deadlock you found.",
            "date": "2011-01-18T20:19:08.982+0000",
            "id": 29
        },
        {
            "author": "Robert Muir",
            "body": "I am reopening just so we don't miss fixing the deadlock... its hung in the same exact part of the tests as earlier\ntoday so I think its somehow related...",
            "date": "2011-01-18T20:20:52.047+0000",
            "id": 30
        },
        {
            "author": "Robert Muir",
            "body": "sorry, hudson just slowed to a crawl apparently... it wasn't hung.\n\nwhen i looked at its console it seemed stuck in the same place... but wasn't.",
            "date": "2011-01-18T23:31:45.098+0000",
            "id": 31
        },
        {
            "author": "Grant Ingersoll",
            "body": "Bulk close for 3.1",
            "date": "2011-03-30T15:49:51.452+0000",
            "id": 32
        }
    ],
    "component": "core/index",
    "description": "While running optimize on a large index, I've noticed several things that got me to read CMS code more carefully, and find these issues:\n\n* CMS may hold onto a merge if maxMergeCount is hit. That results in the MergeThreads taking merges from the IndexWriter until they are exhausted, and only then that blocked merge will run. I think it's unnecessary that that merge will be blocked.\n\n* CMS sorts merges by segments size, doc-based and not bytes-based. Since the default MP is LogByteSizeMP, and I hardly believe people care about doc-based size segments anymore, I think we should switch the default impl. There are two ways to make it extensible, if we want:\n** Have an overridable member/method in CMS that you can extend and override - easy.\n** Have OneMerge be comparable and let the MP determine the order (e.g. by bytes, docs, calibrate deletes etc.). Better, but will need to tap into several places in the code, so more risky and complicated.\n\nOn the go, I'd like to add some documentation to CMS - it's not very easy to read and follow.\n\nI'll work on a patch.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2755",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Some improvements to CMS",
    "systemSpecification": true,
    "version": ""
}