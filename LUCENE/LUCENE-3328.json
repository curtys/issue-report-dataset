{
    "comments": [
        {
            "author": "Simon Willnauer",
            "body": "here is a first patch that rewrites to ConjunctinTermQuery if possible. ",
            "date": "2011-07-20T10:41:54.833+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "do we really need an extra query or rewrite? Can't booleanweight just pick ConjunctionTermScorer in this case?",
            "date": "2011-07-20T10:46:12.580+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "here is the same thing, only as a scorer that booleanweight picks.\n\nthis is much simpler imo:\n* no state-keeping of 'rewriteToConjunctionTermsQuery' in the Query\n* no hassles for any highlighters or anything doing instanceof\n* plays correct with booleanquery's rewrite: e.g. hoisting of single-clauses into termqueries.\n\nIn general i think Query.rewrite should be reserved for simplifying Queries, this is not a simpler query, just a faster scorer :)",
            "date": "2011-07-20T11:35:30.049+0000",
            "id": 2
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. here is the same thing, only as a scorer that booleanweight picks.\n\nI like the size of the patch! Thanks for moving this into the weight. I had it separate to make BW less complex but this looks good though.\n\n\nbq. In general i think Query.rewrite should be reserved for simplifying Queries, this is not a simpler query, just a faster scorer \n\nI disagree here, if this would be the case it should be called simplify(Query). In general its a rewrite method and should not be judged if it simplifies or not. \n\n\n\nHere are some benchmark results trunk vs. patch (10M medium wiki docs):\n\n\n||Task||QPS Trunk||StdDev||QPS Patch||\u00a0StdDev||Pct diff||\n|Prefix3|29.84|1.14|29.02|1.37| -10% - 5%|\n|IntNRQ|\u00a05.82|0.67|5.68 | \u00a00.55|-20% - 20%|\n|Wildcard|15.96|\u00a00.77|15.62|\u00a00.63| -10% - 7%|\n|Term |79.10|\u00a04.32|77.43|\u00a03.25| -11% -  7%|\n|OrHighMed |\u00a015.67|\u00a00.94|15.44|\u00a01.00|-13% - 11%|\n|TermGroup1M  |\u00a0 10.82|\u00a00.76|10.77|\u00a00.69 |-13% - \u00a0 13%|\n|OrHighHigh|\u00a03.31|\u00a00.37|\u00a03.29|\u00a00.37 | -20% - 24% |\n|Respell|15.99|\u00a00.59|15.95|\u00a00.52|-6% -  6%|\n|TermBGroup1M|12.87|\u00a01.09|12.86|\u00a00.94|-14% - 17% |\n|Fuzzy1|24.38|\u00a01.19|24.39|\u00a00.84|-7% -  8% |\n|TermBGroup1M1P|17.67|\u00a01.33|17.79|\u00a01.14|-12% - 15% |\n|Fuzzy2|\u00a07.60|\u00a00.64|\u00a07.67|\u00a00.59|-14% - 18% |\n|Phrase|\u00a06.84|\u00a00.64|\u00a06.91|\u00a00.62|-15% - 21% |\n|SpanNear|\u00a01.90|\u00a00.24|\u00a01.92|\u00a00.22|-20% - 29% |\n|PKLookup|76.01|\u00a04.56|76.99|\u00a03.26|-8% - 12% |\n|SloppyPhrase|\u00a02.49|\u00a00.25|\u00a02.53|\u00a00.23|-16% - 23% |\n|AndHighMed|29.80|\u00a01.11|33.50|\u00a01.31 |\u00a04% - 21% |\n|AndHighHigh|10.74|\u00a00.67|12.26|\u00a00.55 |\u00a02% - 27% |",
            "date": "2011-07-20T14:17:05.396+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nI disagree here, if this would be the case it should be called simplify(Query). In general its a rewrite method and should not be judged if it simplifies or not. \n{quote}\n\nI think this is really important to hash out: if we want to optimize query execution, we should do this totally internally at the lowest level possible.\nIf the optimization is to use a specialized scorer, then I think the right place to do this is inside the Weight.\n\nI don't think we should create a bunch of queries that are really the same and rewrite to each other: because this is more 'exposed' to end users, e.g.\nhighlighting, caching, and who knows what people are doing in their custom code.\n\nIt also requires a heavy maintenance burden of duplicate logic and testing for explain, hashcode, equals, etc.\n",
            "date": "2011-07-20T14:24:21.560+0000",
            "id": 4
        },
        {
            "author": "Simon Willnauer",
            "body": "I agree with you that in this case a scorer is more elegant. Yet, the rewrite process is a very powerful process that can be used for query optimization etc. from the outside. What I am trying to say is that this is not necessarily bound to \"simplification\". All your points are valid!",
            "date": "2011-07-20T15:16:34.122+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "That's a nice speedup for AND of terms!!",
            "date": "2011-07-20T15:44:56.693+0000",
            "id": 6
        },
        {
            "author": "Robert Muir",
            "body": "Also, I am usually positive on backporting improvements to 3.x to get them back to the users quickly, but I think\nwe should do this only in trunk.\n\nThe reason is: 3.x is going to be very hairy here, since the computation of scoring (including score caches and shit) is\nconflated into the postings list matching for termquery, since it has no termstate to pull from, ...\n",
            "date": "2011-07-20T16:02:07.598+0000",
            "id": 7
        },
        {
            "author": "Robert Muir",
            "body": "setting 4.0-only.\n\nif someone volunteers to comes up with some smart not-buggy and not-hairy patch, thats cool, I just can't visualize it now.",
            "date": "2011-07-20T16:11:25.068+0000",
            "id": 8
        },
        {
            "author": "Simon Willnauer",
            "body": "next iteration. I added two util methods to get a TermsEnum and a ExactDocScorer from a TermWeight which allowed to make all the members private again. This looks little cleaner now and eventually if we cut over PhraseQuery to use BQ + PosIterators it can simply get all it needs from the TermsEnum like DocsAndPosEnum & totalTermFreq.\n\nI also tried to optimize the doNext() loop even further to save one more comparison to hopefully help hotspot even further. I need to benchmark this patch one more time but overall this looks close.\n\nI also added a CHANGES.TXT entry.\n",
            "date": "2011-07-20T22:38:11.027+0000",
            "id": 9
        },
        {
            "author": "Michael McCandless",
            "body": "Results from latest patch:\n\n||Task||QPS base||StdDev base||QPS bqterms||StdDev bqterms||Pct diff||||\n|Fuzzy2|34.74|0.40|34.58|0.49|{color:red}2%{color}-{color:green}2%{color}|\n|Fuzzy1|23.85|0.25|23.78|0.31|{color:red}2%{color}-{color:green}2%{color}|\n|Respell|31.26|0.40|31.24|1.08|{color:red}4%{color}-{color:green}4%{color}|\n|PKLookup|137.63|2.79|138.19|6.90|{color:red}6%{color}-{color:green}7%{color}|\n|OrHighHigh|18.91|0.29|19.04|0.49|{color:red}3%{color}-{color:green}4%{color}|\n|Wildcard|50.35|1.12|50.82|1.32|{color:red}3%{color}-{color:green}5%{color}|\n|IntNRQ|9.14|0.38|9.24|0.42|{color:red}7%{color}-{color:green}10%{color}|\n|OrHighMed|10.38|0.36|10.55|0.39|{color:red}5%{color}-{color:green}9%{color}|\n|Prefix3|15.22|0.34|15.51|0.30|{color:red}2%{color}-{color:green}6%{color}|\n|TermBGroup1M1P|57.45|2.11|58.81|1.75|{color:red}4%{color}-{color:green}9%{color}|\n|SpanNear|4.28|0.28|4.40|0.08|{color:red}5%{color}-{color:green}11%{color}|\n|TermBGroup1M|46.36|1.38|47.93|1.88|{color:red}3%{color}-{color:green}10%{color}|\n|TermGroup1M|47.63|0.93|49.31|1.83|{color:red}2%{color}-{color:green}9%{color}|\n|Term|137.86|6.74|142.82|6.55|{color:red}5%{color}-{color:green}13%{color}|\n|SloppyPhrase|19.72|0.87|20.62|0.01|{color:green}0%{color}-{color:green}9%{color}|\n|Phrase|3.28|0.19|3.50|0.11|{color:red}2%{color}-{color:green}16%{color}|\n|AndHighMed|87.52|2.55|100.80|4.80|{color:green}6%{color}-{color:green}24%{color}|\n|AndHighHigh|14.92|0.55|17.33|0.91|{color:green}6%{color}-{color:green}26%{color}|\n\nLooks great!",
            "date": "2011-07-20T23:16:03.000+0000",
            "id": 10
        },
        {
            "author": "Michael Busch",
            "body": "Nice improvements!\n\nI'm wondering if you considered having ConjunctionTermScorer use the terms' IDF values to decide which iterator to advance when all are on the same docID? It should always be best to pick the rarest term.\n\nWe've talked about doing that in the past, but it's hard to support this for any type of subclause, because you'd have to add the ability to estimate the IDFs of possible subclauses.\n\nBut with this change it seems very feasible to try for BQs that only have TQ clauses.",
            "date": "2011-07-21T05:23:56.021+0000",
            "id": 11
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. I'm wondering if you considered having ConjunctionTermScorer use the terms' IDF values to decide which iterator to advance when all are on the same docID? It should always be best to pick the rarest term.\n\nThe ConjunctionTermScorer sorts the DocsEnums by their frequency in the ctor. The leader will always be the lowest frequent term in the set. is this what you mean here?\n\nWe could even optimize the doNext loop and advance the lead to the last document we stepped out of the inner loop since this is guaranteed to be greater than the document the lead enum is on. I just wonder if we at some point step into the slowness of DocsEnum#advance(). It very important to make #advance(doc+1) as fast as #nextDoc() in order to keep our algs clean! ",
            "date": "2011-07-21T06:08:25.302+0000",
            "id": 12
        },
        {
            "author": "Simon Willnauer",
            "body": "I think this is ready. I will commit this tomorrow if nobody objects.",
            "date": "2011-07-21T13:49:13.056+0000",
            "id": 13
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nThe ConjunctionTermScorer sorts the DocsEnums by their frequency in the ctor. The leader will always be the lowest frequent term in the set. is this what you mean here?\n{quote}\n\nCool, yeah that's roughly what I meant. In general, it's best to always pick the lowest-df enum as leader:\n1) after initialization\n2) after a hit was found\n3) whenever a doc matched m out of n enums, 1 < m < n\n\nI think what you described covers situation 1), does it also cover 2) and 3)?",
            "date": "2011-07-21T16:42:43.913+0000",
            "id": 14
        },
        {
            "author": "Simon Willnauer",
            "body": "{quote}\n2) after a hit was found\n3) whenever a doc matched m out of n enums, 1 < m < n\n{quote}\n\nmaybe I miss something here but really how can we know how many docs are left in an enum during 2. and 3. We could use the doc an enum has advanced to in 3. to also advance the leader but as I said in a comment above I am still afraid of the advance call since it can give a serious perf hit if docs are close together.\n",
            "date": "2011-07-22T10:02:11.023+0000",
            "id": 15
        },
        {
            "author": "Simon Willnauer",
            "body": "I just committed the latest patch to trunk. should we open a new issue for disjunction?\n\nsimon",
            "date": "2011-07-22T10:28:49.299+0000",
            "id": 16
        },
        {
            "author": "Michael McCandless",
            "body": "bq. should we open a new issue for disjunction?\n\n+1",
            "date": "2011-07-22T12:44:48.664+0000",
            "id": 17
        },
        {
            "author": "Paul Elschot",
            "body": "Sorry for not looking at this earlier, but in trunk now in ConjunctionTermScorer in the doNext method the lead TermScorer is not advanced when breaking to the advanceHead label even though the comment at the break states so.\nI would expect this to works correctly but it is probably not as efficient as intended.\n\nI think advancing the lead in program code at the place of the break comment could fix this.",
            "date": "2011-07-22T19:24:26.436+0000",
            "id": 18
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. I think advancing the lead in program code at the place of the break comment could fix this.\nPaul this works and looks as expected. Once we break to the advanceHead label we step out the inner do {} while; and advance the head. Maybe I don't understand your comment correctly?\n\nThere is certainly space for improvement here. for instance could the head be advanced to the doc we break on but the advance call there actually yields a perf hit. Yet, we can play some tricks like if (DF / maxdoc > X) enum.advance( n ) else while(n > enum.nextDoc()); which I think I'll look into after vacation :)",
            "date": "2011-07-22T20:38:19.330+0000",
            "id": 19
        },
        {
            "author": "Paul Elschot",
            "body": "bq. this works and looks as expected. \nIndeed so. I mistook the working of a labeled break for jumping to the beginning instead of to the end.\n(The last time I used a label was actually with another programming language...)",
            "date": "2011-07-24T09:54:23.859+0000",
            "id": 20
        },
        {
            "author": "Uwe Schindler",
            "body": "Indeed breaks in Java are no real gotos. The label must always be placed *before* the loop that you want to break out (it would give syntax error otherwise). In fact it simply exits the loop to this level and proceeds working *after* the loop. A simple break without a label is identical to a non-hierarchical loop with a autogenerated label in front of it.",
            "date": "2011-07-24T10:12:45.380+0000",
            "id": 21
        }
    ],
    "component": "core/search",
    "description": "During work on LUCENE-3319 I ran into issues with BooleanQuery compared to PhraseQuery in the exact case. If I disable scoring on PhraseQuery and bypass the position matching, essentially doing a conjunction match, ExactPhraseScorer beats plain boolean scorer by 40% which is a sizeable gain. I converted a ConjunctionScorer to use DocsEnum directly but still didn't get all the 40% from PhraseQuery. Yet, it turned out with further optimizations this gets very close to PhraseQuery. The biggest gain here came from converting the hand crafted loop in ConjunctionScorer#doNext to a for loop which seems to be less confusing to hotspot. In this particular case I think code specialization makes lots of sense since BQ with TQ is by far one of the most common queries.\n\nI will upload a patch shortly",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3328",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Specialize BooleanQuery if all clauses are TermQueries",
    "systemSpecification": true,
    "version": "3.4, 4.0-ALPHA"
}