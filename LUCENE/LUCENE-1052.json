{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "Attached patch derived from Doug's & Chuck's patches from the thread.  All tests pass.",
            "date": "2007-11-13T17:46:12.989+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "I just committed this.  Thanks Chuck & Doug!",
            "date": "2007-11-15T21:15:29.789+0000",
            "id": 1
        },
        {
            "author": "Chuck Williams",
            "body": "Michael, thanks for creating an excellent production version of this idea and committing it!\n\nI'd like to take it one step further to eliminate the need to call IndexReader.setTermInfosIndexDivisor up front.  The idea is to instead specify a maximum number of index terms to cache in memory.  This could then allow TermInfosReader to set indexDivisor automatically to the smallest value that yields a cache size less than the maximum.\n\nThis seems a simple and extremely useful extension.  Unfortunately, I'm still on an older Lucene, but will post my update.  If you like this idea, you may want to just add the feature directly to your implementation in the trunk.\n",
            "date": "2007-11-17T19:48:08.465+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nI'd like to take it one step further to eliminate the need to call IndexReader.setTermInfosIndexDivisor up front.  The idea is to instead specify a maximum number of index terms to cache in memory.  This could then allow TermInfosReader to set indexDivisor automatically to the smallest value that yields a cache size less than the maximum.\n\nThis seems a simple and extremely useful extension.  Unfortunately, I'm still on an older Lucene, but will post my update.  If you like this idea, you may want to just add the feature directly to your implementation in the trunk.\n{quote}\n\nGood idea!  This allows you to simply outright cap the memory usage,\nrather than having memory usage be a fraction of the number of terms\nand thus grow as your term count grows.\n\nSo you would propose replacing IndexReader.setTermInfosIndexDivisor\nwith IndexReader.setTermInfosIndexMaxCount or some such?  Ie you would\nstill need to call this on creating your reader...",
            "date": "2007-11-18T11:14:26.043+0000",
            "id": 3
        },
        {
            "author": "Chuck Williams",
            "body": "I believe this needs to be a formula as a reasonable bound on the number of terms is in general a function of the number of documents in the segment and the nature of the index (e.g., types of fields).  A common thing to do would be to enforce that RAM usage for cached terms grows no faster than logarithmically in the number of documents.  The specific formula that is appropriate will depend on the index, i.e. on the application.  It might be of the form:  c*ln(numdocs+k), wnere c and k are constants dependent on the index.\n\nOne consequence of this approach, or any approach along these lines, is that the indexDivisor will vary across the segments, both in a single index and across indexes.  It seems to me from the code that this should work fine.\n\nThis leaves the issue of how to best specify an arbitrary formula.  This requires a method to compute the max cached terms allowed for a segment based on the number of docs in the segment, the number of terms in the segment's index, and possibly other factors.  The most direct way to do this is to introduce an interface, e.g. TermInfosConfigurer, to define the method signature, and to add setTermInfosConfigurer as an alternative to setTermInfosIndexDivisor.  It would need to be in all the same places.\n\nA more general approach would be to introduce an IndexConfigurer class which over time could hold additional methods like this.  It could even replace the current setters on IndexReader (as well as IndexWriter, etc.) with a more general mechanism that would allow dynamic parameters used to configure any classes in the index structure.  Each constructor would be passed the IndexConfigurer and call getters or other methods on it to obtain its config.  The methods could provide constant values or dynamic formulas.\n\nI'm going to implement the straightforward solution at the moment in our older version of Lucene, then will sync up to whatever you guys decide is best for the trunk later.\n ",
            "date": "2007-11-18T17:50:41.397+0000",
            "id": 4
        },
        {
            "author": "Chuck Williams",
            "body": "termInfosConfigurer.patch extends the termInfoIndexDivisor mechanism to allow dynamic management of this parameter.  A new new interface, TermInfosConfigurer, allows specification of a method, getMaxTermsCached(), that bounds the size of the in-memory term infos as a function of the segment name, segment numDocs, and total segment terms.  This bound is then used to automatically set termInfosIndexDivisor whenever a TermInfosReader reads the term index.  This mechanism provides a simple way to ensure that the total amount of memory consumed by the term cache is bounded by, say, O(log(numDocs)).\n\nAll Lucene core tests pass.  I'm using another version of this same patch in Lucene 2.1+ in an application that has indexes with binary term pollution, using the TermInfosConfigurer to dynamically bound the term cache in the polluted segments.\n\nTried to test contrib, but it appears gdata-server needs external libraries I don't have to compile.\n\nMichael, this patch applies cleanly to today's Lucene trunk.  I'd appreciate if you could verify one thing.  Lucene 2.3 has the incremental reopen mechanism (can't wait to get that!), new since Lucene 2.1.  It appears that reopen of a segment reuses the same TermInfosReader and thus does not need to configure a new one.  I've implemented that part of the patch with this assumption.\n",
            "date": "2007-11-19T20:25:22.101+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "Thanks Chuck for such a wonderfully thorough patch & unit tests, and\nfor adding the methods to ParallelReader, too (I had missed it the\nfirst time around)!  The patch looks good.\n\nShould we use an abstract base class instead of interface for\nTermInfosConfigurer so we can add additional methods in the future\nwithout breaking back compatibility?\n\nAlso I think we should mark this API as advanced, somewhat\nexperimental and subject to change?\n",
            "date": "2007-11-20T10:54:02.215+0000",
            "id": 6
        },
        {
            "author": "Doug Cutting",
            "body": "I think we should be cautious about adding a new public interface or abstract class to support just this feature.  If we want to add a generic configuration API for Lucene, then I'd prefer something fully general, like what I proposed on the mailing list, not something specific to configuring TermInfosReader.  Otherwise we'll keep adding new configuration interfaces and adding more parameters to IndexReader constructors each time we wish to make some obscure feature configurable.\n\nhttp://www.gossamer-threads.com/lists/lucene/java-dev/54421#54421\n\nIn the model proposed there, adding a new configuration parameter involves just adding a new static method to the public class that implements a new configurable feature.\n",
            "date": "2007-11-20T20:03:12.525+0000",
            "id": 7
        },
        {
            "author": "Chuck Williams",
            "body": "I agree a general configuration system would be much better.  Doug. we use a similar method to what you described in our application.\n\nTermInfosConfigurer is slightly different though since the desired config is a method that implements a formula, rather than just a value.  This could still be done more generally by allowing methods as well as properties or setters on a higher level configuration object.\n\nI didn't want to take on the broader issue just for this feature.\n\nMichael I agree with both of your points.\n\nI'd be happy to clean up this patch if you guys provide some guidance for what would make it acceptable to commit.\n",
            "date": "2007-11-20T20:45:04.765+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "\nMaybe, instead, we should simply make it \"easy\" to subclass\nTermInfosReader whenever a SegmentReader wants to instantiate it?\n\nIe, the formula is such an advanced use case that it seems appropriate\nto subclass instead of trying to break it out into a special\ninterface/abstract class?\n\nOf course, we need to know this class at SegmentReader construction\ntime, so I think to specify it we should in fact take Doug's suggested\napproach using generic properties.\n\nThe challenge with Lucene (and Hadoop) is how can you reach deep down\ninto a complex IndexReader.open static method call to change various\ndetails of the embedded *Readers while they are being constructed,\nand, after they are constructed... I agree it is messy now that we\nmust propogate the setTermInfosIndexInterval method up the *Reader\nhierarchy when not all Readers would even use a TermInfosReader.\n\nSo ... maybe we 1) implement generic Lucene properties w/ static\nclasses/methods to set/get these properties, then 2) remove\nset/getTermInfosIndexInterval from *Reader and make a generic property\nfor it instead, and 3) add another property that allows you to specify\nthe Class (or String name) of that is your TermInfosReader subclass\n(and make it non-final)?\n",
            "date": "2007-11-20T21:33:45.826+0000",
            "id": 9
        },
        {
            "author": "Doug Cutting",
            "body": "What class would we put TermInfosReader-specific setters & getters on, since that class is not public?  Do we make TermInfosReader public or leave it package-private?  My intuition is to leave it package-private for now, in order to retain freedom to re-structure w/o breaking applications, and because making it public would drag a lot of other stuff into the public.  We could consider making SegmentReader public, so that there's a public class that corresponds to the concrete index implementation, but that'd also drag more stuff public (like DirectoryIndexReader).\n\nI'm also not yet convinced that it is critical to support arbitrary formulae for this feature.  Sure, it would be nice, but it has costs, like increasing public APIs that must be supported.  Folks have done fine without this feature for many years.  Adding a simple integer divisor is a sufficient initial step here.\n\nSo, even if we add a configuration system, I think the setter methods could still end up on IndexReader.  The difference is primarily whether the methods are:\n\npublic void setTermIndexInterval(int interval);\npublic void setTermIndexDivisor(int divisor);\n\nor\n\npublic static void setTermIndexInterval(LuceneProps props, int interval);\npublic static void setTermIndexDivisor(LuceneProps props, int divisor);\n\nWith the latter just a fa\u00e7ade that uses package-private stuff.  I think the latter style will be handy as we start adding parameters to, e.g., Query classes.  In those cases we'll probably want fa\u00e7ade's too, since a Query setter will probably really tweak something for a private Scorer class.  In the case of indexes, however, we don't have a public, concrete class.\n\nAnother option is to make a public class whose purpose is just to only such parameters, something like SegmentIndexParameters.  That'd be my first choice and was the direction I pointed in my initial proposal, but with considerably less explanation.",
            "date": "2007-11-21T00:27:38.570+0000",
            "id": 10
        },
        {
            "author": "Chuck Williams",
            "body": "I can report that in our application having a formula is critical.  We have no control over the content our users index, nor in fact do they.  These are arbitrary documents.  We find a surprising number of them contain embedded encoded binary data.  When those are indexed, lucene's memory consumption skyrockets, either bringing the whole app down with an OOM or slowing performance to a crawl due to excessive GC's reclaiming a tiny remaining working memory space.\n\nOur users won't accept a solution like, wait until the problem occurs and then increment your termIndexDivisor.  They expect our app to manage this automatically.\n\nI agree that making TermInfosReader, SegmentReader, etc. public classes is not a great solution  The current patch does not do that.  It simply adds a configurable class that can be used to provide formula parameters as opposed to just value parameters.  At least for us, this special case is sufficiently important to outweigh any considerations of the complexity of an additional class.\n\nA single configuration class could be used at the IndexReader level that provides for both static and dynamically-varying properties through getters, some of which take parameters.\n\nHere is another possible solution.  My current thought is that the bound should always be a multiple of sqrt(numDocs).  E.g., see Heap's Law here:  http://nlp.stanford.edu/IR-book/html/htmledition/heaps-law-estimating-the-number-of-terms-1.html\n\nI'm currently using this formula in my TermInfosConfigurer:\n\n            int bound = (int) (1+TERM_BOUNDING_MULTIPLIER*Math.sqrt(1+segmentNumDocs)/TERM_INDEX_INTERVAL);\n\nThis has Heap's law as foundation.  I provide TERM_BOUNDING_MULTIPLIER as the config parameter, with 0 meaning don't do this.  I also provide a TERM_INDEX_DIVISOR_OVERRIDE that overrides the dynamic bounding with a manually specified constant amount.\n\nIf that approach would be acceptable to lucene in general, then we just need two static parameters.  However, I don't have enough experience with how well this formula works in our user base yet to know whether or not we'll tune it further.\n\n\n",
            "date": "2007-11-21T01:38:10.449+0000",
            "id": 11
        },
        {
            "author": "Doug Cutting",
            "body": "> We find a surprising number of them contain embedded encoded binary data.\n\nIt sounds like a detector for this would be very useful.  It would, e.g., substantially speed updates of such indexes, and not slow searches of them like a divisor does.  At Excite we evolved effective heuristics for wordness to keep our dictionaries from exploding.  Perhaps you should look into that?  Also, it sounds like you might increase your default term index interval, since it sounds like you have big indexes with noisy data.\n\n> Our users won't accept a solution like, wait until the problem occurs and then increment your termIndexDivisor. They expect our app to manage this automatically.\n\nYou could look at the size of the .tii files before you open an index, and, if they're too large, set the divisor automatically as you see fit.\n\n> int bound = (int) (1+TERM_BOUNDING_MULTIPLIER*Math.sqrt(1+segmentNumDocs)/TERM_INDEX_INTERVAL);\n\nThis sounds like a fine approach.",
            "date": "2007-11-21T17:54:01.633+0000",
            "id": 12
        },
        {
            "author": "Michael McCandless",
            "body": "\n{quote}\nWhat class would we put TermInfosReader-specific setters & getters on, since that class is not public? Do we make TermInfosReader public or leave it package-private? My intuition is to leave it package-private for now, in order to retain freedom to re-structure w/o breaking applications, and because making it public would drag a lot of other stuff into the public. We could consider making SegmentReader public, so that there's a public class that corresponds to the concrete index implementation, but that'd also drag more stuff public (like DirectoryIndexReader).\n{quote}\n\nAgreed: package private.  People who do advanced things should be fine\nwith that.\n\n{quote}\nAnother option is to make a public class whose purpose is just to only such parameters, something like SegmentIndexParameters. That'd be my first choice and was the direction I pointed in my initial proposal, but with considerably less explanation.\n{quote}\n\nSo I took a closer look at making generic properties by coding up\nDoug's approach (attached patch).\n\nI replaced *#setTermInfosIndexDivisor with a separate\nSegmentIndexProperties class that has static methods to set/get\ntermIndexDivisor, and added/threaded down ctors that allow you to pass\na LuceneProperties when opening an IndexReader.\n\nI came up with a number of questions along the way:\n\n  * Who should know/store the default value for a given property?\n    TermIndexDivisor defaults to 1.\n    .\n    Is this stored in that static facade class (a)?  Or, passed in as\n    defaultValue arg by TermInfosReader when it looks up the property\n    (b)?  Or, do we make a base DefaultLuceneProperties that has the\n    default set for all properties (c)?\n    .\n    (b) is nice because I feel like the default should live in the\n    class that uses it, but then that's bad because the outside world\n    can't see the default value.\n\n  * Every property must clearly define when it will be looked at.  So\n    for termIndexDivisor in the javadoc we would say \"it's used only\n    when the termInfos index is loaded (once)\".  This means changing\n    that property after termInfos index is loaded has no effect.\n\n  * We should presumably create a default LuceneProperties to save\n    checking for props != null everywhere when user didn't make their\n    own props.  This favors option (c) in the first bullet above.\n\n  * Presumably once you've created a class, passing in your props\n    instance, you cannot later install a new props instance.  The\n    LuceneProperties class is \"write once\".\n\n  * We would need guidelines for when something should be an arg to\n    the ctor, setter/getter on the class.  I think there are shades of\n    gray here.\n\nAfter this, I suddenly realized if we indeed make termIndexDivisor a\ngeneric property, it's actually hard for Chuck to then do his formula\nby looking at the size of the .tii file: when the index has multiple\nsegments, you would presumably need to set different indexDivisors for\neach segment, but the properties only lets you set one global value.\n\nYou could carefully set the property, then somehow get ahold of just\nthat one SegmentReader and have it load the term index, then move onto\nthe next one, etc, but that's quite messy.\n\nNote that this limitation is also the case with the top-level\nsetTermInfosIndexDivisor as it now stands in trunk -- it's not easy to\nset different index divisors per segment.\n\nIt almost feels like we should have \"hooks\" that are invoked at\ncertain times, like when we are about to load the term infos index,\nthat give the application a chance to change something...\n\n\n",
            "date": "2007-11-21T20:22:53.369+0000",
            "id": 13
        },
        {
            "author": "Chuck Williams",
            "body": "> It almost feels like we should have \"hooks\" that are invoked at\n> certain times, like when we are about to load the term infos index,\n> that give the application a chance to change something...\n\nI agree with the need for some kind of hook.  This is what TermInfosConfigurer is.  It calls a method whenever a SegmentReader reads an index to obtains parameters (termIndexDivisor) that should be used to configure the TermInfosReader.\n\nWhy not make the setters/getters on SegmentIndexProperties regular non-static methods, and allow hook methods as well?  E.g., setTermIndexDivsior(), getTermIndexDivisor(), getMaxTermsCached(String segmentName, int segmentNumDocs, long segmentNumTerms).  Non-static methods make the defaulting straightforward and allow for subclassing to override hook methods. \n\n> It sounds like a detector for this would be very useful. It would, e.g., substantially\n> speed updates of such indexes, and not slow searches of them like a divisor does.\n> At Excite we evolved effective heuristics for wordness to keep our dictionaries from exploding.\n\nYes, we are pursuing that approach as well, but we have some stringent requirements in our market.  E.g., we cannot filter *any* valid content, because searches must be guaranteed to find all matching results.  As of result of this, we cannot impose any maximum length for documents.\n\nAny type of binary content recognizer would either need to be 100% accurate, which is impossible, or require human intervention to validate filtering.  For a human intervention approach to be viable the false positive rate must be tiny.  To be effective the false negative rate must be tiny.  Although invalid content is pretty easy for people tor recognize, I've found so far that high-accuracy recognition rules are surprising subtle.\n\nDo you by chance no of any quality work in this area?\n\n> > int bound = (int) (1+TERM_BOUNDING_MULTIPLIER*Math.sqrt(1+segmentNumDocs)/TERM_INDEX_INTERVAL);\n\n> This sounds like a fine approach.\n\nIt seems to be working ok, but there is one issue.  Heap's Law is based on the total number of tokens in the content, not the total number of documents.  I.e., longer documents will generate more distinct terms than shorter documents.  For large segments the use of numDocs works ok due to statistical averaging, but for smaller segments there are errors.  I may loosen the bound somewhat on smaller segments in order to allow for their larger standard deviation.\n\nIf Lucene indexes tracked totalTokens (with duplicates, i.e. not numDistinctTokens) that would be perfect, but they don't.  I don't know whether or not there would be other good uses for totalTokens but mention its relevance here in case there are.\n",
            "date": "2007-11-21T23:54:16.341+0000",
            "id": 14
        },
        {
            "author": "Michael McCandless",
            "body": "I think for 2.3 we should go with the approach as currently committed, and take this ongoing debate into 2.4?  I'll mark this as 2.4 target.",
            "date": "2007-12-06T12:38:43.948+0000",
            "id": 15
        },
        {
            "author": "Michael McCandless",
            "body": "Changing fix version from 2.4 to Unknown.",
            "date": "2008-08-19T10:17:18.141+0000",
            "id": 16
        },
        {
            "author": "Mark Miller",
            "body": "Should any further improvements be in a new issue? It confuses tracking in changes.txt to rework issues after placing them in changes doesnt it? The issues could then be linked.",
            "date": "2008-11-11T01:38:05.543+0000",
            "id": 17
        },
        {
            "author": "Mark Miller",
            "body": "This issue was resolved - lets open a new one if we want to do more.",
            "date": "2009-12-08T04:26:18.779+0000",
            "id": 18
        }
    ],
    "component": "core/index",
    "description": "The termIndexInterval, set during indexing time, let's you tradeoff\nhow much RAM is used by a reader to load the indexed terms vs cost of\nseeking to the specific term you want to load.\n\nBut the downside is you must set it at indexing time.\n\nThis issue adds an indexDivisor to TermInfosReader so that on opening\na reader you could further sub-sample the the termIndexInterval to use\nless RAM.  EG a setting of 2 means every 2 * termIndexInterval is\nloaded into RAM.\n\nThis is particularly useful if your index has a great many terms (eg\nyou accidentally indexed binary terms).\n\nSpinoff from this thread:\n\n  http://www.gossamer-threads.com/lists/lucene/java-dev/54371\n\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1052",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Add an \"termInfosIndexDivisor\" to IndexReader",
    "systemSpecification": true,
    "version": "2.2"
}