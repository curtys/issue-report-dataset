{
    "comments": [
        {
            "author": "Simon Willnauer",
            "body": "I started on this issue with a rough idea and wanna upload it to get some initial feedback. The idea is to provide access to TermState via the TermsEnum Attribute API to eventually use the TermState inside of TermQuery to prevent a second lookup as well as term cache. Its very rough and I tried to go the least intrusive way as possible so the implementation is mainly to show the main principles.\n\nfeedback welcome.",
            "date": "2010-11-18T17:46:53.926+0000",
            "id": 0
        },
        {
            "author": "Uwe Schindler",
            "body": "Havent looked closely into the patch (still need to understand the whole thing), just some comments from attribute policeman in general:\n- The TermStateAttributeImpl.copyTo should throw ClassCastEx if attributes are not conform (compare other impls), so the if statement should not be there. AttributeSource takes care of copying. This is not used, but for completeness.\n- the convenience addClause() method in abstract base class should be final! Else you could incorrectly override the wrong one. We already have code duplication in your patch because of this. When you make it final you will see!\n- why is the attribute using a SetOnce? Attributes generally should be modifiable multiple times. Now you have to call clear() first. This may change in future when we have set-once attributes, but for now that violates the contract :-)\n- Is the docFreq no already part of the state so TermCollectingRewrite does not need to expose it separately?\n- What happens in the term collectors when the same term with different states are merged in the PQ/TermsHash/...?",
            "date": "2010-11-18T18:06:55.937+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "I would rather not use an attribute here -- this is a very core thing so I think we should extend TermsEnum API.\n\nWe can just add a getTermState and a seek(TermState) to terms enum (and, actually, remove cacheTermState)?\n\nAlso, then we wouldn't need to add the get docs/positions enum methods to TermState.",
            "date": "2010-11-18T18:45:03.027+0000",
            "id": 2
        },
        {
            "author": "Simon Willnauer",
            "body": "Uwe I agree with your comments - I just didn't pay lots of attention to it since I was rather interested in feedback for the idea....\n\nI actually think that we should move the getTermState into the termsEnum though rather than using an attribute but for now that was easier to implement though.\n\nbq. What happens in the term collectors when the same term with different states are merged in the PQ/TermsHash/...?\nThat one should work since I map the TermState per reader in a PerReaderTermState though.\n\nsimon",
            "date": "2010-11-18T18:49:32.196+0000",
            "id": 3
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. We can just add a getTermState and a seek(TermState) to terms enum (and, actually, remove cacheTermState)?\nYes! please! - i used the attribute to move faster here since it didn't require to change the API really.\n\nbq. Also, then we wouldn't need to add the get docs/positions enum methods to TermState.\n\nyeah see above....\n\ni will workout a cleaner patch",
            "date": "2010-11-18T19:43:23.507+0000",
            "id": 4
        },
        {
            "author": "Simon Willnauer",
            "body": "next iteration. This patch removes the term cache completely and exposes getTermState via TermsEnum. Terms, TermsEnum and IndexReader can now obtain a DocEnum directly by passing in a TermState.\n\nI need to run some benchmarks on an index with several segments on a index with two segments its just slightly faster...\nmike do you have one ready?",
            "date": "2010-11-19T16:54:08.857+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "Phew that was fast!\n\nWow, you nuked the terms dict cache :) Nice!\n\nThough it makes me a bit nervous... like there'll always be a risk\nwe've missed some path through Lucene that does two lookups...  And,\neven for external reasons (eg same query arrives to Lucene, looking\nfor next page or something), the cache is useful.\n\nEG, a straight TermQuery (not spawned by MTQ) is now hitting the terms\ndict twice.  Once inside Sim.idfExplain, where it calls\nsearcher.docFreq(term), and then again to pull the scorers per sub\nreader.  Probably, TermQuery should pull the PerReaderTermState, up\nfront, if it wasn't already handed it?  And then pass the docFreq to\nSim.idfExplain.\n\nShould we add a PerReaderTermState.docFreq(), which just sums up\nacross all subs?\n\nDoes TermState really need field()?  Seems wasteful to have to store\nthat... eg an MTQ will store many TermStates against the same field.\nI think we should keep TermState lean.\n\nAlso, I think it shouldn't need that clone method?\n\nI think instead of duplicating docs/docsAndPositions (and soon\nbulkPostings) on TermsEnum, once for TermState and once without, we\nshould just add a seek(TermState)?  And then the single\ndocs/docsAndPositions/etc. method can be used to get the enum for that\nterm.  (Likewise for Terms) Also, we should remove docFreq and ord\nfrom TermsEnum since you should get it from TermState?\n\nI think IndexReader can offer the sugar methods (that take either\nBytesRef term or String field + TermState state).\n\nAlso: I tried to run the benchmark on beast but unfortunately there's\na bug somewhere (even though Lucene core tests pass) -- I see\ndifferent results for some fuzzy queries.\n\nNice work!!  Getting to single term lookup for all queries will be awesome!\n",
            "date": "2010-11-19T17:57:09.583+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "BTW, one use case where this patch should show a sizable performance gain is a \"primary key lookup\" against a multi-segment index.\n\nSo this'd be a TermQuery against eg an \"id\" field, where the app knows at most one doc contains the requested value.\n\nToday, we pay a high price for the 2nd pass, because we do not cache a miss against a segment.  So on the first pass (computing IDF) we know which segment has a match and which segments do not, but then on the 2nd pass we re-pay the lookup cost against all the misses (the single segment w/ the hit will be cached).\n\nSo this ought to be a big win... especially once we combine this w/ the speedups from pulsing codec (we still need to cutover to this as a default) then primary key lookups in a Lucene index will be much faster...",
            "date": "2010-11-21T12:04:05.977+0000",
            "id": 7
        },
        {
            "author": "Simon Willnauer",
            "body": "Attaching current state - all test pass for me and luceneutils brings consistent results with trunk.\n\n{code}\n\n               Query   QPS trunkQPS termstate  Pct diff\n            unit~2.0       14.70       14.39     -2.1%\n          united~2.0        6.91        6.83     -1.1%\n          united~1.0        7.42        7.38     -0.6%\n        \"unit state\"       12.31       12.37      0.5%\n            unit~1.0       15.41       15.49      0.5%\n                uni*        7.18        7.22      0.6%\n                un*d        7.97        8.04      0.9%\n               unit*       12.89       13.09      1.6%\n        +unit +state       28.16       28.64      1.7%\n    +nebraska +state       81.26       82.67      1.7%\nspanNear([unit, state], 10, true)       11.60       11.83      2.0%\n               state       40.50       41.47      2.4%\n  spanFirst(unit, 5)       47.65       48.84      2.5%\n          unit state       17.72       18.19      2.7%\n                 u*d        4.27        4.48      5.0%\n{code}\nthose are the results I have for now.... Fuzzy only expands to 50 terms so that might no be very meaningful. I re-added the TermCache for this patch though... \nWill attach more info tomorrow.",
            "date": "2010-12-16T15:57:52.995+0000",
            "id": 8
        },
        {
            "author": "Robert Muir",
            "body": "We shouldn't lose the clone() optimization in StandardPostingsReader... \nthe class is final so it should use 'copy' instead of calling super.clone()\nThis is important for -client.\n",
            "date": "2010-12-16T16:06:15.106+0000",
            "id": 9
        },
        {
            "author": "Simon Willnauer",
            "body": "FYI - there is a coding error in the latest patch that causes the TermState to be ignored - TermWeight uses the wrong reference to the PerReaderTermState. I will upload a new patch later this weekend\n\nsimon",
            "date": "2010-12-17T18:40:41.577+0000",
            "id": 10
        },
        {
            "author": "Simon Willnauer",
            "body": "here is a new patch. I removed the hacky TermWeight part to make only MTQ single pass for now. Other TermQueries will hit the TermCache for now.  No nocommit left. Currently there is some duplication / unncessary classes in the TermState hierarchy - that needs cleanup. \n\nBTW. I see some highlighter test failing - will look into this later...\nsimon",
            "date": "2010-12-17T19:24:41.811+0000",
            "id": 11
        },
        {
            "author": "Michael McCandless",
            "body": "If I force scoring BQ rewrite for wildcard & prefix queries (ie set that rewrite mode and then relax BQ max clause count) I see healthy speedups (~23-27%) for these queries!  Great :)\n\nWhile this doesn't happen w/ our default settings (ie these queries quickly cutover to constant filter rewrite), apps that change these defaults will see a gain, plus, the term cache (which today \"protects\" you) is terribly fragile since apps w/ many MTQ queries in flight can thrash that cache thus killing performance.  This patch prevents that entirely since MTQs do their own caching of the TermStates they need: awesome.",
            "date": "2010-12-18T09:35:21.364+0000",
            "id": 12
        },
        {
            "author": "Michael McCandless",
            "body": "I love seeing cacheCurrentTerm removed!!\n\nOK I think we are close!  A bunch of smallish things:\n\n  * I think we should remove TermsEnum.docFreq and .ord?  Ie replace\n    with .termState().docFreq() and .ord()?\n\n  * At first I was thinking we should merge up TermStateBase into\n    TermState but actually there are cases (eg PulsingCodec, which )\n    where you want the separation.\n\n  * Maybe rename TermStateBase -> PrefixCodedTermState?  Ie this is\n    really the TermState impl used by any codec using\n    PrefixCodedTerms?  EG the fact that it stores the filePointer into\n    a _X.tis file is particular to it...\n\n  * Maybe rename MockTermState -> BasicTermState?  At first I was\n    thinking the codec should return null if it cannot seek by\n    TermState... (I generally don't like mock returns that hide/lose\n    information...) but then it's convenient to always have something\n    to hold the docFreq for the term to avoid lots of special cased\n    code... so I think it's OK?\n\n  * We lost the \"clone using new\" in StandardTermState...\n\n  * Maybe revert changes to AppendingCodec?  (Ie let it pass its terms\n    dict cache size again)\n\n  * I wonder if we can somehow make PerReaderTermState use an array\n    (keyed by sub reader index) instead... seems like a new HashMap\n    per Term in an MTQ could be heavy.  It's tricky because we don't\n    store enough information (ie to quickly map parent reader + sub\n    reader -> sub index). But I don't think this should hold up\n    committing... since our defaults don't typically allow for *that*\n    many terms in-flight it should be fine...\n\n  * It's a little spooky the TermQuery.scorer calls .take()\n    (destructive), eg it means if you ask for scorer again on same\n    reader you get diff't behavior?  Can we make that a .get() instead\n    of .take()?  (This may also bite us if we use diff't threads to\n    score each segment, ie suddenly this .take() must be thread safe).\n    In fact, same deal w/ nulling out the TQ.perReaderTermState?\n\n  * The comment on top of TermStateByteStart looks wrong?\n\n  * Small whitespace issue -- missing space on \"if(\".  Also, our\n    generics are not supposed to have whitespace inside, eg we\n    shouldn't have the space in \"new DoubleBarrelLRUCache<FieldAndTerm, TermStateBase>(termsCacheSize);\"\n\n  * I think the TQ ctor that takes both docFreq and states can drop\n    the docFreq?  Ie it can ask the states for it?\n",
            "date": "2010-12-18T09:35:43.022+0000",
            "id": 13
        },
        {
            "author": "Uwe Schindler",
            "body": "I have also some things:\n- We currently don't support seeking a FilteredTermsEnum, this is disallowed by UnsupportedOperationException (we may change this, but its complicated, Robert and me are thinking about it, but for now its disallowed, as it would break the enum logic). So the TermState seek method in FilteredTermsEnum should also throw UOE:\n{code}\n/** This enum does not support seeking!\n * @throws UnsupportedOperationException\n */\n@Override\npublic SeekStatus seek(BytesRef term, boolean useCache) throws IOException {\n  throw new UnsupportedOperationException(getClass().getName()+\" does not support seeking\");\n}\n{code}\n- Additionally, can the next() implementation in FilteredTermsEnum use TermState? It does lots of seeking on the underlying (filtered) TermsEnum. This is the reason why sekking on the FilteredTermsEnum is not allowed. Filtering is done here on the accept() methods.\n- For what is setNextReader in TermCollector? I don't like that, but you seems to need it for the PerReaderTermState. The collector should really only work on the enum not on any reader. At least the\n\nThats what I have seen on first patch review, will now apply patch and look closer into it :-) But the first point is important, FilteredTermsEnum currently should not support seeking.",
            "date": "2010-12-18T10:34:57.354+0000",
            "id": 14
        },
        {
            "author": "Uwe Schindler",
            "body": "Here just the patch for a correct behaving FilteredTermsEnum (according to docs, that it does currently not support seeking). The assert is also not needed, as tenum is guranteed to be not null (its final and ctor already asserts this) :-)",
            "date": "2010-12-18T11:36:11.136+0000",
            "id": 15
        },
        {
            "author": "Simon Willnauer",
            "body": "{quote}\nI think we should remove TermsEnum.docFreq and .ord? Ie replace\nwith .termState().docFreq() and .ord()?\n{quote}\n\nI disagree on that - at least docFreq() is an essential part of the API and we should not force TermState creation just to get the df. Yet, TermState is an expert API you should not need to pull an expert API to get something essential like df.\nI would leave those as they are or only pull ord into TermState.\n\n{quote}\nMaybe rename TermStateBase -> PrefixCodedTermState? Ie this is\nreally the TermState impl used by any codec using\nPrefixCodedTerms? EG the fact that it stores the filePointer into\na _X.tis file is particular to it..\n{quote}\nYeah that sounds reasonable.\n\n{quote}\nMaybe rename MockTermState -> BasicTermState? At first I was\nthinking the codec should return null if it cannot seek by\nTermState... (I generally don't like mock returns that hide/lose\ninformation...) but then it's convenient to always have something\nto hold the docFreq for the term to avoid lots of special cased\ncode... so I think it's OK?\n{quote}\n\nI think we can get rid of it entirely. We can use TermStateBase for it and let PrefixCodedTermState just add the pointer though. That way we get rid of it nicely. I would like to keep that api as it is since it makes the usage easier especially in the rewrite methods..\n\nbq. We lost the \"clone using new\" in StandardTermState...\nI don't get that really - IMO this is quite minor but I will look into it again... \n\n{quote}\nMaybe revert changes to AppendingCodec? (Ie let it pass its terms\ndict cache size again)\n{quote}\n\nunintentional - will fix \n\n\n{quote}\n wonder if we can somehow make PerReaderTermState use an array\n(keyed by sub reader index) instead... seems like a new HashMap\nper Term in an MTQ could be heavy. It's tricky because we don't\nstore enough information (ie to quickly map parent reader + sub\nreader -> sub index). But I don't think this should hold up\ncommitting... since our defaults don't typically allow for that\nmany terms in-flight it should be fine...\n{quote}\n\nI actually had this in a very similar way. I used a custom linked list and relied on the fact that the incoming reader are applied in the same order and skipped until the next reader with that term appeared. I changed that back to Map impl to make it simpler since I didn't see speedups - well this was caused by a very nifty coding error :D \n\ni think I have that patch around somewhere is the history... lets see..\n\nbq. I think the TQ ctor that takes both docFreq and states can drop the docFreq? Ie it can ask the states for it?\n\nyeah sure - well the patch is my current state since I had to drop everything and leave on friday... I clean up an upload a new patch early this week\n\n@Uwe: I will incorporate your fix - thanks\n\n\n",
            "date": "2010-12-19T15:46:54.527+0000",
            "id": 16
        },
        {
            "author": "Robert Muir",
            "body": "bq. I would leave those as they are or only pull ord into TermState.\n\nI agree about docfreq, but ord should go. Ord should be in e.g. StandardTermState, but not in TermState nor TermsEnum.\n\nThis is an implementation detail for our current terms dictionary, and its silly how we just throw UOE for other codecs:\nIts codec-specific. Other terms implementations might have \"something like an ord\" but it definitely might not even be a long!\n\nWithin StandardCodec etc this creates no problem as it still has access to it. If we find ourselves wanting/needing to use ord\noutside of Standard we should ask ourselves why this is and instead fix the APIs to not depend on some codec-specific long value.",
            "date": "2010-12-19T16:57:22.643+0000",
            "id": 17
        },
        {
            "author": "Simon Willnauer",
            "body": "Here are some numbers for the latest patch with 10M wiki index (commitpoint: delmulti) and all MTQ rewriting to ScoreBoolean:\n\n{code}\n               Query    QPS base    QPS spec  Pct diff\n    +nebraska +state       42.96       42.17     -1.8%\n          unit state        3.63        3.61     -0.4%\n        \"unit state\"        1.72        1.71     -0.3%\n               state       10.55       10.54     -0.1%\nspanNear([unit, state], 10, true)        0.96        0.96      0.1%\n        +unit +state        4.03        4.04      0.2%\n  spanFirst(unit, 5)        4.83        4.86      0.7%\n          united~1.0        4.76        4.86      2.1%\n            unit~1.0        2.62        2.69      2.7%\n          united~2.0        0.82        0.84      2.8%\n            unit~2.0        0.34        0.37      8.2%\n                un*d        3.55        4.14     16.6%\n                uni*        0.52        0.61     18.1%\n                 u*d        0.47        0.57     19.9%\n               unit*        2.04        2.52     23.8%\n{code}",
            "date": "2010-12-19T18:38:56.922+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nI disagree on that - at least docFreq() is an essential part of the API and we should not force TermState creation just to get the df. Yet, TermState is an expert API you should not need to pull an expert API to get something essential like df.\nI would leave those as they are or only pull ord into TermState.\n{quote}\n\nOK I agree, let's leave at least dF directly in TermsEnum.\n\nCalling .termState presumably entails a clone right?  Ie the returned object is guaranteed private?  So that's a good reason not to require it...\n\n{quote}\nI actually had this in a very similar way. I used a custom linked list and relied on the fact that the incoming reader are applied in the same order and skipped until the next reader with that term appeared. I changed that back to Map impl to make it simpler since I didn't see speedups - well this was caused by a very nifty coding error \n{quote}\n\nLet's just stick w/ map for now I think?  Progress not perfection!",
            "date": "2010-12-19T22:19:41.078+0000",
            "id": 19
        },
        {
            "author": "Simon Willnauer",
            "body": "here is a new patch with a slightly different implementation of PerReaderTermState. I build a view from the subreader used to build the MTQ which is shared across all PerReaderTermState instance for the query. The PrTS then uses only the ordinal from the ReaderView to reference a TermState which prevents us from creating Map instances for each term. In turn this also made it possible to fall back to re-seeking the TermDict if the reader is not in the view. \n\nI fixed all other issues and all tests including the highlighter pass now.\n\n",
            "date": "2010-12-20T15:25:59.208+0000",
            "id": 20
        },
        {
            "author": "Simon Willnauer",
            "body": "mike - do you mind if I take this?\n\nsimon",
            "date": "2010-12-20T18:46:03.471+0000",
            "id": 21
        },
        {
            "author": "Michael McCandless",
            "body": "bq. mike - do you mind if I take this?\n\nOf course not!  Please take it :)",
            "date": "2010-12-21T11:43:23.291+0000",
            "id": 22
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks awesome!\n\nReally, ord() support is a function of the terms dict impl, not the\ncodec (well, indirectly codec has ord() support if its terms dict impl\ndoes).  PrefixCodedTermsDict, in turn, supports ord() only if its\nterms index does.\n\nCan we move TermStateBase (now under codecs.standard) up into codecs\nand rename it to PrefixCodedTermState?  Ie, it's awkward that\nPrefixCodedTermsReader (a terms dict impl shared across many codecs)\nis reaching into standard codec to get its TermState impl.  Then, the\nprivate static class in StandardPostingsReader can be renamed to\nStandardTermState?\n\nI like this new ReaderView!  I think it can be more generally useful\noutside of PerReaderTermState, eg Filter/Collector could receive this\nso that they can map sub reader to context in parent.  But let's leave\nthat for another day.\n\nStill some small whitespace issues, eg if(\n",
            "date": "2010-12-21T11:44:04.323+0000",
            "id": 23
        },
        {
            "author": "Michael McCandless",
            "body": "OK I tested perf on 10 M wiki index, multi-segment no deletes.  For the test I [unnaturally] forced Prefix & Wildcard queries to always use scoring BQ rewrite (and upped the BQ max clause count way high) to force testing of TermState.\n\n||Query||QPS mmap||QPS mmap||Pct diff||||\n|\"unit state\"~3|5.29|4.96|{color:red}-6.3%{color}|\n|unit state|11.70|11.21|{color:red}-4.2%{color}|\n|\"unit state\"|7.80|7.71|{color:red}-1.2%{color}|\n|spanNear([unit, state], 10, true)|4.58|4.53|{color:red}-1.1%{color}|\n|state|29.42|29.39|{color:red}-0.1%{color}|\n|unit~2.0|9.90|9.91|{color:green}0.2%{color}|\n|doctimesecnum:[10000 TO 60000]|9.52|9.55|{color:green}0.3%{color}|\n|+unit +state|11.04|11.09|{color:green}0.4%{color}|\n|unit~1.0|10.11|10.19|{color:green}0.7%{color}|\n|united~2.0|3.34|3.36|{color:green}0.8%{color}|\n|spanFirst(unit, 5)|16.71|16.93|{color:green}1.3%{color}|\n|+nebraska +state|195.03|198.25|{color:green}1.7%{color}|\n|united~1.0|15.78|16.11|{color:green}2.1%{color}|\n|un*d|12.59|29.45|{color:green}133.9%{color}|\n|unit*|6.87|16.54|{color:green}140.7%{color}|\n|u*d|2.39|6.66|{color:green}178.2%{color}|\n|uni*|1.82|5.29|{color:green}190.6%{color}|\n\nAwesome speedups!",
            "date": "2010-12-21T11:46:43.650+0000",
            "id": 24
        },
        {
            "author": "Simon Willnauer",
            "body": "{quote}\nCan we move TermStateBase (now under codecs.standard) up into codecs\nand rename it to PrefixCodedTermState? Ie, it's awkward that\nPrefixCodedTermsReader (a terms dict impl shared across many codecs)\nis reaching into standard codec to get its TermState impl. Then, the\nprivate static class in StandardPostingsReader can be renamed to\nStandardTermState?\n{quote}\ndone - that makes sense \n\n\nbq. Still some small whitespace issues, eg if(\ndone\n\nI think we are close \n",
            "date": "2010-12-21T15:33:13.460+0000",
            "id": 25
        },
        {
            "author": "Michael McCandless",
            "body": "I think instead of ReaderView we could change Weight.scorer API so that instead of receiving IndexReader reader, it receives a struct that has parent reader, sub reader, ord of that sub?\n\nIt's easy to be back compat because we could just forward to prior scorer method with only the sub?",
            "date": "2010-12-21T21:25:31.009+0000",
            "id": 26
        },
        {
            "author": "Simon Willnauer",
            "body": "{quote}\nI think instead of ReaderView we could change Weight.scorer API so that instead of receiving IndexReader reader, it receives a struct that has parent reader, sub reader, ord of that sub?\nIt's easy to be back compat because we could just forward to prior scorer method with only the sub?\n{quote}\nMike I am not sure if that helps us here. If you use this method you can not disambiguate between the set of readers that where used to create the PerReaderTermState and the once that have a certain ord assigned to it. Disambiguation would be more difficult if we do that. IMO sharing a ReaderView seems to be the best solution so far. I don't think we should bind it to an IR directly since users can easily build a ReaderView from a Composite Reader. Yet, for searching it would be nice to have a ReaderView on Seacher / IndexSearcher which can be triggered upon weight creation.\nThat way we can also disambiguate between PerReaderTermState given to the TermQuery ctor when we create the weight so that if the view doesn' t match we either create a new PerReaderTermState or just don't use it for this weight.\n\nI thought about TermsEnum#ord() again. I don' t think we should really add it back though. Its really an implementation detail and folks that wanna use it should be aware of that and cast correctly. On the other hand I don't like to have the seek(ord) in TermsEnum either if we remove #ord(). I think we should remove it from the interface entirely though.\n\nsimon",
            "date": "2010-12-22T09:28:34.298+0000",
            "id": 27
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. I think instead of ReaderView we could change Weight.scorer API so that instead of receiving IndexReader reader, it receives a struct that has parent reader, sub reader, ord of that sub?\n\nso I changed the Weight#scorer API to use a class called ScoreContext that holds the parent reader, the current sub and the subs ord. That change is absolutely massive! I don't upload that change since I think if we do that we need to do it in a different issue anyway. I ran into a couple of problems:\n\n* if we pass in such a context we also need to change the explain interface since its calling Weight#scorer here and there\n* Once we pass in the Context stuff like QueryWrapperFilter doesn't work anymore since it doesn't know which ord the incoming reader has. So Filters would need a context too. I don't like that!\n* Stuff like scoreDocsInOrder are hard to put into such a context since almost all scorers internally are called with scoreDocsInOrder=true with a contant. meaning that nobody really respects the incoming value for subscorers though. but if i just forward the context the member needs to be set to true or the context needs to be cloned for subs - see BooleanQuery for instance.\n\n* such a context would somehow enforce that MTQ are only executed against the Reader they where rewritten against. Which is how it should be IMO but we are also depending on that everybody who uses a MTQ knows exactly how the query was rewritten which is kind of not obvious. I think we need a better way to enforce stuff like that.\n\nafter all I think this must be done in a different issue though. This issue was meant to make MTQ single pass so lets do that first.... progress over perfection ey mike :). \nNonetheless, it seems like that we need to rethink the Weight API entirely I also don't like that Weight operates on Searcher instead of IndexSearcher though.\n",
            "date": "2010-12-22T15:53:55.240+0000",
            "id": 28
        },
        {
            "author": "Michael McCandless",
            "body": "bq. after all I think this must be done in a different issue though\n\n+1\n\nIf, when we now pass a naked IndexReader (eg to Weight.scorer, Weight.explain, Filter.getDocIdSet) we replace that with a ReaderContext which has reader, its parent, and its ord, then this precursor makes both TermState (this issue) and the awesome PK speedup (LUCENE-2829) much simpler.  And I agree we should break it out as its own issue.  It's good to do that as its own issue since that's a rote API cutover -- we are passing a struct instead of a naked reader, but otherwise no change.\n\nThis also lets us solve cases where the Filter needs the full context, eg LUCENE-2348.\n\nAlso, with this I think we should sharpen in the jdocs that when you call Query.rewrite the returned query must be searched only against he same reader you rewrote against.  Similarly when you create a Weight, it should only be used against the same Searcher used to create it from a Query.",
            "date": "2010-12-22T16:32:48.167+0000",
            "id": 29
        },
        {
            "author": "Simon Willnauer",
            "body": "Another iteration on this after LUCENE-2831 was committed last week. \n\n - updated to trunk & all test pass\n- re-added all ord() related stuff back to TermsEnum since I think we should decouple this and solve it in a different issue. There is already enough changes in here and discussions should be focused on making MTQ single pass.\n- Changed IndexSearcher to run concurrent searches on a \"leaf slice\" rather than on a leaf converted to a Top-Level Context. That made the callables a bit simpler and is more consistent since the hierarchy is preserved.\n- TermState is now referenced by leaf ordinal and asserted using the leaf's top-level ctx.\n- TermQuery is not single pass for all queries while state is only hold in Weight unless PerReaderTermState as not set. But even then the top-level ctx must be identical to the given IS's top-level ctx otherwise the give PerReaderTermState is not used.\n\nthis one seems pretty close ",
            "date": "2011-01-10T11:27:15.284+0000",
            "id": 30
        },
        {
            "author": "Robert Muir",
            "body": "One question, I'm look at the definition of TermState:\n{noformat}\nHolds all state required for {@link TermsEnum} to produce a {@link DocsEnum} without re-seeking the terms dict.\n{noformat}\n\nSo why do we have seek(BytesRef, TermState)\nshouldnt it just be seek(Termstate) ?\nI think its confusing it takes an unnecessary bytes parameter.",
            "date": "2011-01-10T12:21:58.141+0000",
            "id": 31
        },
        {
            "author": "Robert Muir",
            "body": "here's a hack patch (dont think it actually works) just showing what i mean.\n\nI think termsenum should only have seek(TermState).\nin the hack-patch, i made the termState() and seekTermState() non-abstract:\nthe default impl returns a 'SimpleTermState' containing the term bytes and saved docFreq and implements seek(TermState) with those bytes.\n\nThis is basically what the patch had everywhere anyway as an implementation (for many of these, we should use more efficient impls, i fixed this for MemoryIndex as an example, but MultiTermsEnum comes to mind).\n\nAlso, i don't understand what was going on with setting bytes on the DeltaBytesReader with your seek(BytesRef, TermState) before.\n\nIf StandardCodec needs to know the shared byte[] prefix or something like that to reposition the enum, then it\nshould put this in its termstate.\n\n\n",
            "date": "2011-01-10T13:35:07.540+0000",
            "id": 32
        },
        {
            "author": "Simon Willnauer",
            "body": "Next iteration.  I took roberts patch and cleaned up a few things and added a new OrdTermState that can be used for instanceof testing and thoughout all TermsEnum that use ord primarily. I also removed the docFreq() getter from TermState since its really an impl. detail. The downside of this patch is that PrefixCodedTermState is kind of heavyweight now since it carries the BytesRef to re-init the DeltaBytesReader but I didn't see another way to fix this right now.\n\n",
            "date": "2011-01-11T11:44:41.943+0000",
            "id": 33
        },
        {
            "author": "Michael McCandless",
            "body": "The failure in TestFSTs is because PrefixCodedTermsReader is somehow returning an OrdTermState when its terms index (var gap) does not support ord.\n\nThe ord member of PrefixCodedTermState is undefined when the terms dict doesn't support ord (ie when ord() throws UOE).\n\nSo to fix this we should fix TestFSTs to go back to calling .ord() and catching the UOE, maybe?  Separately, make sure you don't overwrite storeOrds in that test.  Ie the test randomly sets it to true or false (so that we test both cases); only if the terms index cannot suppord ord should we wire it to false.  If it can support ord then we should leave it as the random value...",
            "date": "2011-01-11T12:18:39.309+0000",
            "id": 34
        },
        {
            "author": "Simon Willnauer",
            "body": "fixed the TestFST - thanks mike for looking into that and updated to trunk",
            "date": "2011-01-11T15:26:20.491+0000",
            "id": 35
        },
        {
            "author": "Simon Willnauer",
            "body": "This patch changes TermsEnum#seek(TermState) back to TermsEnum#seek(BytesRef, TermState). Yet, TermState is opaque now and TermsEnum has a default impl for TermsEnum#seek(BytesRef, TermState). Holding the BytesRef in TermState for our PrefixCoded* based codecs seems way too costly though. seems like this time perf rules out purity in the interface.",
            "date": "2011-01-12T14:07:38.656+0000",
            "id": 36
        },
        {
            "author": "Robert Muir",
            "body": "bq. seems like this time perf rules out purity in the interface.\n\nI know i didn't like this aspect of the patch, but I am ok with it for now as long as we keep things experimental and try to keep an eye on improving the 'purity' of TermsEnum a bit.\nwe are making a lot of progress on the terms handling with flexible indexing and i could easily see more interesting implementations being available other than just PrefixCoded...\nIn some ideal world I guess i'd prefer if TermsEnum was an attributesource with seek() and next(), FilteredTermsEnum was like tokenFilter, and TermState was just captureState/restoreState...\nbut I agree we should just lean towards whatever works for now.\n\ndefinitely like it better now that things such as docFreq() are pulled out of termstate and its completely opaque, i think this is the right way to go.",
            "date": "2011-01-12T15:22:14.864+0000",
            "id": 37
        },
        {
            "author": "Simon Willnauer",
            "body": "Added Changes.txt entry and fixed the remaining JavaDoc on TermState. \n\nMy latest benchmark results with that patch are here:\n{code}\n\n          unit state        3.81        3.70     -2.9%\n    +nebraska +state       41.26       40.61     -1.6%\n        +unit +state        3.95        3.90     -1.1%\n  spanFirst(unit, 5)        4.55        4.51     -0.9%\n               state       10.11       10.07     -0.3%\n      \"unit state\"~3        0.98        0.98     -0.2%\n        \"unit state\"        1.49        1.49     -0.0%\n          united~1.0        3.66        3.72      1.5%\n            unit~1.0        2.33        2.37      1.6%\n          united~2.0        0.81        0.83      2.7%\n            unit~2.0        0.35        0.38     10.1%\n                 u*d        0.52        0.67     29.5%\ndoctitle:.*[Uu]nited.*        0.19        0.25     31.6%\n                un*d        3.59        4.77     33.0%\n                uni*        0.56        0.75     34.9%\n               unit*        2.20        3.15     43.3%\n{code}\n\nI think we are ready to go - I will commit later today if nobody objects",
            "date": "2011-01-12T16:23:35.119+0000",
            "id": 38
        },
        {
            "author": "Simon Willnauer",
            "body": "I just figured that PKLookups are actually slower with this patch 164 msec for 1000 lookups (164 us per lookup) vs 144 msec for 1000 lookups (144 us per lookup) on trunk. I will dig!",
            "date": "2011-01-12T16:55:45.293+0000",
            "id": 39
        },
        {
            "author": "Michael McCandless",
            "body": "Actually I see PK lookups faster -- 23 usec w/ patch vs 33 usec w/ trunk (per lookup) for 20K lookups.\n\nAnd good speedups on many-term MTQs when I force BQ rewrite:\n\n\n||Query||QPS base||QPS termstate||Pct diff||||\n|+nebraska +state|169.75|154.64|{color:red}-8.9%{color}|\n|doctitle:.*[Uu]nited.*|4.26|4.11|{color:red}-3.5%{color}|\n|+unit +state|11.40|11.09|{color:red}-2.7%{color}|\n|spanFirst(unit, 5)|17.38|16.93|{color:red}-2.6%{color}|\n|spanNear([unit, state], 10, true)|4.37|4.32|{color:red}-1.2%{color}|\n|\"unit state\"~3|4.94|4.89|{color:red}-1.0%{color}|\n|\"unit state\"|8.05|8.03|{color:red}-0.2%{color}|\n|state|26.58|26.76|{color:green}0.7%{color}|\n|unit state|11.24|11.46|{color:green}1.9%{color}|\n|united~2.0|3.87|3.98|{color:green}2.8%{color}|\n|doctimesecnum:[10000 TO 60000]|8.26|8.70|{color:green}5.3%{color}|\n|unit~2.0|10.04|10.59|{color:green}5.4%{color}|\n|united~1.0|16.84|18.13|{color:green}7.7%{color}|\n|unit~1.0|10.09|10.99|{color:green}8.9%{color}|\n|un*d|11.96|21.63|{color:green}80.8%{color}|\n|unit*|7.60|14.23|{color:green}87.3%{color}|\n|u*d|2.22|4.17|{color:green}87.8%{color}|\n|uni*|1.83|3.53|{color:green}93.7%{color}|\n\n+1 to commit!",
            "date": "2011-01-12T20:53:39.604+0000",
            "id": 40
        },
        {
            "author": "Simon Willnauer",
            "body": "Here is a final patch, I opened up Terms#getThreadTermsEnum() to reuse TermsEnum in PRTE#build().\nPRTE#build() now also accepts a boolean if the termlookup should be cached or not which makes sense for common TermQuery.\n\nI will commit that shortly - yay!",
            "date": "2011-01-12T21:32:31.418+0000",
            "id": 41
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Actually I see PK lookups faster - 23 usec w/ patch vs 33 usec w/ trunk (per lookup) for 20K lookups.\nso I run that on a 32bit machine which is quite slow in general though. I will further investigate that on 32bit platform vs. 64 bit. Yet, I only used 1k lookups though.",
            "date": "2011-01-12T21:34:29.669+0000",
            "id": 42
        },
        {
            "author": "Simon Willnauer",
            "body": "Committed revision 1058328.\n",
            "date": "2011-01-12T21:40:50.745+0000",
            "id": 43
        }
    ],
    "component": "core/search",
    "description": "Spinoff of LUCENE-2690 (see the hacked patch on that issue)...\n\nOnce we fix MTQ rewrite to be per-segment, we should take it further and make weight/scorer init also run in the same single pass as rewrite.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2694",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "MTQ rewrite + weight/scorer init should be single pass",
    "systemSpecification": true,
    "version": ""
}