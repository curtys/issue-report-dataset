{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "I created a new merge policy, to take advantage of non-contiguous merging (LUCENE-1076) and fix certain limitations of LogMergePolicy.\n\nThe new policy does not support contiguous merging, and always merges according to byte size, always pro rated by pct deletes.\n\nThe policy's core logic is similar to LogMP, in that it tries to merge roughly equal sized segments at once, maxMergeAtOnce (renamed from mergeFactor) at a time, resulting in the usual exponential staircase pattern when you feed it roughly equal sized segments.\n\nYou configure the approx max merged segment size (unlike LogMP where you configure the max to-be-merged size, which was always a source of confusion!).  Unlike LogMP, when segments are getting close to being too large, the new policy will merge fewer segs, eg down to merging pairwise, to reach approx the max allowed size.  This is important since it makes that setting more \"accurate\"; I now default it to 5 GB (vs LogMP's 2 GB).\n\nThere is a separate maxMergeAtOnceExplicit that controls \"explicit\" merging (ie, app calls optimize or expungeDeletes, and maybe in the future also addIndexes); I defaulted it to 30.  There is no max segment size for optimize.\n\nThe big difference vs LogMP is that the new policy does not \"over-merge\", meaning it does not \"pay it forward\"/forcefully cascade the way LogMP does today.  This fixes the \"inadvertent optimize\" that LogMP does.\n\nFor any given sized index, the new policy computes a budget of how many segments that index is allowed to have (ie, it enumerates the steps in the stair case, based on mergeAtOnce, [floored] min segment size, and total bytes in the index); then, if the index is over-budget it picks the least-cost merge.  This results in a smoother progression over time of number of segments.\n\nThere is a new configuration, segmentsPerTier, that lets you control how many segments per level you can \"tolerate\".  This is a nice knob to turn to tradeoff merge cost vs search cost.  It defaults to 10, which means it matches the staircase pattern that LogMP produces, but you can now separately control the \"width\" of the stairs in the staircase, from how many segments are merged at once for non-explicit merges.\n\nIt has useCompoundFile and noCFSRatio just like LogMP.\n\nIt has a new setting \"expungeDeletesPctAllowed\", default 10%, which allows expungeDeletes to skip merging a segment if it has < 10% deletions.\n\nI think we should keep LogMergePolicy available for apps that want contiguous merging, merge by doc count, to not pro-rate by deletions, or to enforce a max segment size during optimize.  But, with this, I'd remove the non-contiguous support for LogMergePolicy that was added under LUCENE-1076, and make this new MP the default one.\n",
            "date": "2011-02-11T15:35:41.255+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "I put up a blog post showing a movie of how TieredMP differs from LogByteSizeMP: http://chbits.blogspot.com/2011/02/visualizing-lucenes-segment-merges.html",
            "date": "2011-02-13T14:38:27.498+0000",
            "id": 1
        },
        {
            "author": "Uwe Schindler",
            "body": "Nice videos, have already seen them on twitter yesterday *g*",
            "date": "2011-02-13T15:59:06.783+0000",
            "id": 2
        },
        {
            "author": "Robert Muir",
            "body": "Bulk closing for 3.2",
            "date": "2011-06-03T16:37:20.323+0000",
            "id": 3
        }
    ],
    "component": "core/index",
    "description": "The current merge policy, at every maxBufferedDocs *\npower-of-mergeFactor docs added, will do a fully cascaded merge, which\nis the same as an optimize.\n\nI think this is not good because at that \"optimization poin\", the\nparticular addDocument call is [surprisingly] very expensive.  While,\namortized over all addDocument calls, the cost is low, the cost is\npaid \"up front\" and in a very \"bunched up\" manner.\n\nI think of this as \"pay it forward\": you are paying the full cost of\nan optimize right now on the expectation / hope that you will be\nadding a great many more docs.  But, if you don't add that many more\ndocs, then, the amortized cost for your index is in fact far higher\nthan it should have been.  Better to \"pay as you go\" instead.\n\nSo we could make a small change to the policy by only merging the\nfirst mergeFactor segments once we hit 2X the merge factor.  With\nmergeFactor=10, when we have created the 20th level 0 (just flushed)\nsegment, we merge the first 10 into a level 1 segment.  Then on\ncreating another 10 level 0 segments, we merge the second set of 10\nlevel 0 segments into a level 1 segment, etc.\n\nWith this new merge policy, an index that's a bit bigger than a\ncurrent \"optimization point\" would then have a lower amortized cost\nper document.  Plus the merge cost is less \"bunched up\" and less \"pay\nit forward\": instead you pay for what you are actually using.\n\nWe can start by creating this merge policy (probably, combined with\nwith the \"by size not by doc count\" segment level computation from\nLUCENE-845) and then later decide whether we should make it the\ndefault merge policy.\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-854",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Create merge policy that doesn't periodically inadvertently optimize",
    "systemSpecification": true,
    "version": "2.2"
}