{
    "comments": [
        {
            "author": "Michael Busch",
            "body": "The patch file for this improvement (based on Lucene Rev. 419199)",
            "date": "2006-07-17T21:51:04.000+0000",
            "id": 0
        },
        {
            "author": "Yonik Seeley",
            "body": "Thanks Michael, very impressive results!\nIt might take a little while to review the patch, but the goals and general approach certainly seem correct.\n\nWhat is the impact (if any) for non-compressed fields?  ",
            "date": "2006-07-18T02:51:09.000+0000",
            "id": 1
        },
        {
            "author": "Michael Busch",
            "body": "Yonik,\n\nin the original version the FieldsReader maps the boolean values \"compressed\", \"tokenize\", \"binary\", \"storeOffsetWithTermVector\", \"storePositionWithTermVector\", and \"storeTermVector\" to the Parameters Field.Index, Field.Store, and Field.TermVector. For writing, the FieldsWriter again maps those Parameters to the boolean values. My patched version avoids these mappings, thus we save some if-statements even while merging non-compressed fields. However, the overall merge performance does not benefit significantly in the non-compressed case.\n\nThat should be the only impact for non-compressed fields. \n\nMichael",
            "date": "2006-07-18T18:59:23.000+0000",
            "id": 2
        },
        {
            "author": "Otis Gospodnetic",
            "body": "This looks fine to me, patch applied after a bit of persuading, and unit tests all pass.  I'll commit this in a bit.\nOne question, why \"...ForMerge\" names?  Doesn't this patch really address only compressed fields?  Wouldn't it make sense to name things (classes, fields, vars) to indicate that?  Something like \"...DontTouchMeImAlreadyCompressed\".  Just kidding, but you get the idea.\n",
            "date": "2006-08-13T06:03:24.000+0000",
            "id": 3
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Committed. Muchos gracias!",
            "date": "2006-08-13T06:10:39.000+0000",
            "id": 4
        }
    ],
    "component": "core/index",
    "description": "Hello everyone,\n\ncurrently the merging of stored, compressed fields is not optimal for the following reason: every time a stored, compressed field is being merged, the FieldsReader uncompresses the data, hence the FieldsWriter has to compress it again when it writes the merged fields data (.fdt) file. The uncompress/compress step is unneccessary and slows down the merge performance significantly.\n\nThis patch improves the merge performance by avoiding the uncompress/compress step. In the following I give an overview of the changes I made:\n   * Added a new FieldSelectorResult constant named \"LOAD_FOR_MERGE\" to org.apache.lucene.document.FieldSelectorResult\n   * SegmentMerger now uses an FieldSelector to get stored fields from the FieldsReader. This FieldSelector's accept() method returns the FieldSelectorResult \"LOAD_FOR_MERGE\" for every field.\n   * Added a new inner class to FieldsReader named \"FieldForMerge\", which extends  org.apache.lucene.document.AbstractField. This class holds the field properties and its data. If a field has the FieldSelectorResult \"LOAD_FOR_MERGE\", then the FieldsReader creates an instance of \"FieldForMerge\" and does not uncompress the field's data.\n   * FieldsWriter checks if the field it is about to write is an instanceof FieldsReader.FieldForMerge. If true, then it does not compress the field data.\n\n\nTo test the performance I index about 350,000 text files and store the raw text in a stored, compressed field in the lucene index. I use a merge factor of 10. The final index has a size of 366MB. After building the index, I optimize it to measure the pure merge performance.\n\nHere are the performance results:\n\nold version:\n   * Time for Indexing:  36.7 minutes\n   * Time for Optimizing: 4.6 minutes\n\npatched version:\n   * Time for Indexing:  20.8 minutes\n   * Time for Optimizing: 0.5 minutes\n\nThe results show that the index build time improved by about 43%, and the optimizing step is more than 8x faster. \n\nA diff of the final indexes (old and patched version) shows, that they are identical. Furthermore, all junit testcases succeeded with the patched version. \n\nRegards,\n  Michael Busch",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-629",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Performance improvement for merging stored, compressed fields",
    "systemSpecification": true,
    "version": ""
}