{
    "comments": [
        {
            "author": "Aaron McCurry",
            "body": ":)  I will try to get my patch ready this weekend.  Otherwise it will be first of the week.",
            "date": "2010-01-15T22:58:30.231+0000",
            "id": 0
        },
        {
            "author": "Aaron McCurry",
            "body": "This is a lucene 3.0 paging collector.  This should allow for paging through any amount of results without exhausting the jvm's memory.\n\nLet me know if you have any questions or would like me to make any mods.\n\nhttp://www.nearinfinity.com/blogs/aaron_mccurry/making_lucene_hit_results_pagi.html",
            "date": "2010-01-19T01:47:09.506+0000",
            "id": 1
        },
        {
            "author": "Adam Heinz",
            "body": "Awesome, thanks!  I'll schedule some time in the coming week to patch our dev installation and sic some QA guys on it.",
            "date": "2010-01-19T14:29:52.709+0000",
            "id": 2
        },
        {
            "author": "Aaron McCurry",
            "body": "Not sure if anyone has looked at this yet, but I just fixed a minor issue with the IterablePaging.java class.  If you did not specify a gather amount, it wouldn't gather any hits.",
            "date": "2010-02-04T01:00:08.392+0000",
            "id": 3
        },
        {
            "author": "jmwap",
            "body": "Kudos Aaron, this is cool for what I need. \n\nI just integrated in my project, upgraded to 3.0 just to get this in. But I am having an issue in my first test:\n\njava.lang.ArrayIndexOutOfBoundsException: 1\n\tat org.apache.lucene.util.PriorityQueue.initialize(PriorityQueue.java:96)\n\tat org.apache.lucene.search.HitQueue.<init>(HitQueue.java:67)\n\tat org.apache.lucene.search.PagingCollector.<init>(PagingCollector.java:43)\n\tat org.apache.lucene.search.PagingCollector.<init>(PagingCollector.java:39)\n\tat org.apache.lucene.search.IterablePaging$PagingIterator.search(IterablePaging.java:158)\n\tat org.apache.lucene.search.IterablePaging$PagingIterator.<init>(IterablePaging.java:151)\n\tat org.apache.lucene.search.IterablePaging.iterator(IterablePaging.java:140)\n\tat ...CombinedLuceneDBStep.proceed(CombinedLuceneDBStep.java:71)\n\nI use it like this:\n            MultiSearcher ms = new MultiSearcher(indexes);\n            TotalHitsRef totalHitsRef = new TotalHitsRef();\n            ProgressRef progressRef = new ProgressRef();\n            IterablePaging paging = new IterablePaging(ms, lucquery, NB_LUCENE_HITS_PER_BATCH);\n\nI have no clue where the issue lies, I am using MultiSearcher , and norms are disabled. Or maybe I screwed up something while upgrading to 3.0... I got the files as of feb 11th.",
            "date": "2010-02-12T15:27:22.977+0000",
            "id": 4
        },
        {
            "author": "jmwap",
            "body": "disregard my previous comment... There was some refactoring in my codebase to get this in and NB_LUCENE_HITS_PER_BATCH was uninitialized...so far it is working sweetly, I will report when I finish my tests.\n\nthanks",
            "date": "2010-02-12T15:59:23.163+0000",
            "id": 5
        },
        {
            "author": "Grant Ingersoll",
            "body": "I think in order to properly implement this, topDocs() needs to be non-final, otherwise there is some oddities in initing a PQ with more results than are available once paging.  Updated patch shortly.",
            "date": "2010-03-23T18:38:35.619+0000",
            "id": 6
        },
        {
            "author": "Shai Erera",
            "body": "I've reviewed PagingCollector.java and the first thing I have to say about it is that I really like it ! :) Saves lots of unnecessary heapify code, if the application can allow itself to store the lowest last SD.\n\nI have few comments/questions.\n\nI don't understand what getLastScoreDoc is for? Is it just a utility method? Is it something the app can compute by itself? Anyway, it lacks javadocs, so perhaps if they existed I wouldn't need to ask ;).\n\nIn collect(), there's the following code:\n{code}\n\t\t} else if (score == previousPassLowest.score && doc <= previousPassLowest.doc) {\n\t\t\t// if the scores are the same and the doc is less than or equal to\n\t\t\t// the\n\t\t\t// previous pass lowest hit doc then skip because this collector\n\t\t\t// favors\n\t\t\t// lower number documents.\n\t\t\treturn;\n{code}\n\nI think there's a typo in the comment \"favors lower number documents\" .. while it seems to prefer higher doc IDs? The way I understand it, irregardless of whether docs are collected in/out of order, HitQueue ensures that when scores are equals, the lowest IDs are favored. Thus the first round always keeps the lowest IDs among the docs whose scores match. The next round will favor the docs whose IDs come next, and so forth ... am I right? (just clarifying my understanding).\nIf that's the case, I think it'll be good if it's spelled out in the comment, and also mention that it means that document has already been returned previously (like it's documented in the previous 'if').\n\nThe last 'else' really looks like TSDC's out-of-order version, which makes me think whether PagingCollector can be viewed as a filter on top of TSDC (and possibly even TopFieldCollector)? So if a hit should be collected, it just calls super.collect? I realize though that a Collector is a hotspot and we want to minimize 'if' let alone method call statements as much as possible. But it just feels so strong that it should be a filter ... :). And you wouldn't need to specifically handle in/out orderness ... and w/ the right design, it can also wrap a TFC or any other TDC implementation ...\n\nBTW, I've noticed that you don't track maxScore - is it assumed that the application stores it from the first round? If so I'd document it, because the application needs to know it should use TSDC the first round, and PagingCollector the second round.\n\nAlso, PagingCollector offers a ctor which does not force the application to pass in a ScoreDoc. See my comment from above - it might be misleading, because if you use this collector right from the very first search, you lose the maxScore tracking. I also don't see why it should be allowed - if a dummy previousPassLowest ScoreDoc is used, collect() does a lot of unnecessary 'if's. I think this collector should be used only from the second round, and a single ctor which forces a ScoreDoc to be passed would make more sense. If the application wishes to shoot itself in the leg (performance-wise), it can pass a dummy SD itself.",
            "date": "2010-03-23T20:33:52.946+0000",
            "id": 7
        },
        {
            "author": "Grant Ingersoll",
            "body": "Here's an update of Aaron's work with the following changes:\n\n1. Added real unit tests\n2. Made topDocs() non final in order to override in PagingCollector to handle the case where the some edge cases with larger PQ size than total hits.  Overrode the other topDocs(...) methods to throw UnsupportedOperation as they aren't needed for a Paging Collector\n3. Pass in num already seen so that PQ operations can be calculated correctly.  Not sure if we really need, but otherwise it puts the burden on the user to make sure the PQ is sized properly, I think, which may not be such a bad burden\n4. Renamed IterablePaging to be PagingIterable.  Not a huge fan of that name either, but couldn't think of anything better\n5. Collapsed the if/else clauses in the collect method into a single if clause.\n\nLeft to do:\n1. benchmark.  Is it really better?\n2. Not entirely certain on the PagingIterable API stuff yet.  Looks useful.\n3. Should we have an InOrder Collector as well?  Seems like we might be able to save a few operations per doc.",
            "date": "2010-03-23T20:36:41.052+0000",
            "id": 8
        },
        {
            "author": "Grant Ingersoll",
            "body": "bq. BTW, I've noticed that you don't track maxScore\n\nGood point.  I think we probably should track it, so that the PagingColl could be used right from the get go.\n\nWe might also consider deprecating the topDocs() methods that take in parameters and think about how the paging collector might be integrated at a lower level in the other collectors, such that one doesn't even have to think about calling a diff. collector.",
            "date": "2010-03-23T20:46:22.814+0000",
            "id": 9
        },
        {
            "author": "Shai Erera",
            "body": "I must admit I don't like throwing UOE. I imagine the naive user calling one of these and hit w/ UOE out of nowhere really :). Perhaps it's a sign PagingCollector should not be a sub-class of TopDocsCollector? It does not benefit from it in any way because it overrides all the main methods, impls them or throws UOE for those it doesn't like. So perhaps it should just be a TopScorePagingCollector which copies some of the functionality of TSDC, but is not a TDC itself. It will have a topDocs() method, and only it (b/c I agree the rest don't make any sense).\n\nNotice the different name I propose - to make it clear it's a collector that can be used for paging through a scored list of results.\n\nI BTW liked that the if/else clauses were separated, b/c you could include meaningful documentation for each. Right now those are just very long lines.\n\nAbout in-order, I think the only thing you will save is the last 'else'. Read my comment above about wrapping TSDC ... not sure about it, but it will make it more elegant.\n\nI'll review the rest of the patch. Didn't yet understand what's PagingIterable for ...",
            "date": "2010-03-23T20:55:43.646+0000",
            "id": 10
        },
        {
            "author": "Grant Ingersoll",
            "body": "{quote}\nI must admit I don't like throwing UOE. I imagine the naive user calling one of these and hit w/ UOE out of nowhere really . Perhaps it's a sign PagingCollector should not be a sub-class of TopDocsCollector? It does not benefit from it in any way because it overrides all the main methods, impls them or throws UOE for those it doesn't like. So perhaps it should just be a TopScorePagingCollector which copies some of the functionality of TSDC, but is not a TDC itself. It will have a topDocs() method, and only it (b/c I agree the rest don't make any sense).\n{quote}\n\nI agree, not a huge fan of it either, but it is bad form to call it when using this collector and I'd rather people learn that up front.  Like I said in the last comment, I think we'd be better off trying to integrate this in to a lower level and not even having a \"special\" collector.  If we just added a create option that took in the necessary info, then we could just mod the existing collectors, possibly.  Then those two topDocs methods could just be deprecated/removed.",
            "date": "2010-03-24T14:04:28.924+0000",
            "id": 11
        },
        {
            "author": "Shai Erera",
            "body": "So what's the motivation of declaring PagingCollector a TopDocsCollector? Would you envision one to request for a TopDocsCollector but don't care if it's TSDC, TFC or PagingCollector? I would rather have it extend TDC directly, and then you won't need to throw UOE for the rest of the methods ...\n\nWhat about renaming it to TopScorePagingCollector?",
            "date": "2010-03-24T14:31:00.022+0000",
            "id": 12
        },
        {
            "author": "Grant Ingersoll",
            "body": "I'm saying PagingColl. doesn't even exist and it is just folded into the two existing In/Out Collectors with a new create() method that knows when it's paging and when it's not.",
            "date": "2010-03-24T14:46:59.650+0000",
            "id": 13
        },
        {
            "author": "Shai Erera",
            "body": "Ohh I see. Missed that. So that can be folded into TSDC.create, or actually another create method which in addition to numHits specifies a 'startFrom' w/ a ScoreDoc, and a similar one for TFC.create. The only complication I see is that if we want to make it extremely efficient, we'll need to double the number of Collector impls for TSDC and TFC (the internal instances that are created) ...\n\nThen ... I think ... TDC can have just one topDocs() indeed.\n\nBut the idea of doubling the number of collector impls worries me. Especially for cases where even for paging, you won't use the Paging thing because you simply don't maintain any state on the server. I wonder if for those apps, who do maintain the state, and I imagine there aren't lots of them, having a PagingCollector which either wraps TSDC, or is the one you provided in the patch (but does not extend TDC) would be better? It won't unnecessarily over-complicate the code of TSDC and TFC (which will have 12 impls) and give you sort of what you need - if you maintain state, then you know that's the second page the user requested, so using a PagingCollector specifically doesn't sound that bad to me?",
            "date": "2010-03-24T15:05:13.209+0000",
            "id": 14
        },
        {
            "author": "Grant Ingersoll",
            "body": "{quote}\nThe only complication I see is that if we want to make it extremely efficient, we'll need to double the number of Collector impls for TSDC and TFC (the internal instances that are created) ... \n{quote}\n\nI'm not convinced yet.  I think we can likely make it short circuit quite fast for the non-paging case, but rather than guess, let's benchmark.  I'm extracting my Benchmark collector stuff right now on LUCENE-2343.  I also am not sure we need to double the number of collectors.",
            "date": "2010-03-24T15:23:36.043+0000",
            "id": 15
        },
        {
            "author": "Michael McCandless",
            "body": "This is a neat collector!\n\nI like the idea of chaining/filtering... couldn't we put this in core\n(under TFC/TSDC.create), but instead of doubling the 12 specialized\n(anonymous) impls we now have, just delegate?\n\nIe, we'd make a FilteredCollector, taking another collector when it's\ncreated, and then on every collect call, only if the hit is \"weak\"\nenough (ie is worse than what the app provided as prev low score/doc)\nwould it forward it to the delegate?  I guess we should test perf w/\n(the new additions to benchmark -- yay!) to see if specializing the\ncode (even anonymously) is warranted.\n\nThe indent whitespace needs to fixed to 2 spaces...\n",
            "date": "2010-03-25T09:47:47.037+0000",
            "id": 16
        },
        {
            "author": "Grant Ingersoll",
            "body": "Mike,  don't you think, though, that through a fairly simple update of some of the clauses to appropriate short circuit things that we can just hook this into the existing collectors w/o no need for any delegation or changes?  Let me try a patch.  Now that the benchmark stuff is in, we should be able to test.\n",
            "date": "2010-03-25T19:00:36.493+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "Hey, and I want to fix the NaN thing in TSDC: LUCENE-2271\n\nMaybe when we delegate, we can also use my cool code that switches the delegate to remove on comparison after the queue is full.",
            "date": "2010-03-25T19:10:19.246+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "bq. ...through a fairly simple update of some of the clauses to appropriate short circuit things that we can just hook this into the existing collectors w/o no need for any delegation or changes? Let me try a patch. Now that the benchmark stuff is in, we should be able to test.\n\nThis'd make me nervous...\n\nIe I don't think we should insert bytecodes for the 99.9% of searches that wouldn't make use of this, even if we can't uncover a slowdown with benchmarking.\n\nWe should still benchmark it though (I'm curious)... we should also benchmark the delegate solution.",
            "date": "2010-03-25T19:23:09.449+0000",
            "id": 19
        },
        {
            "author": "Grant Ingersoll",
            "body": "Yeah, but one could make the argument, Mike, that the existing \"optimizations\" are useless for the most common case, since I think it's safe to say most applications implement paging.  Of course, that being said, most users don't page all that deeply.  Also, for something like Solr that prefetches the top 50 it might not be good, either.  Still, in my mind it is one additional boolean check, as in:\n{code}\nif ( (current stuff) || (pagingInfoPresent == true && paging check) )\n...\n{code}\n\npagingInfoPresent can be determined at construction time and that whole clause would be short circuited very quickly.\n\nThat being said, delegation could be done at construction time, too and more cleanly separates things.  I'll try to put up my version tomorrow.",
            "date": "2010-03-26T00:26:16.609+0000",
            "id": 20
        },
        {
            "author": "Shai Erera",
            "body": "bq. since I think it's safe to say most applications implement paging\n\nLet's be careful about the semantics here Grant. Most if not all applications implement paging indeed, but I believe only FEW actually store user contexts between searches. PagingCollector relies on the application to store the lowest ranking doc that was returned previously, which means storing context between user's searches.\n\nI agree w/ Mike's statement about 99.9% of the searches would never run that code, which is why I've proposed a delegation/wrapper approach from the beginning. I also think that we should make some allowances here and there, for the non-common case, and introduce better software design than specialized code. A Collector filter approach for some rare (or even less common) cases seems very reasonable to me.\n\nAlso, I think that if we add to TSDC a create method which takes into account the previously scored lowest doc, it will confuse people. Now they will need to think \"where do I get this low score from?\" - but perhaps after I see the code, it wouldn't be such a bad thing .... just have a feeling TSDC and TFC should be left on their own, and extreme paging stuff should either be its own specialized collector, or a wrapper.",
            "date": "2010-03-26T04:22:40.214+0000",
            "id": 21
        },
        {
            "author": "Grant Ingersoll",
            "body": "bq. Let's be careful about the semantics here Grant. Most if not all applications implement paging indeed, but I believe only FEW actually store user contexts between searches. PagingCollector relies on the application to store the lowest ranking doc that was returned previously, which means storing context between user's searches.\n\nI think, assuming the math plays out, that once you show the gains to be had here, esp. for deep paging, storing an int and a float is trivial.  If they are implementing paging, they are already keeping state about what page they are on.  \n\nbq. Now they will need to think \"where do I get this low score from?\"\n\nSorry, but If that is that hard to figure out, then I don't see how they have any business writing a Lucene application to begin with.  A simple javadoc that says these two values are taken from the last result of the previously seen page should do the trick\n\nAt any rate, let's put up the patches and find out instead of debating.  I should have time today to do mine.",
            "date": "2010-03-26T10:39:56.931+0000",
            "id": 22
        },
        {
            "author": "Shai Erera",
            "body": "Sure let's wait for the patch and some perf. results.",
            "date": "2010-03-26T11:14:58.608+0000",
            "id": 23
        },
        {
            "author": "Itamar Syn-Hershko",
            "body": "Hi guys, any update on this?\n\nI'm interested in using this for production code. Can anyone comment on how safe / mature this code is?\n\nThanks!",
            "date": "2011-04-20T21:08:43.534+0000",
            "id": 24
        },
        {
            "author": "jmwap",
            "body": "Itamar, in case it's helpful for you: my code is not in production yet, but close, and I am not using latest patch, but the original one. I have not seen any issue in my regression tests against my older code where I was not using this.",
            "date": "2011-04-26T14:12:05.575+0000",
            "id": 25
        },
        {
            "author": "Itamar Syn-Hershko",
            "body": "Thanks. I ended up using the standard Lucene paging code.\n\nHopefully this will get into Lucene soon...",
            "date": "2011-05-12T11:05:45.933+0000",
            "id": 26
        },
        {
            "author": "Simon Willnauer",
            "body": "it this still valid / needed? Grant are you planning to work on this any time soon?",
            "date": "2011-07-13T06:31:27.170+0000",
            "id": 27
        },
        {
            "author": "Grant Ingersoll",
            "body": "I do think it is still valid and much needed, but haven't had time to work on it and I don't think we ever got agreement on the API level.",
            "date": "2011-07-13T11:05:40.921+0000",
            "id": 28
        },
        {
            "author": "Charlie Hubbard",
            "body": "So this is not apart of 3.x yet.  If I want to use this with 3.x where is the most recent version?  It looks like Grant has made some changes since the original upload I'd like to get those changes since it sounds like it fixed several bugs in the original.",
            "date": "2011-09-15T20:26:29.520+0000",
            "id": 29
        },
        {
            "author": "Robert Muir",
            "body": "I think for this issue, we should just add IndexSearcher.pagedSearch() methods for paging, passing in the bottom result of the previous page (ScoreDoc lastBottom).\n\nNote for the first page of results, this means you pass in null for lastBottom and its doing the same thing as search(), so even if you choose to use this method your 'page 1 results' will be just as fast as IndexSearcher.search()\n\nAlso, its easy to make a ScoreDoc from the int+float so apps that want to keep this state can probably do so easily (and maybe they benchmark and decide its only worthwhile to cutover to this once you hit page 3, or 4, or whatever).\n\nI also added a few optimizations to the previous code: specialized InOrder/OutOfOrder, subtract docBase from the bottom's doc in setNextReader to remove an add, etc.\n\nI didn't add the methods that take sort, but I think we could do this in a separate issue.",
            "date": "2011-09-16T21:55:39.095+0000",
            "id": 30
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks great!  I like the API -- all the app must do is hold onto the bottom doc from last page and resubmit for next page.",
            "date": "2011-09-16T22:02:59.891+0000",
            "id": 31
        },
        {
            "author": "Hoss Man",
            "body": "I'm not overly familiar with the historical evolution of this patch, but is a new IndexSearcher.pagedSearch really warranted in this case?\n\nAdding the \"ScoreDoc lastBottom\" param to TopScoreDocCollector.create seems like it would make this easy enough to use.\n\nMy concern is that most novice users doing \"simple paginated search\" aren't ever going to hit the deep paging problem -- keeping track of the current page number and multiplying by the number of items per page to determine the numHit value works just fine for most applications.  But if they see an explicit IndexSearcher.pagedSearch method, they are going to think \"this is what i need for paginated search\" and then be confused as to how they should keep track in their app of the last ScoreDoc instance.\n\nI mean, i'm all in favor of simple convince methods -- but isn't TopScoreDocCollector.create simple enough for the level of knowledge a user will need to use this effectively?",
            "date": "2011-09-17T00:17:20.372+0000",
            "id": 32
        },
        {
            "author": "Robert Muir",
            "body": "Hoss, how can they use this in combination with an ExecutorService then?\n\nWith the current patch: this works?",
            "date": "2011-09-17T00:43:43.317+0000",
            "id": 33
        },
        {
            "author": "Hoss Man",
            "body": "bq. Hoss, how can they use this in combination with an ExecutorService then?\n\nI sync'ed up with rmuir on irc,  i wasn't aware that the ExecutorService only worked with some IndexSeracher methods and not others.  I see now why a new method is important (for deep paging you're really going ot want to use the ExecutorService), but i'm still a little concerned about hte name sucking in novice users who don't really need it to do paginated search.\n\nwe can add detailed javadocs making it clear to folks what the diff is, but perhaps a diff name would be more appropriate?  at a minimum maybe call it \"deepPagingSearch\" or something else that conveys more  explicitly how it works (\"searchAfterLastMatch\" ?)\n",
            "date": "2011-09-17T01:22:50.198+0000",
            "id": 34
        },
        {
            "author": "Robert Muir",
            "body": "Maybe instead 'searchAfter' ? perhaps we could rearrange the arguments too, to make it read better:\ninstead of:\n\nTopDocs pagedSearch(Query query, ScoreDoc lastBottom, int n)\n\nwe could do:\n\nTopDocs searchAfter(ScoreDoc previous, Query query, int n)\n\nor something like that?",
            "date": "2011-09-17T01:35:07.153+0000",
            "id": 35
        },
        {
            "author": "Michael McCandless",
            "body": "+1 for TopDocs searchAfter(ScoreDoc previous, Query query, int n), though maybe name the param \"after\" not \"previous\"?",
            "date": "2011-09-17T12:17:15.921+0000",
            "id": 36
        },
        {
            "author": "Robert Muir",
            "body": "renamed to searchAfter, added a little to the javadocs, and improved the test coverage a bit.",
            "date": "2011-09-17T14:03:15.092+0000",
            "id": 37
        },
        {
            "author": "Grant Ingersoll",
            "body": "+1.",
            "date": "2011-09-17T17:47:23.415+0000",
            "id": 38
        },
        {
            "author": "Robert Muir",
            "body": "I committed the patch to trunk: we can discuss if/how we should backport to 3.x, backwards break or add sophisticated layer or whatever.",
            "date": "2011-09-20T23:28:08.649+0000",
            "id": 39
        },
        {
            "author": "Michael McCandless",
            "body": "For 3.x can we just add these methods to IndexSearcher (not Searcher/Searchable)?   This would require the app to use IndexSearcher if they are not already, which is great because that's what they'll need to do in 4.0 anyway (since Searcher/Searchable are deprecated).\n\nOr is there some other back compat issue?",
            "date": "2011-09-21T15:00:55.189+0000",
            "id": 40
        },
        {
            "author": "Robert Muir",
            "body": "bq. Or is there some other back compat issue?\n\nWe add this param to a protected method signature, so it would affect subclasses of IndexSearcher.",
            "date": "2011-09-21T15:24:45.679+0000",
            "id": 41
        },
        {
            "author": "Michael McCandless",
            "body": "bq. We add this param to a protected method signature, so it would affect subclasses of IndexSearcher.\n\nAhh, right.  Well, I think we can make an exception here -- subclassing IS is very expert.",
            "date": "2011-09-21T15:27:03.890+0000",
            "id": 42
        },
        {
            "author": "Uwe Schindler",
            "body": "Bulk close after release of 3.5",
            "date": "2011-11-27T12:29:27.726+0000",
            "id": 43
        }
    ],
    "component": "core/search",
    "description": "http://issues.apache.org/jira/browse/LUCENE-2127?focusedCommentId=12796898&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12796898\n\nSomebody assign this to Aaron McCurry and we'll see if we can get enough votes on this issue to convince him to upload his patch.  :)",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2215",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "paging collector",
    "systemSpecification": true,
    "version": "2.4, 3.0"
}