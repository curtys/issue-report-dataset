{
    "comments": [
        {
            "author": "Paul Smith",
            "body": "Another workaround might be to use '-client' instead of the default '-server' (for server class machines).  This affects a few things, not least this switch:\n\n-XX:CompileThreshold=10000 \tNumber of method invocations/branches before compiling [-client: 1,500]\n\n-server implies a 10000 value.  I have personally observed similar behaviour like problems like the above with -server, and usually -client ends up 'solving' them.\n\nI'm sure there was also a way to mark a method to not jit compile too (rather than resort to -Xint which disables i for everything), but now I cant' find what that syntax is at all.",
            "date": "2008-05-11T22:40:32.451+0000",
            "id": 0
        },
        {
            "author": "Bruce Ritchie",
            "body": "From Mark Miller on the developer's mailing list:\n\nHere's a couple examples of that exclude method syntax (had to use it recently with eclipse):\n\n-XX:CompileCommand=exclude,org/apache/lucene/index/IndexReader\\$1,doBody\n-XX:CompileCommand=exclude,org/eclipse/core/internal/dtree/DataTreeNode,forwardDeltaWith\n\n",
            "date": "2008-05-12T00:34:05.189+0000",
            "id": 1
        },
        {
            "author": "Stu Hood",
            "body": "I've also been struck by this bug, with Lucene 2.3.2. I'd been running for a while with JRE 1.6.0_05 when I noticed it, so I downgraded to JRE 1.6.0_02 to try and work around it, but no luck.\n\nCould a bugged index created with JRE 1.6.0_05 be causing addIndexesNoOptimize to trigger this bug, even with JRE 1.6.0_02?\n\nThanks.",
            "date": "2008-05-14T01:49:21.513+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Could a bugged index created with JRE 1.6.0_05 be causing addIndexesNoOptimize to trigger this bug, even with JRE 1.6.0_02\n\nUnfortunately, yes.  Once the corruption enters the index, then no matter which JRE you are using, you will hit that exception.\n\nIn your case, I can see that indeed segment _2y9, which is pre-existing when you call addIndexesNoOptimize, is the corrupt segment.\n\nIn general, you can use CheckIndex to see if you have any latent corruption.\n\nI'm afraid you either have to run CheckIndex -fix to remove that segment (and possibly others that are also corrupt) from your index, or, create a new index.\n\nThis bug is very frustrating!\n\nCan you describe how you built up this index?  EG was this bulk created (open a single writer, add all the docs, close it), or, created with many separate instances of IndexWriter over time?  Were documents added via add/updateDocument or via addIndexes*?  Do you run the JRE with any \"interesting\" command-line options?  I'd really like to narrow down the \"typical\" cases when this bug strikes if we can...",
            "date": "2008-05-14T07:44:35.586+0000",
            "id": 3
        },
        {
            "author": "Nick Menere",
            "body": "We had a lot of customers [report this bug|http://jira.atlassian.com/browse/JRA-9198], though it was about 2 years ago that sun fixed this so we only see it in very rare cases now, and even then our fix is... \"Please upgrade you JVM\".\n\nI am flat out at the moment, but if you need, I will try and get some more info on this if you want.",
            "date": "2008-05-14T08:42:56.727+0000",
            "id": 4
        },
        {
            "author": "Nick Menere",
            "body": "Actually, not convinced it is the same bug.. We kept getting complete JVM crashes...  I just assumed it was (I wouldn't be surprised if it was related though).",
            "date": "2008-05-14T08:47:35.950+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "Another datapoint from Ian Lea:\n\nMy job (http://lucene.markmail.org/message/awkkunr7j24nh4qj) still\nfails with java version 1.6.0_06 (build 1.6.0_06-b02), downloaded\ntoday, with both lucene 2.3.1 and 2.3.2.\n\nFor me, downgrading to 1.6.0_03-b05 fixed things.\n",
            "date": "2008-05-14T13:59:15.723+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "\nI finally managed to reproduce this JVM bug, except, my case happens\nwhile merging term vectors (mergeVectors) not stored fields as all\nother cases seem to be.\n\nI'm running JRE 1.6.0_05 on a Debian Linux box.\n\nIn my case, which just uses a modified contrib/benchmark to add 2000\nwikipedia docs to a large index, I got to the point (when index was 19\nGB) where every single time I run the benchmark alg, it hits an\nexception.  Often the exception looks like this:\n\n{code}\nException in thread \"Lucene Merge Thread #0\" org.apache.lucene.index.MergePolicy$MergeException: java.io.IOException: read past EOF\n\tat org.apache.lucene.index.ConcurrentMergeScheduler.handleMergeException(ConcurrentMergeScheduler.java:323)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:300)\nCaused by: java.io.IOException: read past EOF\n\tat org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:146)\n\tat org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:38)\n\tat org.apache.lucene.store.IndexInput.readInt(IndexInput.java:68)\n\tat org.apache.lucene.store.IndexInput.readLong(IndexInput.java:91)\n\tat org.apache.lucene.index.TermVectorsReader.get(TermVectorsReader.java:345)\n\tat org.apache.lucene.index.SegmentReader.getTermFreqVectors(SegmentReader.java:992)\n\tat org.apache.lucene.index.SegmentMerger.mergeVectors(SegmentMerger.java:441)\n\tat org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:138)\n\tat org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:3998)\n\tat org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3650)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:214)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:269)\n{code}\n\nI then added the same check that we now have for mergeFields, ie, to\nverify the size of index file (_X.tvx) matches the number of\ndocuments merged.  Sometimes, however, I see this different exception:\n\n{code}\nException in thread \"Lucene Merge Thread #0\" org.apache.lucene.index.MergePolicy$MergeException: java.lang.ArrayIndexOutOfBoundsException: 9375\n\tat org.apache.lucene.index.ConcurrentMergeScheduler.handleMergeException(ConcurrentMergeScheduler.java:323)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:300)\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 9375\n\tat org.apache.lucene.store.BufferedIndexOutput.writeByte(BufferedIndexOutput.java:36)\n\tat org.apache.lucene.store.IndexOutput.writeVInt(IndexOutput.java:71)\n\tat org.apache.lucene.index.TermVectorsWriter.addAllDocVectors(TermVectorsWriter.java:76)\n\tat org.apache.lucene.index.SegmentMerger.mergeVectors(SegmentMerger.java:443)\n\tat org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:138)\n\tat org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:3998)\n\tat org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3650)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:214)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:269)\n{code}\n\nwhere the particular array index would vary all over the place.  This\nis VERY odd because that array is the buffer in BufferedIndexOutput\nand is always allocated to 16384 bytes so 9375 (and all others I saw)\nis *not* out of bounds.\n\nJRE 1.5.0_08 always runs fine.  Likewise running JRE 1.6.0_05 with\n-Xint also runs fine.  However, JRE 1.6.0_05 with -Xbatch still hits\nexceptions.\n\nSo then I started testing \"trivial\" modifications to the Java source\ncode in the mergeVectors, and found, insanely, that this simple diff\ncompletely stopped the exceptions:\n\n{code}\n             } else {\n-              termVectorsWriter.addAllDocVectors(reader.getTermFreqVectors(docNum));\n+              // NOTE: it's very important to first assign\n+              // to vectors then pass it to\n+              // termVectorsWriter.addAllDocVectors; see\n+              // LUCENE-1282\n+              TermFreqVector[] vectors = reader.getTermFreqVectors(docNum);\n+              termVectorsWriter.addAllDocVectors(vectors);\n{code}\n\n(Ie, just forcing an assignment to a local variable).\n\nIt's crazy that such a trivial mod actually makes a difference in this\nJRE bug (I would have expected it to be optimized away fairly early on\nin compilation), but, I'm quite sure that diff resolves at least the\nexceptions I've been seeing.  So I plan to commit this JRE bug\nworkaround to 2.4 & 2.3 branch.\n\nI still haven't been able to hit the JRE bug when merging stored\nfields, but, I'm still making that same corresponding mod to\nmergeFields.\n",
            "date": "2008-05-14T21:40:04.999+0000",
            "id": 7
        },
        {
            "author": "Yonik Seeley",
            "body": "See, that complex code even confuses the JVM ;-)\nAwesome job coming up with this workaround! (crosses fingers for stored fields)",
            "date": "2008-05-14T21:51:51.316+0000",
            "id": 8
        },
        {
            "author": "Ismael Juma",
            "body": "Hi,\n\nGreat work on tracking this down, it looks like a very nasty bug. Has it been reported to Sun yet? It seems like the kind of bug that could manifest itself in other places too, so important to get a real fix.",
            "date": "2008-05-14T22:14:00.890+0000",
            "id": 9
        },
        {
            "author": "Paul Smith",
            "body": "Throwing up an idea here for consideration.  I'm sure it could be shot down, but I thought I'd raise it just in case it hasn't already been considered and discarded.. \n\nOne of the _classic_ problems between -client and -server mode is the way the CPU registers are used.  Is it possible that some of the fields are suffering from concurrency issues?  I was wondering if, say, BufferedInfexOutput.buffer* may need to be marked volatile ?\n\nOne easy way to test if this makes a difference is to just try switching between explicit use of '-client' and '-server'.  Most newer machines (even desktops & laptops) appear to qualify for Sun's 'am I a server-class machine' check.  By switching to -client, if these problems disappear, this to me would smell more and more like a 'volatile' like behaviour, because AIUI, -server will be more aggressive with some of it's register optimizations and I've seen behaviour just like this where variables that have clearly been written, the changes are not 'appearing' on the other side.  Even the same thread marking the change can be switched across to a different CPU right in the middle, and could see different results.\n\nOf course those people with lots of concurrency experience can probably dismiss this theory in a second, but that's fine.  ",
            "date": "2008-05-14T22:17:35.304+0000",
            "id": 10
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Has it been reported to Sun yet? It seems like the kind of bug that could manifest itself in other places too, so important to get a real fix.\n\nNot yet, but I intend to.  I'm trying to whittle it down.  I agree the bug is nasty and could strike again at any time.  The AIOOB exceptions I was hitting were truly bizarre.",
            "date": "2008-05-15T07:57:11.352+0000",
            "id": 11
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nOne of the classic problems between -client and -server mode is the way the CPU registers are used. Is it possible that some of the fields are suffering from concurrency issues? I was wondering if, say, BufferedInfexOutput.buffer* may need to be marked volatile ?\n{quote}\nIn my 100% reproducible case of this JRE bug, I'm using only 1 thread, so I don't think a volatile should be necessary here.\n\nBut I like your idea to try -client vs -server -- I will test that & post back.  The more data we can gather the better... I did find it interesting that -Xbatch did NOT resolve it, but has for at least one of the above users.\n\nI'm wondering if it has something to do with writing to large (> 32 bit) files.  In my test case, the index keeps kicking off a large merge (produces 2.7 GB segment) and it's that merge that trips the bug.",
            "date": "2008-05-15T08:04:47.003+0000",
            "id": 12
        },
        {
            "author": "Michael McCandless",
            "body": "bq. In my 100% reproducible case of this JRE bug, I'm using only 1 thread, so I don't think a volatile should be necessary here.\n\nWoops: I am, however, using the default ConcurrentMergeScheduler, so this very-large merge runs in its own thread.  Still, it's only that one thread that's accessing this code/state, so by the spec volatile should not be necessary.",
            "date": "2008-05-15T08:13:26.239+0000",
            "id": 13
        },
        {
            "author": "Michael McCandless",
            "body": "OK: running with -client prevents the bug.\n\nRunning with SerialMergeScheduler still shows the bug.\n\nI'm going to try to make a standalone test that just runs this one merge....",
            "date": "2008-05-15T10:22:24.596+0000",
            "id": 14
        },
        {
            "author": "Michael McCandless",
            "body": "Using the 19 GB index I have that consistently reproduces this hotspot bug, I boiled the bug down to a very small testcase that no longer involves Lucene.\n\nHowever, this occurence of the bug is slightly different: for me, by specifying -Xbatch to java command line, the bug consistently happens.  It only rarely happens without -Xbatch.  Nonetheless, I'm hopeful that if Sun fixes this one test case properly, it will fix all the odd exceptions we've been seeing from this code.\n\nI opened the bug 4 days ago (5/15) with http://bugs.sun.com, but have yet to hear if it's been accepted as a real bug.\n\nif others could try out the code below on their Linux boxes, using 1.6.0_04/05 of Sun's java, specifying -Xbatch, to see if the bug can be reproduced, that'd be great.\n\nHere's the bug I opened:\n\n{code}\nDate Created: Thu May 15 11:53:15 MDT 2008\nType:        bug\nCustomer Name:   Michael McCandless\nCustomer Email:  mail@mikemccandless.com\nSDN ID:       mail@mikemccandless.com\nstatus:      Waiting\nCategory:    hotspot\nSubcategory: runtime_system\nCompany:     IBM\nrelease:     6\nhardware:    x86\nOSversion:   linux\npriority:    4\nSynopsis:    Simple code runs incorrectly with -Xbatch\nDescription:\n FULL PRODUCT VERSION :\njava version \"1.6.0_06\"\nJava(TM) SE Runtime Environment (build 1.6.0_06-b02)\nJava HotSpot(TM) Server VM (build 10.0-b22, mixed mode)\n\n\n\nFULL OS VERSION :\nLinux 2.6.22.1 #7 SMP PREEMPT Tue Mar 18 18:22:09 EDT 2008 i686 GNU/Linux\n\nA DESCRIPTION OF THE PROBLEM :\nOn the Apache Lucene project, we've now had 4 users hit by an apparent\nJRE bug.  When this bug strikes, it silently corrupts the search\nindex, which is very costly to the user (makes the index unusable).\nDetails are here:\n\n  https://issues.apache.org/jira/browse/LUCENE-1282\n\nI can reliably reproduce the bug, but only on a very large (19 GB)\nsearch index.  But I narrowed down one variant of the bug to attached\ntest case.\n\n\n\nTHE PROBLEM WAS REPRODUCIBLE WITH -Xint FLAG: No\n\nTHE PROBLEM WAS REPRODUCIBLE WITH -server FLAG: Yes\n\nSTEPS TO FOLLOW TO REPRODUCE THE PROBLEM :\nCompile and run the attached code (Crash.java), with -Xbatch and it should fail (ie, throw the\nRuntimeException, incorrectly).  It should pass without -Xbatch.\n\n\n\n\n\nEXPECTED VERSUS ACTUAL BEHAVIOR :\nExpected is no RuntimeException should be thrown.  Actual is it is thrown.\nREPRODUCIBILITY :\nThis bug can be reproduced always.\n\n---------- BEGIN SOURCE ----------\npublic class Crash {\n\n  public static void main(String[] args) {\n    new Crash().crash();\n  }\n\n  private Object alwaysNull;\n\n  final void crash() throws Throwable {\n    for (int r = 0; r < 3; r++) {\n      for (int docNum = 0; docNum < 10000;) {\n        if (r < 2) {\n          for(int j=0;j<3000;j++)\n            docNum++;\n        } else {\n          docNum++;\n          doNothing(getNothing());\n          if (alwaysNull != null) {\n            throw new RuntimeException(\"BUG: checkAbort is always null: r=\" + r + \" of 3; docNum=\" + docNum);\n          }\n        }\n      }\n    }\n  }\n\n  Object getNothing() {\n    return this;\n  }\n\n  int x;\n  void doNothing(Object o) {\n    x++;\n  }\n}\n\n\n---------- END SOURCE ----------\n\nCUSTOMER SUBMITTED WORKAROUND :\nDon't specify -Xbatch.  You can also tweak the code to have it pass the test.  Reducing the 10000\nor 3000 low enough makes it pass.  Changing the doNothing(...)  line\nto assign the result of getNothing() to an intermediate variable\nfirst, also passes (this is the approach we plan to use for Lucene). Removing the x++ also passes.\nworkaround:  \ncomments:    (company - IBM , email - mail@mikemccandless.com)\n{code}",
            "date": "2008-05-19T11:06:08.585+0000",
            "id": 15
        },
        {
            "author": "Ismael Juma",
            "body": "Great work finding a reduced test-case. I tried the sample application with JDK6u4 32-bit and I can add the following:\n\n- It always happens with -Xbatch -server when the code is compiled with javac.\n- It happens sometimes (sometimes after 3 attempts, sometimes after 10, etc.) with -server when the code is compiled with javac.\n- I am unable to reproduce it when compiling with the eclipse compiler (running from the command-line to avoid any other differences)",
            "date": "2008-05-19T11:36:33.804+0000",
            "id": 16
        },
        {
            "author": "Ismael Juma",
            "body": "Btw, if I increase the number of iterations to 1000000 for docNum and 300000 for j I can reproduce it every time without -Xbatch.",
            "date": "2008-05-19T12:02:51.106+0000",
            "id": 17
        },
        {
            "author": "Ismael Juma",
            "body": "It's worth noting that jdk 6u10 beta b24 (released today) and openjdk6 in Fedora 9 are also affected by the problem shown in the test-case.",
            "date": "2008-05-20T20:43:48.901+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "This bug is spooky.  I tried another workaround, which is to just increment an unused variable, instead of the above diff but at the same spot.  That then causes the JRE to reliably crash (SEGV).  I'm attaching the hs_err log.\n\nSun has not yet \"accepted\" my bug.  If/when they do, I'll attach this error log to it.",
            "date": "2008-05-21T21:55:48.345+0000",
            "id": 19
        },
        {
            "author": "Michael McCandless",
            "body": "OK I've committed the workaround & bug detection to trunk (2.4) and 2.3 branch.\n\nAt this point I think that's all we can do here; we are now waiting on Sun to fix the JRE bug.",
            "date": "2008-05-22T09:26:55.601+0000",
            "id": 20
        },
        {
            "author": "andreaskohn",
            "body": "We've seen this bug (rarely) when indexing quite huge amounts of data.\n\nJust to add some datapoints, attached is [^crashtest], using the above Crash.java to test all java VMs I have currently available.\n[^crashtest.log] contains the output. \n\nTests were run on a loaded EM64T dual core machine with fedora 9/x86_64, all VMs are 64bit. The openjdk is a build from yesterdays public repository contents, build using gcc 4.3 (trivial patches to make it build were added).\n\nSome scary solaris (SunOS 5.10 Generic_120011-14 sun4u sparc SUNW,UltraAX-i2) results as well:\n{quote}\n/usr/jdk/jdk1.6.0_04 (java full version \"1.6.0_04-b12\"):\n   : 0/200 failed: PASS\n   -server: 0/200 failed: PASS\n   -client: 0/200 failed: PASS\n   -Xbatch: 0/200 failed: PASS\n   -Xint: 0/200 failed: PASS\n\n/usr/jdk/jdk1.6.0_04 (java full version \"1.6.0_04-b12\"):\n    -d64: 0/200 failed: PASS\n   -server -d64: 0/200 failed: PASS\n   -client -d64: 0/200 failed: PASS\n   -Xbatch -d64: 0/200 failed: PASS\n   -Xint -d64: 0/200 failed: PASS\n{quote}\n",
            "date": "2008-05-23T15:44:37.366+0000",
            "id": 21
        },
        {
            "author": "Michael McCandless",
            "body": "Here is the bug at Sun: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6707044",
            "date": "2008-05-27T15:57:33.206+0000",
            "id": 22
        },
        {
            "author": "Jed Wesley-Smith",
            "body": "Sun has posted their evaluation on the bug above and accepted it as High priority.",
            "date": "2008-07-11T23:46:14.341+0000",
            "id": 23
        },
        {
            "author": "Paul Smith",
            "body": "\u00a0Can anyone comment as to whether the JRE 1.6.04+ bug affects any _earlier_ versions of Lucene? (say, 2.0.. which we're still using) .\n\nI was just reviewing this issue and noticed Michael mentioned this behaviour shows in both the ConcurrentMergeScheduler and the SerialMergeScheduler.  AIUI,. the SerialMergeScheduler is effectively the 'old' way of previous versions of Lucene, so I'm just starting to think about what affect 1.6.04 might have on earlier versions? (this bug is only marked as affecting 2.3+).\n\nThe reason I ask is that we're just about to upgrade to 1.6.04 -server in some of our production machines.. (reason why not going to 1.6.06 is we only started our development test cycle months ago and stuck with .04 until next cycle).",
            "date": "2008-07-13T22:15:35.525+0000",
            "id": 24
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Can anyone comment as to whether the JRE 1.6.04+ bug affects any earlier versions of Lucene? (say, 2.0.. which we're still using).\n\nAs far as I know, this corruption only happens on Lucene 2.3+.  The changes to Lucene that tickled this JRE bug were bulk-merging of stored fields:\n\n    https://issues.apache.org/jira/browse/LUCENE-1043\n\nwhich landed in 2.3, and also bulk-merging of term vectors:\n\n    https://issues.apache.org/jira/browse/LUCENE-1120",
            "date": "2008-07-14T10:06:43.201+0000",
            "id": 25
        },
        {
            "author": "Ismael Juma",
            "body": "As can be seen in the Sun database a fix for this has been committed to OpenJDK and they're looking into backporting it into Java 6 Update 10.",
            "date": "2008-07-16T23:56:21.513+0000",
            "id": 26
        },
        {
            "author": "Ismael Juma",
            "body": "The latest build of JDK 6 Update 10 (b28) includes the fix for this. It can be downloaded from:\n\nhttp://download.java.net/jdk6/binaries/\n\nIn the summary of changes, you can see that it refers to a bug that requests the integration of a new HotSpot build that includes the fix for this:\n\nhttp://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6727119\n\nI have also verified that the test-case now passes on my machine.\n\n",
            "date": "2008-07-25T01:53:53.198+0000",
            "id": 27
        },
        {
            "author": "Michael McCandless",
            "body": "Indeed, I can confirm that JDK 6 Update 10 (b28) fixes my 19 GB test case that reliably crashes with earlier JDK 6 versions.\n\nI'll resolve this as fixed, and send an email to users.",
            "date": "2008-07-30T17:56:01.985+0000",
            "id": 28
        }
    ],
    "component": "core/index",
    "description": "This is not a Lucene bug.  It's an as-yet not fully characterized Sun\nJRE bug, as best I can tell.  I'm opening this to gather all things we\nknow, and to work around it in Lucene if possible, and maybe open an\nissue with Sun if we can reduce it to a compact test case.\n\nIt's hit at least 3 users:\n\n  http://mail-archives.apache.org/mod_mbox/lucene-java-user/200803.mbox/%3c8c4e68610803180438x39737565q9f97b4802ed774a5@mail.gmail.com%3e\n  http://mail-archives.apache.org/mod_mbox/lucene-solr-user/200804.mbox/%3c4807654E.7050900@virginia.edu%3e\n  http://mail-archives.apache.org/mod_mbox/lucene-java-user/200805.mbox/%3c733777220805060156t7fdb8fectf0bc984fbfe48a22@mail.gmail.com%3e\n\nIt's specific to at least JRE 1.6.0_04 and 1.6.0_05, that affects\nLucene.  Whereas 1.6.0_03 works OK and it's unknown whether 1.6.0_06\nshows it.\n\nThe bug affects bulk merging of stored fields.  When it strikes, the\nsegment produced by a merge is corrupt because its fdx file (stored\nfields index file) is missing one document.  After iterating many\ntimes with the first user that hit this, adding diagnostics &\nassertions, its seems that a call to fieldsWriter.addDocument some\neither fails to run entirely, or, fails to invoke its call to\nindexStream.writeLong.  It's as if when hotspot compiles a method,\nthere's some sort of race condition in cutting over to the compiled\ncode whereby a single method call fails to be invoked (speculation).\n\nUnfortunately, this corruption is silent when it occurs and only later\ndetected when a merge tries to merge the bad segment, or an\nIndexReader tries to open it.  Here's a typical merge exception:\n\n{code}\nException in thread \"Thread-10\" \norg.apache.lucene.index.MergePolicy$MergeException: \norg.apache.lucene.index.CorruptIndexException:\n    doc counts differ for segment _3gh: fieldsReader shows 15999 but segmentInfo shows 16000\n        at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:271)\nCaused by: org.apache.lucene.index.CorruptIndexException: doc counts differ for segment _3gh: fieldsReader shows 15999 but segmentInfo shows 16000\n        at org.apache.lucene.index.SegmentReader.initialize(SegmentReader.java:313)\n        at org.apache.lucene.index.SegmentReader.get(SegmentReader.java:262)\n        at org.apache.lucene.index.SegmentReader.get(SegmentReader.java:221)\n        at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:3099)\n        at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:2834)\n        at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:240)\n{code}\n\nand here's a typical exception hit when opening a searcher:\n\n{code}\norg.apache.lucene.index.CorruptIndexException: doc counts differ for segment _kk: fieldsReader shows 72670 but segmentInfo shows 72671\n        at org.apache.lucene.index.SegmentReader.initialize(SegmentReader.java:313)\n        at org.apache.lucene.index.SegmentReader.get(SegmentReader.java:262)\n        at org.apache.lucene.index.SegmentReader.get(SegmentReader.java:230)\n        at org.apache.lucene.index.DirectoryIndexReader$1.doBody(DirectoryIndexReader.java:73)\n        at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:636)\n        at org.apache.lucene.index.DirectoryIndexReader.open(DirectoryIndexReader.java:63)\n        at org.apache.lucene.index.IndexReader.open(IndexReader.java:209)\n        at org.apache.lucene.index.IndexReader.open(IndexReader.java:173)\n        at org.apache.lucene.search.IndexSearcher.<init>(IndexSearcher.java:48)\n{code}\n\nSometimes, adding -Xbatch (forces up front compilation) or -Xint\n(disables compilation) to the java command line works around the\nissue.\n\nHere are some of the OS's we've seen the failure on:\n\n{code}\nSuSE 10.0\nLinux phoebe 2.6.13-15-smp #1 SMP Tue Sep 13 14:56:15 UTC 2005 x86_64 \nx86_64 x86_64 GNU/Linux \n\nSuSE 8.2\nLinux phobos 2.4.20-64GB-SMP #1 SMP Mon Mar 17 17:56:03 UTC 2003 i686 \nunknown unknown GNU/Linux \n\nRed Hat Enterprise Linux Server release 5.1 (Tikanga)\nLinux lab8.betech.virginia.edu 2.6.18-53.1.14.el5 #1 SMP Tue Feb 19 \n07:18:21 EST 2008 i686 i686 i386 GNU/Linux\n{code}\n\nI've already added assertions to Lucene to detect when this bug\nstrikes, but since assertions are not usually enabled, I plan to add a\nreal check to catch when this bug strikes *before* we commit the merge\nto the index.  This way we can detect & quarantine the failure and\nprevent corruption from entering the index.\n\n",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-1282",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Sun hotspot compiler bug in 1.6.0_04/05 affects Lucene",
    "systemSpecification": true,
    "version": "2.3, 2.3.1"
}