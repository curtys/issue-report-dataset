{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "ZIP file that needs to be put in src/test/org/apache/lucene/index (used by backwards compatibility test).",
            "date": "2006-10-27T23:41:51.000+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "ZIP file that needs to be put in src/test/org/apache/lucene/index (used by backwards compatibility test).",
            "date": "2006-10-27T23:42:16.000+0000",
            "id": 1
        },
        {
            "author": "Yonik Seeley",
            "body": "Nice job on this very ambitious patch (all 3500 lines of it!) Good tests are certainly important!\n\nCould you elaborate on how the backward compatibility works w.r.t. modifying an old index?\nHow do versioned norms & del files mix with older unversion files?\n\nIn the absense of contention, have you noticed any performance differences in opening an IndexReader?\n\n> on one platform (OS X) I found that the directory listing can be incorrect (stale) by up to 1.0 seconds. \n\nThat sucks... (but great job on the very thorough testing).\nCan it happen with the latest version of OS X?  If not, couldn't we just require an upgrade, or do you think that other platforms suffer from this.",
            "date": "2006-10-31T23:49:16.000+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "Thanks Yonik for looking at this!\n\n> Could you elaborate on how the backward compatibility works w.r.t. modifying an old index?\n> How do versioned norms & del files mix with older unversion files?\n\nOK, first off, the only file whose contents and name are changed is\nthe \"segments_N\" file.  Then, the only files whose name (but not\ncontents) is changed are the \"_X_N.del\" deletes file, and \"_X_N.sZ\"\nseparate norms files).  Finally, the only file that is deleted is\ndeletable.  All other segments files are unchanged.\n\nThe unit test I added for this (TestBackwardsCompatibility) un-zips a\npre-lockless index (I have one zip file for CFS format and one for\nnon-CFS) and then runs various tests: adding docs, deleting a doc,\nsetting a norm for a doc, searching, etc., verifying that the results\nare then as expected.\n\nOn opening an pre-lockless index, first we see only a \"segments\" file\nwith no _N extension, and record its generation as 0.  Second, since\nthat file's contents doesn't lead with format lockless code (-2), we\nknow to load the old segments info format that does not contain the\n\"del\" gen, \"separate norm\" gen nor the \"isCompundFile\" marker.\n\nWhen loading each Segmentinfo, since the format of the segments files\nwas old, we record this with \"preLockless = true\" and set delGen and\nisCompoundFile to 0 and normGen to null.  0 means \"must check\nfilesystem for existence\".  The various methods (hasSeparateNorms,\nhasDeletions, etc.) know to handle these \"0\" cases as falling back to\nfilesystem existence checks of the existing naming (ie, _X.del).  I\ntried to capture / contain all of this inside the methods of\nSegmentInfo.\n\nNow, when a writer commits to this pre-lockless index, we write in the\nnew (format lockless) format and to the file \"segments_1\".  (Actually,\nwith compound file turned on, we then make a .cfs file and commit\nagain to \"segments_2\").  This file will reference all of the old\nsegments (except eg those deleted by a merge) plus the one new\nsegment.\n\nThe old segments have written the \"0\"'s for delGen, normGen (null is\nwritten as -1 length), isCompoundFile so that on re-loading this\nsegments_2 file these segments remain pre-lockless.  The SegmentInfo\nfor the new segment file will have isCompoundFile=1 (meaning it is a\ncompound file), delGen=-1 (there are no separate deletes yet) and\nnormGen=null (there are no separate norms yet).  When normGen is null,\nwe look at \"preLockless\" to differentiate whether this means there are\nno separate norms at all for any fields, or, this segment is pre\nlockless and therefore we must fallback to the filesystem check.\n\nIf a delete or setNorm call takes place against an old segment format,\nwe will at that time create \"generation 1\" for that file.  This means\nyou can have an old segment whose separate del file is still\n\"generation 0\" (you have to check for existence of _X.del) but whose\nseparate norms generations are known (or, only certain fields are\nknown and the others are \"generation 0\" and require filesystem check).\nThis means an \"old\" segment file could become \"slightly newer\" as\nnorm/del changes are made against it.\n\nSo an index can have mixed old/new segments.  The SegmentInfo for each\nsegment keeps track of old/new (and tries to hide these implementation\ndetails under its methods) with delGen, normGen, isCompoundFile and\npreLockless (which is derived from isCompoundFile).\n\nOnce an optimize is done, or, all old segments have been merged away,\nthen all segments are now the lockless format.\n\n",
            "date": "2006-11-01T18:34:13.000+0000",
            "id": 3
        },
        {
            "author": "Michael McCandless",
            "body": "> > on one platform (OS X) I found that the directory listing can be incorrect (stale) by up to 1.0 seconds.\n> \n> That sucks... (but great job on the very thorough testing).\n> Can it happen with the latest version of OS X? If not, couldn't we just require an upgrade, or do you think that other platforms suffer from this.\n\nYes, this was very surprising and annoying!  Unfortunately, this\nhappens on the latest version of OS X (10.4.8).  Other platforms that\nI tested do \"the right thing\" meaning when you list a directory the\nNFS client on Linux first checks with the server to see if its cache\nis stale and correctly clears the cache.  Windows SMB is also always\ncorrect.  But I think it's entirely likely that filesystems do this\nkind of time-based (only) cache validation. I figured better safe than\nsorry here, and Lucene should tolerate stale caching around either\nfile contents or directory listing.\n",
            "date": "2006-11-01T18:35:38.000+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "> In the absense of contention, have you noticed any performance differences in opening an IndexReader? \n\n[First one side note: it's during contention that lock-less really\nshines.  Because, currently Lucene hits at least a [default] 1.0\nsecond delay under contention, whereas lockless immediately retries.\nAnd, readers now have contention with one another, but not with\nlock-less.]\n\nI ran the following basic performance test.  In each case I measure\navg wall clock time to instantiate readers & writers against the same\nindex.  A writer creates the index, adding documents as quickly as it\ncan, and commits and closes/reopens its writer every 2 seconds.  Then,\na reader reads against the same index, just instantiating a searcher\nthen closing it and then pausing for 2 seconds.  I skew the writer by\n1 sec to try to minimize contention.  Each test is avg of 3 runs,\nwhere each run is 2 minutes.\n\nIn order to not count contention, I made temporary mods, to both\ncurrent lucene & lockless, to throw IOException on hitting contention.\nThen, I catch that above and discard the time for that one\ninstantiation of reader or writer.\n\nAll times are mili-seconds.  Each time is formatted as current Lucene\ntime followed by lockless in (...)s:\n\n       Local index (Linux):   4.62  (6.04)\n       Local index (WIN32):  85.45 (66.37)\n\n  NFS remote index (Linux): 171.26 (11.04)\n  SMB remote index (WIN32):  48.91 (31.55)\n\nThe \"remote index\" case means a writer on that OS, and a reader on\nanother machine with the same OS, reading the index on a mount from\nthe writer machine (ie, writer is writing locally and reader is\nreading remotely).\n\nOne caveat: I saw quite a bit of variance between runs.  I tried to\neliminate causes (stopped all services, other applications, etc.)  but\nstill there is variance.  Maybe I should be taking the \"minumum\" time\nseen instead of the average (this was mentioned on the benchmarking\nJira issue)...\n\nAnyway, the surprising thing is that lockless is faster in most cases\nIn the remote cases (especially NFS) it's quite a bit faster.  I think\nthis may be because lockless does far fewer \"fileExists\" calls\ncompared to current Lucene.  For example, the \"openNorms\" call\npresently does a \"fileExists\" call per field that has norms index\ntimes the number of segments.\n\nI'm not sure these speedups/differences are all that important in a\ntypical Lucene use case, where the cost of instantiating a reader is\namortized over all the searches that occur during the lifetime of that\nreader.  Though, maybe one real difference is: if we can make sure the\nlatency is low enough, it's OK to have a single query pay the price of\nreopening the searcher.  Ie, it becomes reasonable to have an incoming\nquery first check whether the searcher is current and if not, reopen\nit, and then run the query, vs having separate background thread do\nthis, which is certainly feasible just more complicated.\n",
            "date": "2006-11-01T18:42:35.000+0000",
            "id": 5
        },
        {
            "author": "Yonik Seeley",
            "body": "Thanks for all the details Michael!  A few more random comments and questions:\n\nIn the future, it might be nice if there was an option to disable segments.gen to be more friendly to write-once filesystems like HDFS.\n\nAs far as performance goes, I was personally interested in the contentionless case since that's what processes that coordinate everything (like Solr) will see.\n\nI'm not sure I understand the \"segments.gen\" logic of writing two longs that are identical.\nLooking at the code, it doesn't seem like you are implementing this:\nhttp://www.nabble.com/Re%3A-Lock-less-commits-p5978090.html\nAre there two longs instead of one in order to leave \"space\" for that implementation if needed, w/o having to change the file format?\n\nThe file deleting code does much more than in the past, and that's a good thing IMO.  For example it looks like leftover non-compound segment files from a failed CFS merge (say the JVM dies) will now be cleaned up!\n\nI'm having a hard time figuring out how older delete files are removed (since they contain the current segment name, it looks like findDeletableFiles would skip them).",
            "date": "2006-11-01T22:55:25.000+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "Good questions!\n\n> In the future, it might be nice if there was an option to disable\n> segments.gen to be more friendly to write-once filesystems like\n> HDFS.\n\nI think this makes sense.  I will add control over this on the next\niteration of the patch.\n\n> As far as performance goes, I was personally interested in the\n> contentionless case since that's what processes that coordinate\n> everything (like Solr) will see.\n\nAhh got it, OK.  That's fair.\n\n> I'm not sure I understand the \"segments.gen\" logic of writing two\n> longs that are identical.  Looking at the code, it doesn't seem like\n> you are implementing this:\n> http://www.nabble.com/Re%3A-Lock-less-commits-p5978090.html\n> Are there two longs instead of one in order to leave \"space\" for\n> that implementation if needed, w/o having to change the file format?\n\nRight, I settled on a simplification of that approach.  I write two\nlongs so that reader can read both & compare and only trust them if they\nare identical.  With one long I was worried eg that perhaps 3 bytes\nfrom the writer were written but not yet the remaining 5 bytes, and\nthen reader would get the wrong value.  I don't think IO systems\nguarantee atomicity of eg 8 byte chunks (though in practice it's\nprobably often the case).\n\nOne thing I will also add is a version header to this file.\n\n> The file deleting code does much more than in the past, and that's a\n> good thing IMO.  For example it looks like leftover non-compound\n> segment files from a failed CFS merge (say the JVM dies) will now be\n> cleaned up!\n\nOh, right!  In fact any time an index crashes not having committed its\nsegments file, there is potential for leftover (unreferenced) files\nnow.  This separate IndexFileDeleter class should correctly reclaim in\nsuch cases.  And even other potential future situations like the\ndiscussion in LUCENE-702 would be reclaimed correctly with this\napproach.\n\n> I'm having a hard time figuring out how older delete files are\n> removed (since they contain the current segment name, it looks like\n> findDeletableFiles would skip them).\n\nOooh -- you are correct.  I do record this file for deleting at the\npoint it becomes unreferenced (ie, as a reader is committing its\nseparate norms/deletes), and then I delete this file after the commit\nis done.  But if JVM crashes after the new del file was written and\nbefore the commit, then you're right on restarting I don't correctly\ndelete the unreferenced old _X_N.del files, nor I believe the separate\nnorms _X_N.sM files.  I will add a unit test to verify this bug and\nthen fix it -- good catch!",
            "date": "2006-11-02T15:19:16.000+0000",
            "id": 7
        },
        {
            "author": "Ning Li",
            "body": "Can the following scenario happen with lock-less commits?\n\n1 A reader reads segments.1, which says the index contains seg_1.\n2 A writer writes segments.2, which says the index now contains seg_2, and deletes seg_1.\n3 The reader tries to load seg_1 and fails.\n",
            "date": "2006-11-02T16:11:02.000+0000",
            "id": 8
        },
        {
            "author": "Yonik Seeley",
            "body": "> 3 The reader tries to load seg_1 and fails. \n\nThat wouldn't be considered a failure because it's part of the retry logic.  At that point, an attempt would be made to open seg_2.\nTo minimize the possibility of this happening, the segments are opened in reverse order (since the last segments change the most often).\n\nThen a question might be, could a writer possibly change the index fast enough to prevent a reader from opening at all?  I don't think so (and it would be a mis-configured writer IMO), but maybe Michael could speak to that.",
            "date": "2006-11-02T16:51:05.000+0000",
            "id": 9
        },
        {
            "author": "Ning Li",
            "body": "> That wouldn't be considered a failure because it's part of the retry logic. At that point, an attempt would be made to open seg_2. \n\nFrom the description of the retry logic, I thought the retry logic only applies to the loading of the \"segments_N\" file, but not to the entire process of loading all the files of an index.\n\nYou are right, it wouldn't be a failure if the retry logic is applied to the loading of all the files of an index.",
            "date": "2006-11-02T17:18:24.000+0000",
            "id": 10
        },
        {
            "author": "Yonik Seeley",
            "body": "> > In the future, it might be nice if there was an option to disable\n> > segments.gen to be more friendly to write-once filesystems like\n> > HDFS.\n> I think this makes sense. I will add control over this on the next\n> iteration of the patch. \n\nJust to be clear, I didn't mean that I thought it was needed now... \nthere is another place in Lucene that prevents write-once from working (segment file lengths at the beginning IIRC).\n\nWhen this option is added, perhaps the configuration name should be generic and not tied to the implementation specifics that could change more frequently?  Something like WRITE_ONCE or setWriteOnce()?",
            "date": "2006-11-02T17:41:49.000+0000",
            "id": 11
        },
        {
            "author": "Michael McCandless",
            "body": "\nRight, this is just normal contention.  We do indeed retry around not\nonly loading of segments_N but also the loading of the individual\nsegments files.  There are other places (eg lastModified()) that do\nother things with the segments file.  These places also use the retry\nlogic.\n\nIn Lucene currently, contention causes a pause (default 1.0 second)\nand then retry to obtain the commit lock.  With lockless, we simply\nretry immediately loading the latest segments_N file.\n\nIt's important to note that at any given instant, the index is always\n\"consistent\" (well, except for issues like LUCENE-702 ).\n\nBut, because a reader takes non-zero time to load the index, you can\nhit contention if a writer's commit spans that time.  If a reader\ncould load an index in zero time there would never be contention.\n\nThere are several ways that contention will manifest itself.  These\nare just the different alignments / convolutions of the series of\nsteps that reader goes through \"sliding against\" the series of steps\nthat a writer goes through:\n\n  * Reader opens the segments_N but in reading it hits EOF because\n    writer has not finished writing it yet.\n\n  * Reader opens segments_N, fully reads its contents, but then hits\n    IOException on loading each segment file because during this team\n    writer has committed and is now deleting segments files.  This\n    case is your example above.\n\n  * Reader opens segments_N, but hits IOException while reading its\n    contents because it was deleted by writer before reader could read\n    all of its contents (should only happen on fileystems that don't\n    do \"delete on last close\" or \"can't delete open files\").\n\n  * Reader takes listing of directory, locates segments_N, but fails\n    to open that file because writer has now removed it.\n\nAnyway, on hitting an IOException, we first retry segments_N-1 (if it\nexists).  Failing that we recheck the directory for latest segments_N.\nIf N has advanced we try that.  If N has not advanced we give it one\nmore chance to load (since it could be on first try we hit case 1\nabove).  If it fails that second chance and on re-listing we are still\nat N, we throw the original exception we hit.\n\nI added a couple of tests cases to TestIndexWriter to verify that a\nmessed up index indeed throws an IOException.\n\nOn Yonik's question:\n\n> Then a question might be, could a writer possibly change the index\n> fast enough to prevent a reader from opening at all?  I don't think\n> so (and it would be a mis-configured writer IMO), but maybe Michael\n> could speak to that.\n\nThis is definitely possible.  This really is a form of \"starvation\".\nIf a writer is committing too fast, or, readers are constantly\nre-opening too fast, they will starve one another.\n\nBoth current Lucene and lockless will hit starvation under high enough\nrate of commit/opens, but, different things happen.  EG LUCENE-307\nissue is exactly this case on the current Lucene.  Lockless will retry\nindefinitely though may at some point succeed (but take many\nretries to do so).\n\nStill, I think the point at which starvation starts to happen is far\nbeyond a normal usage of Lucene (ie, committing > ten times / sec).\n",
            "date": "2006-11-02T18:13:49.000+0000",
            "id": 12
        },
        {
            "author": "Michael McCandless",
            "body": "> > In the future, it might be nice if there was an option to disable\n> > segments.gen to be more friendly to write-once filesystems like\n> > HDFS.\n> I think this makes sense. I will add control over this on the next\n> iteration of the patch.\n\n> Just to be clear, I didn't mean that I thought it was needed now...\n> there is another place in Lucene that prevents write-once from\n> working (segment file lengths at the beginning IIRC).\n\n> When this option is added, perhaps the configuration name should be\n> generic and not tied to the implementation specifics that could change\n> more frequently? Something like WRITE_ONCE or setWriteOnce()?\n\nOK, I see, this is part of a wider context.  Maybe it's the creation\nof the compound file you're thinking of?  That writes 0's into the\nheader, adds the files, then rewinds and puts the actual offsets into\nit.  Then let's open a separate issue to track this -- I'll do that.\nDon't want to make this patch any bigger!\n",
            "date": "2006-11-02T18:18:11.000+0000",
            "id": 13
        },
        {
            "author": "Michael McCandless",
            "body": "OK, another version of the lockless commits patch with these fixes:\n\n  - Added new unit test (TestIndexFileDeleter) for deleter, caught the\n    above bug Yonik found (we can fail to delete orphan'd separate\n    del/norm files), fixed it, and unit test now passes.\n\n  - We were also failing to deleted orphan'd .fN files (norm files\n    that do get included into CFS file).  Fixed that case too.\n\n  - Added version header to segments.gen file.\n\n  - Added static setter/getters for advanced configuration of the\n    retry logic.  Note: this required making the SegmentInfos class\n    public.\n\nYou still need to put those two zip files into\nsrc/test/org/apache/lucene/index after applying this patch.\n\nThis addresses all feedback/TODOs that I knew about.\n\nAll unit tests pass.\n",
            "date": "2006-11-06T19:26:45.000+0000",
            "id": 14
        },
        {
            "author": "Yonik Seeley",
            "body": "Looks good Michael, I think this is ready to commit!\nDoes anyone have any concerns with this going into the trunk?",
            "date": "2006-11-06T22:59:57.000+0000",
            "id": 15
        },
        {
            "author": "Steven Parkes",
            "body": "I'm all for the patch ... the only thing I'm wondering is about release timing, if that's issue? This changes the on-disk format, which affects more than Lucene Java and, should anyone that's using Lucene out there care (via scripts, etc.), the naming of files on disk.\n\nI'm just wondering if there's any interest/reason for doing a 2.1 before something with those side effects?",
            "date": "2006-11-07T01:12:14.000+0000",
            "id": 16
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Steven - I don't see any issues with this going in before 2.1.  As a matter of fact, this may be a sufficiently substantial change that will make us want to make a 2.1 release.\n\nMaybe Michael should commit this next week.\n",
            "date": "2006-11-10T23:25:24.000+0000",
            "id": 17
        },
        {
            "author": "Michael McCandless",
            "body": "Oooh -- I would love to!",
            "date": "2006-11-11T00:13:35.000+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "Closing all issues that were resolved for 2.1.",
            "date": "2007-02-27T18:10:35.496+0000",
            "id": 19
        }
    ],
    "component": "core/index",
    "description": "This is a patch based on discussion a while back on lucene-dev:\n\n    http://mail-archives.apache.org/mod_mbox/lucene-java-dev/200608.mbox/%3c44E5B16D.4010805@mikemccandless.com%3e\n\nThe approach is a small modification over the original discussion (see\nRetry Logic below).  It works correctly in all my cross-machine test\ncase, but I want to open it up for feedback, testing by\nusers/developers in more diverse environments, etc.\n\nThis is a small change to how lucene stores its index that enables\nelimination of the commit lock entirely.  The write lock still\nremains.\n\nOf the two, the commit lock has been more troublesome for users since\nit typically serves an active role in production.  Whereas the write\nlock is usually more of a design check to make sure you only have one\nwriter against the index at a time.\n\nThe basic idea is that filenames are never reused (\"write once\"),\nmeaning, a writer never writes to a file that a reader may be reading\n(there is one exception: the segments.gen file; see \"RETRY LOGIC\"\nbelow).  Instead it writes to generational files, ie, segments_1, then\nsegments_2, etc.  Besides the segments file, the .del files and norm\nfiles (.sX suffix) are also now generational.  A generation is stored\nas an \"_N\" suffix before the file extension (eg, _p_4.s0 is the\nseparate norms file for segment \"p\", generation 4).\n\nOne important benefit of this is it avoids files contents caching\nentirely (the likely cause of errors when readers open an index\nmounted on NFS) since the file is always a new file.\n\nWith this patch I can reliably instantiate readers over NFS when a\nwriter is writing to the index.  However, with NFS, you are still forced to\nrefresh your reader once a writer has committed because \"point in\ntime\" searching doesn't work over NFS (see LUCENE-673 ).\n\nThe changes are fully backwards compatible: you can open an old index\nfor searching, or to add/delete docs, etc.  I've added a new unit test\nto test these cases.\n\nAll units test pass, and I've added a number of additional unit tests,\nsome of which fail on WIN32 in the current lucene but pass with this\npatch.  The \"fileformats.xml\" has been updated to describe the changes\nto the files (but XXX references need to be fixed before committing).\n\nThere are some other important benefits:\n\n  * Readers are now entirely read-only.\n\n  * Readers no longer block one another (false contention) on\n    initialization.\n\n  * On hitting contention, we immediately retry instead of a fixed\n    (default 1.0 second now) pause.\n\n  * No file renaming is ever done.  File renaming has caused sneaky\n    access denied errors on WIN32 (see LUCENE-665 ).  (Yonik, I used\n    your approach here to not rename the segments_N file(try\n    segments_(N-1) on hitting IOException on segments_N): the separate\n    \".done\" file did not work reliably under very high stress testing\n    when a directory listing was not \"point in time\").\n\n  * On WIN32, you can now call IndexReader.setNorm() even if other\n    readers have the index open (fixes a pre-existing minor bug in\n    Lucene).\n\n  * On WIN32, You can now create an IndexWriter with create=true even\n    if readers have the index open (eg see\n    www.gossamer-threads.com/lists/lucene/java-user/39265) .\n\n\nHere's an overview of the changes:\n\n  * Every commit writes to the next segments_(N+1).\n\n  * Loading the segments_N file (& opening the segments) now requires\n    retry logic.  I've captured this logic into a new static class:\n    SegmentInfos.FindSegmentsFile.  All places that need to do\n    something on the current segments file now use this class.\n\n  * No more deletable file.  Instead, the writer computes what's\n    deletable on instantiation and updates this in memory whenever\n    files can be deleted (ie, when it commits).  Created a common\n    class index.IndexFileDeleter shared by reader & writer, to manage\n    deletes.\n\n  * Storing more information into segments info file: whether it has\n    separate deletes (and which generation), whether it has separate\n    norms, per field (and which generation), whether it's compound or\n    not.  This is instead of relying on IO operations (file exists\n    calls).  Note that this fixes the current misleading\n    FileNotFoundException users now see when an _X.cfs file is missing\n    (eg http://www.nabble.com/FileNotFound-Exception-t6987.html).\n\n  * Fixed some small things about RAMDirectory that were not\n    filesystem-like (eg opening a non-existent IndexInput failed to\n    raise IOException; renames were not atomic).  I added a stress\n    test against a RAMDirectory (1 writer thread & 2 reader threads)\n    that uncovered these.\n\n  * Added option to not remove old files when create=true on creating\n    FSDirectory; this is so the writer can do its own [more\n    sophisticated because it retries on errors] removal.\n\n  * Removed all references to commit lock, COMMIT_LOCK_TIMEOUT, etc.\n    (This is an API change).\n\n  * Extended index/IndexFileNames.java and index/IndexFileNameFilter.java\n    with logic for computing generational file names.\n\n  * Changed index/IndexFileNameFilter.java to use a HashSet to check\n    file extentsions for better performance.\n\n  * Fixed the test case TestIndexReader.testLastModified: it was\n    incorrectly (I think?) comparing lastModified to version, of the\n    index.  I fixed that and then added a new test case for version.\n\n\nRetry Logic (in index/SegmentInfos.java)\n\nIf a reader tries to load the segments just as a writer is committing,\nit may hit an IOException.  This is just normal contention.  In\ncurrent Lucene contention causes a [default] 1.0 second pause then\nretry.  With lock-less the contention causes no added delay beyond the\ntime to retry.\n\nWhen this happens, we first try segments_(N-1) if present, because it\ncould be segments_N is still being written.  If that fails, we\nre-check to see if there is now a newer segments_M where M > N and\nadvance if so.  Else we retry segments_N once more (since it could be\nit was in process previously but must now be complete since\nsegments_(N-1) did not load).\n\nIn order to find the current segments_N file, I list the directory and\ntake the biggest segments_N that exists.\n\nHowever, under extreme stress testing (5 threads just opening &\nclosing readers over and over), on one platform (OS X) I found that\nthe directory listing can be incorrect (stale) by up to 1.0 seconds.\nThis means the listing will show a segments_N file but that file does\nnot exist (fileExists() returns false).\n\nIn order to handle this (and other such platforms), I switched to a\nhybrid approach (originally proposed by Doron Cohen in the original\nthread): on committing, the writer writes to a file \"segments.gen\" the\ngeneration it just committed.  It writes 2 identical longs into this\nfile.  The retry logic, on detecting that the directory listing is\nstale falls back to the contents of this file.  If that file is\nconsistent (the two longs are identical), and, the generation is\nindeed newer than the dir listing, it will use that.\n\nFinally, if this approach is also stale, we fallback to stepping\nthrough sequential generations (up to a maximum # tries).  If all 3\nmethods fail, we throw the original exception we hit.\n\nI added a static method SegmentInfos.setInfoStream() which will print\ndetails of retry attempts.  In the patch it's set to System.out right\nnow (we should turn off before a real commit) so if there are problems\nwe can see what retry logic had done.\n",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-701",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Lock-less commits",
    "systemSpecification": true,
    "version": "2.1"
}