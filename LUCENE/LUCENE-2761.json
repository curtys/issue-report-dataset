{
    "comments": [
        {
            "author": "Robert Muir",
            "body": "Here's my result from a crappy benchmark that just does SpanFirst query on a very common term:\n\n{code}\n    SpanQuery sq = new SpanFirstQuery(new SpanTermQuery(new Term(\"body\", \"the\")), 1);\n    System.out.println(searcher.search(sq, 10).totalHits);\n    long ms = System.currentTimeMillis();\n    for (int i = 0; i < 100; i++) {\n      searcher.search(sq, 10);\n    }\n    long ms2 = System.currentTimeMillis();\n    System.out.println(\"time = \" + (ms2 - ms));\n{code}\n\nAll times below in milliseconds.\n\n||setup||run1||run2||run3||run4||run5||run6||\n|TRUNK|13055|13054|13061|13068|13070|13058|\n|LUCENE-2760|7987|7993|7995|7987|8012|7989|\n|LUCENE-2760+LUCENE-2761|7741|7723|7701|7702|7693|7702|\n\nI think it sucks to introduce duplication, but if we can eek out a few \n% faster phrasequeries/spanqueries for the common case, i think this is worth it for codecs\n",
            "date": "2010-11-15T15:37:39.852+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "This looks great Robert!  I think it makes sense to manually specialize this.",
            "date": "2010-11-15T15:43:03.252+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "updated patch: in the non-payloads case, when we are blasting through \"useless positions\", we dont care about \nthe return value from readVint, just want to skip over them.\n\nthis seems to help a lot, none of the shifting etc.\n\n||setup||run1||run2||run3||run4||run5||run6||\n|LUCENE-2760+LUCENE-2761|7175|7204|7175|7169|7176|7165|\n",
            "date": "2010-11-15T19:41:15.913+0000",
            "id": 2
        },
        {
            "author": "Robert Muir",
            "body": "same patch with an additional optimization from Mike.\n\n||setup||run1||run2||run3||run4||run5||run6||\n|LUCENE-2760+LUCENE-2761|6854|6874|6850|6855|6856|6846|\n\nalso, because we assume things about read/writeVint, i made these final in DataInput.\n\nI think we can use this same trick to speed up the terms dictionary, where it scans past lots of useless vints/vlongs\n",
            "date": "2010-11-15T20:34:18.081+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "Committed revision 1035473.",
            "date": "2010-11-15T22:20:17.129+0000",
            "id": 4
        }
    ],
    "component": "",
    "description": "In LUCENE-2760 i started working to try to improve the speed of a few spanqueries.\nIn general the trick there is to avoid processing positions if you dont have to.\n\nBut, we can improve queries that read lots of positions further by cleaning up SegmentDocsAndPositionsEnum, \nin nextPosition() this has no less than 3 payloads-related checks.\n\nhowever, a large majority of users/fields have no payloads at all.\nI think we should specialize this case into a separate implementation and speed up the common case.\n\nedit: dyslexia with the jira issue number.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2761",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "specialize payload processing from of DocsAndPositionsEnum",
    "systemSpecification": true,
    "version": ""
}