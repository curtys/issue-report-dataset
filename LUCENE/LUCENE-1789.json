{
    "comments": [
        {
            "author": "Hoss Man",
            "body": "This idea orriginated in LUCENE-1749, see these comments...\n\nhttps://issues.apache.org/jira/browse/LUCENE-1749?focusedCommentId=12740155#action_12740155\nhttps://issues.apache.org/jira/browse/LUCENE-1749?focusedCommentId=12740256#action_12740256\nhttps://issues.apache.org/jira/browse/LUCENE-1749?focusedCommentId=12740278#action_12740278\n\n\nI've marked this for 2.9 for now .... i think it's a \"nice to have\" in 2.9, because unlike general FieldCache usage, the API is abstract enough we can protect our users from mistakes; but i don't personally think it's critical that we do this if no one else wants to take a stab at it.\n\n(EDIT: shorter versions of URLs to prevent horizontal scroll)",
            "date": "2009-08-07T00:35:01.683+0000",
            "id": 0
        },
        {
            "author": "Mark Miller",
            "body": "Its basically what I did as a first attempt at 1771 actually (you have a glimpse into how hectic my brain is in that I didn't remember that 30 minutes ago) :\n\n(with some of this in ReaderUtil now, it can be written in half the length)\n{code}\n+    // constructor\n+    private ValueSourceScorer(Similarity similarity, IndexReader reader, ValueSourceWeight w, boolean valuesFromSubReaders) throws IOException {\n       super(similarity);\n+      if(!valuesFromSubReaders) {\n+        this.weight = w;\n+        this.qWeight = w.getValue();\n+        // this is when/where the values are first created.\n+        vals = valSrc.getValues(reader);\n+        termDocs = reader.termDocs(null);\n+        return;\n+      }\n+      \n       this.weight = w;\n       this.qWeight = w.getValue();\n-      // this is when/where the values are first created.\n-      vals = valSrc.getValues(reader);\n+      List subReadersList = new ArrayList();\n+      ReaderUtil.gatherSubReaders(subReadersList, reader);\n+      subReaders = (IndexReader[]) subReadersList.toArray(new IndexReader[subReadersList.size()]);\n+      valsArray = new DocValues[subReaders.length];\n+      docStarts = new int[subReaders.length];\n+      int maxDoc = 0;\n+      for (int i = 0; i < subReaders.length; i++) {\n+        docStarts[i] = maxDoc;\n+        maxDoc += subReaders[i].maxDoc();\n+        valsArray[i] = valSrc.getValues(subReaders[i]);\n+      }\n+      \n+      vals = new DocValues() {\n+\n+        //@Override\n+        public float floatVal(int doc) {\n+          int n = ReaderUtil.subSearcher(doc, subReaders.length, docStarts);\n+          return valsArray[n].floatVal(doc);\n+        }\n+\n+        //@Override\n+        public String toString(int doc) {\n+          return Float.toString(floatVal(doc));\n+        }\n+        \n+      };\n       termDocs = reader.termDocs(null);\n     }\n\n{code}",
            "date": "2009-08-07T02:07:42.856+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "It is nice that DocValues gives us the freedom to do this, but.... I'm\nnot sure we should, because it's a sizable performance trap.\n\nIe, we'll be silently inserting a call to ReaderUtil.subSearcher on\nevery doc value lookup (vs previously when it was a single top-level\narray lookup).\n\nWhile client code that has relied on this in the past will nicely\ncontinue to function properly, if we make this change, its performance\nis going to silently take a [possibly sizable] hit.\n\nIn general, with Lucene, we can do the per-segment switching \"up high\"\n(which is what the core now does, exclusively), or we can do it \"down\nlow\" (creating MultiTermDocs, MultiTermEnum, MultiTermPositions,\nMultiDocValues, etc.), which has sizable performance costs.  It's also\ncostly for us because we'll have N different places where we must\ncreate & maintain a MultiXXX class.  I would love to someday deprecate\nall of the \"down low\" switching classes :)\n\nIn the core I think we should always switch \"up high\".  We've already\ndone this w/ searching and collection/sorting.  In LUCENE-1771 we're\nfixing IndexSearcher.explain to do so as well.\n\nWith external code, I'd like over time to strongly encourage only\nswitching \"up high\" as well.\n\nMaybe it'd be best if we could somehow allow this \"down low\" switching\nfor 2.9, but 1) warn that you'll see a performance hit right off, 2)\ndeprecate it, and 3) and somehow state that in 3.0 you'll have to send\nonly a SegmentReader to this API, instead.\n\nEG, imagine an app that created an external custom HitCollector that\ncalls say FloatFieldSource on the top reader in order to use of a\nfloat value per doc in each collect() call.  On upgrading to 2.9, this\napp will already have to make the switch to the Collector API, which'd\nbe a great time for them to also then switch to pulling these float\nvalues per-segment.  But, if we make the proposed change here, the app\ncould in fact just keep working off the top-level values (eg if the\nctor in their class is pulling these values), thinking everything is\nfine when in fact there is a sizable, silent perf hit.  I'd prefer in\n2.9 for them to also switch their DocValues lookup to be per segment.\n\n[Aside: once we gain clarity on LUCENE-831, hopefully we can do away\nwith oal.search.function.FieldCacheSource,\n{Byte,Short,Int,Ord,ReverseOrd}FieldSource, etc.  Ie these classes\nbasically copy what FieldCache does, but expose a per-doc method call\ninstead of a fixed array lookup.]\n\n",
            "date": "2009-08-07T10:22:04.497+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "Or... how about if we made a separate \"helper\" class, whose purpose\nwas to accept a top-level reader and do \"down low\" switching to this\nnew MultiDocValues class.  This class would be deprecated, ie, exist\nonly in 2.9 to help external usage of the DocValues API migrate to \"up\nhigh\" switching.\n\nHowever, you'd have to explicitly create this class.  EG, in the\nnormal DocValues classes we throw an exception if you pass in a\ntop-level reader, noting clearly that you could 1) switch to this\nhelper class (at a sizable per-lookup performance hit), or 2) switch\nto looking up your values per-segment?\n\nThis way at least it'd be much clearer to the external consumer the\ncost of using the \"down low\" switching class.  It'd make the decision\nexplicit, not silent, on upgrading to 2.9.\n",
            "date": "2009-08-07T10:27:59.986+0000",
            "id": 3
        },
        {
            "author": "Hoss Man",
            "body": "{quote}\nWhile client code that has relied on this in the past will nicely\ncontinue to function properly, if we make this change, its performance\nis going to silently take a [possibly sizable] hit.\n{quote}\n\nCorrect: a change like this could cause 2.9 to introduce a _time_ based performance hit from the added method call to resolve the sub(reader|docvalue) on each method call ... but if we don't have a change like this, 2.9 could introduce a _memory_ based performance hit from the other FieldCache changes as it client code accessing DocValues for the  top level reader will create a duplication of the whole array.\n\nIncidently: I'm willing to believe you that the time based perf hit would be high, but my instinct is that it wouldn't be that bad: the DocValues API already introduces at least one method call per doc lookup (two depending on datatype).  adding a second method call to delegate to a sub-DocValues isntance doesn't seem that bad (especially since a new MultDocValues class could get the subReader list and compute the docId offsets on init, and then reuse them on each method call)\n\nbq. In the core I think we should always switch \"up high\".\n\n(In case there is any confusion: wasn't suggesting that we stop using \"up high\" switching on DocValues in code included in the Lucene dist, i was suggesting that if someone uses DocValues directly in their code (against a top level reader) then we help them out by giving them the \"down low\" switching ... so \"expected\" usages wouldn't pay the added time based hit, just \"unexpected\" usages (which would be saved from the memory hit))\n\n{quote}\nMaybe it'd be best if we could somehow allow this \"down low\" switching\nfor 2.9, but 1) warn that you'll see a performance hit right off, 2)\ndeprecate it, and 3) and somehow state that in 3.0 you'll have to send\nonly a SegmentReader to this API, instead.\n{quote}\n\nthat would get into really sticky territory for people writting custom IndexReaders (or using FilteredIndexReader)\n\nbq. But, if we make the proposed change here, the app could in fact just keep working off the top-level values (eg if the ctor in their class is pulling these values), thinking everything is fine when in fact there is a sizable, silent perf hit.\n\nI agree ... but unless i'm missing something about the code on the trunk, that situation already exists: the developer might switch to using the Collector API, but nothing about the   current trunk will prevent/warn him that this...\n\n{code}\nValueSource vs = new ValueSource(\"aFieldIAlsoSortOn\");\nIndexReader r = getCurrentReaderThatCouldBeAMultiReader();\nDocValues vals = vs.getDocValues(r);\n{code}\n\n...could have a sizable, silent, _memory_ perf hit in 2.9\n\n(ValueSource.getValues has a javadoc indicating that caching will be done on the IndexReader passed in, but your comment suggests that if 2.9 were released today (with hte current trunk) people upgrading would have some obvious way of noticing that they need to pass a sub reader to getValues)\n\n\n\n\n",
            "date": "2009-08-07T14:46:20.179+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. Correct: a change like this could cause 2.9 to introduce a time based performance hit from the added method call to resolve the sub(reader|docvalue) on each method call ... but if we don't have a change like this, 2.9 could introduce a memory based performance hit from the other FieldCache changes as it client code accessing DocValues for the top level reader will create a duplication of the whole array.\n\nTrue, and of the two, I agree a hidden time cost is the lesser evil.\n\nBut I'd prefer to not hide the cost, ie, encourage/force an explicit\nchoice when users upgrade to 2.9.  If we can't think of some realistic\nway to do that, then I agree we should go forward with the current\napproach...\n\nbq. Incidently: I'm willing to believe you that the time based perf hit would be high, but my instinct is that it wouldn't be that bad: the DocValues API already introduces at least one method call per doc lookup (two depending on datatype). adding a second method call to delegate to a sub-DocValues isntance doesn't seem that bad (especially since a new MultDocValues class could get the subReader list and compute the docId offsets on init, and then reuse them on each method call)\n\nIt's the added binary search in ReaderUtil.subSearcher that worries\nme.\n\n{quote} \nbq. In the core I think we should always switch \"up high\".\n\n(In case there is any confusion: wasn't suggesting that we stop using \"up high\" switching on DocValues in code included in the Lucene dist, i was suggesting that if someone uses DocValues directly in their code (against a top level reader) then we help them out by giving them the \"down low\" switching ... so \"expected\" usages wouldn't pay the added time based hit, just \"unexpected\" usages (which would be saved from the memory hit))\n{quote}\n\nUnderstood.  We are only talking about external usages of these APIs,\nand even then, exceptionally advance usage.  Ie, users who make their\nown ValueSourceQuery and then run it against an IndexSearcher will be\nfine.  It's only people who directly invoke getValues, w/ some random\nreader, that hit the hidden cost.\n\n{quote}\nbq. But, if we make the proposed change here, the app could in fact just keep working off the top-level values (eg if the ctor in their class is pulling these values), thinking everything is fine when in fact there is a sizable, silent perf hit.\n\nI agree ... but unless i'm missing something about the code on the trunk, that situation already exists: the developer might switch to using the Collector API, but nothing about the current trunk will prevent/warn him that this...\n\nValueSource vs = new ValueSource(\"aFieldIAlsoSortOn\");\nIndexReader r = getCurrentReaderThatCouldBeAMultiReader();\nDocValues vals = vs.getDocValues(r);\n...could have a sizable, silent, memory perf hit in 2.9\n\n(ValueSource.getValues has a javadoc indicating that caching will be done on the IndexReader passed in, but your comment suggests that if 2.9 were released today (with hte current trunk) people upgrading would have some obvious way of noticing that they need to pass a sub reader to getValues)\n{quote}\n\nHow about this: we add a new param to the ctors of the value sources,\ncalled (say) acceptMultiReader.  It has 3 values:\n\n  - NO means an exception is thrown on seeing a top reader (where \"top\n    reader\" means any reader whose getSequentialSubReaders is\n    non-null)\n\n  - YES_BURN_TIME means accept the top reader and make a\n     MultiDocValues\n\n  - YES_BURN_MEMORY means use the top reader against the field cache\n\nWe deprecate the existing ctors, so on moving to 3.0 you have to make\nan explicit choice, but default it to YES_BURN_TIME.\n\nOne benefit of making the choice explicit is for those apps that have\nmemory to burn they may in fact choose to burn it.\n\nWould this give a clean migration path forward?\n",
            "date": "2009-08-07T16:01:32.243+0000",
            "id": 5
        },
        {
            "author": "Hoss Man",
            "body": "bq. How about this: we add a new param to the ctors of the value sources, called (say) acceptMultiReader. It has 3 values:\n\n...that would work ... but i feel like there may be a cleaner API possible here...\n\nWhat if we just added a new MultiValueSource wrapper class, that acted as a proxy around another ValueSource so that the only non-transparent behavior is that MultiValueSource.getDocValues returns an instance of the new MultiDocValues we've been talking about.\n\nIf you use something like FloatFieldSource directly in your code, you get what you ask for: the FieldCache is fetched agaisnt the exact reader you supply (ie: YES_BURN_MEMORY).  If you want to use a FieldSource directly in your code, and you want to get good cache reuse, and you don't want to sorry about the subreaders yourself, you wrap your FieldSource in a new MultiValueSource(myFieldSource)  (YES_BURN_TIME)\n\nThe only thing this wouldn't get us is an obvious warning to developers on upgrading (like the deprecation warnings htat would come from your suggested API) ... but since nothing about backwards compatibility is actually breaking here, that doesn't seem like the end of the world -- we can document it in CHANGES.txt (we're going to need a nice big section there about all the FieldCache usage changes anyway) drawing their attention to the new MultiValueSource they should consider using.\n\nMy thinking is this: anybody who is constructing new ValueSOurces directly is pretty deep into the code, odds are if they're using that type of code, they might be mucking with the FieldCache directly in other ways as well -- we can't solve all their problems, but we can give them helper code to make the transition easier)\n",
            "date": "2009-08-10T18:19:24.837+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "bq. What if we just added a new MultiValueSource wrapper class, that acted as a proxy around another ValueSource\n\nOK I like this solution!",
            "date": "2009-08-10T18:41:39.167+0000",
            "id": 7
        },
        {
            "author": "Hoss Man",
            "body": "Cool... i don't suppose you have time to work on a patch? \n\n(what's the emoticon for fingers crossed?)",
            "date": "2009-08-12T17:16:36.744+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "OK, I'll take a crack at this!",
            "date": "2009-08-12T17:27:15.764+0000",
            "id": 9
        },
        {
            "author": "Michael McCandless",
            "body": "Attached patch.",
            "date": "2009-08-12T18:29:45.614+0000",
            "id": 10
        }
    ],
    "component": "",
    "description": "When scoring a ValueSourceQuery, the scoring code calls ValueSource.getValues(reader) on *each* leaf level subreader -- so DocValue instances are backed by the individual FieldCache entries of the subreaders -- but if Client code were to inadvertently  called getValues() on a MultiReader (or DirectoryReader) they would wind up using the \"outer\" FieldCache.\n\nSince getValues(IndexReader) returns DocValues, we have an advantage here that we don't have with FieldCache API (which is required to provide direct array access). getValues(IndexReader) could be implimented so that *IF* some a caller inadvertently passes in a reader with non-null subReaders, getValues could generate a DocValues instance for each of the subReaders, and then wrap them in a composite \"MultiDocValues\".\n\n\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1789",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "getDocValues should provide a MultiReader DocValues abstraction",
    "systemSpecification": true,
    "version": ""
}