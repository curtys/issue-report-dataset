{
    "comments": [
        {
            "author": "Uwe Schindler",
            "body": "Here the patch for 3.x, really easy here!\n\n3.x was missing to return null in contrib/misc for getSequentialSubReaders. Further optimizations here could also work per segment. For now we have to keep them \"atomic\".\n\nAs a side note: Why is contrib/misc's IndexSorter missing in trunk?",
            "date": "2010-11-19T16:37:30.044+0000",
            "id": 0
        },
        {
            "author": "Uwe Schindler",
            "body": "Updated patch for trunk, else MultiPassIndexSplitter fails when source index has more then one segment.",
            "date": "2010-11-19T16:48:08.992+0000",
            "id": 1
        },
        {
            "author": "Uwe Schindler",
            "body": "Final patches, will commit soon.\n\nThe changes in MultiPassIndexSplitter are not yet really needed, but this is because FilterIndexReader is broken in trunk (see related issue). But I add it here, because for consistency we need it.\n\nThis patch also removes the useless closeReaders() method in SegmentMerger. This was used by tests only (incorrectly) and should never be called from production code.",
            "date": "2010-11-19T18:16:59.686+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "Looks great Uwe!",
            "date": "2010-11-19T18:21:50.877+0000",
            "id": 3
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed trunk revision: 1036970\nCommitted 3.x revision: 1036971\n\nThanks Mike for the help with the stupid bug because of not-cloned TVReader!",
            "date": "2010-11-19T18:31:59.674+0000",
            "id": 4
        },
        {
            "author": "Uwe Schindler",
            "body": "After a discussion with Robert, I supply a new patch with optrimized norms merging without reallocating and ArrayUtil.oversize() (implied y BytesRef). The fix is now to simply look before starting to merge norms how big the normsBuffer must be. So there is never reallocation needed.\n\nWill heavy commit now :-)",
            "date": "2010-11-19T23:18:33.448+0000",
            "id": 5
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed optimization in trunk revision: 1037077\n",
            "date": "2010-11-19T23:20:47.597+0000",
            "id": 6
        },
        {
            "author": "Uwe Schindler",
            "body": "Backported optimization to 3.x revision: 1037083",
            "date": "2010-11-19T23:50:39.832+0000",
            "id": 7
        },
        {
            "author": "Grant Ingersoll",
            "body": "Bulk close for 3.1",
            "date": "2011-03-30T15:50:05.592+0000",
            "id": 8
        }
    ],
    "component": "core/index",
    "description": "This is a spin-off from LUCENE-2769:\n\nCurrently SegmentMerger has some optimizations when it merges segments that are SegmentReaders (e.g. when doing normal indexing or optimizing). But when you do IndexWriter.addIndexes(IndexReader...) the listed IndexReaders may not really be per-segment. SegmentMerger should track down all passed in reads down to the lowest level (Segment)Reader (or other atomic readers like SlowMultiReaderWrapper) and then merge. We can then remove most MultiFields usage (except term merging itsself) and clean up the code.\n\nThis especially saves lots of memory for merging norms, as no longer the duplicate norms arrays are created when MultiReaders are used!",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2770",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Optimize SegmentMerger to work on atomic (Segment)Readers where possible",
    "systemSpecification": true,
    "version": ""
}