{
    "comments": [
        {
            "author": "Christian Moen",
            "body": "Find attached a draft patch that replaces term attributes with readings.  I saw in Ohtani-san's Twitter feed that Koji had checked this functionality into lucene-gosen and I'm providing a similar patch here hoping to support the Japanese spell-checking work.\n\nThis patch can also convert katakana readings to romaji and it might make sense to use a romaji representation to do the spell-checking.  We probably also need to deal with misspellings turning into several tokens, and that we need to recompose them using their readings before we do matching.\n\nJust some thoughts...",
            "date": "2012-03-24T21:06:09.863+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "looks good!\n\nwe should also do a little optimization\nto the romanization method... \n\nwe can make instead of String f(String kana)\nand then it making its own stringbuilder,\nthen toStringing that, it can be f(Appendable sb, Charsequence kana)\nand we just pass termAtt.setEmpty() as the 'sb'.\n",
            "date": "2012-03-24T21:16:00.216+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "updated patch with this optimization.",
            "date": "2012-03-25T03:09:44.558+0000",
            "id": 2
        },
        {
            "author": "Christian Moen",
            "body": "Thanks, Robert.\n\nI'm thinking it could be useful to expand this filter with an option that controls how the reading is actually being used.  I see two primary cases for this:\n\n# Use the reading as the term attribute\n# Use the reading as a synonym\n\nThe latter option can be useful for certain applications where we'd like to be able to search by reading and get kanji matches.\n\nExpanding further on this scenario, we would then probably want to support readings in several scripts:\n\n* Romaji (Hepburn)\n* Hiragana\n* Katakana\n\nThis filter should be optional and available as tool to support these applications -- and of course the on-going Japanese spell-check work.\n\nThoughts?",
            "date": "2012-03-25T10:58:53.099+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nThe latter option can be useful for certain applications where we'd like to be able to search by reading and get kanji matches.\n{quote}\n\nThese apps can just copy their text to another field with a different analysis chain (particularly with this filter as-is) and search on both or whatever to get this behavior. This is just as efficient as adding a bunch of code to do the same thing, but keeps all of our analysis much simpler.\n\n",
            "date": "2012-03-25T11:09:32.028+0000",
            "id": 4
        },
        {
            "author": "Christian Moen",
            "body": "Thanks, Robert.  Understood.\n\nI'll run tests and commit this shortly.",
            "date": "2012-03-25T13:48:08.239+0000",
            "id": 5
        },
        {
            "author": "Christian Moen",
            "body": "Committed revision 1305046 on {{trunk}}.  Backporting to {{branch_3x}}.",
            "date": "2012-03-25T14:18:01.848+0000",
            "id": 6
        },
        {
            "author": "Christian Moen",
            "body": "Committed revision 1305051 and 1305052 to {{branch_3x}}.",
            "date": "2012-03-25T14:46:46.026+0000",
            "id": 7
        },
        {
            "author": "Christian Moen",
            "body": "Thanks, Robert and Koji!",
            "date": "2012-03-25T14:50:38.786+0000",
            "id": 8
        }
    ],
    "component": "modules/analysis",
    "description": "Koji and Robert are working on LUCENE-3888 that allows spell-checkers to do their similarity matching using a different word than its surface form.\n\nThis approach is very useful for languages such as Japanese where the surface form and the form we'd like to use for similarity matching is very different.  For Japanese, it's useful to use readings for this -- probably with some normalization.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3915",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Add Japanese filter to replace term attribute with readings",
    "systemSpecification": true,
    "version": "3.6, 4.0-ALPHA"
}