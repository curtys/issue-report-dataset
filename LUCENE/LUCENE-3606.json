{
    "comments": [
        {
            "author": "Simon Willnauer",
            "body": "+1 - this would be awesome",
            "date": "2011-11-28T17:12:42.641+0000",
            "id": 0
        },
        {
            "author": "Yonik Seeley",
            "body": "+1 for read-only readers!",
            "date": "2011-11-28T17:12:59.358+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "+1",
            "date": "2011-11-28T17:30:25.370+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "I appreciate the purity of a truly read-only IndexReader, but there\nare things deleting from IR can do that IW cannot:\n\n  * Real-time deletes: you can delete from IR and have it take\n    immediate effect on a searcher using that IR.  With IW you have to\n    do an NRT reopen instead.\n\n  * Delete by docID... users seem to use/want this (eg ask from time\n    to time if we can do this in IW, which we can't since merging can\n    shift docIDs at any time).\n\n  * IR tells you how many documents were affected by a delete-by-Term.\n    IW cannot, since it buffers and only resolves all deletes in bulk\n    later.\n\nNow... just because IR can do these things that IW cannot.... doesn't\nmean they are compelling / important.  Ie maybe no app out there\nrelies on these special things and so we can lose this functionality?\nI'm not sure...\n\nOn removing IR.setNorm, I agree we should just remove it: in trunk now\nyou can make a custom sim that boost norms \"live\", so we won't lose\nany functionality.  The setNorm code (and the implications -- all the\nper-field normGen, reference counting, scary SR.reopen, etc.) is truly\nhairy; would be great to nuke it all.\n",
            "date": "2011-11-28T19:53:22.833+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "well, just like live changing of scoring factors with setNorm, the first two of these \nthings *could* be done by the user, with Bits/liveDocs/filters right?\n",
            "date": "2011-11-28T20:01:08.337+0000",
            "id": 4
        },
        {
            "author": "Uwe Schindler",
            "body": "Mike,\nI agree that this might affect some apps, but as I said in the introduction: I want to only do this for 4.0 aka Trunk, so we are free to break some strange internal never-documented behaviour. By changing from atomic to per-segment search in 2.9 we already broke lots of incorrectly implemented stuff in Lucene, and these IndexReader deletion behaviour \"features\" are far less often used than Filters tied to top-level IndexSearcher instead the IR passed to getDocIdSet().\n\nDelete by doc id is dangerous and should be prevented. But you can still do this: Create a custom Filter and do the deletion work in getDocIdSet(IndexReader) and pass it as Query to IndexWriter using ConstantScoreQuery. Using the IndexReader passed to getDocIdSet() you can do any funny things on it, just to produce valid docIds. IW will take care of deleteing them after getDocIdSet() returns.\n\nAs Robert said, with FilterIndexReader you can also delete documents without delay (same like in contrib/misc: PKIndexSplitter, MultiPassIndexSplitter) by just overlaying another Bits. To make those hidden documents disappear on disk, too use the aproach decsribed before.\n\nAnd of course, let's nuke my favourite hate-candidate: setNorms()",
            "date": "2011-11-28T22:57:26.333+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "OK I agree!  It looks like in 4.0 it's possible to achieve these same capabilities.  So let's nuke away :)",
            "date": "2011-11-29T00:29:35.806+0000",
            "id": 6
        },
        {
            "author": "Uwe Schindler",
            "body": "OK, I will work on this as soon as I can (next weekend). I will be gald to remove the copy-on-write setNorm stuff in Lucene40 codec and make Lucene3x codec completely read-only (only reading the newest norm file). I hope Robert will possibly help me :-)",
            "date": "2011-12-01T00:31:40.751+0000",
            "id": 7
        },
        {
            "author": "Robert Muir",
            "body": "Hi, I will help too. I think norms itself is a pretty big project to clean up and its a good one to do first.\n\nWe don't have to do it this way, but here is my idea of a way we could do it in commitable steps:\n# remove the setNorm first from IR, and fix all tests.\n# rename NormsWriter to NormsConsumer, rote refactor of norms i/o code into codec as NormsFormat (yes with just one default, and just reads whole byte[])\n# remove IndexFileNames constant and default implementation handles files(), including .sNNN hairiness\n# create SimpleText implementation\n\nThen even more cleanups:\n# split Default implementation to Preflex (with all hairiness like .sNNN) and Lucene40 (clean implementation)\n# clean up 'behind the scenes' api, e.g. NormsFormat presents docvalues API (hardcoded at fixed bytes), SegmentReader does getArray(). IndexReader still returns just byte[]\n# finally, \"holy grail\" where similarities can declare the normalization factor(s) they need, using byte/float/int whatever, and its all unified with the docvalues api. IndexReader.norms() maybe goes away here, and maybe NormsFormat too.\n",
            "date": "2011-12-01T01:00:14.023+0000",
            "id": 8
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nfinally, \"holy grail\" where similarities can declare the normalization factor(s) they need, using byte/float/int whatever, and its all unified with the docvalues api. IndexReader.norms() maybe goes away here, and maybe NormsFormat too.\n{quote}\n\nThinking about this: a clean way to do it would be for Similarity to get a new method:\n{code}\nValueType getValueType();\n{code}\n\nand we would change:\n{code}\nbyte computeNorm(FieldInvertState state);\n{code}\nto:\n{code}\nvoid computeNorm(FieldInvertState state, PerDocFieldValues norm);\n{code}\n\nSims that want to encode multiple index-time scoring factors separately \ncould just use BYTES_FIXED_STRAIGHT. This should be only for some rare\nsims anyway, because a Sim can pull named 'application' specific scoring\nfactors from IR.perDocValues() today already.\n\nIts not too crazy either since sims are already doing their own encoding,\nso e.g. default sim would just use FIXED_INTS_8.\n\nPeople that don't want to mess with bytes or smallfloat could use things\nlike FLOAT_32 if they want and need this.\n\nwe would just change FieldInfo.omitNorms to instead be FieldInfo.normValueType,\nwhich is the value type of the norm (null if its omitted, just like docValueType).\n\nPreflex FieldInfosReader would just set FIXED_INTS_8 or null, based on\nwhether the fieldinfos had omitNorms or not. it doesnt support\nany other types... \n\nFinally then, sims would be own their scoring factors, and we could\neven remove omitNorms from Field/FieldType etc (just use the correct \nscoring algorithm for the field, if you don't want norms, use a sim\nthat doesn't need them for scoring)\n\nThis would remove the awkward/messy situation where every similarity \nimplementation we have has to 'downgrade' itself to handle things like\nif the user decided to omit parts of their formula!",
            "date": "2011-12-01T01:41:27.080+0000",
            "id": 9
        },
        {
            "author": "Uwe Schindler",
            "body": "I created a branch, because this job is horrible: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene3606",
            "date": "2011-12-03T13:17:08.176+0000",
            "id": 10
        },
        {
            "author": "Uwe Schindler",
            "body": "As first step, I removed setNorm/doSetNorm from all IndexReaders, deleted the NormModifier from contrib/misc and modified tests.\n\nI am not sure, if TestBackwardsCompatibility really checks that .sXX files are read correctly, we may need to add tests, as we no longer check the writing of norms anymore in the standard tests. So when reading old indexes with modified norms, we must ensure that the modified norms are read.\n\nWhen changing tests I already removed tests that opened IndexReader in RW mode (like TestBackwards), even if not only norms were modified. But as deletions/commit will also be removed later, this is easier than fixing the test at all.\n\nTestIndexReaderReopen should maybe modified to modify the Index using IndexWriter instead of IndexReader to test reopen functionality better. I removed the whole modifyIndex method from this test, so it is now not going deep enough. We should maybe revert the commit on this file and change modifyIndex to use IndexWriter.",
            "date": "2011-12-03T23:45:14.033+0000",
            "id": 11
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. TestIndexReaderReopen should maybe modified to modify the Index using IndexWriter instead of IndexReader to test reopen functionality better. I removed the whole modifyIndex method from this test, so it is now not going deep enough. We should maybe revert the commit on this file and change modifyIndex to use IndexWriter.\n\nDone.",
            "date": "2011-12-04T00:26:22.920+0000",
            "id": 12
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed removal of IndexReader.deleteDocument*() and undeleteAll() to branch in revision: 1210153:\n\n- Removal of those methods from abstract IR and all its implementations, except SegmentReader\n- SegmentReader only contains doDelete(in) implementation (as used by BufferedDeletes & Co from IW\n- Rewritten lots of tests to use IW.deleteDocuments(Term), some tests commented out and noncommit added - some of them I dont even understand!\n- Contrib/MultiPassIndexSplitter.FakeDeletesIndexReader has a package-private delete/undelete operating on the FixedBitSet",
            "date": "2011-12-04T17:38:31.906+0000",
            "id": 13
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Thinking about this: a clean way to do it would be for Similarity to get a new method:\nI have been talking to robert about moving norms to IDV earlier and the biggest issues we had in our discussion were when Sims have more than one value for a document since we'd need to add custom (nested) fields or similar things which'd be yet another mess further down the road. I think it's totally valid to restrict to a single DV and if you need more than one you simply use a byte variant and impl you custom decoding / encoding in your sim (that seems more performant too IMO).\n\nOnce we moved over to this new API ie. no custom norm code anymore we can actually make use of IDV directly, norms would be just another CFS file and each fields norms would just be a \"virtual\" file in the IDV CFS. All loading and writing could/would be done by the codecs IDV. \n\nYet, I think once we have this we should even go further and remove omitNorms from the Field entirely and let the similarity decide if a field has norms or not. This would remove a lot of hairiness in the code too. I'd really like to see that! ",
            "date": "2011-12-04T20:05:48.754+0000",
            "id": 14
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed removal of IR.commit(...).\n\nStill todo:\n- remove readOnly from DirectoryReader / SegmentReader internals (SR.delete is only called syncrhonized from inside IW)\n- remove deleteionPolicy from DirectoryReader\n- DirectoryReader is now a very simple class, I will change it to extend MultiReader and only implement open() and doOpenIfChanged differrent (check SegemntInfos)",
            "date": "2011-12-04T22:07:10.145+0000",
            "id": 15
        },
        {
            "author": "Uwe Schindler",
            "body": "Clean up IR.open(...) methods to no longer accept readOnly and IndexDeletionPolicy: Core, Contrib, Solr (Modules need fixing, benchmark was broken before, too)\n\nNew branch revision: 1210305",
            "date": "2011-12-05T01:42:58.606+0000",
            "id": 16
        },
        {
            "author": "Uwe Schindler",
            "body": "Robert and I committed more fixes to the remaining tests to the branch.\nI also added the test of LUCENE-3620 to this branch and fixed FilterIndexReader.",
            "date": "2011-12-07T18:52:53.300+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "I tried to fix the remaining tests today, but this seems impossible without IndexReader.deleteDocument(int docId). Some of those tests with commented out by nocommits are so old that its impossible to understand what they are really testing (especially TestAddIndexes and TestIndexWriterMerging). I would simply delete them, because all this stuff is heavyily random tested otherwise (those \"old tests\" have no randomization at all).\n\nThe remaining nocommits are:\n\n{noformat}\n./src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader.java:      // nocommit: change to a real check? see LUCENE-3619\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: move the whole modification stuff to IW\n./src/java/org/apache/lucene/index/SegmentReader.java:  // end nocommit\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: remove deletions from SR\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: remove deletions from SR\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: is this needed anymore by IndexWriter?\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: remove deletions from SR\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: remove deletions from SR\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: remove deletions from SR\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: remove deletions from SR\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: remove deletions from SR\n./src/java/org/apache/lucene/index/SegmentReader.java:  // nocommit: remove deletions from SR\n./src/test/org/apache/lucene/index/TestAddIndexes.java:  /* nocommit: reactivate these tests\n./src/test/org/apache/lucene/index/TestDeletionPolicy.java:  /* nocommit: fix this test, I don't understand it!\n./src/test/org/apache/lucene/index/TestIndexWriterMerging.java:  /* nocommit: Fix tests to use an id and delete by term\n./src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java:  /* nocommit: Fix tests to use an id and delete by term\n./src/test/org/apache/lucene/index/TestSizeBoundedForceMerge.java:  /* nocommit: Fix tests to use an id and delete by term\n./src/test/org/apache/lucene/index/TestSizeBoundedForceMerge.java:  /* nocommit: Fix tests to use an id and delete by term\n{noformat}\n\nThe parts in SegmentReader should be made TODO and a new issue should be opened, which removed RW from SegmentReader (Mike?). The tests should be deleted as described above. Otherwise the branch seems finalized otherwise so I would like to merge back to trunk asap.",
            "date": "2011-12-07T23:27:10.702+0000",
            "id": 18
        },
        {
            "author": "Robert Muir",
            "body": "Tests are all fixed... i think this one is close.",
            "date": "2011-12-08T18:03:02.147+0000",
            "id": 19
        },
        {
            "author": "Uwe Schindler",
            "body": "Thanks to Robert for fixing the last tests.\n\nThis is the patch of the branch merged back to trunk. I will try to commit this ASAP, as it might get outdated very fast.\n\nPlease review the changes!\n\nAfter committing I will keep the issue open and add deprecations to Lucene 3.x on most methods removed in trunk.",
            "date": "2011-12-08T18:48:25.066+0000",
            "id": 20
        },
        {
            "author": "Michael McCandless",
            "body": "+1!  Nice work guys... I love all the minuses :)",
            "date": "2011-12-08T19:13:57.802+0000",
            "id": 21
        },
        {
            "author": "Simon Willnauer",
            "body": "+1 I love that Norms are under codec now! ",
            "date": "2011-12-08T19:54:55.351+0000",
            "id": 22
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed to trunk revision: 1212292",
            "date": "2011-12-09T09:13:53.453+0000",
            "id": 23
        },
        {
            "author": "Uwe Schindler",
            "body": "Patch that hides an accidently visible method IndexReader.open with Directory and IndexCommit again.\n\nCommitted in trunk revision: 1212294",
            "date": "2011-12-09T09:20:05.279+0000",
            "id": 24
        },
        {
            "author": "Uwe Schindler",
            "body": "I will post a patch later adding the needed deprecations to 3.x! This issue is kept open until the deprecations are solved.",
            "date": "2011-12-09T09:26:29.654+0000",
            "id": 25
        },
        {
            "author": "Uwe Schindler",
            "body": "Here a patch that deprecates the removed methods in 3x:\n- delete*, undeleteAll\n- IR.open(..., readonly,...)\n- adds missing non-readOnly IR.open()\n- for now I also deprecated setNorm(). If I would not deprecate it, it would be inconsistent, as setNorm only works with readOnly=false - but you can never call that wthout a deprecation warning. I think we should leave setNorm deprecated.\n\nI did not fix the tests to not use deprecated readOnly=true IR.open()! :(\n\nI found a serious API glitch in 3.x with openIfChanged:\n- the base class defines doOpenIfChanged(boolean readOnly), but MultiReader and ParallelReader \"override\" this method with a signature doOpenIfChanged(doClone) and missing @Override. This makes consumers calling IR.openIfChanged(boolean readOnly) do the wrong thing. Instead they should get UOE like for the other unimplemented doOpenIfChanged methods in MR and PR.",
            "date": "2011-12-09T09:56:22.303+0000",
            "id": 26
        },
        {
            "author": "Uwe Schindler",
            "body": "Updated patch, some javadoc changes (deprecated method replacements) and one more missing method.",
            "date": "2011-12-09T10:52:01.900+0000",
            "id": 27
        },
        {
            "author": "Uwe Schindler",
            "body": "Final patch including changes.txt. Will commit this now.",
            "date": "2011-12-09T17:44:03.329+0000",
            "id": 28
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed 3.x revision: 1212539",
            "date": "2011-12-09T17:45:08.692+0000",
            "id": 29
        },
        {
            "author": "Uwe Schindler",
            "body": "Merged changes to trunk revision: 1212545\n\nThis issue is now finished, thanks to Robert for the great help during fixing tests and funny discussions :-)\n*edit* ...and for porting norms to codec! *edit*",
            "date": "2011-12-09T17:55:01.485+0000",
            "id": 30
        }
    ],
    "component": "core/index",
    "description": "As we change API completely in Lucene 4.0 we are also free to remove read-write access and commits from IndexReader. This code is so hairy and buggy (as investigated by Robert and Mike today) when you work on SegmentReader level but forget to flush in the DirectoryReader, so its better to really make IndexReaders readonly.\n\nCurrently with IndexReader you can do things like:\n- delete/undelete Documents -> Can be done by with IndexWriter, too (using deleteByQuery)\n- change norms -> this is a bad idea in general, but when we remove norms at all and replace by DocValues this is obsolete already. Changing DocValues should also be done using IndexWriter in trunk (once it is ready)",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3606",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "OTHER",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Make IndexReader really read-only in Lucene 4.0",
    "systemSpecification": true,
    "version": "4.0-ALPHA"
}