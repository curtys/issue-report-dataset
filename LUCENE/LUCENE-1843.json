{
    "comments": [
        {
            "author": "Uwe Schindler",
            "body": "Patch - Will commit soon.",
            "date": "2009-08-22T12:36:11.207+0000",
            "id": 0
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed revision: 806847",
            "date": "2009-08-22T12:40:34.909+0000",
            "id": 1
        },
        {
            "author": "Uwe Schindler",
            "body": "There are some more tests, that fail with onlyUseNewAPI in contrib/analyzers.",
            "date": "2009-08-23T17:02:07.311+0000",
            "id": 2
        },
        {
            "author": "Uwe Schindler",
            "body": "From a private mail with Robert Muir:\n\nyes, all of what you mentioned are problems, and testing for\nattributes that should be there is good in my opinion too.\n\nI noticed the shingle problem as well, it was strange to test\ntermAtt.toString() and expect position increments or types to appear\n:/\n\none reason I asked about this, is at some point it would be nice to\ntry to factor test cases in lucene contrib. currently, they all have\nsame helper methods such as assertAnalyzesTo and this is silly in my\nopinion.\n\nOn Sun, Aug 23, 2009 at 12:57 PM, Uwe Schindler<uwe@thetaphi.de> wrote:\n> There are more problems. The test with getAttribute is good, if you are\n> really sure, if the attribute is really available and want assert this. In\n> all other cases addAttribute should be used to consume a TokenStream. The\n> changed ones were problematic, because they used foreign TokenStreams, do\n> not for sure have all these attributes.\n>\n> I thought, all tests in contrib use LuceneTestCase as superclass, but they\n> use the standard junit class. Because of that I did not notice when I put\n> setOnlyUseNewAPI(true) into LuceneTestCase.setUp(), that they are run with\n> the default false setting.\n>\n> Other problems in these tests are, that some (shingle tests) use\n> TermAttribute.toString() which looks different if the attribute is\n> implemented by TermAttributeImpl (newAPI=true) or Token (newAPI=false).",
            "date": "2009-08-23T17:04:34.745+0000",
            "id": 3
        },
        {
            "author": "Uwe Schindler",
            "body": "Patch that makes all contrib/analyzer tests that work with TokenStreams subclasses of BaseTokenStreamTestCase. This superclass now has a lot of utility methods to check TokenStreams using arrays of strings/ints.\n\nThe patch also contains a better version of SingleTokenTokenStream, using the Token.copyTo() function and a Token/TokenWrapper instance as attribute implementation.\n\nThis patch may still include some unused imports, had no time to check this manually (I am the person, that codes with Notepad...)",
            "date": "2009-08-23T23:27:29.605+0000",
            "id": 4
        },
        {
            "author": "Uwe Schindler",
            "body": "Now the right file.\n\nWill commit tomorrow.",
            "date": "2009-08-23T23:28:26.861+0000",
            "id": 5
        },
        {
            "author": "Uwe Schindler",
            "body": "- Small updates\n- forget conversion of two filters in contrib/memory\n\nHope this is the last patch.",
            "date": "2009-08-24T00:06:31.923+0000",
            "id": 6
        },
        {
            "author": "Uwe Schindler",
            "body": "Some more tests converted. Also optimized Token.copyTo() to also respect TokenWrapper as target.",
            "date": "2009-08-24T08:53:15.451+0000",
            "id": 7
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed revision: 807190",
            "date": "2009-08-24T12:45:09.027+0000",
            "id": 8
        }
    ],
    "component": "modules/analysis",
    "description": "This patch converts some remaining tests to the new TokenStream API and non-deprecated classes.\nThis patch also enhances AttributeImpl.copyTo() of Token and TokenWrapper to also support copying e.g. TermAttributeImpl into Token. The target impl must only support all interfaces but must not be of the same type. Token and TokenWrapper use optimized coping without casting to 6 interfaces where possible.\nMaybe the special tokenizers in contrib (shingle matrix and so on using tokens to cache may be enhanced by that). Also Yonik's request for optimized copying of states between incompatible AttributeSources may be enhanced by that (possibly a new issue).",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1843",
    "issuetypeClassified": "OTHER",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Convert some tests to new TokenStream API, better support of cross-impl AttributeImpl.copyTo()",
    "systemSpecification": true,
    "version": "2.9"
}