{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "+1\n\nWe very much need this now -- it should be strongly (statically) typed, whether you are using an AtomicIndexReader vs CompositeIndexReader.\n\nAnd I agree CompositeIndexReader should feel more like a Collection than what IR is today.",
            "date": "2011-01-11T18:00:34.094+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "bq. (SlowMultiReaderWrapper - please rename, the name is really ugly; or Multi*)\n\nMy problem with Multi* is that this makes things sound cool and powerful.\nIf they are really slow transition mechanisms, I prefer Slow* as it will actually discourage their use.\n\nBut I agree with this issue in general and it would be great for it to be cleaned up.\n",
            "date": "2011-01-11T18:02:01.341+0000",
            "id": 1
        },
        {
            "author": "Earwin Burrfoot",
            "body": "bq. On the other side, atomic readers do not need reopen logic anymore? When a segment changes, you need a new atomic reader?\nThere is a freakload of places that \"upgrade\" SegmentReader in various ways, with deletions guilty only for the part of the cases. I'll try getting back to LUCENE-2355 at the end of the week.",
            "date": "2011-01-11T22:30:47.223+0000",
            "id": 2
        },
        {
            "author": "Uwe Schindler",
            "body": "Any comments about removing write access from IndexReaders? I think setNorms() will be removed soon, but how about the others like deleteDocument()? I would propose to also make all IndexReaders simply *readers* not writers?",
            "date": "2011-01-15T10:26:14.857+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "bq. I think setNorms() will be removed soon\n\nWhy do you think this?\n\nOn the norms cleanup issue, i only removed setNorm(float), because its completely useless.\nAll it did was call Similarity.getDefault().encode(float) + setNorm(byte).\n",
            "date": "2011-01-15T14:30:37.591+0000",
            "id": 4
        },
        {
            "author": "Uwe Schindler",
            "body": "I was talking about replacing norms by CSF, maybe It's just not soon.",
            "date": "2011-01-15T14:50:22.849+0000",
            "id": 5
        },
        {
            "author": "Robert Muir",
            "body": "Ah, ok. sorry i was confused. Still, i think we would need this method (somewhere) even \nwith CSF, so that people can change the norms and they instantly take effect for searches.\n",
            "date": "2011-01-15T15:18:05.619+0000",
            "id": 6
        },
        {
            "author": "Earwin Burrfoot",
            "body": "bq. Any comments about removing write access from IndexReaders? I think setNorms() will be removed soon, but how about the others like deleteDocument()? I would propose to also make all IndexReaders simply readers not writers? \n\nVoting with all my extremities - yes!!",
            "date": "2011-01-15T16:34:58.769+0000",
            "id": 7
        },
        {
            "author": "Earwin Burrfoot",
            "body": "bq. Still, i think we would need this method (somewhere) even with CSF, so that people can change the norms and they instantly take effect for searches.\nThis still puzzles me. I can strain my imagination, and get people who just need to change norms without reindexing.\nBut doing this and *requiring* instant turnaround? Kid me not :)\n",
            "date": "2011-01-15T16:49:39.218+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "I don't think we should remove setNorm/deleteDocuments, even from the composite reader class.\n\nDeleting docs from IR has advantages over deleting from IW: the change is \"live\" to any searches running on that IR; you get an immediate count of how many docs were deleted; you can delete by docID.\n\nsetNorm is also useful in that it can be use to boost docs (globally), live, if that reader is being used for searching.  When/if we cutover norms -> doc values we'll have to decide what to do about setNorm...\n\nAt a higher level, for this \"strong typing of atomic vs composite IRs\", we shouldn't try to change functionality -- let's just do a rote refactoring, such that methods that now throw UOE on IR are moved to the atomic reader only.\n\nSeparately we can think about whether existing functions should be dropped...",
            "date": "2011-01-15T16:57:44.705+0000",
            "id": 9
        },
        {
            "author": "Marvin Humphrey",
            "body": "> Deleting docs from IR has advantages over deleting from IW: the change is\n> \"live\" to any searches running on that IR; you get an immediate count of how\n> many docs were deleted; you can delete by docID.\n\nAlternate plan:\n\n  * Move responsibility for deletions to a pluggable DeletionsReader\n    subcomponent of SegmentReader.\n  * Have the default DeletionsReader be read-only.\n  * People who need the esoteric functionality described above can use a\n    subclass of DeletionsReader.\n",
            "date": "2011-01-15T19:07:30.357+0000",
            "id": 10
        },
        {
            "author": "Earwin Burrfoot",
            "body": "APIs have to be there still. All that commity, segment-deletery, mutabley stuff (that spans both atomic and composite readers).\nSo, while your plan is viable, it won't remove that much cruft.",
            "date": "2011-01-15T20:52:04.772+0000",
            "id": 11
        },
        {
            "author": "Uwe Schindler",
            "body": "I try to do this now, Robert will help.\n\nMost crap is removed form IndexReader, so this should be easy now. We should use AtomicIndexReader and CompositeIndexReader.\n\n- IndexReader base class only contains the methods that can actually be implemented in *every* reader.\n- The current BaseMultiReader (pkg-private) would be the later CompositeIndexReader\n- AtomicIndexReader is also abstract, SegmentReader and SlowMultiReaderWrapper would implement it.\n- The static open methods should maybe in a separate class or the abstract IndexReader base with the limited API, but they would return CompositeIndexReader\n- FilterIndexReader could be split in two classes, but a FilterMultiReader makes no sense :-) FilterIndexReader will be FilterAtomicIndexReader (also the superclass of SlowMultiReaderWrapper)\n",
            "date": "2011-12-14T22:35:13.412+0000",
            "id": 12
        },
        {
            "author": "Simon Willnauer",
            "body": "uwe are you gonna work on this?",
            "date": "2012-01-17T21:19:26.583+0000",
            "id": 13
        },
        {
            "author": "Uwe Schindler",
            "body": "I will hopefully start this weekend. I just have a schedule currently that has no slots left for that.\n\nRobert and I wanted to start a branch soon, maybe I simply do that as first step soon!",
            "date": "2012-01-17T22:30:02.355+0000",
            "id": 14
        },
        {
            "author": "Uwe Schindler",
            "body": "Simon: Just to inform you, I am working on this. Currently I have a heavy broken checkout that does no longer compile at all :( Working, working, working... It's a mess!\n\nOnce I have something intially compiling for core (not tests), I will create a branch!",
            "date": "2012-01-21T16:19:07.607+0000",
            "id": 15
        },
        {
            "author": "Uwe Schindler",
            "body": "I created the branch at [https://svn.apache.org/repos/asf/lucene/dev/branches/lucene2858] and committed my first steps:\n\n- Add CompositeIndexReader and AtomicIndexReader\n- Moved methods around, still not yet finished (see below)\n- DirectoryReader is public now and is returned by IR.open() and IW.getReader()\n\nTODO:\n\n- IR.openIfChanged makes no sense for any reader other than DirectoryReader, let's move it also there\n- isCurrent and getVersion() is also useless for atomic readers and composite readers except DR\n- The strange generics in ReaderContext caused by the final field will go away, when changing reader field to aaccessor method returning the correct type (by return type overloading).\n\nComments welcome and also heavy committing.\n",
            "date": "2012-01-21T23:50:54.460+0000",
            "id": 16
        },
        {
            "author": "Uwe Schindler",
            "body": "Some TODOs fixed:\n\n- -The strange generics in ReaderContext caused by the final field will go away, when changing reader field to aaccessor method returning the correct type (by return type overloading).-\n- Some refactoring done on docFreq()\n- Moved the ReaderContext impls to the corresponding abstract reader class: CompositeReaderContext -> CompositeIndexReader, AtomicReaderContext -> AtomicIndexReader\n",
            "date": "2012-01-22T12:56:20.280+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "More TODOs:\n\n- Rename SlowMultiReaderWrapper -> SlowCompositeReaderWrapper (as its not only for MultiReaders, also other CompositeIndexReaders like DirectoryReader. Name is not in line with our current naming\n- All version/commit/reopen stuff should go into DirectoryReader, its useless for the abstract IR interfaces",
            "date": "2012-01-22T12:59:40.602+0000",
            "id": 18
        },
        {
            "author": "Uwe Schindler",
            "body": "I now fixed the branch's test-framework and all remaining TODOs about the API.\n\nNow the horrible stupid slave-work to port all test starts. I assume the API is now fixed, as nobody complained after one week.",
            "date": "2012-01-29T14:17:28.623+0000",
            "id": 19
        },
        {
            "author": "Yonik Seeley",
            "body": "bq.  SlowMultiReaderWrapper - please rename, the name is really ugly; or Multi*\n\n+1, the Slow* is misleading as it makes it seem like there's a faster way you should be doing it.\nCompositeReaderWrapper should be fine.  And no, it doesn't sound too \"cool\" for the hypothetical developers who use that as a criteria when coding ;-)\n\nOther possibilities include AtomicReaderEmulator, AtomicEmulatorReader, CompositeAsAtomicReader, etc",
            "date": "2012-01-29T15:38:34.075+0000",
            "id": 20
        },
        {
            "author": "Robert Muir",
            "body": "Can we please do some eclipse-renames like:\n\nAtomicIndexReader -> AtomicReader\nAtomicIndexReader.AtomicReaderContext -> AtomicReader.Context\n\nThe verbosity of the api is killing me :)\n",
            "date": "2012-01-29T22:58:17.094+0000",
            "id": 21
        },
        {
            "author": "Michael McCandless",
            "body": "+1 for those names.",
            "date": "2012-01-29T23:06:58.617+0000",
            "id": 22
        },
        {
            "author": "Uwe Schindler",
            "body": "Jaja, will fix this...",
            "date": "2012-01-29T23:25:45.127+0000",
            "id": 23
        },
        {
            "author": "Uwe Schindler",
            "body": "I renamed the enclosing classes and also removed the public ctors from ReaderContexts (to prevent stupid things already reported on mailing lists).\n\nThe renameing of ReaderContexts all to the same name Context, but with different enclosing class is a refactoring, Eclipse cannot do (it creates invalid code). It seems only NetBeans can do this, I will try to find a solution. The problem is that Eclipse always tries to import the inner class, what causes conflicts.\n\nFinally, e.g. the method getDocIdSet should look like getDocIdSet(AtomicReader.Context,...) [only importing AtomicReader], but Eclipse always tries to use Context [and import oal.AtomicReader.Context]. At the end we should have abstract IndexReader.Context, AtomicReader.Context, CompositeReader.Context.\n\nWill go to bed now.",
            "date": "2012-01-30T01:27:50.346+0000",
            "id": 24
        },
        {
            "author": "Uwe Schindler",
            "body": "After sleeping one more night about it, the easiest and most simple way to remove the stupid verbosity in imports:\n\nI will move the ReaderContexts out of their enclosing class and make a top-level class without ctor out of it. Then import statements look nice. The RCs are now so important for search, so they should be on its own.",
            "date": "2012-01-30T10:08:52.805+0000",
            "id": 25
        },
        {
            "author": "Uwe Schindler",
            "body": "Here the final patch. Thanks for the good work and lots of help from Robert and Mike.\n\nAs this patch contains heavy changes, we will commit it as soon as possible so work can go on. It would be nice, if you would not commit anything until this is done.\n\nThere are some minor issues open:\n- DirectoryReader is final and has only static factory methods. It is not possible to subclass it in any way. The problem is mainly Solr, as Solr accesses directory(), IndexCommits,... and therefore cannot work on abstract IndexReader anymore. This should be changed, by e.g. handling reopening in the IRFactory, also versions, commits,... Currently its not possible to implement any other IRFactory that returns something else.\n- The PayloadProcessorProvider has a broken API, this should be fixed. The current patch mimics the old behaviour, but not 100%.\n- ParallelReader is now atomic. We should add a sugar wrapper method to allow synchronized composite readers (with same segment sizes) to be aligned with MultiReaders or wrapped by Slow.\n\nThe remaining issues will be fixed in later issues!",
            "date": "2012-01-30T22:21:04.161+0000",
            "id": 26
        },
        {
            "author": "Uwe Schindler",
            "body": "Patch with nocommits removed.",
            "date": "2012-01-30T22:37:01.967+0000",
            "id": 27
        },
        {
            "author": "Robert Muir",
            "body": "Thanks for all the work here Uwe! I think its a great step forward. \nThe previous situation where half the methods were UOE is really unreleasable.",
            "date": "2012-01-30T23:02:43.976+0000",
            "id": 28
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed trunk revision: 1238085",
            "date": "2012-01-30T23:38:42.094+0000",
            "id": 29
        },
        {
            "author": "Michael McCandless",
            "body": "Nice work guys!",
            "date": "2012-01-31T00:01:54.778+0000",
            "id": 30
        },
        {
            "author": "Uwe Schindler",
            "body": "Patch that adds FC insanity checking for slow wrappers back. Will commit now.",
            "date": "2012-01-31T00:32:54.658+0000",
            "id": 31
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed trunk revision: 1238112",
            "date": "2012-01-31T00:37:11.336+0000",
            "id": 32
        },
        {
            "author": "Robert Muir",
            "body": "I think somehow ensureOpen is broken here in some situations (possibly slowmultireaderwrapper):\n\n{noformat}\nant test -Dtestcase=TestReaderClosed -Dtestmethod=test -Dtests.seed=42907a63342da06b:-1490dd5f0d0f26d9:-7e3c360ea2d32539 -Dargs=\"-Dfile.encoding=UTF-8\"\n{noformat}\n\n",
            "date": "2012-01-31T19:16:57.609+0000",
            "id": 33
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Robert, this patch fixes the problem:\n\nSlowMultiReaderWrapper creates the fields and liveDocs on its ctor (as its expensive) and reuses. This is no problem, but the test did something very bad: It closed not the slow reader but the wrapped DirectoryReader. As fields() was not delegated to the DR or MultiFields with DR, Slow returned its own cached instance. Slow's ensureOpen was not throwing Ex, as it was still open.\n\nTheoretically, Slow* should incRef the underlying indexreader and decRef on close(). But that would require, that you close the SlowReader after wrapping.\n\nThe current solution is not optimal but makes it easy to wrap without explicitely closing the slow wrapper.\n\nThe fix was to call in.ensureOpen() in slow before the cached instance was returned.",
            "date": "2012-01-31T20:21:04.929+0000",
            "id": 34
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed fix in revision: 1238788\nI removed the extra in.ensureOpen() for hasDeletions(), as this was only a null-check.",
            "date": "2012-01-31T20:24:09.661+0000",
            "id": 35
        },
        {
            "author": "Michael McCandless",
            "body": "Not entirely sure why but it looks like the commits here slowed down our NRT reopen latency.  If you look at the nightly bench graph: http://people.apache.org/~mikemccand/lucenebench/nrt.html and click + drag from Jan 2012 to today, annotation R shows we increased from ~46 msec NRT reopen latency to ~50 msec ... could just be hotspot being upset...",
            "date": "2012-06-01T17:48:43.453+0000",
            "id": 36
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Not entirely sure why but it looks like the commits here slowed down our NRT reopen latency.\n\nOK, sorry, I was wrong about this!\n\nI went back and re-ran the NRTPerfTest and isolated the slowdown to LUCENE-3728 (also committed on the same day)... it was because we lost the SegmentInfo.sizeInBytes caching... but then in LUCENE-4055 we got it back and we got the performance back ... so all's well that ends well :)",
            "date": "2012-06-03T09:59:31.328+0000",
            "id": 37
        },
        {
            "author": "Uwe Schindler",
            "body": "Thanks Mike for taking care. For me this looked crazy, because refactoring like this should not change perf.\n\nThis explains the change back  after 4055, I thought un-compressed oops responsible for the speedup.",
            "date": "2012-06-03T10:16:03.036+0000",
            "id": 38
        },
        {
            "author": "Michael McCandless",
            "body": "bq. This explains the change back after 4055, I thought un-compressed oops responsible for the speedup.\n\nThat's what I thought too (and I was very confused that uncompressed oops would improve things)!  But LUCENE-4055 landed on the same day I turned off uncompressed oops... so I think all mysteries are now explained.",
            "date": "2012-06-03T10:19:42.111+0000",
            "id": 39
        }
    ],
    "component": "",
    "description": "With current trunk, whenever you open an IndexReader on a directory you get back a DirectoryReader which is a composite reader. The interface of IndexReader has now lots of methods that simply throw UOE (in fact more than 50% of all methods that are commonly used ones are unuseable now). This confuses users and makes the API hard to understand.\n\nThis issue should split \"atomic readers\" from \"reader collections\" with a separate API. After that, you are no longer able, to get TermsEnum without wrapping from those composite readers. We currently have helper classes for wrapping (SlowMultiReaderWrapper - please rename, the name is really ugly; or Multi*), those should be retrofitted to implement the correct classes (SlowMultiReaderWrapper would be an atomic reader but takes a composite reader as ctor param, maybe it could also simply take a List<AtomicReader>). In my opinion, maybe composite readers could implement some collection APIs and also have the ReaderUtil method directly built in (possibly as a \"view\" in the util.Collection sense). In general composite readers do not really need to look like the previous IndexReaders, they could simply be a \"collection\" of SegmentReaders with some functionality like reopen.\n\nOn the other side, atomic readers do not need reopen logic anymore? When a segment changes, you need a new atomic reader? - maybe because of deletions thats not the best idea, but we should investigate. Maybe make the whole reopen logic simplier to use (ast least on the collection reader level).\n\nWe should decide about good names, i have no preference at the moment.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2858",
    "issuetypeClassified": "REFACTORING",
    "issuetypeTracker": "OTHER",
    "priority": "Blocker",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Separate SegmentReaders (and other atomic readers) from composite IndexReaders",
    "systemSpecification": true,
    "version": ""
}