{
    "comments": [
        {
            "author": "Mark Miller",
            "body": "Have a proposed patch? Doesn't look easy - I don't think AttributeSource is necessarily attached to any TokenStream - so you would have to trap it lower and rework the exception. I don't see the clean path for this myself. Though I certainly agree with its use.",
            "date": "2009-08-20T16:13:25.873+0000",
            "id": 0
        },
        {
            "author": "Tim Smith",
            "body": "Looked a little closer on this and it looks like if the root TokenStream does not addAttribute() for all attributes expected by the indexer, this exception occurs\n\nI suppose if the Indexer called addAttribute() instead of getAttribute() this wouldn't happen (attributes not provided by TokenStream, but required by Indexer would be initialized at index time (and would remain \"empty\"))",
            "date": "2009-08-20T17:07:30.151+0000",
            "id": 1
        },
        {
            "author": "Tim Smith",
            "body": "Updated getAttribute() on AttributeSource as follows to find the source of my pain:\n{code}\n  /**\n   * The caller must pass in a Class&lt;? extends Attribute&gt; value. \n   * Returns the instance of the passed in Attribute contained in this AttributeSource\n   * \n   * @throws IllegalArgumentException if this AttributeSource does not contain the\n   *         Attribute\n   */\n  public AttributeImpl getAttribute(Class attClass) {\n    AttributeImpl att = (AttributeImpl) this.attributes.get(attClass);\n    if (att == null) {\n      throw new IllegalArgumentException(getClass().getName() + \" does not have the attribute '\" + attClass + \"'.\");\n    }\n\n    return att;\n  }\n{code}\n\nI see that this could end up being an arbitrary \"org.apache.lucene.util.AttributeSource\" though if you aren't fully integrating the new api\n",
            "date": "2009-08-20T17:14:21.780+0000",
            "id": 2
        },
        {
            "author": "Mark Miller",
            "body": "Gotchya - in the summary it said you were looking for the TokenStream rather than the AttributeSource. I didn't follow that you could figure that out by knowing the AttributeSource impl name.",
            "date": "2009-08-20T17:29:44.574+0000",
            "id": 3
        },
        {
            "author": "Uwe Schindler",
            "body": "In principle you should always use addAttribute() when consuming a TokenStream, if the attribute is unknown, it will be created empty - no problem. MostLucene-internal code uses it in that way. getAttribute() is currently only used for very special cases (e.g. in tests, to check if an attribute was really added). But there seems to be one relict of getAttribute in the code. To fix this bug, I should replace the getAttribute() call in the indexer by addAttribute(). I will provide a patch for that.\n\nIf you have an unknown TokenStream instance you will never know, which of the attributes are really used. If you want to optimize this, you could check before, if the attribute is really used and e.g. exclude some code paths with very complicated calculations based on these missing attributes.\n\nI will also add an JavaDoc comment for this. The \"more helpful\" error message is in my opinion not needed, because you cannot find out which of the filter/stream in the chain is missing the attribute, because all in the chain use the same Attribute instances.",
            "date": "2009-08-20T20:41:41.281+0000",
            "id": 4
        },
        {
            "author": "Tim Smith",
            "body": "I agree that a 'more helpful' error message may not be so helpful\n\ni refactored all my code to use the same \"new AttributeSource()\"  for all TokenStreams for the same Document anyway, so all it would tell me is \"AttributeSource\" missing parameter",
            "date": "2009-08-20T20:44:41.917+0000",
            "id": 5
        },
        {
            "author": "Uwe Schindler",
            "body": "Attached is a first patch, that fixes the wrong getAttribute() calss without checking, if the attribute is available.\nFor testing, I added a system property to LuceneTestCase \"TokenStream.onlyUseNewAPI\", that can be set to true. When I have done this (and explicitely excluded some tests like the deprecated Tee/Sink test and the extra backwards test) using this switch, especially Highlighter fails because of assuming that all Attributes are always there. With onlyUseNewAPI=false, the tests pass, because the used Attribute Impl is Token, which implements all attributes.\nThere is still one test (TestMappingCharFilter) using TokenStream.next(), which I fix tomorrow to use incrementToken. I am currently thinking about testing all affected tests automatically two times with both settings. Maybe I add a special LuceneTestCase subclass, that runs all tests two times. All test depending on TokenStreams like the indexer should simply subclass this special class.\nFor the beginning, the system property is ON. I added it to common-build as true for testing. How do I pass the command line parameters from ant itsself to the underlying tests?",
            "date": "2009-08-20T21:47:10.547+0000",
            "id": 6
        },
        {
            "author": "Uwe Schindler",
            "body": "New patch that fixes also the two failing tests by setting onlyUseNewAPI to false for them.\n\nI will now create a new LuceneTestCase subclass, that tries tests with old and new api automatically.",
            "date": "2009-08-21T10:41:22.179+0000",
            "id": 7
        },
        {
            "author": "Uwe Schindler",
            "body": "Here is my idea for testing both apis of TokenStreams. All testcases that should tests both the backwards layer using Token instances and only the new API (this are *all* analyzer tests, TestIndexWriter, highlighter and query parser test and a few more), should subclass this class instead of LuceneTestCase.",
            "date": "2009-08-21T11:58:57.271+0000",
            "id": 8
        },
        {
            "author": "Uwe Schindler",
            "body": "Here a new patch: The default LuceneTestCase uses onlyUseNewAPI=false (which is the default). Some tests were rewritten to use a special TestCase superclass (see previous file, but updated in this patch), that runs all tests two times with this flag enabled and disabled.\n\nI converted all core analyzer tests, DocumentsWriter and the likely failing highlighter, queryparser and memory index tests.",
            "date": "2009-08-21T14:55:13.958+0000",
            "id": 9
        },
        {
            "author": "Uwe Schindler",
            "body": "I will commit this later, if you like the possibility to run several tests two times with backwards layer enabled and not.",
            "date": "2009-08-22T08:03:34.846+0000",
            "id": 10
        },
        {
            "author": "Uwe Schindler",
            "body": "The new base test case has now support to only run the tests twice for a Set of test names. I will commit this now.",
            "date": "2009-08-22T12:02:28.258+0000",
            "id": 11
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed Revision: 806844",
            "date": "2009-08-22T12:05:48.414+0000",
            "id": 12
        }
    ],
    "component": "modules/analysis",
    "description": "when seting \"use only new API\" for TokenStream, i received the following exception:\n\n{code}\n   [junit] Caused by: java.lang.IllegalArgumentException: This AttributeSource does not have the attribute 'interface org.apache.lucene.analysis.tokenattributes.TermAttribute'.\n    [junit] \tat org.apache.lucene.util.AttributeSource.getAttribute(AttributeSource.java:249)\n    [junit] \tat org.apache.lucene.index.TermsHashPerField.start(TermsHashPerField.java:252)\n    [junit] \tat org.apache.lucene.index.DocInverterPerField.processFields(DocInverterPerField.java:145)\n    [junit] \tat org.apache.lucene.index.DocFieldProcessorPerThread.processDocument(DocFieldProcessorPerThread.java:244)\n    [junit] \tat org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:772)\n    [junit] \tat org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:755)\n    [junit] \tat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:2613)\n{code}\n\nHowever, i can't actually see the culprit that caused this exception\n\nsuggest that the IllegalArgumentException include \"getClass().getName()\" in order to be able to identify which TokenStream implementation actually caused this\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1825",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Incorrect usage of AttributeSource.addAttribute/getAttribute leads to failures when onlyUseNewAPI=true",
    "systemSpecification": true,
    "version": "2.9"
}