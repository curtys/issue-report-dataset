{
    "comments": [
        {
            "author": "Robert Muir",
            "body": "I think its strange that tokenizer allows a null reader, but we can forget about that temporarily and nuke this default ctor.\n\nThen, we can put assert reader != null in the 'real' ctor and see which analyzers fail.\nMaybe its only PatternAnalyzer and it could be implemented differently/properly (e.g. make a TokenStream).\n\nThen we could also keep our assert.",
            "date": "2012-02-09T16:43:17.157+0000",
            "id": 0
        },
        {
            "author": "Uwe Schindler",
            "body": "As far as I remember this was because of Solr. Some tokenizers in Solr were originally TokenStreams. After we restructured all of them, there is no reason to keep default ctor or allow null at all.",
            "date": "2012-02-09T17:15:12.597+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "Here's an initial patch.  Tests pass, but, it's hacky to pass new StringReader(\"\") to all those test tokenizers... really they should be TokenStreams instead.\n",
            "date": "2012-02-09T17:47:41.820+0000",
            "id": 2
        },
        {
            "author": "Robert Muir",
            "body": "updated patch: i tried to clean up these tests some. I think its good to go now.",
            "date": "2012-02-10T13:58:45.998+0000",
            "id": 3
        },
        {
            "author": "Michael McCandless",
            "body": "+1\n\nI like CannedTokenStream :)",
            "date": "2012-02-10T18:34:27.808+0000",
            "id": 4
        }
    ],
    "component": "",
    "description": "I was working on a new Tokenizer... and I accidentally forgot to call super(input) (and super.reset(input) from my reset method)... which then meant my correctOffset() calls were silently a no-op; this is very trappy.\n\nFortunately the awesome BaseTokenStreamTestCase caught this (I hit failures because the offsets were not in fact being corrected).\n\nOne minimal thing we can do (but it sounds like from Robert there may be reasons why we can't) is add {{assert input != null}} in Tokenizer.correctOffset:\n\n{noformat}\nIndex: lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java\n===================================================================\n--- lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java\t(revision 1242316)\n+++ lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java\t(working copy)\n@@ -82,6 +82,7 @@\n    * @see CharStream#correctOffset\n    */\n   protected final int correctOffset(int currentOff) {\n+    assert input != null: \"subclass failed to call super(Reader) or super.reset(Reader)\";\n     return (input instanceof CharStream) ? ((CharStream) input).correctOffset(currentOff) : currentOff;\n   }\n{noformat}\n\nBut best would be to remove the default ctor that leaves input null...",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3766",
    "issuetypeClassified": "OTHER",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Remove/deprecate Tokenizer's default ctor",
    "systemSpecification": true,
    "version": ""
}