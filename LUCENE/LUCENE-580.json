{
    "comments": [
        {
            "author": "Karl Wettin",
            "body": "Field.java.diff\nDocumentWriter.java.diff",
            "date": "2006-05-27T12:57:37.000+0000",
            "id": 0
        },
        {
            "author": "Karl Wettin",
            "body": "The description should be \"This patch\"... and not \"This page\"...",
            "date": "2006-05-27T12:58:42.000+0000",
            "id": 1
        },
        {
            "author": "Nadav Har'El",
            "body": "This patch will be useful for users LUCENE-755, the payloads patch. That patch adds \"payloads\" to tokens, but using it to add a few tokens with payloads in some field can be ugly because you need to split the code into two places: at one place you add the field, only text, and at another place you need to write a special analyzer which will work only on that field, recognize the specific tokens and add the payloads to them. This patch makes this easier, because when you add a field, you can add it pre-analyzed, already as a list of tokens, and these tokens will already have their special payloads in them.\n\nI have just a few comments on this patch:\n\n1. The description above suggests that it might not work if the same field name is used for two Field's, one stored and the other preanalyzed. I think it is important that this combination (as well as all other combinations) are supported. I actually use all these combinations in my code, and I don't see why it should cause problems.\n\n2. The patch has some strange changes in the comments, changing the word \"Index\" to \"NotificationService\". I bet this wasn't intentional :-)\n\n3. The new Field constructor still has a \"Index\" paramter, taking TOKENIZED, UN_TOKENIZED or NO_NORMS (only NO is forbidden). I wonder, what's the difference between TOKENIZED and UN_TOKENIZED in this case? The NO_NORMS is a very useful case, because it allows you to do something not previously possible in Lucene (a tokenized field, but without norms). Perhaps this parameter should be better documented in the javadoc comment.\n\n4. In the new Field constructor's comment, the phrase \"if name or reader\" should be \"if name or tokenStream\".\n\nThanks!",
            "date": "2007-01-18T16:21:04.311+0000",
            "id": 2
        },
        {
            "author": "Karl Wettin",
            "body": "Nadav Har'El [18/Jan/07 08:21 AM]\n\n> The description above suggests that it might not work if the same\n> field name is used for two Field's, one stored and the other preanalyzed. \n> I think it is important that this combination (as well as all other \n> combinations) are supported. I actually use all these combinations in my\n> code, and I don't see why it should cause problems.\n\nActually, I can't remember why I thought there could be a problem, nor can I think of one now.  This code is from my pre-tests era, and it should could need some.\n\nIf you like this  strategy, I think it would be more elegant passing a factory rather than the actual token stream.\n\n> The patch has some strange changes in the comments, changing the word\n>  \"Index\" to \"NotificationService\". I bet this wasn't intentional :-)\n\nHehe, that must be an old refactoring search and replace incident.\n\n",
            "date": "2007-01-18T17:03:04.977+0000",
            "id": 3
        },
        {
            "author": "Karl Wettin",
            "body": "Michael, let me know if you start working on this. I would not mind a discussion on how the token stream supplier should look like. For one it should be an interface/class that supplies the token stream and not a TokenStream it self as it could only be read once. Or?",
            "date": "2007-04-24T02:25:29.534+0000",
            "id": 4
        },
        {
            "author": "Karl Wettin",
            "body": "Perhaps it would be nice if standard term vector, positions et c. was available for easy extraction? Pass a TokenStream to the constructor of the pre analyzed field, buffer it up in a LinkedHashMap, or something in that direction.",
            "date": "2007-04-24T04:28:23.553+0000",
            "id": 5
        },
        {
            "author": "Karl Wettin",
            "body": "An implementation suggestion. The project will not compile as there are two Fieldable implementations that does not implement the tokenStreamFactoryValue() method, LazyField and FieldForMerge. I suspect they could just return null values, but I leave it open as I'm not sure.\n\nPatch contains:\n\npublic interface TokenStreamFactory {\n  public abstract TokenStream factory() throws IOException;\n}\n\n/** Encapuslates a single instance of TokenStream that can be passed on ONCE. */\npublic class SimplePreAnalyzedField implements TokenStreamFactory {\n\n/** Caches an instance of TokenStream in a List, reassembled to a TokenStream for each call to factory() */\npublic class CachedPreAnalyzedField implements TokenStreamFactory {\n",
            "date": "2007-04-25T07:41:53.570+0000",
            "id": 6
        },
        {
            "author": "Michael Busch",
            "body": "Hi Karl,\n\nthank you for your comments and your new patch! I actually updated you initial patch a couple of days ago to apply cleanly on the current trunk as I found it quite simple and straightforward. \n\nI have a question regarding the new patch: What kind of use cases do you have in mind with the cached field? I would think that a TokenStream will only be read once by the DocumentWriter? Currently you can add a field with a Reader, and as far as I know is it not guaranteed that a Reader supports reset(), which means it can only be read once, too. Thoughts?\n\nMichael",
            "date": "2007-04-25T08:21:29.036+0000",
            "id": 7
        },
        {
            "author": "Karl Wettin",
            "body": "25 apr 2007 kl. 10.23 skrev Michael Busch (JIRA):\n> What kind of use cases do you have in mind with the cached field?\n\nI made the inital implementation for text mining purposes -- I needed the term vector prior to inserting the document to the index. Back then I analyzed, cached it up, did my secondary analysis of the vector, and finally reconstructed the token stream and passed it to the field. I think it would be easier to just pass a token stream to an extention of CachedPreAn.. that also features a termFreqVector(), termPosVector(), et c.\n\nKarl",
            "date": "2007-04-25T08:32:00.954+0000",
            "id": 8
        },
        {
            "author": "Michael Busch",
            "body": "Karl,\n\nthanks again for your suggestions. I created a patch with a slightly different approach compared to your latest patch. Similar to java.io.Reader I added the public method reset() to TokenStream, which does nothing per default. Subclasses may or may not overwrite this method. I also added the new class CachingTokenFilter to the analysis package which does the same as your CachedPreAnalyzedField. Before the DocumentWriter consumes the TokenStream it calls reset() reposition the stream at the beginning.\n\nWith this approach it is not neccessary anymore to introduce a TokenStreamFactory and the PreAnalyzedField classes, which is simpler and more consistent with the Analyzer API in my opinion. Yet it also allows to consume the Tokens of a stream more than once, which should satisfy your needs?\n\nPlease let me know what you thing about this new patch. Maybe other committers could take a look as well, since this is an API change (well, extension) to two very common classes: TokenStream and Field.",
            "date": "2007-04-28T18:41:23.446+0000",
            "id": 9
        },
        {
            "author": "Karl Wettin",
            "body": "28 apr 2007 kl. 20.42 skrev Michael Busch (JIRA):\n> Please let me know what you thing about this new patch.\n\n+1. Very clean.\n",
            "date": "2007-04-28T22:07:10.208+0000",
            "id": 10
        },
        {
            "author": "Karl Wettin",
            "body": "A patch that supports omitting norms.\n\n /**\n   * Create a tokenized and indexed field that is not stored, optionally with \n   * storing term vectors.\n   * \n   * @param name The name of the field\n   * @param tokenStream The reader with the content\n+   * @param index Must be tokenized or no norms.\n   * @param termVector Whether term vector should be stored\n   * @throws NullPointerException if name or reader is <code>null</code>\n   */ \n - public Field(String name, TokenStream tokenStream, TermVector termVector) {\n+ public Field(String name, TokenStream tokenStream, Index index, TermVector termVector) {\n\n    if (name == null)\n      throw new NullPointerException(\"name cannot be null\");\n    if (tokenStream == null)\n      throw new NullPointerException(\"tokenStream cannot be null\");\n+    if (index != Index.TOKENIZED && index != Index.NO_NORMS) {\n+      throw new IllegalArgumentException(\"index must be either TOKENIZED or NO_NORMS\");\n+    }\n\n\nAlso fixed some copy/paste related javadoc errors.",
            "date": "2007-04-29T02:50:59.003+0000",
            "id": 11
        },
        {
            "author": "Michael Busch",
            "body": "I'd like to keep the new Constructor consistent with the Constructor that takes a Reader argument. You can use Fieldable.setOmitNorms() to disable norms.",
            "date": "2007-04-29T03:33:27.182+0000",
            "id": 12
        },
        {
            "author": "Karl Wettin",
            "body": "How about two constructors?",
            "date": "2007-04-29T03:46:32.117+0000",
            "id": 13
        },
        {
            "author": "Michael Busch",
            "body": "I hesitate to add even more constructors to Field, since it has already a bunch of them. And I don't see the value in the constructor you proposed, because the same can be achieved by using setOmitNorms(). I think it is a bit confusing to have the Index parameter with only two out of four allowed values in the constructor.",
            "date": "2007-04-29T11:01:33.597+0000",
            "id": 14
        },
        {
            "author": "Michael Busch",
            "body": "I just committed this. Thanks a lot for your patches and the productive discussions, Karl!",
            "date": "2007-04-29T19:28:24.836+0000",
            "id": 15
        }
    ],
    "component": "modules/analysis",
    "description": "Adds the possibility to set a TokenStream at Field constrution time, available as tokenStreamValue in addition to stringValue, readerValue and binaryValue.\n\nThere might be some problems with mixing stored fields with the same name as a field with tokenStreamValue.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-580",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Pre-analyzed fields",
    "systemSpecification": true,
    "version": "1.9"
}