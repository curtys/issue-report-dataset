{
    "comments": [
        {
            "author": "Gilad Barkai",
            "body": "example code",
            "date": "2011-08-22T11:34:44.957+0000",
            "id": 0
        },
        {
            "author": "Hoss Man",
            "body": "This is a fairly well known behavior of the FieldCache in Lucene (and all sorting uses FieldCache) ... i'm guessing it's probably not documented very well however.\n\nThere are a bunch of open issues that relate to trying to rectify this problem - but the one known work arround at this point is to *not* use NumericField, and use StrIndex based FieldCache (which does understand docs w/o values).  This is the approach used in Solr for the \"Sortable*Field\" numerics.",
            "date": "2011-08-22T17:26:41.518+0000",
            "id": 1
        },
        {
            "author": "Hoss Man",
            "body": "a few semi-related issues based on a quick search of \"sortMissingLast\" ... there are lots of others that are likely just as on point (or possible more current)",
            "date": "2011-08-22T17:28:39.853+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "In Lucene trunk I believe this (how/where a doc that's missing the fields sorts) is now controllable: you can call SortField.setMissingValue.",
            "date": "2011-08-22T17:53:14.791+0000",
            "id": 3
        },
        {
            "author": "Doron Cohen",
            "body": "I think it may be useful to solve this also in 3x - without the cached-array-creators of the trunk, but with similar concept - i.e. an additional cache \"type\" will cache the docs missing values for certain field, and will allow to use the default value assigned by apps calling setMissingValue() as in trunk. Gilad and I looked at this, will post a patch shortly for review...",
            "date": "2011-09-01T16:53:31.938+0000",
            "id": 4
        },
        {
            "author": "Doron Cohen",
            "body": "Attached patch fixing this bug. \nTestSort was enhanced to test the new setMissingValue() method - actually merging the test from trunk r1002460 (LUCENE-2671).\n\nAll search test passed (running the rest now..)",
            "date": "2011-09-01T17:02:56.815+0000",
            "id": 5
        },
        {
            "author": "Doron Cohen",
            "body": "Fixed in 3.x r1164794.\nThanks Gilad!",
            "date": "2011-09-03T02:26:34.970+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "I like how we solved this in 3.x!  Ie, a whole separate entry for holding a bitset indicating if the doc has a value.\n\nThis is generally useful, alone, ie one can just pull this bitset and use it directly.\n\nIt's also nice because it's one source that computes this, vs N copies (one per value) that we have on trunk.\n\nI guess the downside is it takes 2 passes over the terms (one to get the values, another to fill this bitset), but maybe that tradeoff is worth not duplicating the code all over... maybe we should take a similar approach in trunk?",
            "date": "2011-09-05T14:46:53.704+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "Also, can we use FastBitSet, not OpenBitSet, here?",
            "date": "2011-09-05T14:57:06.340+0000",
            "id": 8
        },
        {
            "author": "Robert Muir",
            "body": "+1 to revisit how this was done in trunk.",
            "date": "2011-09-05T15:00:20.785+0000",
            "id": 9
        },
        {
            "author": "Uwe Schindler",
            "body": "There is a bug in this impl:\nIf you have two different SortFields with different missing values and you do sorts on both in parallel, the setNextReader in the comparator modifies the shared field cache, leading to concurrency issues.\n\nI dont understand why this is done in setNextReader? Why not do the Bits check in the comparator itsself instead of merging the missing values directly into the field cache, which is a violation to multithreading, caching,...\n\nAlso doing the merging of missing values into the cache on every setNextReader seems like lots of additional work on every sort.\n\nWe should do the check for the missing value directly in the compare/compareBottom method (like we do on trunk).",
            "date": "2011-09-18T17:17:54.972+0000",
            "id": 10
        },
        {
            "author": "Uwe Schindler",
            "body": "The problem is that it's not easy to fix, because the unvalued values BitSet is exposed as DocIdSet not Bits like in trunk. The only quick fix is to clone the cached values before modifying in setNextReader and leave code unchanged.\n\nCorrect fix is to return Bits from getUnvaluedValues and so can do random access in compare/compareBottom, FieldComparator code can be copied 1:1 from trunk, only small changes needed. This would break code already using the new APIs in 3.x, but this is too broken, so we *must* change/fix this.",
            "date": "2011-09-18T17:41:52.664+0000",
            "id": 11
        },
        {
            "author": "Uwe Schindler",
            "body": "Here a quick fix:\n- Uses same code like trunk inside the comparators\n- Uses FixedBitSet instead of OpenBitSet\n\nUnfortunately this breaks backwards compatibility as explained before.\n\nThis patch needs some cleanup (remove code duplication and maybe move the missingValue code to a numeric base class like in trunk). This is also broken in current code, it has missing value code in FieldComparator base class, which should only be in a NumericFieldComparator abstract base class (missing in 3.x).",
            "date": "2011-09-18T18:18:19.392+0000",
            "id": 12
        },
        {
            "author": "Uwe Schindler",
            "body": "Here my final fix. The code in the comparator is exactly like trunk, the NumericComparator superclass was added and the API is now similar to trunk. Also fixed the remaining TODO.\n\nWith this code we break the already broken 3.4 code, but make it similar to trunk, so migration is easier again. It is unlikely that somebody is affected by this, in most cases a simple recompilation fixes the problem.",
            "date": "2011-09-18T20:19:09.414+0000",
            "id": 13
        },
        {
            "author": "Uwe Schindler",
            "body": "Small change:\n- added a TODO: In my opinion the mentioned check is bogus and can never work. IR.docFreq(new Term(field)) will never return the sum of all docFreqs from a field.\n- Moved the empty bitmask check down and use cardinality().\n\nI am currently looking into a possibility to remove the additional uninversion, if the FieldCache already uninverted the field. The bitset should be populated together with the values, but still stored as a separate cache entry.",
            "date": "2011-09-18T21:09:27.231+0000",
            "id": 14
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. I am currently looking into a possibility to remove the additional uninversion, if the FieldCache already uninverted the field. The bitset should be populated together with the values, but still stored as a separate cache entry.\n\nAfter reading the comments in LUCENE-2649 I don't want to discuss this again. In my opinion, it does not matter to always produce the bitset, even if not needed. But as there are people who care about maxDoc/8 additional bytes in FieldCache seem to fight against this idea, so I would leave this open.\n\nI would like to fix the issue, any comments on the new and trunk-like FieldComparator implementation/class structure?\n",
            "date": "2011-09-19T17:40:45.711+0000",
            "id": 15
        },
        {
            "author": "Doron Cohen",
            "body": "Hi Uwe, thanks for catching this. \nI agree that this is a bug, and needs to be fixed.\nJust to make sure that we agree on what the problem is, let me describe it again: in current 3x code in setNextReader() we extract the values from the cache, e.g. by {code}FieldCache.DEFAULT.getDoubles(reader, field, parser);{code} and, if a missing value was set, we iterate the unvalued docs and set them to that missing value. However this settings takes place at the same array just obtained from the cache, and so this is (1) inefficient as it will happen again in the next sort with same field, (2) incorrect as if two sorts of *same* field have different missing value they will collide, and (3) unsafe as you indicated.\nI was very happy with the reuse of the cache for caching the missing values so I would like to try to solve this with that \"frame\"... More later...",
            "date": "2011-09-20T10:02:39.094+0000",
            "id": 16
        },
        {
            "author": "Uwe Schindler",
            "body": "Doron: That's exactly the problem. This easy use case is problematic:\n\nYou allow sorting by Price. The user can switch between forward and backward sorting. In all cases, you want all articles without a price at the beginning. To achieve this, you have to set the price value e.g. to negative_infinity for the forward sorting, but positive_infinity for backwards sorting. If now two users are using your user interface in parallel, they collide.\n\nThe fix used here is identical to Lucene trunk and we should keep the code similar. FieldComparator is now almost identical between trunk and 3.x (except the new BytesRef/Docvalues stuff in trunk).\n\nThinking more about it: Another apporoach (also possible for trunk) is to supply the missing value to FieldCache.getXxx(). The FieldCache would the first use Arrays.fill() to populate the FieldCache array with the default value and after that populate the index values. The drawback is that you get a separate FieldCache entry for each distinct missing value. For the above se case, you would have two float/double price caches.",
            "date": "2011-09-21T08:19:12.413+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "Final patch:\n- Added changes for backwards breaks\n- Removed the bogus docFreq check\n- Optimized the case of empty unvalued docs bit set (like in trunk)\n\nThis patch is now 100% in line with trunk. The code was already tested in trunk and does not affect sort speed for the common case without missing value, as the compiler will ignore the additional null check.\n\nWill commit later this day.",
            "date": "2011-09-21T08:35:25.223+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "I would love to take this even further, and have trunk's FC implement missing values the same way 3.x does (ie, separate FC method to getUnvaluedDocs, rather than bundling this bitset w/ the computation of the values array).  But we should do that separately.\n\nThis is actually a serious bug; maybe we should release 3.4.1 soon (this would also fix the Maven packaging problem in 3.4.0).\n\nWhy did we need to narrow the return value from FC.getUnvaluedDocs to FixedBitSet?",
            "date": "2011-09-21T10:48:21.660+0000",
            "id": 19
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. Why did we need to narrow the return value from FC.getUnvaluedDocs to FixedBitSet?\n\nWe have no Bits interface in 3.x. And DocIdSet is not random access. Maybe we should backport the Bits interface?",
            "date": "2011-09-21T10:52:41.624+0000",
            "id": 20
        },
        {
            "author": "Uwe Schindler",
            "body": "In my opinion a much more clean and simple approach for FieldComaparator and all other stuff would be the following, as it removes all additional branches from FieldComaparator and makes the code as simple as it was before missingValues at all (also in trunk):\n\n{quote}\nThinking more about it: Another apporoach (also possible for trunk) is to supply the missing value to FieldCache.getXxx(). The FieldCache would the first use Arrays.fill() to populate the FieldCache array with the default value and after that populate the index values. The drawback is that you get a separate FieldCache entry for each distinct missing value. For the above se case, you would have two float/double price caches.\n{quote}\n\nWe just have to think about additional memory requirements (which would affect only users actually using different missingValues for several searches). From my perspective this is much cleaner, as you can pass in a missingValue directly when populating the FieldCache. FieldComaparator would simply call FieldCache.DEFAULT.getInts(reader, parser, defaultValue). The cache would use the triplet including defaultValue as key. The sorting code would not need to be changed at all (this is similar to Doron's idea, but moved to FieldCache and not FC.setNextReader).\n\nWe should think about this in an additional issue and for now only fix the broken implementation in 3.x.",
            "date": "2011-09-21T11:08:28.255+0000",
            "id": 21
        },
        {
            "author": "Uwe Schindler",
            "body": "Here a patch with a more clean API (as noted by Mike McCandless):\n- backported the Bits interface from Lucene trunk (do a svn cp http://svn.apache.org/..../trunk/..../Bits.java before applying the patch\n- Added interface to the well-known impls in util package\n- FieldCache.getUnValuesDocs returns Bits now which makes the API very clean\n\nThis breaks backwards a bit more, as Bits does not extend DocIdSet, so code using the new FieldCache method will break, before recompilation was enough (as FixedBitSet extends DocIdSet).\n\nMike: How about this?",
            "date": "2011-09-21T12:06:48.557+0000",
            "id": 22
        },
        {
            "author": "Michael McCandless",
            "body": "Looks great Uwe!  I think we can assert that the cardinality is <= numDocs, and then short-circuit the common == numDocs (all docs have values) case like you are.\n\nI love how 3.x handles the unvalued bits... I think we should port this forward to trunk, but maybe make it possible to set the bits as we build up the values (single pass) if you specify up front you want the bit set.  I'll open a new issue for this...",
            "date": "2011-09-21T12:31:56.878+0000",
            "id": 23
        },
        {
            "author": "Doron Cohen",
            "body": "I wrote a small test that should fail with the bug Uwe fixed here and pass with the fix. For some reason it is still failing even with that fix. Tried this with previous patch, will now try with last one, though I think it it should pass also with previous one. I'll give it another try.",
            "date": "2011-09-21T12:58:59.014+0000",
            "id": 24
        },
        {
            "author": "Doron Cohen",
            "body": "Attached patch with a test that fails before this fix (otherwise patch same as previous).\n\nThe test uses 4 collectors simultaneously, each with different missing values.",
            "date": "2011-09-21T14:33:07.434+0000",
            "id": 25
        },
        {
            "author": "Uwe Schindler",
            "body": "I added a further test in TestFieldCache to check the Bits returned.\n\nI think that's ready to commit.",
            "date": "2011-09-21T14:55:22.735+0000",
            "id": 26
        },
        {
            "author": "Michael McCandless",
            "body": "bq. I think that's ready to commit.\n\n+1, looks great!  Thanks Uwe.",
            "date": "2011-09-21T15:04:40.508+0000",
            "id": 27
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed 3.x branch revision: 1173701",
            "date": "2011-09-21T15:07:29.791+0000",
            "id": 28
        },
        {
            "author": "Uwe Schindler",
            "body": "When discussing about the forward port with Mike McCandless on IRC, we thought the double inversion is useless (it was in Doron's patch, because he wanted to use DocIdSetIterator effectively).\n\nWe changed the name to FieldCache.getDocsWithField().\n\nPatch is easy.",
            "date": "2011-09-21T16:05:26.710+0000",
            "id": 29
        },
        {
            "author": "Uwe Schindler",
            "body": "Patch with the BitSet inverted. We break backwards compatibility so this is not an issue at all.",
            "date": "2011-09-21T16:05:57.975+0000",
            "id": 30
        },
        {
            "author": "Michael McCandless",
            "body": "Looks great!",
            "date": "2011-09-21T16:10:19.007+0000",
            "id": 31
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed 3.x branch revision: 1173745",
            "date": "2011-09-21T16:26:54.008+0000",
            "id": 32
        },
        {
            "author": "Uwe Schindler",
            "body": "Bulk close after release of 3.5",
            "date": "2011-11-27T12:29:26.151+0000",
            "id": 33
        }
    ],
    "component": "core/search",
    "description": "While sorting results over a numeric field, documents which do not contain a value for the sorting field seem to get 0 (ZERO) value in the sort. (Tested against Double, Float, Int & Long numeric fields ascending and descending order).\nThis behavior is unexpected, as zero is \"comparable\" to the rest of the values. A better solution would either be allowing the user to define such a \"non-value\" default, or always bring those document results as the last ones.\n\nExample scenario:\nAdding 3 documents, 1st with value 3.5d, 2nd with -10d, and 3rd without any value.\nSearching with MatchAllDocsQuery, with sort over that field in descending order yields the docid results of 0, 2, 1.\n\nAsking for the top 2 documents brings the document without any value as the 2nd result - which seems as a bug?",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3390",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Incorrect sort by Numeric values for documents missing the sorting field",
    "systemSpecification": true,
    "version": "3.3"
}