{
    "comments": [
        {
            "author": "Shai Erera",
            "body": "While I change SortableSingleDocMaker I noticed it create a new Random() in getNextDocData(). Shouldn't that Random be created once? Also, I think it should be created with a seed?",
            "date": "2009-05-21T11:41:18.345+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "bq. While I change SortableSingleDocMaker I noticed it create a new Random() in getNextDocData(). Shouldn't that Random be created once? Also, I think it should be created with a seed?\n\nOK, sharing a Random instance seems good.\n\nMaybe make the seed an optional config?  If it's not present, let it pick a random seed?",
            "date": "2009-05-21T11:53:38.997+0000",
            "id": 1
        },
        {
            "author": "Shai Erera",
            "body": "bq. Maybe make the seed an optional config? If it's not present, let it pick a random seed?\n\nI already went ahead and did that. Only if it's not present, I chose 13 instead of drawing one every time. That way, runs can be consistent and compared to each other.",
            "date": "2009-05-21T11:56:47.288+0000",
            "id": 2
        },
        {
            "author": "Shai Erera",
            "body": "BTW, am I allowed to use Java 5 generics in benchmark? Or until 3.0 benchmark should stay on 1.4 as well? I'm asking because I heard a couple of times that contrib is allowed to move to Java 5",
            "date": "2009-05-21T11:59:08.177+0000",
            "id": 3
        },
        {
            "author": "Michael McCandless",
            "body": "Probably it's best to stick w/ 1.4.  Someday, I hope, we will get to 3.0 :)",
            "date": "2009-05-21T16:27:09.475+0000",
            "id": 4
        },
        {
            "author": "Mark Miller",
            "body": "Right - the back compat for each contrib is completely up to that contrib. In the past though, anything thats 1.4 has stayed 1.4 without good reason so that users are not jolted (probably more out there using java 1.4 than you might think).\n\nOn 3.0, when core goes 1.5, it will make sense to allow 1.5 in all the contribs that are 1.4 now.",
            "date": "2009-05-21T16:32:27.610+0000",
            "id": 5
        },
        {
            "author": "Shai Erera",
            "body": "Ok I'll make sure it's 1.4 compatible then.",
            "date": "2009-05-21T20:48:35.985+0000",
            "id": 6
        },
        {
            "author": "Shai Erera",
            "body": "Patch includes a new ContentSource class with appropriate extensions for all previously defined DocMakers. DocMaker is a concrete class which creates Documents based on the ContentSource DocData output. It can be configured to reuse fields.\n\nThere are many ContentSource impls now, but only few DocMaker (such as LineDocMaker and EnwikiDocMaker - since their makeDocument() logic is quite simple).\n\nAll tests pass. I also modified all alg files to define content.source instead of doc.maker (default is DocMaker) where appropriate.\n\nI think we can start iterating on this",
            "date": "2009-05-25T14:14:26.098+0000",
            "id": 7
        },
        {
            "author": "Mark Miller",
            "body": "Just attempted to patch it in - it looks like a bunch of files that don't exist are in the patch as patches rather than as the new file?\n\nHaving trouble with SingleDocSource, and it looks like half a dozen of the other new files...\n\n",
            "date": "2009-05-25T14:41:48.945+0000",
            "id": 8
        },
        {
            "author": "Shai Erera",
            "body": "I was afraid that something like that will happen. I used Eclipse refactoring and also Team - \"create patch\". That's the output. Do you use Eclipse to patch it in?\n\nWhat should I do with existing classes which I renamed? Add new classes and delete the existing ones? (At least from the eclipse SVN console, that's what it seems to do when I refactor a class name)",
            "date": "2009-05-25T14:47:16.403+0000",
            "id": 9
        },
        {
            "author": "Shai Erera",
            "body": "Can you try now?",
            "date": "2009-05-25T15:09:49.629+0000",
            "id": 10
        },
        {
            "author": "Mark Miller",
            "body": "Yes, was using eclipse to patch.\n\nThe patch you just posted appears to work - it compiled and the new files appeared to be created, thanks!",
            "date": "2009-05-25T15:15:26.907+0000",
            "id": 11
        },
        {
            "author": "Shai Erera",
            "body": "Hey Mark, are you reviewing this? Did you catch something interesting so far?",
            "date": "2009-06-01T11:00:56.570+0000",
            "id": 12
        },
        {
            "author": "Shai Erera",
            "body": "Some updates:\n# Added to PerfTask a log.step config parameter, and implemented in tearDown logging messages. Also introduced a getLogMessage(int recsCount) which can be overridden by sub classes.\n#* Overrode getLogMessage in the relevant tasks which logged messages, such as AddDocTask, DeleteDocTask, WriteLineDocTask ... I also removed logging from these tasks\n# Added ConsumeContentSource task together with a readContent.Source.alg - this can be used to simply read from a content source, if we want to measure the performance of a particular impl.\n# Removed the \"xerces\" class name from EnwikiContentSource (read more below).\n\nI changed EnwikiContentSource to not specifically request for a Xerces SAXParser. However, the default is to use the JRE's SAXParser, which is Xerces.\n\nI wanted to remove the Xerces .jar, but when I attempted to read the enwiki-20090306-pages-articles.xml, it failed w/ an AIOOBE, so I don't think we can remove the .jar yet.\nBTW, in LUCENE-1591 I reported that I am not able to parse that particular enwiki version, w/ and w/o Xerces, however Mike succeeded. So I don't know if this enwiki version is defective, or it's a problem on Windows.\n\nAnyway, the bottom line is we cannot remove the Xerces .jar.\n\nI think this patch is ready for commit. All benchmark tests pass.",
            "date": "2009-06-10T13:02:02.783+0000",
            "id": 13
        },
        {
            "author": "Mark Miller",
            "body": "Someone else can nab this from me if they want to go ahead before I get a chance.\n\nOtherwise, I'll try and take a look by the end of the weekend. I started looking at it before, but just havn't yet had a chance to go back to it.\n\nIn either case, we will get it in soon.",
            "date": "2009-06-10T14:21:52.897+0000",
            "id": 14
        },
        {
            "author": "Mark Miller",
            "body": "I hope to look at this today. Shai, will this at all invalidate any benchmark algorithms that are already out there?",
            "date": "2009-06-14T13:18:24.031+0000",
            "id": 15
        },
        {
            "author": "Shai Erera",
            "body": "Yes, it will. Basically, DocMaker is now a concrete class which accepts a ContentSource and creates documents out of it. So all the DocMakers were replaced w/ ContentSource (such as Reuters, Trec etc.). I left EnwikiDocMaker and LineDocMaker to create a LineContentSource and EnwikiContentSource, ignoring any content.source parameter that may be set in the config.\n\nI also updated all the current .alg files to reflect those changes.\n\nDo you think I should spell it out in CHANGES? Basically the migration is super simple - if you use any doc maker which is not Enwiki or Line, simply rename doc.maker to content.source, and the appropriate ContentSource class.",
            "date": "2009-06-14T15:40:42.401+0000",
            "id": 16
        },
        {
            "author": "Mark Miller",
            "body": "I'd love other opinions. \n\nIf we go with it, I think we should def spell it out in the benchmark CHANGES.\n\nBenchmark has no back compat commitment as far as I see, but we should consider breaking existing algorithms out there very carefully I think. And if there is a way to map the invalid values to values that keep the old behavior, we should def investigate that as well.",
            "date": "2009-06-14T15:53:41.816+0000",
            "id": 17
        },
        {
            "author": "Shai Erera",
            "body": "Well ... depends on what are the \"existing algorithms out there\". .alg files that someone wrote which use existing DocMakers (from benchmark) would break, but fixing them is a no brainer (just reference the ContentSource where applicable). .alg files which use custom DocMakers are a bit more challenging, since you'll need to decide if your DocMaker is a ContentSource, really a DocMaker or both (i.e., split it to DocMaker and ContentSource). Since I haven't changed the API of DocMaker much, it shouldn't be a hard task to refactor your custom DocMaker.\n\nIn general. I believe benchmark is not used in production environments, and therefore it shouldn't be a real problem to adapt your benchmark .alg and/or custom classes to the refactored one. You can also earn by extending DocMaker and using its DocState for a reuse logic. If we say that contrib in general does not need to maintain back-compat, and we're talking about classes that are in production environments, then I don't think we have a real issue here.\n\nI won't ask how much we believe benchmark is extended (even though it's important) or used, since this issue was originated from my extension of it. I can only assume that Solr extends it too (or uses it).\n\n",
            "date": "2009-06-14T19:00:06.877+0000",
            "id": 18
        },
        {
            "author": "Mark Miller",
            "body": "bq. If we say that contrib in general does not need to maintain back-compat, and we're talking about classes that are in production environments, then I don't think we have a real issue here.\n\nContrib does not necessarily have a back compat, but its up to each contrib to determine what its back compat policy is. Even without an explicit policy, we try to do what make sense. Everytime you ignore back compat completely for certain things, you risk alienating certain people. For example, because the highlighter is a semi core type thing, even though we have never made a back compat policy for it, we don't break back compat there without good reason.\n\nI agree that the Benchmark contrib comes down on the low end of concern. In fact, I'm not too concerned with breaking back compat anywhere in benchmark except for the algs. Every time we break the algs, we risk causing people who have written custom algs to think twice about writing and maintaining them. Generally, I'd expect things like that to be careful about maintaining back compat or a mode that can run older version algs.\n\nThat said, I'm not saying this change isnt worth a little algorithm disruption. I wouldn't mind getting the opinion of another committer first though. I doubt too many people even have that many custom algs out there - but thats not a scenioro I want to help and try to perpetuate.\n\nSo its not like I'm sitting here saying this is a huge deal - but I think it should def be considered a bit.",
            "date": "2009-06-14T23:13:18.080+0000",
            "id": 19
        },
        {
            "author": "Mark Miller",
            "body": "{quote}Well ... depends on what are the \"existing algorithms out there\". .alg files that someone wrote which use existing DocMakers (from benchmark) would break, but fixing them is a no brainer (just reference the ContentSource where applicable). .alg files which use custom DocMakers are a bit more challenging, since you'll need to decide if your DocMaker is a ContentSource, really a DocMaker or both (i.e., split it to DocMaker and ContentSource). Since I haven't changed the API of DocMaker much, it shouldn't be a hard task to refactor your custom DocMaker. {quote}\n\nWhat about these changes? Are they incompat as well?\n\n-doc.add.log.step=500\n-doc.delete.log.step=100\n+log.step=500\n+delete.log.step=100\n\nSorry, didn't really get a chance to dig in today as I was feeling a bit under the weather. We will get it in for 2.9.",
            "date": "2009-06-15T02:39:37.319+0000",
            "id": 20
        },
        {
            "author": "Shai Erera",
            "body": "bq. So its not like I'm sitting here saying this is a huge deal - but I think it should def be considered a bit.\n\nI didn't mean to imply that. In all my recent contributions, back-compat played a major role. I just explained here why here I didn't give it a second thought, and was actually happy I am more free to make these changes. But I definitely see your point, and would love to get another committer's opinion too.\n\n{quote}\nWhat about these changes? Are they incompat as well?\n\n-doc.add.log.step=500\n-doc.delete.log.step=100\n+log.step=500\n+delete.log.step=100\n{quote}\n\nI took another step here, adding code to PerfTask.tearDown() which logs messages, and changed all the current tasks that does it to stop doing it, and instead override a getLogMessage(). That consolidated the logic behind when to log messages, in what format etc. It was not consistent between tasks, and some newer tasks did better job than others.\n\nWith that, I also changed the property name (which was invalid even before - doc.add.log.step wasn't used just in AddDocTask). About the delete.log.step - I first removed it, relying on the new log.step, but then spotted some .alg which differentiate between when how often to log messages for delete and how often for the rest, so I re-instated it. If you think it matters, I can change revert the name back to doc.delete.log.step.\n\nbq. We will get it in for 2.9\n\nGreat ! that will relieve some of my custom benchmarking code, and allow me to test on more content sources (today I implemented this model just for TREC for lack of time).",
            "date": "2009-06-15T03:31:23.328+0000",
            "id": 21
        },
        {
            "author": "Mark Miller",
            "body": "Okay, how about something like this:\n\nwe document up the changes and the conversion processes in the benchmark CHANGES and then, maybe check for removed alg properties in the algorithms and throw an exception pointing people to the CHANGES file if we find one? Or something along those lines?\n\nI'd like to make the transition as smooth as possible.",
            "date": "2009-06-15T13:43:56.960+0000",
            "id": 22
        },
        {
            "author": "Shai Erera",
            "body": "ok I agree. I've already documented CHANGES. I'll add to PerfTask a deprecated method checkObsoleteSettings which will throw an exception if it finds \"doc.add.log.step\" and \"doc.delete.log.step\". doc.maker is still a valid one, but when you'll try to cast the argument to a DocMaker, you'll get an exception, b/c it's now a concrete class and not interface.\n\nDoes this make sense?\n\nI'll post a patch soon.",
            "date": "2009-06-15T13:58:46.503+0000",
            "id": 23
        },
        {
            "author": "Mark Miller",
            "body": "bq. Does this make sense?\n\nOkay, sounds good.\n\nSilence is consent around here, so I think we are good to go with this patch as soon as I go over it a bit. I'll wait till you post this last one.",
            "date": "2009-06-15T14:04:21.129+0000",
            "id": 24
        },
        {
            "author": "Shai Erera",
            "body": "Patch adds a checkObsoleteSettings to PerfTask to alert on the use of doc.add.log.step and doc.delete.log.step, as well as documentation in CHANGES.\n\nall benchmark tests pass.",
            "date": "2009-06-15T14:56:30.069+0000",
            "id": 25
        },
        {
            "author": "Mark Miller",
            "body": "Added to changes a bit\nRemoved modification to core Document class\nupdated deletepercent.alg to new alg changes\nfixed a couple comment typos\nset to use content.source.forever rather than doc.maker.forever in ExtractWikipedia#main(String[] args)\nthe sort algs don't work :( unrelated to this patch and related to our deprecation of the auto sort field - Ryan just hit that over in solr-land too.\n\nI still want to run some tests with the wikipedia stuff, but still waiting for that mondo file to download :)\n\nLooks pretty nice overall, thanks Shai!",
            "date": "2009-06-18T03:09:57.255+0000",
            "id": 26
        },
        {
            "author": "Shai Erera",
            "body": "bq. I still want to run some tests with the wikipedia stuff\n\nI added readContentSource.alg just for that purpose and ran it over the Wikipedia dump. All documents were read successfully.\n\nbq. Removed modification to core Document class\n\nNice ! I don't know how I missed that getFields().clear() option.",
            "date": "2009-06-18T05:53:21.763+0000",
            "id": 27
        },
        {
            "author": "Mark Miller",
            "body": "bq. I added readContentSource.alg just for that purpose and ran it over the Wikipedia dump. All documents were read successfully.\n\nI figured you probably had, but they won't end up coming after you, they will come after me :) As expected, no issues hit yet though.\n\n\nI'll commit this later today.",
            "date": "2009-06-18T15:36:52.064+0000",
            "id": 28
        },
        {
            "author": "Shai Erera",
            "body": "bq. they won't end up coming after you, they will come after me :)\n\nI promise to cover for you if that happens :)\n\nbq. I'll commit this later today.\n\nThanks !",
            "date": "2009-06-18T15:49:39.413+0000",
            "id": 29
        },
        {
            "author": "Mark Miller",
            "body": "Thanks Shai, I just committed this.",
            "date": "2009-06-18T20:02:39.286+0000",
            "id": 30
        },
        {
            "author": "Michael McCandless",
            "body": "Could we remove LineDocMaker entirely, now?  And then move up the doc.random.id.limit into DocMaker (for testing updateDocument performance)?\n\nI think we could also remove EnwikiDocMaker?  The only different its makeDocument seems to have is that it uses wiki's name as the id field, rather than incrNumDocsCreated()?\n\nbq. the sort algs don't work  unrelated to this patch and related to our deprecation of the auto sort field\n\nMark what was this issue?  Was it fixed already?",
            "date": "2009-07-24T18:42:31.045+0000",
            "id": 31
        },
        {
            "author": "Mark Miller",
            "body": "bq. Mark what was this issue? Was it fixed already?\n\nYes - if you didnt specify a type, it used Auto - but a switch was made to use the new TopField collector, which doesnt resolve auto. I just removed auto support - you must type the field now.\n\nhttps://issues.apache.org/jira/browse/LUCENE-1725",
            "date": "2009-07-24T19:02:12.370+0000",
            "id": 32
        },
        {
            "author": "Michael McCandless",
            "body": "bq. I just removed auto support - you must type the field now.\n\nOK... though it looks like it still falls back to AUTO (in getType()) if it doesn't recognize the provided type.  I'll attach a patch shortly, to just accept all types that SortField accepts, and throw an exception if the type isn't recognized.",
            "date": "2009-07-24T20:20:11.022+0000",
            "id": 33
        },
        {
            "author": "Michael McCandless",
            "body": "Attached patch.",
            "date": "2009-07-24T20:20:58.344+0000",
            "id": 34
        },
        {
            "author": "Michael McCandless",
            "body": "Reopening to make sure I remember to commit that patch, and to maybe remove Line/EnwikiDocMaker.",
            "date": "2009-07-24T22:33:29.942+0000",
            "id": 35
        },
        {
            "author": "Shai Erera",
            "body": "I kept Line/EnwikiDocMaker just because they contain very simple logic and are very short. I don't know if we want to pull the id stuff up to DocMaker since some DocMakers have their own ID (example - TrecDocMaker).\n\nBut I don't mind removing them. Just, like I said, now they are very optimized for the content source they work on, no extra 'ifs' etc. Especially LineDocMaker, which reads a Line file that has only title, date and body. Also notice that both init their own content source.\n\nBut I don't have a strong feeling for removing/keeping them. Are you going to do it, or shall I?",
            "date": "2009-07-25T03:15:02.573+0000",
            "id": 36
        },
        {
            "author": "Michael McCandless",
            "body": "My driver here was... updating Lucene in Action to explain all the recent changes to contrib/benchmark, and explaining the tiny differences between these 3 DocMakers was awkward :)  They are \"nearly\" the same.\n\nI'll work up a patch.",
            "date": "2009-07-25T10:41:46.419+0000",
            "id": 37
        },
        {
            "author": "Michael McCandless",
            "body": "Attached patch that addresses the SortField.AUTO issue, and deprecates\nLine/EnwikiDocMaker.\n\nI do think we could do some speeding up of the fields handling in\nDocMaker for the reuse case, eg make dedicated members in DocData to\nhold the known fields (id, body, title, etc.) but I think we can wait\non that for now.\n",
            "date": "2009-07-25T15:14:07.086+0000",
            "id": 38
        },
        {
            "author": "Uwe Schindler",
            "body": "Just an idea, when redoing the field stuff: maybe we should add the DATE field as a long timestamp (Date.getTime()) using NumericField with default precStep? We could then also do benchmarks on NumericRangeQuery and easily sort by date with type=\"long\".",
            "date": "2009-07-25T15:33:31.726+0000",
            "id": 39
        },
        {
            "author": "Michael McCandless",
            "body": "bq. maybe we should add the DATE field as a long timestamp (Date.getTime()) using NumericField with default precStep?\n\n+1",
            "date": "2009-07-25T16:37:30.845+0000",
            "id": 40
        }
    ],
    "component": "modules/benchmark",
    "description": "This issue proposes some refactoring to the benchmark package. Today, DocMaker has two roles: collecting documents from a collection and preparing a Document object. These two should actually be split up to ContentSource and DocMaker, which will use a ContentSource instance.\n\nContentSource will implement all the methods of DocMaker, like getNextDocData, raw size in bytes tracking etc. This can actually fit well w/ 1591, by having a basic ContentSource that offers input stream services, and wraps a file (for example) with a bzip or gzip streams etc.\n\nDocMaker will implement the makeDocument methods, reusing DocState etc.\n\nThe idea is that collecting the Enwiki documents, for example, should be the same whether I create documents using DocState, add payloads or index additional metadata. Same goes for Trec and Reuters collections, as well as LineDocMaker.\nIn fact, if one inspects EnwikiDocMaker and LineDocMaker closely, they are 99% the same and 99% different. Most of their differences lie in the way they read the data, while most of the similarity lies in the way they create documents (using DocState).\nThat led to a somehwat bizzare extension of LineDocMaker by EnwikiDocMaker (just the reuse of DocState). Also, other DocMakers do not use that DocState today, something they could have gotten for free with this refactoring proposed.\n\nSo by having a EnwikiContentSource, ReutersContentSource and others (TREC, Line, Simple), I can write several DocMakers, such as DocStateMaker, ConfigurableDocMaker (one which accpets all kinds of config options) and custom DocMakers (payload, facets, sorting), passing to them a ContentSource instance and reuse the same DocMaking algorithm with many content sources, as well as the same ContentSource algorithm with many DocMaker implementations.\n\nThis will also give us the opportunity to perf test content sources alone (i.e., compare bzip, gzip and regular input streams), w/o the overhead of creating a Document object.\n\nI've already done so in my code environment (I extend the benchmark package for my application's purposes) and I like the flexibility I have. I think this can be a nice contribution to the benchmark package, which can result in some code cleanup as well.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1595",
    "issuetypeClassified": "REFACTORING",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Split DocMaker into ContentSource and DocMaker",
    "systemSpecification": true,
    "version": ""
}