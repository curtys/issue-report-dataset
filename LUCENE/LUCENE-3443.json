{
    "comments": [
        {
            "author": "Ryan McKinley",
            "body": "+1  \n\nA separate cache entry for Bits is a good thing assuming it can be calculated in a single pass.\n",
            "date": "2011-09-21T17:22:01.433+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "Initial patch, cutting over to 3.x's approach.\n\nI still need to check the patch a bit more closely.... but tests do pass.\n\nI think we should commit this, first, then separately optimize the valid bits to single pass....",
            "date": "2011-11-08T11:43:42.200+0000",
            "id": 1
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. I think we should commit this, first, then separately optimize the valid bits to single pass....\n\nThat represents a pretty significant performance regression though, and it seems we should try to avoid stuff like that on trunk (better in a branch if one is going to remove functionality with the idea of adding it back later).  Or we could generate the bits by default - the extra cache entry if not needed is less serious than doubling the generation time.\n\nAnother small piece we are losing from trunk is numUniqueTerms.\nWhat about returning an object, so instead of getLongs() returning a long[], it would return a LongValues that had\na long[] as well as numUniqueTerms, and docsWithValues (optionally set).  This also halves the number of cache lookups needed when using sortMissinglast and supplies a place to put more info in the future (stuff like numUniqueTerms).",
            "date": "2011-11-08T15:44:59.691+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. That represents a pretty significant performance regression though, and it seems we should try to avoid stuff like that on trunk (better in a branch if one is going to remove functionality with the idea of adding it back later).\n\nWell we haven't released trunk yet, and this is not a perf regression\nvs 3.4.0?\n\nIe, there's no guarantee w/in trunk that performance won't \"change\",\njust like there's no guarantee APIs and index format won't \"change\".\n\nbq. Or we could generate the bits by default - the extra cache entry if not needed is less serious than doubling the generation time.\n\nI'd rather not do that; apps that don't use sort missing first/last\nshouldn't be forced to spend the RAM (even if it's only a bit per\ndoc).\n\nI think we can find a solution that makes it optional; I just don't\nthink we have to do it here, now.\n\nThis issue can focus on getting to 3.x's FC impl.\n\nbq. Another small piece we are losing from trunk is numUniqueTerms.\n\nWell, we track this in FC (only in trunk) today, but it's not used\nanywhere, I think?  Also, this is redundant with\nTerms.getUniqueTermCount()?\n\n{quote}\nWhat about returning an object, so instead of getLongs() returning a long[], it would return a LongValues that had\na long[] as well as numUniqueTerms, and docsWithValues (optionally set). This also halves the number of cache lookups needed when using sortMissinglast and supplies a place to put more info in the future (stuff like numUniqueTerms).\n{quote}\n\nI think for now we should stick w/ simple arrays for this issue; we\ncan explore returning an object under a new issue.  The extra cache\nlookup is really a negligible cost.\n",
            "date": "2011-11-08T18:30:58.284+0000",
            "id": 3
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. Ie, there's no guarantee w/in trunk that performance won't \"change\",\n\nOf course not.  I'm arguing a specific point though: that we shouldn't double time time it takes solr users to instantiate field caches (or other lucene users that regularly use sortMissingLast).  \"we can do it later\" is not a good argument to remove existing functionality.\n\nbq. > Or we could generate the bits by default - the extra cache entry if not needed is less serious than doubling the generation time.\n\nI mean, generate the bits by default until the two-pass problem is fixed (not forever).\n\nbq. I'd rather not do that; apps that don't use sort missing first/last shouldn't be forced to spend the RAM (even if it's only a bit per doc).\n\nBut it's trunk, right?  There's no guarantee w/in trunk that performance won't \"change\" ;-)\nUsing 1/32 more memory (3%) is way less evil than doubling field cache entry times.\n\nbq. Also, this (uniqueTermCount) is redundant with Terms.getUniqueTermCount()?\n\nNot for numeric fields, where a precisionStep causes nTerms > nUniqueValues\n\n",
            "date": "2011-11-08T18:42:53.419+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. I'm arguing a specific point though: that we shouldn't double time time it takes solr users to instantiate field caches (or other lucene users that regularly use sortMissingLast). \"we can do it later\" is not a good argument to remove existing functionality.\n\nWe're not doubling the time vs 3.x.\n\n{quote}\nI'd rather not do that; apps that don't use sort missing first/last shouldn't be forced to spend the RAM (even if it's only a bit per doc).\n\nbq. But it's trunk, right? There's no guarantee w/in trunk that performance won't \"change\" ;-)\nbq. Using 1/32 more memory (3%) is way less evil than doubling field cache entry times.\n{quote}\n\nAgain, compared to 3.x, that'd be worse.  Ie, w/ the patch as it now\nstands we could ship 4.0 and we'd match 3.x.\n\nFor a byte[] FC entry that's 12.5% extra RAM.\n\nI think one-time FC init cost is the lesser evil vs \"permanently\"\ntying up unused RAM.\n\n{quote}\nbq. Also, this (uniqueTermCount) is redundant with Terms.getUniqueTermCount()?\n\nNot for numeric fields, where a precisionStep causes nTerms > nUniqueValues\n{quote}\n\nAhh, true.\n",
            "date": "2011-11-09T00:15:01.879+0000",
            "id": 5
        },
        {
            "author": "Yonik Seeley",
            "body": "Just because the functionality isn't in 3.x doesn't mean we should feel free to rip it out of trunk and replace it with something that has less functionality (well, we should be able to if we think it's for the best, but my point is... it's not.)  IMO, this patch should be further developed as a patch until the 2-pass problem has been solved as well.  Unless there's a good reason, we shouldn't be moving backwards.",
            "date": "2011-11-09T00:24:25.207+0000",
            "id": 6
        },
        {
            "author": "Robert Muir",
            "body": "I like this patch (it makes the fieldcache less confusing to me, currently I only understand the 3.x one).\n\nI updated the patch with a tiny optimization, maybe it can help resolve some concerns. I see that solr defaults its \"string\" field etc to sortMissingLast.\n\nI think its very common that many fields are populated for every document (of course this option is totally stupid in this case...), but regardless of stupid configurations we shouldn't do any additional pass there:\n{code}\n        // if the field is fully populated, don't bother enumerating\n        if (terms.getDocCount() == maxDoc) {\n          return new Bits.MatchAllBits(maxDoc);\n        }\n{code}",
            "date": "2011-11-09T01:08:09.513+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "New patch.\n\nI managed to fold in setting the docsWithField bits with a single pass.  You pass an extra boolean to each getXXX.\n\nI think it's ready!",
            "date": "2011-11-09T18:49:08.201+0000",
            "id": 8
        },
        {
            "author": "Yonik Seeley",
            "body": "Looks good!  +1 to commit.\n\nSomething we should consider for the future is expanding the functionality of the Parser class.\nIf the parser could handle the creation of the whole entry, we could get rid of hacks like throwing+catching an exception for the NumericField parsers and enable doing other things like populating a FieldCache entry from a CSF.\n",
            "date": "2011-11-10T18:01:31.216+0000",
            "id": 9
        },
        {
            "author": "Uwe Schindler",
            "body": "Bulk close after release of 3.5",
            "date": "2011-11-27T12:29:33.294+0000",
            "id": 10
        }
    ],
    "component": "core/search",
    "description": "[Spinoff from LUCENE-3390]\n\nI think the approach in 3.x for handling un-valued docs, and making it\npossible to specify how such docs are sorted, is better than the\nsolution we have in trunk.\n\nI like that FC has a dedicated method to get the Bits for docs with field\n-- easy for apps to directly use.  And I like that the\nbits have their own entry in the FC.\n\nOne downside is that it's 2 passes to get values and valid bits, but\nI think we can fix this by passing optional bool to FC.getXXX methods\nindicating you want the bits, and the populate the FC entry for the\nmissing bits as well.  (We can do that for 3.x and trunk). Then it's\nsingle pass.\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3443",
    "issuetypeClassified": "OTHER",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Port 3.x FieldCache.getDocsWithField() to trunk",
    "systemSpecification": true,
    "version": ""
}