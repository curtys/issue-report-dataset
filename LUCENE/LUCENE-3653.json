{
    "comments": [
        {
            "author": "Uwe Schindler",
            "body": "The problems you are mentioning are no issues at all:\n- VirtualMethod is only used during class instantiations and class loading and must be synchronized. There is unlikely contention at all, just because its synchronized it does not mean its slow.\n- getAttributeInterfaces must be synchronized, too, as it has a reflection cache and is also only used during TokenStream instantiation. Analyzers should reuse TokenStreams so its not an issue at all. Fix your analyzers to resuse TokenStreams.\n\nOn concurency the average time increases because of eventual contention in your file system directory implementation, not because methods may be synchronized.",
            "date": "2011-12-17T00:30:18.913+0000",
            "id": 0
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "profile_1_[x].png images shows lucene 3.4 used in the sample application App.java profiled using YourKit.\n\n1_a : shows the threads Blocking.\n1_b : shows where the threads block. I went through all of the methods and almost all were blocking on SegmentCoreReaders\n1_c : Shows the monitors on which the threads are blocking.\n\n\n\n",
            "date": "2011-12-17T19:27:38.224+0000",
            "id": 1
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "profile_2_[X].png shows have lucene performs after having removed all synchronized methods from SegmentCoreReaders and some other areas which I'm still investigating if they had effect or not.\n\n\n2_a : shows the thread view. Threads are not blocking any more but there is some thread sleep going on.\n\n",
            "date": "2011-12-17T19:30:08.384+0000",
            "id": 2
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "Hi Uwe,\n\nThanks for the fast response. Maybe it would help you to understand my use case:\n\n-------------- Start ------------------------\nI receive a customer request.\nThe create a Query based on the customer data.\nSearch a Lucene index in memory, not disk activity is done. i.e. I use RAMDirectory.\nThen return the response to the customer.\n\nWith a single request I get on average 3ms response times.\nIf I ramp it up to 200 requests I start getting 200-500ms response times.\n------------ End ------------------------\nFor my application every millisecond counts, just does and out of my control.\n\nAssumptions:\n (1)  I create a new Instance of Query on each Request. The Query object is not shared ever. So, no locking is needed and no thread blocking should ever happen.\n (2)  The index is read only, and in memory so no OS file locking is applicable or will ever occur.\n (3) No index refresh happens and no writing, this is purely read only.\n\nPoint is no need for locking anywhere.\n\n\n   \n\n\n\n\n \n\n\n",
            "date": "2011-12-17T19:37:49.235+0000",
            "id": 3
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "Just to explain App.java:\n\nI've created this app to show the problem.\nBasically I create 500 threads.\n Each thread do:\n        Create a Single Query.\n        Does 10000 search requests against the lucene index.\n        Calculate max,min,average\n Wait for threads to complete.\n Print out max,min,average\n\n\nThe images attached are taken from profiling while running this class.\n\n",
            "date": "2011-12-17T19:42:12.365+0000",
            "id": 4
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi,\n\nshort comment about your code and how to remove parts of the sync:\n- The SegmentCoreReaders sync cannot be removed in Lucene 3.x, as segments are read/write. You can remove the synchronization partly in *your* Lucene instance by patching it, the risk is on your side! This is not a bug in Lucene. In Lucene trunk, most of this sync is removed as IndexReaders will be pure read-only. We are currently working on removing contention in SegmentReader's SegmentCore.\n- You are not resusing the Analyzer. Create *one* analyzer instance and reuse it for indexing and for QueryParser! When you do this, you will see no contention on TokenStream creation (VirtualMethod.getImplementationDistance, AttributeSource.getAttributeInterfaces). TokenStream creation by Analyzers is a heavy operation (not only the reflection cache contention), so use only one Analyzer per app and pass it to all you QueryParsers. Removing sync from AttributeSource/VirtualMethod caches will corrupt the cache and cause bugs - but thats unneeded if you reuse as already said.",
            "date": "2011-12-17T21:10:19.494+0000",
            "id": 5
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. The SegmentCoreReaders sync cannot be removed in Lucene 3.x, as segments are read/write. You can remove the synchronization partly in your Lucene instance by patching it, the risk is on your side! This is not a bug in Lucene. In Lucene trunk, most of this sync is removed as IndexReaders will be pure read-only. We are currently working on removing contention in SegmentReader's SegmentCore.\n\nUwe, I had a quick look at it and I think we can remove this. We set the tis in the ctor or if we load a NRT reader. So basically we can assign the tisNoIndex reader to the tis instead of leaving it will a null ref and use a second boolean to actually signal if it was loaded or not. for read access this is not necessarily required to be synced since if you pull a NRT reader you can rely on the IW sync / mem barrier to see the latest reference. I will take a closer look at this next week.",
            "date": "2011-12-17T22:10:50.610+0000",
            "id": 6
        },
        {
            "author": "Uwe Schindler",
            "body": "Thanks Simon, Mike is currently working on that in Trunk (SegmentReader is getting so simple now...). For 3.x your solution might work.",
            "date": "2011-12-17T22:26:55.555+0000",
            "id": 7
        },
        {
            "author": "Uwe Schindler",
            "body": "Based on my work for another issue I added removal of synchronization for the caches in VirtualMethod and AttributeSource. As those caches are generally read (should be without synchronization) and seldom populated, ConcurrentHashMap is the best choice, as gets are without locks.\nThe problem is that those reflection caches need a WeakHashMap, but there is no ConcurrentWeakHashMap. Based on the work on issue LUCENE-3531, I reactivated my WeakIdentityMap and made the backing map exchangeable (there are 2 static factory methods allowing ConcurrentHashMap or simple HashMaps as backing map). For the reflection caches, identity is also fine (Class.equals/hashcode is based on class identity). The reflection caches also have no problem doing the heavy reflection work twice if two threads are requesting the same class at the same time - work is done twice and stored twice in map, but who cares?\n\nThis patch improves concurrency on creation of TokenStreams and instantiation of all classes using VirtualMethod for backwards compatibility.",
            "date": "2011-12-18T00:58:34.338+0000",
            "id": 8
        },
        {
            "author": "Uwe Schindler",
            "body": "Updated patch (code cleanup, javadocs)",
            "date": "2011-12-18T01:23:52.332+0000",
            "id": 9
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "Thanks, I'll keep an eye on the things happening in the trunk.\n\nCreating a Single Tokenizer does help, but the thread blocking still happens because of the synchronization used in several classes.\n\nI've made some quick changes during the last few days on lucene-3.5, and have included the diff. (this is not an svn diff sorry).\n\nI agree, if anybody has to decide between, concurrency or storing things twice then concurrency wins, eventually all the cache data will be available to all threads, and the overhead goes away. But with synchronization the overhead never goes away.\n\nSome other points of contention are:\n RAMFile : all methods are synchronized.\n RAMInputStream: clone() \n             This method came up during the profiling allot. I changed it from calling clone to: just create an new instance directly.\n\n \n \nI'll try to cleanup some of the code and add a better diff.\n\n",
            "date": "2011-12-18T01:24:42.687+0000",
            "id": 10
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. Creating a Single -Tokenizer-Analyzer does help, but the thread blocking still happens because of the synchronization used in several classes.\n\nNot reusing is stupid because of heavy construction cost (not contention)\n\nbq. I agree, if anybody has to decide between, concurrency or storing things twice then concurrency wins, eventually all the cache data will be available to all threads, and the overhead goes away. But with synchronization the overhead never goes away.\n\nThere are places where we cannot remove synchronization - and those places are no issue at all. Just because there is synchronization, there is not necessarily a bottleneck. Not everything you mention is an issue.\n\nbq. RAMFile : all methods are synchronized.\n\nThere is contention, but will not slowdown your search. Please keep synchronization there. every RAMFile is only opened once and then contention is gone. Not everything what your profiler shows as contention is one, only the first query will have some minor contention.\n\nbq. RAMInputStream: clone() This method came up during the profiling allot. I changed it from calling clone to: just create an new instance directly.\n\nThats fine, but same applies here. You only have contention on first few queries.\n\nbq. I'll try to cleanup some of the code and add a better diff.\n\nThe VirtualMethod and AttributeSource is already fixed in my patch.\n\nOn the time-line of your profiler output I see no improvement in speed. How much faster does your code get?",
            "date": "2011-12-18T02:03:55.873+0000",
            "id": 11
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "|There is contention, but will not slowdown your search. Please keep synchronization there. every RAMFile is \n|only opened once and then contention is gone. \n\nI'm not clear on this one, you mean every RAMFile is opened once per search? or Will be reused across all searches? If the later all threads will block on RAMFile always, this is not minor but major, especially taking into account that I want to move from 200 concurrent requests to 8000.\n\n|Not everything what your profiler shows as contention is one,only the first query will have some minor contention.\n\n:)  yes indeed. Thats why I've run several tests with warmups and try to fish out based on call frequency, total time spent and total time a Thread  was blocking on a certain monitor.\n\n|On the time-line of your profiler output I see no improvement in speed. How much faster does your code get?\n\nI've not profiled for individual search speed, but rather for contention, doing the tests on my laptop first and will move these changes to a production system during next week to test total search time with loading.\n\nWith the current version i.e. with the synchronization in there the search times go up drastically, as I've mentioned above. On our production deploy and indexes search times go from 3ms on single requests to 200-500ms and more on average when 200 concurrent requests are made. \n\n ",
            "date": "2011-12-18T02:42:18.737+0000",
            "id": 12
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. I'm not clear on this one, you mean every RAMFile is opened once per search? or Will be reused across all searches? If the later all threads will block on RAMFile always, this is not minor but major, especially taking into account that I want to move from 200 concurrent requests to 8000.\n\nOnce per opening IndexReader, during searches there is no file open/closing done at all. Synchronization on the directory of files is only done when writing the files, and only when opening files during IndexReader openm, but not on every access. When files are deleted there are other contention points, but not during searches, as IndexReader is opened R/O.",
            "date": "2011-12-18T08:47:55.866+0000",
            "id": 13
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "OK, so for searching (after loading) the RAMFile synced methods would not be called, now bare with me for a moment:\n\nThis does not seem to be the case when you retrieve the Document, which is probably to be expected.\nIn my code I do:\n\nsearcher.doc(matched[i].doc) //searcher == IndexSearcer and matched[] == ScoreDoc[] \n\nIn my code I see the following call trace (Top to Bottom):\n\n\nIndexSearcher.doc\nIndexReader.document\nDirectoryReader.document\nSegementReader.document\nFieldsReader.doc\nRAMInputStream.seek\nRAMInputStream.switchCurrentBuffer\nRAMFile.getBuffer\n\n\nWhich means I can search concurrently but as soon as I try to retrieve something again I hit contention. \nNow I appreciate that with File IO this is required but a fully in memory index should not have these problems. I'm trying to change the RAMFile usage so that it does not require synchronization.\n\n\n\n",
            "date": "2011-12-18T13:01:37.348+0000",
            "id": 14
        },
        {
            "author": "Uwe Schindler",
            "body": "Updated patch with test for the concurrent weak hash map. I will commit this to 3.x and trunk as it improves the sophisticated\u2122 backwards layers and creation cost of AttributeSource (because ConcurrentHashMap has lockless get).\n\nI will keep this issue open for Simon to check the SegmentCoreReaders.",
            "date": "2011-12-18T17:01:48.592+0000",
            "id": 15
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed VirtualMethod/AttributeSource improvements in trunk revision: 1220458, 3.x revision: 1220464",
            "date": "2011-12-18T17:36:35.739+0000",
            "id": 16
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed improvement for WeakIndentityMap to not use ReferenceQueue on get/contains/remove operations, only put (trunk: 1220555, 3.x:  r1220557)",
            "date": "2011-12-18T22:35:35.749+0000",
            "id": 17
        },
        {
            "author": "Simon Willnauer",
            "body": "Gerrit, before I spend time on fixing this single IMO likely uncontented lock in org.apache.lucene.index.SegmentCoreReaders.getTermsReader() can I ask you to run your tests / benchmarks with -XX:BiasedLockingStartupDelay=0 as far as I can see you are running micro benchmarks which start up very quickly. Locks accessed right after startup behave differently in the JVM than other locks ie. sync blocks. Can you retest and report back?\n\nsimon",
            "date": "2011-12-19T08:51:28.879+0000",
            "id": 18
        },
        {
            "author": "Simon Willnauer",
            "body": "here is a patch that removes the sync on SegmentCoreReaders#getTermsReader() - since this method is access on basically every search we should try to prevent any sync even if they are cheap in the uncontended case.",
            "date": "2011-12-19T08:59:14.063+0000",
            "id": 19
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "Hi Simon,\nThanks, I'll try these on our production systems.\nOne other change I've made, which I'll submit a patch for (pending testing) is introducing a ReadonlyRAMFile.\n\nSearch for my use case is split into two:\n             (1) Search \n             (2) Get Stored data from index.\nNow in an in memory index almost zero locking can be achieved.\n   All the patches will do great for (1), the ReadonlyRAMFile seems to solve item (2).\n\n",
            "date": "2011-12-19T10:10:09.612+0000",
            "id": 20
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "These are the results from profiling with the Latest trunk checkout as from 2011-12-19 11:03.\n\nThe Thread-LUCENE_3653.patch.png is without BiasedLockingStartupDelay.\n\nThe others are with this option added to java + the patch.\n\nI've included 3 images of the later so show that contention has improved but still other areas of contention exist that are probably related to the RAMFile itself being fully synchronized.\n",
            "date": "2011-12-19T11:05:13.765+0000",
            "id": 21
        },
        {
            "author": "Robert Muir",
            "body": "I think this is all profiler ghosts.\n\nGuys lets be careful not to introduce bugs over what isn't a performance problem at all.",
            "date": "2011-12-19T11:47:44.747+0000",
            "id": 22
        },
        {
            "author": "Michael McCandless",
            "body": "Why are we using ConcurrentHashMap when we know there's a JVM deadlock bug, on certain 1.5.x's and certain CPUs...?  (LUCENE-3235)\n\nShouldn't we move in the other direction here (don't use CHM unless it cannot be avoided)?\n\nFor example it's crazy to use this class to back the core/reader closed listeners.... and I don't think we should back the AttrSource with it...?",
            "date": "2011-12-19T12:01:40.101+0000",
            "id": 23
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. For example it's crazy to use this class to back the core/reader closed listeners.... and I don't think we should back the AttrSource with it...?\n\nCHM is only risky on contention. Contention here is unlikely as once all classes are \"inspected\" there are only read accesses.\n\nOn my tests, creating lots of AttributeSources and IndexSearchers are improved. The problem is that both VirtualMethod and AttributeSource block on construction on these cache locks.",
            "date": "2011-12-19T12:12:50.785+0000",
            "id": 24
        },
        {
            "author": "Simon Willnauer",
            "body": "Gerrit, I looked at your test and what you are seeing with soo many threads is certainly profiler ghosts. 500 threads is a lot even on a highly concurrent system. the blocking you see might not be due to a monitor.\n\nbq. I think this is all profiler ghosts.\nI disagree I ran Gerrits simple test with 100 threads and its 2x faster without the locking on SegmentCoreReaders#getTermsReader() I agree this is not the part which takes time on a big index but this locking is certainly unnecessary and it takes up CPU resources. We should make the path down the IR as efficient as possible. \n\nI will attache my profiling session with and without the patch and you will see the differences.\n",
            "date": "2011-12-19T12:13:00.636+0000",
            "id": 25
        },
        {
            "author": "Simon Willnauer",
            "body": "here are two runs with 100 threads and 100000 iterations per thread. I think this is definitly something we can prevent with the LUCENE-3653.patch",
            "date": "2011-12-19T12:14:12.855+0000",
            "id": 26
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nI disagree I ran Gerrits simple test with 100 threads and its 2x faster without the locking on SegmentCoreReaders#getTermsReader() \n{quote}\n\nWait, if this stuff is a big problem, surely we can just use luceneutil with lots of threads right?\n\nI want to see the QPS change, I don't trust the benchmarks or the various fancy jvm tools being used on this issue. I think its all ghosts.",
            "date": "2011-12-19T12:22:02.719+0000",
            "id": 27
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Wait, if this stuff is a big problem, surely we can just use luceneutil with lots of threads right?\nas I said, the index is tiny so just measuring the overhead of the lock on SegmentCoreReaders#getTermsReader() - this is a low hanging fruit IMO which we should pick even  if there is no real change in QPS. Its unnecessary and the patch is simple, any objections?",
            "date": "2011-12-19T12:32:51.680+0000",
            "id": 28
        },
        {
            "author": "Uwe Schindler",
            "body": "I general if we can remove contention anywhere we should do it. As I said, contention on thing that generally only reads but very seldom writes is horrible. Just write a test that creates 200 threads and creates TokenStreams or IndexSearchers (around a single IndexReader). They will all lock on the cache (ok, without reflection cache it would even be slower...)",
            "date": "2011-12-19T12:37:26.687+0000",
            "id": 29
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nJust write a test that creates 200 threads and creates TokenStreams or IndexSearchers (around a single IndexReader). They will all lock on the cache (ok, without reflection cache it would even be slower...)\n{quote}\n\nI don't care. They should be reusing tokenstreams in their application.\n\nWe don't need to make lucene more complicated to (possibly) speed up someones broken code.\n\nLots of commits here, a title that says 'lucene doesn't scale, lots of arguing that there are locking problems, but not one luceneutil benchmark run?\n\nSeriously?",
            "date": "2011-12-19T12:50:32.408+0000",
            "id": 30
        },
        {
            "author": "Uwe Schindler",
            "body": "The code for the commit was standing here more than 24 hours and was tested extensively to remove contention on creation on all classes using VirtualMethod (IndexSearcher and TokenStream are only example). What's your problem with it? The latest commit 1 hr ago was only a fix in the tests and had nothing to do with ConcurrentHashMap.\n\nAs I said, CHM is used for read-access only, but the guard is needed, if two ctors are running at same time and need to add a new entry to cache. All other cases are read-only, so lockless is better. It is just stupid to wait on a ctor, just because there is a lock on a map thats never be updated once your code is running an no new classes using VirtualMethod are loaded. We can also use Google Guava to use their MapMaker or wait until Java 8, where Doug Lea's ConcurrentWeakHashMap is maybe added (JSR-166).\n\nIn fact the code of AttributeSource got simplier because we have no sync blocks.",
            "date": "2011-12-19T13:22:24.088+0000",
            "id": 31
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. For example it's crazy to use this class [ConcurrentHashMap] to back the core/reader closed listeners\n\nThis is indeed totally crazy, as this is the wrong use-case for this map. This map should be used when you have lot's of reads and less writes to the map. For this case, you have only one thread reading (on close only, LOL), but maybe mayn adding listeners. So this is in general a bug to use CHM here. Should be a simple sycnrhonized HashMap (which performs better on writes, as it has less complexity inside).\n\n=> We should open issue for that!",
            "date": "2011-12-19T13:48:16.081+0000",
            "id": 32
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "Just to clear up on some comments:\n\nGuys I'm testing this on a production deploy and the use case is simple. Parser Query, Search, Get Doc fields. Contention was seen without profiling and profiling was used to find where the contention in the application.\n\n|I don't care. They should be reusing tokenstreams in their application.\n\nToken streams is not the only place of contention discussed here. Please look at the test attached (App.java). It does not recreate the token streams on each search, only (by mistake) for each thread. But still this only has a very small impact. Searches are repeated from each thread reusing the same token stream.\n\n|We don't need to make lucene more complicated to (possibly) speed up someones broken code.\n\nPlease write an example and show me your findings. I've done the same already. Have a look at App.java\n\n|I want to see the QPS change, I don't trust the benchmarks or the various fancy jvm tools being used on this issue. \nI think its all ghosts.\n\nYourkit is a standard Profiling tool. I didn't just wake up and say hey I'll profile lucene. I only started after I noticed the contention on a production application where we are trying to use lucene in memory.\n\n|Lots of commits here, a title that says 'lucene doesn't scale, lots of arguing that there are locking problems, but not one luceneutil benchmark run\n\n??, You don't need to be a scientist nor use a profiling tool to see that all threads will block on a synchronized block or method on each request if that method is called during each search request, from that it doesn't take much to know that this does not scale. \n\n\nAgain, this is not a go at lucene, the heading 'Lucene Search not scalling' is causing toooo much problems here I see, I could have chosen a better heading and if we can change it to something else please do so. I think lucene is really great, thats why I'm trying to use it. Thanks for the support, ideas and patches so far. \n\n\n\n",
            "date": "2011-12-19T14:08:13.985+0000",
            "id": 33
        },
        {
            "author": "Robert Muir",
            "body": "Sorry, I don't care what Yourkit says: its wrong.\n\na synchronized method that is just a *getter* only called once per-segment is *NOT* locking up your search.",
            "date": "2011-12-19T14:16:22.874+0000",
            "id": 34
        },
        {
            "author": "Simon Willnauer",
            "body": "Gerrit, what robert is saying is that if your index has a reasonable size the cost of a search is not dominated by calling the getter nor by the lock its using. You App is using 1k documents with a tiny number of terms. you are also using 500 threads where scheduling actually dominates the cost. A reasonable benchmark will not see a significant impact due to this synchronization in SegmentCoreReaders#getTermsReader() it will be dominated by retrieving the documents etc. What you are measuring is literally the impact of the lock in a case where your search is super super cheap. I still think we can and should get rid of the SegmentCoreReaders#getTermsReader() sync but in general saving a couple of cpu cycles but paying the price for more complicated code is not worth it IMO. so I agree with robert there will likely be no contention there.",
            "date": "2011-12-19T14:24:43.525+0000",
            "id": 35
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "\nthis is not a problem if your ok with 200 or less requests on a server and your search time can be 0.5 or more seconds. But if your whole execution window is measured in milliseconds and you get 7000-10000 requests per second on a server then yes it does matter.\n\nIf that method is called in each thread that is trying to search on the index then it becomes a point of contention, if there are several synchronized separately synchronized methods it only becomes worse. Your basically saying its ok for all threads to wait sequentially in several areas of the code during an in memory readonly index search. \n",
            "date": "2011-12-19T14:25:03.898+0000",
            "id": 36
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "Just to clarify, my index is 2 gigs (may grow to 10 gigs, I've got 72gigs of RAM to work with), with thousands of documents, documents are not big. The total processing time in my app without the index searches is on average 2-3 milliseconds (after warmup), this includes searching through a treemap with 11million entries.\n\nContention was not only seen on the single method in SegmentCoreReaders#getTermsReader() but also on all methods in RAMFile and SegmentNorms etc. Its not just about a single method, that's what I've been trying to make clear in my comments from the start.  \n",
            "date": "2011-12-19T14:29:08.316+0000",
            "id": 37
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nContention was not only seen on the single method in SegmentCoreReaders#getTermsReader() but also on all methods in RAMFile and SegmentNorms etc.\n{quote}\n\nNot actually seen, just spit out by a profiling tool. I really don't think you should interpret what Yourkit is telling you as gospel truth.",
            "date": "2011-12-19T14:35:08.481+0000",
            "id": 38
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "IndexSearch.doc calls RAMFile indirectly through RAMInputStream, once search is complete you need to know what's been found so IndexSearch.doc needs to be called.\ni.e. RAMInputStream calls RAMFile.numBuffers and getBuffer on the switchCurrentBuffer which happens allot during my searches. \n\nIndexSearcher calls TermQuery$TermWeightScorer.scorer which calls SegmentReader.norms, which calls SegmentNorms.bytes on each search.\nSegmentNorms has almost all methods synchronized.\n \n\n\n\n\n\n",
            "date": "2011-12-19T14:47:54.487+0000",
            "id": 39
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. IndexSearcher calls TermQuery$TermWeightScorer.scorer which calls SegmentReader.norms, which calls SegmentNorms.bytes on each search. SegmentNorms has almost all methods synchronized.\n\nThats the idea behind this class, it caches norms, as they are heavy to load. Even accidently loading them two times because of double-checked-locking is too expensive. Hotspot does the removal of sync later!\n\nHave you thought about yourkit effectively disabling hotspot, so your analysis is bogus here?",
            "date": "2011-12-19T15:08:35.369+0000",
            "id": 40
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "OK got you. Just keep in mind that I'm still profiling this and will post my findings as I go along. \n\n",
            "date": "2011-12-19T15:17:34.580+0000",
            "id": 41
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. IndexSearch.doc calls RAMFile indirectly through RAMInputStream, once search is complete you need to know what's been found so IndexSearch.doc needs to be called. i.e. RAMInputStream calls RAMFile.numBuffers and getBuffer on the switchCurrentBuffer which happens allot during my searches.\n\nIf you use RAMDirectory on a large index its slowing down things as it drives the garbage collector crazy. Use an on-disk index with MMapDirectory, which has no locking at all (only on sometimes called IndexInput.clone, but if you remove that your JVM will SIGSEGV if you use Lucene incorrectly with multiple threads).\n\nRAMDirectory is written for tests, not for production use. There are already plans to remove it from Lucene trunk and move to tests only. Have you seen that it allocates buffers in 8 Kilobytes blocks? Calculate how many byte[] you have on a 50 Gigabytes index... GC will drive crazy when it starts to cleanup. And then it stops your whole application, not because it locks inside RAMFile, because it does a stop-the world GC.\n\nWe are working on a RAM-Dir like approach storing the files outside Java heap using a large DirectByteBuffer (which is the same code as MMapDirctory). The problem is writing to such a directory, but reading is as fast (or even faster) than RAMDirectory without locks.",
            "date": "2011-12-19T15:23:13.973+0000",
            "id": 42
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "Oh, ok I thought RAMDirectory would make things faster, good to know. I will try with MMapDirectory then post back.",
            "date": "2011-12-19T15:29:56.424+0000",
            "id": 43
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. Oh, ok I thought RAMDirectory would make things faster, good to know. I will try with MMapDirectory then post back.\n\nThats a hard to eliminate misbelief - same like \"optimizing indexes is good\".\n\nJust remember that MMapDirectory will use memory outside the JVM heap. If the whole index is in file system cache, Lucene can directly access the cache using MMapDirectory (thats like a swap file, loaded on demand). So reduce JVM heap and supply lots of space for the OS kernel to cache file contents, as those are mapped by MMAP into Java's process space.",
            "date": "2011-12-19T15:38:02.162+0000",
            "id": 44
        },
        {
            "author": "DM Smith",
            "body": "bq. Thats a hard to eliminate misbelief - same like \"optimizing indexes is good\".\n\nNot sure why it is a misbelief? On Win98 and XP with Lucene 1.4.x, when creating an index, with Symantec AV and Windows Fast indexing both on, indexing of 64K small documents, took 40+ minutes. With them off, it took about 4 minutes. Going with a RAM dir took >40 seconds.\n\nFrom what I could tell (and remember), Lucene was writing and deleting tens of thousands of documents. It appeared, that the OS was updating its fast search index for each file change hitting the disk. And Symantec, seemed to be scanning every on file creation.\n\nAs this was a desktop application, we couldn't ask end users to turn off those features or to tune them.\n\nDoes MMapDirectory avoid this too many transient files problem?",
            "date": "2011-12-19T17:50:54.819+0000",
            "id": 45
        },
        {
            "author": "Uwe Schindler",
            "body": "DM: At lucene 1.4 times the indexer was working different and really created lots of files. With new merging this is no longer the case.\n\nIn fact we were talking here about searching not indexing. It makes no sense to clone a huge RAM directory from disk to heap and run searches on it.",
            "date": "2011-12-19T17:58:55.381+0000",
            "id": 46
        },
        {
            "author": "Michael McCandless",
            "body": "bq. I still think we can and should get rid of the SegmentCoreReaders#getTermsReader() sync\n\n+1, I think Simon's patch is a good improvement, even if in practice this sync'd getter should be a tiny cost.",
            "date": "2011-12-19T18:40:42.198+0000",
            "id": 47
        },
        {
            "author": "DM Smith",
            "body": "bq. In fact we were talking here about searching not indexing. It makes no sense to clone a huge RAM directory from disk to heap and run searches on it.\n\nI saw that this issue is on searching not indexing. I didn't mean to try to hijack it. I was responding to the statement that RAMDirectory going away (BTW, the statement on optimize does not regard a search feature but an index one). I'll have to test to see if the same index problem still is around.\n\nRegarding MMap, there is an open issue with it on Windows: Lucene-1669.",
            "date": "2011-12-19T20:22:57.536+0000",
            "id": 48
        },
        {
            "author": "Uwe Schindler",
            "body": "LUCENE-1669 seems to be relict and should already be solved since Lucene 2.9 in newer Windows versions? And BTW, MMap is only useful for reading indexes, written are they by NIO/SimpleFS.\n\nbq. BTW, the statement on optimize does not regard a search feature but an index one\n\nThis statement was just a comparison, to underline that both statements \"RAMDir is fast\" and \"Optimize is needed\" are myths.\n\nbq. I was responding to the statement that RAMDirectory going away \n\nSee my previous comment:\n\nbq. We are working on a RAM-Dir like approach storing the files outside Java heap using a large DirectByteBuffer (which is the same code as MMapDirctory). The problem is writing to such a directory, but reading is as fast (or even faster) than RAMDirectory without locks.",
            "date": "2011-12-19T21:34:10.303+0000",
            "id": 49
        },
        {
            "author": "Gerrit Jansen van Vuuren",
            "body": "Hi,\n\nI've tested my application using \n   - Using a single Tokenizer\n   - MMapDirectory, \n   - the latest trunk build that contains the patches committed here.\n   - with the LUCENE-3653.patch applied.\n   - plus using the XX:BiasedLockingStartupDelay=0 option.\n\nMy app request time has gone down from a terrible 400 ms to 120-140ms on average and is constant over 10-200-500 threads (after a 3 hour warmup). (Running java 1.6.0_29 64 bit centos 5.4).\n\nStill strange that I can do a single threaded request 10000 times and get 3-5 ms on average response time.\n\nThanks, Uwe, Simon, your input, comments, and patches have helped allot.\n\n\n\n\n ",
            "date": "2011-12-20T16:27:03.665+0000",
            "id": 50
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. +1, I think Simon's patch is a good improvement, even if in practice this sync'd getter should be a tiny cost.\n\nI agree. However, I don't think we can get entirely rid of a mem-barrier here. Even if this is synced by the IW a thread could reopen the reader and another search thread gets the new instance without yet another barrier. This means that search thread would not use the dictionary resulting in a possibly slow search. I removed the sync and made the tis member volatile. That seems the safest option to me.",
            "date": "2011-12-22T08:45:46.340+0000",
            "id": 51
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Simon, for 3.x I agree. In trunk we already have no synchronization at all (committed 2 days ago; improved yesterday: LUCENE-3631), so there is no need to change anything.",
            "date": "2011-12-22T10:23:33.808+0000",
            "id": 52
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Hi Simon, for 3.x I agree. In trunk we already have no synchronization at all (committed 2 days ago; improved yesterday: LUCENE-3631), so there is no need to change anything.\nuwe that patch is against 3.x - I didn't intend to apply this to 4.0 since we do totally different things there. I will commit this if nobody objects in a bit.",
            "date": "2011-12-22T10:36:13.974+0000",
            "id": 53
        },
        {
            "author": "Uwe Schindler",
            "body": "+1",
            "date": "2011-12-22T11:57:33.984+0000",
            "id": 54
        }
    ],
    "component": "",
    "description": "I've noticed that when doing thousands of searches in a single thread the average time is quite low i.e. a few milliseconds. When adding more concurrent searches doing exactly the same search the average time increases drastically. \nI've profiled the search classes and found that the whole of lucene blocks on \n\norg.apache.lucene.index.SegmentCoreReaders.getTermsReader\norg.apache.lucene.util.VirtualMethod\n  public synchronized int getImplementationDistance \norg.apache.lucene.util.AttributeSourcew.getAttributeInterfaces\n\nThese cause search times to increase from a few milliseconds to up to 2 seconds when doing 500 concurrent searches on the same in memory index. Note: That the index is not being updates at all, so not refresh methods are called at any stage.\n\n\nSome questions:\n  Why do we need synchronization here?\n  There must be a non-lockable solution for these, they basically cause lucene to be ok for single thread applications but disastrous for any concurrent implementation.\n\nI'll do some experiments by removing the synchronization from the methods of these classes.",
    "hasPatch": true,
    "hasScreenshot": true,
    "id": "LUCENE-3653",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Lucene Search not scalling",
    "systemSpecification": true,
    "version": ""
}