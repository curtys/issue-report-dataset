{
    "comments": [
        {
            "author": "Erik Hatcher",
            "body": "There is some commented out code in Highlighter.java:\n\n\t\t\tif (lastEndOffset < text.length())\n\t\t\t\tnewText.append(encoder.encodeText(text.substring(lastEndOffset)));\n\nuncommenting that code fixes this issue.\n\nI've added this test to HighlighterTest.java:\n\n  public void testOffByOne() throws IOException {\n    TermQuery query= new TermQuery( new Term( \"data\", \"help\" ));\n    Highlighter hg = new Highlighter(new SimpleHTMLFormatter(), new QueryScorer( query ));\n    hg.setTextFragmenter( new NullFragmenter() );\n\n    String match = null;\n    match = hg.getBestFragment( new StandardAnalyzer(), \"data\", \"help me [54-65]\");\n    assertEquals(\"<B>help</B> me [54-65]\", match);\n  }\n\nall tests pass even with that code uncommented.   I'll commit if there are no objections.",
            "date": "2006-08-04T00:17:38.000+0000",
            "id": 0
        },
        {
            "author": "Hoss Man",
            "body": "Note that \"svn blame\" indicates that commenting those lines out was the sole change mharwood made in r168452 which had this comment...\n\n> Fixed bug where docs larger than maxDocBytesToAnalyze\n> would cause last fragment to be sized as remainder of doc\n> (which could be huge)\n\nhttp://svn.apache.org/viewvc?view=rev&revision=168452\n\n...it's not clear to me if subsequent commits have fixed this problem in another way so that uncommenting those lines is safe again ... but the behavior described in r168452 certainly seems worse then the behavior descibed in this bug, so i would suggest not reverting that change untill the original problem can be verified with a test case. (there may already be one .. i don't know enough about highlighter to check)\n",
            "date": "2006-08-04T00:55:41.000+0000",
            "id": 1
        },
        {
            "author": "Mark Harwood",
            "body": "[Just got back from holiday and picking up some old messages]\n\nI've committed what I beleive to be a fix for this along with added Junit tests for this scenario + over-sized docs. Let me know if this meets everyone's needs and I'll close this issue.\n\nThis highlighter code may be rewritten shortly because I still need to take a look at Ronnie Kolehmainen's highlighter contribution in more depth. This offers notable speed ups for large docs.\n\nCheers,\nMark\n",
            "date": "2006-08-16T21:46:41.000+0000",
            "id": 2
        },
        {
            "author": "Koji Sekiguchi",
            "body": "This fix works well for our case with JapaneseAnalyzer.\n\ninput text: \"AAA BBB CCC (DDD EEE)\"\n\noutput (w/ lucene-highlighter-2.0.0.jar)\nAAA <B>BBB</B> CCC (DDD EEE\n\noutput(w/ lucene-highlighter-2.1-dev.jar)\nAAA <B>BBB</B> CCC (DDD EEE)\n\nWe hope that the fix will be included at next release.\n\nRegards,\nKoji",
            "date": "2007-02-16T01:58:38.630+0000",
            "id": 3
        },
        {
            "author": "Mark Miller",
            "body": "This issue has been fixed.",
            "date": "2007-07-02T19:13:31.155+0000",
            "id": 4
        },
        {
            "author": "Grant Ingersoll",
            "body": "Last report is this is fixed.",
            "date": "2008-01-10T21:03:35.901+0000",
            "id": 5
        }
    ],
    "component": "core/other",
    "description": "The following code extract show the problem\n\n\n\t\tTermQuery query= new TermQuery( new Term( \"data\", \"help\" )); \n\t\tHighlighter hg = new Highlighter(new SimpleHTMLFormatter(), new QueryScorer( query ));\n\t\thg.setTextFragmenter( new NullFragmenter() );\n\t\t\n\t\tString match = null;\n\t\ttry {\n\t\t\tmatch = hg.getBestFragment( new StandardAnalyzer(), \"data\", \"help me [54-65]\" );\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println( match );\n\n\nThe sytsem outputs \n\n<B>help</B> me [54-65\n\n\nwould expect \n\n<B>help</B> me [54-65]\n\n\n\n",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-645",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Highligter fails to include non-token at end of string to be highlighted",
    "systemSpecification": true,
    "version": "1.9"
}