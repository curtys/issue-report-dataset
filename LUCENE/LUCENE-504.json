{
    "comments": [
        {
            "author": "Joerg Henss",
            "body": "Simple test showing the error",
            "date": "2006-03-02T02:59:14.000+0000",
            "id": 0
        },
        {
            "author": "Paul Borgermans",
            "body": "Here the same problem, used a MultiFieldQueryParser in combination with fuzzy search which triggered the exception",
            "date": "2006-06-02T22:12:32.000+0000",
            "id": 1
        },
        {
            "author": "Doron Cohen",
            "body": "LuceneFAQ item    \"Why am I getting a TooManyClauses exception?\"   \nsuggests:    \"use BooleanQuery.setMaxClauseCount(Integer.MAX_VALUE)\". \n\nThis would cause PriorityQueue to create an array of size maxint:\n  - SUN JRE throws an out-of-memory error.\n  - IBM JRE throws a \"too large allocation\" runtime error.\n\nSeems that at least two fixes are required:\n  + BooleanQuery - hard limit on value of maxClauseCount\n  + PriorityQueue - hard limit on size of queue, since it is stored in memory.\n\nThe attached would set 1,000,000 hard limit - defined in PriorityQueu  - I think the most intensive use of\npriority queue is for docs/hits during search, and 1M docs seems sufficient, unless there are uses that I am not aware of.\n",
            "date": "2006-06-12T09:07:52.000+0000",
            "id": 2
        },
        {
            "author": "Otis Gospodnetic",
            "body": "I imagine the limit will depend on how big of a heap you allow, no?  What happens if you increase the heap size drammatically with -XmxNNNm?\n",
            "date": "2006-06-12T10:29:42.000+0000",
            "id": 3
        },
        {
            "author": "Doron Cohen",
            "body": "Yes this is correct - e.g. on a win32 machine with 2GB RAM, SUN 1.5 JRE would accept up to Xmx1470m and in that case you could set the limit on the queue  size to 355,638,512 - 17% of maxint, before getting an out of mem error.  \n\nFor allowing the caller maximal flexibility (and responsibility), BooleanQuery could interpret the maxint as a hint saying \"maximal possible value\" and then silently modify it to maxint-1, thereby avoiding the negative array size issue in PriorityQueue (and possibly fail later with out of memory).\n\nIs this what you have in mind?",
            "date": "2006-06-12T14:28:03.000+0000",
            "id": 4
        },
        {
            "author": "Nadav Har'El",
            "body": "Hi Doron and Otis,\n\nMy view is that this bug is a problem in FuzzyQuery, not in PriorityQueue or BooleanQuery. It is the caller's duty to create a priority queue with a sensible size, and it's not BooleanQuery's fault that other classes are using its getMaxClauseCount() wrongly. Moreover, changing PriorityQueue or BooleanQuery in the way Doron did, might potentially have side-effects because they are used in many places in Lucene. How do we know that nowhere in Lucene will we ever need a priority queue with a million elements?\n\nTherefore I suggest a different patch, changing only FuzzyQuery. \n\nhe idea in the patch I'm attaching is that while FuzzyQuery *is allowed to* create BooleanQuery.getMaxClauseCount() clauses, it doesn't have to do so, and doesn't need to create a priority queue of that size when this number is huge. I added to FuzzyQuery its own maxClauseCount (with per-instance getter/setter methods)  and FuzzyQuery will never try to create more than this number of clauses, even if Boolean.getMaxClauseCount() is huge.\n\nI set FuzzyQuery's default maxClauseCount to 1024, for backward compatibility (this is what happens today when you use BooleanQuery's defaults). However, it is likely that a user will want to set this number much lower than that. In fact, the whole idea of the priority queue is that it may be enough to take only a small number the most similar terms, so setting a FuzzyQuery's maxClauseCount to 100 or even 10 makes sense to me. This new feature is an added benefit of my patch.\n\nMy patch also includes Javadoc changes describing the new feature, and a new test case that failed before the fix, and succeeds after this patch. ",
            "date": "2006-06-14T17:45:47.000+0000",
            "id": 5
        },
        {
            "author": "Nadav Har'El",
            "body": "This is my proposed patch described above.",
            "date": "2006-06-14T17:47:22.000+0000",
            "id": 6
        },
        {
            "author": "Nadav Har'El",
            "body": "Hi Otis, you did not comment on my patch (fuzzyquery.patch), which I think solves your objections to Doron's previous patch. Do you also see problems in this patchl, or would prefer a different approach to solving this issue?\nIf not, perhaps you can commit this patch?\nThanks in advance, Nadav.",
            "date": "2006-06-29T18:30:04.000+0000",
            "id": 7
        },
        {
            "author": "Doron Cohen",
            "body": "I think it makes sense to separate here between efficiency and correctness.\n\nThe proposed fix above deals with efficiency, and maybe it should become a new separate future issue, perhaps also considering a more lazy allocation of space by PriorityQueue.\n\nThis issue is about correctness - setting max-clause \"by-the-book\" throws an exception - let's fix just that..\n\nModifying PriorityQueue to be tolerant to maxint capacity is one possible solution, though perhaps an overkill.  \n\nA simpler way is for PriorityQueue to silently decrement its maxsize by 1 in case maxsize is requested to be maxint.",
            "date": "2006-07-07T06:48:52.000+0000",
            "id": 8
        },
        {
            "author": "Mark Miller",
            "body": "This really should be fixed. I agree with Nadav, the problem is with the Queries that use MaxClauses to build the priority queue - its just not good use of the queue.\n\nI also agree with Doron that its really two distinct issues though:\n\n1. FuzzyQuery et al should be using lazy allocation of some kind. It makes no sense to create an array that large for every multi term query, especially when we direct users to possibly use Integer.MAX_VALUE.\n\n2.  The FAQ should not say to use Integer.MAX_VALUE if its going to kak with FuzzyQuery. At a minimum, FuzzyQuery should not init the priority queue larger than Integer.MAX_VALUE-1.\n\nI suppose, that almost combines the 2 issues though - we are telling users to set the max clauses to a number that will force ridiculously wasteful memory allocation. Almost seems like both issues really need to be addressed together. Or maybe just the FAQ changed :)",
            "date": "2008-08-21T11:55:09.893+0000",
            "id": 9
        },
        {
            "author": "George Papas",
            "body": "Hi, \n\nThis is still an issue in 2.4.0.  I know this is low priority, but has there been any more thinking about how to address this?\n\nThanks\nGeorge.",
            "date": "2008-12-17T22:59:50.860+0000",
            "id": 10
        },
        {
            "author": "Florian Waltersdorfer",
            "body": "Hi,\n\nsomething along the line of \nScoreDoc[] results = searcher.search(query, MAX_NUMBER_OF_HITS).scoreDocs;\ncauses a viable crash. I would consider this a \"natural\" start when trying to write an own searcher (MAX_NUMBER_OF_HITS beeing Integer.MAX_VALUE) and without the sources attached & the (eclipse) debugger I would have never found the problem I'd guess.\nSo please do something about this pitfall, if only adding a warning in the javadoc of i.e. Searcher.search(..., int n, ...)\n\nThanks \nFlorian",
            "date": "2009-07-15T23:38:33.066+0000",
            "id": 11
        },
        {
            "author": "Ivan Rozhnov",
            "body": "Hi guys,\n\nIt seems to me that problem is still opened. Can it be fixed with dynamic size of storage in PriorityQueue and couple of similar classes and using MaxClauseCount as top limit for size of such storage. It seems to be very weird to have preinitialized array of Max size in collection constructor.\n\nThanks,\nIvan",
            "date": "2009-11-02T09:45:22.175+0000",
            "id": 12
        },
        {
            "author": "Michael McCandless",
            "body": "Since 3.0 is now on Java 1.5, can't we switch to Java's PriorityQueue?  Anyone want to cough up a patch?",
            "date": "2009-11-03T10:20:45.955+0000",
            "id": 13
        },
        {
            "author": "Uwe Schindler",
            "body": "We had a discussion about that in another issue. In general PriorityQueue of Java 1.5 does not have the features we need for Lucene (it dynamically grows, but the grow process is not controllable, making it unuseable for collecting TopDocs and so on). But I think for this special case, we could use Java 5's PQ.",
            "date": "2009-11-03T18:25:17.519+0000",
            "id": 14
        },
        {
            "author": "Nadav Har'El",
            "body": "Hi Uwe, I think that even though PriorityQueue doesn't have a size limit, it is easy to implement a size limit: after an add(), if size() becomes greater than the bound, you simply poll() to remove the lowest element (this poll() returns the old object which insertWithOverflow() is to return).\n\nHowever, I think it's a good idea to compare the performance of Java's PriorityQueue (used as in the paragraph above) . I'm especially worried about the slowdown by the fact that adding a small element (below the current heap's head) in our code just does one comparison and returns, but in the usage I described above it actually modifies the heap twice (adds the element to the heap and then removes it).",
            "date": "2009-11-04T07:16:03.555+0000",
            "id": 15
        },
        {
            "author": "Uwe Schindler",
            "body": "Nadav:\nI suggest to keep Lucene's PriorityQueue, because it is a very central and highly optimized part of Liucene. In Lucene 3.0 it is already generified, so it also fits perfectly into Java's Collection API. The only problem is that the name is now identical to one internal Java class, but we cannot change it without BW breaks.\n\nFor this special issue, we should fix *only* FuzzyQuery to use Java5's PQ, which dynamically grows when new elements are added. And we do not need the upper limit here, like you propsed.\n\nI will prepare a patch tomorrow in the ApacheCon hacking session.\n\n*EDIT*\n\nWe need the upper limit here, but we can implement it like you proposed.",
            "date": "2009-11-04T08:39:41.670+0000",
            "id": 16
        },
        {
            "author": "Uwe Schindler",
            "body": "Here is a patch for this issue, using j.u.PriorityQueue. It currently does not limit the PQ's number of entries, it just only consumes maxClauseCount ones.\n\nAll tests pass, but they are no real test of the PQ behaviour, as the current test cases do not test more terms than maxClauseCount. So the tests pass in all cases, independent how the compareTo method looks like, so the ordering is not important because the queue never gets full. I will add a test.\n\nI will also try to implement the max size, but for now, the patch shows, how the code could look like with j.u.PQ.",
            "date": "2009-11-04T17:11:22.152+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "Here a patch, that fixes FuzzyQuery. It uses j.u.PQ and has a small optimization to not add ScoreTerms, that would never be seen in the first maxClauseCount terms (tracking a bottom value).\n\nIt also adds an testcase, where the maxClauseCount is lowerd downto 2 and the FuzzyQuery would hit 3 terms, so one too much. This tests the algorithm to not add this entry to the PQ.\n\nNadav: The solution you propsed for limiting the number of entries in the PQ does not work, as poll() removes the head element of the queue, not the bottom that falls out. There is no way to remove the bottom value in Java's PQ easily. So we should j.u.PQ only for this issue.",
            "date": "2009-11-04T21:48:18.022+0000",
            "id": 18
        },
        {
            "author": "Nadav Har'El",
            "body": "Uwe, you are right, I got confused... Sorry.",
            "date": "2009-11-05T06:55:22.597+0000",
            "id": 19
        },
        {
            "author": "Uwe Schindler",
            "body": "I think I take this one and commit it, is it ok? Thesolution seems to work quite good.",
            "date": "2009-11-06T18:42:34.730+0000",
            "id": 20
        },
        {
            "author": "Uwe Schindler",
            "body": "Committed revision: 833544",
            "date": "2009-11-06T20:15:43.044+0000",
            "id": 21
        }
    ],
    "component": "core/search",
    "description": "PriorityQueue creates an \"java.lang.NegativeArraySizeException\" when initialized with Integer.MAX_VALUE, because Integer overflows. I think this could be a general problem with PriorityQueue. The Error occured when I set BooleanQuery.MaxClauseCount to Integer.MAX_VALUE and user a FuzzyQuery for searching.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-504",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "FuzzyQuery produces a \"java.lang.NegativeArraySizeException\" in PriorityQueue.initialize if I use Integer.MAX_VALUE as BooleanQuery.MaxClauseCount",
    "systemSpecification": false,
    "version": "1.9"
}