{
    "comments": [
        {
            "author": "Otis Gospodnetic",
            "body": "In a direct email to me, Robert said: \"All of the files can be prepended with the ASL.\"\n",
            "date": "2006-12-11T22:47:20.000+0000",
            "id": 0
        },
        {
            "author": "robert engels",
            "body": "A generic version probably needs to implement reference counting on the Segments or IndexReader in order to know when they can be safely closed.",
            "date": "2006-12-11T22:57:08.000+0000",
            "id": 1
        },
        {
            "author": "Hoss Man",
            "body": "i somehow missed seeing this issues before ... i don't really understand the details, but a few comments that come to mind...\n\n1) this approach seems to assume that when reopening a MyMultiReader, the sub readers will all be MySegmentReaders .. assuming we generalize this to MultiReader/SegmentTeader, this wouldn't work in the case were people are using a MultiReader containing other MultiReaders ... not to mention the possibility of people who have written their own IndexReader implementations.\nin generally we should probably try to approach reopening a reader as a recursive operation if possible where each type of reader is responsible for checking to see if it's underlying data has changed, if not return itself, if so return a new reader in it's place  (much like rewrite works for Queries)\n\n2) there is no more commit lock correct? ... is this approach something that can still be valid using the current backoff/retry mechanism involved with opening segments?",
            "date": "2007-07-19T00:39:51.321+0000",
            "id": 2
        },
        {
            "author": "Michael Busch",
            "body": "> i somehow missed seeing this issues before ... \n\nactually, me too... first I came across this thread:\n\nhttp://www.gossamer-threads.com/lists/lucene/java-dev/31592?search_string=refresh;#31592\n\nin which Doug suggested adding a static method IndexReader.open(IndexReader) \nwhich would either return the passed in IndexReader instance in case is is\nup to date or return a new, refreshed instance. \n\nI started implementing this, using Dougs and Roberts ideas and then realized \nthat there was already this open issue. But the code here is quite outdated.\n\n> in generally we should probably try to approach reopening a reader as a \n> recursive operation\n\nYeah we could do that. However, this might not be so easy to implement.\nFor example, if a user creates a MultiReader instance and adds whatever\nsubreaders, we would have to recursively refresh the underlying readers.\nBut if the MultiReader was created automatically by IndexReader.open() just\ncalling refresh on the subreaders is not enough. New SegmentReaders have to\nbe opened for new segments.\n\nAlso the recursive walk would have to take place within the FindSegmentsFile\nlogic.\n\nI decided therefore to only allow IndexReaders to be refreshed if they were\ncreated by one of the IndexReader.open() methods. I'm going to submit a first\nversion of my patch soon. Do you think this is too limiting? ",
            "date": "2007-07-20T07:10:38.217+0000",
            "id": 3
        },
        {
            "author": "Michael Busch",
            "body": "First version of my patch:\n\n   * Adds the static method IndexReader.open(IndexReader)\n     that returns a new instance of IndexReader in case\n     the reader could be updated. If it was up to date\n     then the passed-in instance is returned. Only\n     IndexReader instances that were created by one of\n     the IndexReader.open() methods can be refreshed.\n\n   * SegmentsReader.reopen(SegmentInfos) looks in the \n     SegmentInfos for a segment with the same name. If\n     one could be found then either the deleted docs or\n     the norms were updated, otherwise the segment name\n     would have changed. reopen() clones the \n     SegmentReader and either loads the deleted docs,\n     the norms or both. Then the clone is returned and\n     the original SegmentReader is marked as closed.\n\n   * If the index has only one segment, then \n     IndexReader.open(IndexReader) checks if the passed\n     in IndexReader can be refreshed. This is only \n     possible if it is no MultiReader and if the segment\n     name has not changed. Otherwise a new SegmentReader\n     instance is returned and the old reader is closed.\n\t \n   * If the index has multiple segments, then\n     IndexReader.open(IndexReader) creates a new \n     MultiReader and tries to reuse the passed-in\n     reader (in case it's a SegmentReader) or its \n     subreaders (in case it's a MultiReader). For new\n     segments new SegmentReaders are created. Old \n     readers that couldn't be reused are closed.\n   \n   * Adds the new testcase TestIndexReaderReopen. It\n     includes the method \n     assertIndexEquals(IndexReader, IndexReader) that\n     checks whether boths IndexReaders have the same\n     content. The testcase creates an index and \n     performes different modifications on that index.\n     One IndexReader is refreshed after each index\n     modification and compared to a fresh IndexReader\n     which is opened after each modification.\n\t \n\nThis first version is for review and not ready to \ncommit. I want to add more extensive tests and \nprobably clean up the code.\n\nAll tests pass.",
            "date": "2007-07-20T07:13:34.008+0000",
            "id": 4
        },
        {
            "author": "Hoss Man",
            "body": "\n> Yeah we could do that. However, this might not be so easy to implement.\n> For example, if a user creates a MultiReader instance and adds whatever\n> subreaders, we would have to recursively refresh the underlying readers.\n> But if the MultiReader was created automatically by IndexReader.open() just\n> calling refresh on the subreaders is not enough. New SegmentReaders have to\n> be opened for new segments. \n\n...this being the curse that is MultiReader -- it can serve two very differenet purposes.  \n\nYou seem to have already solved the multisegments in a single directory approach, the MultiReader over many subreader part actually seems much easier to me (just call your open method on all of the subreaders) the only tricky part is detecting which behavior should be used when. This could be driven by a simple boolean property of MultiReader indicating whether it owns it's directory and we need to look for new segments or not -- in which case we just need to refresh the subreaders.  (My personal preference would be to change MultiReader so \"this.directory\" is null if it was open over several other subReaders, right now it's just assigned to the first one arbitrarily, but there may be other consequences of changing that)\n\nIncidentally: I don't think it's crucial that this be done as a recursive method.  the same approach i describe could be added to  static utility like what you've got, I just think that if it's possible to do it recursively we should so that  *if* someone does write their own MultiReader or SegmentReader subclass they can still benefit from any core reopening logic as long as theey do their part to \"reopen\" their extensions.\n",
            "date": "2007-07-21T00:26:00.150+0000",
            "id": 5
        },
        {
            "author": "Hoss Man",
            "body": "an extremely hackish refactoring of the previous patch that demonstrates the method working recursively and dealing with MultiReaders constructed over multiple subReaders.\n\na few notes:\n\n1) no where near enough tests of the subReader situation\n2) the refactoring is very very ugly and brutish ... most of the code is still in IndexReader just because it needs so many things that are private -- things that really seems like they should be pushed down into SegmentReader (or made protected)\n3) test triggered an apparent NPE in MultiReader.isOptimized() when there are subReaders, i hacked arround this in the test, see usages of assertIndexEqualsZZZ vs assertIndexEquals\n4) the FilterIndexReader situation is ... interesting.  in theory FilterIndexReader should really be abstract (since if you aren't subclassing it anyway, why do you want it?) \n",
            "date": "2007-07-21T01:46:39.651+0000",
            "id": 6
        },
        {
            "author": "Michael Busch",
            "body": "Now, after LUCENE-781, LUCENE-970 and LUCENE-832 are committed, I updated the latest\npatch here, which was now easier because MultiReader is now separated into two classes.\n\nNotes:\n   * As Hoss suggested I added the reopen() method to IndexReader non-static. \n   * MultiReader and ParallelReader now overwrite reopen() to reopen the subreaders\n     recursively.\n   * FilteredReader also overwrites reopen(). It checks if the underlying reader has\n     changed, and in that case returns a new instance of FilteredReader.\n\t \nI think the general contract of reopen() should be to always return a new IndexReader \ninstance if it was successfully refreshed and return the same instance otherwise, \nbecause IndexReaders are used as keys in caches.\nA remaining question here is if the old reader(s) should be closed then or not.\nThis patch closes the old readers for now, if we want to change that we probably have \nto add some reference counting mechanism, as Robert suggested already. Then I would\nalso have to change the SegmentReader.reopen() implementation to clone resources like\nthe dictionary, norms and delete bits. \nI think closing the old reader is fine. What do others think? Is keeping the old \nreader after a reopen() a useful usecase?",
            "date": "2007-08-01T21:41:08.479+0000",
            "id": 7
        },
        {
            "author": "Michael Busch",
            "body": "I ran some quick performance tests with this patch:\n\n1) The test opens an IndexReader, deletes one document by random docid, closes the Reader.\n   So this reader doesn't have to open the dictionary or the norms.\n2) Another reader is opened (or alternatively reopened) and one TermQuery is executed, so \n   this reader has to read the norms and the dictionary. \n\nI run these two steps 5000 times in a loop.\n   \nFirst run: Index size: 4.5M, optimized \n   \n   * 1) + TermQuery:    103 sec\n   * 1) + 2) (open):    806 sec, so open()   takes 703 sec\n   * 1) + 2) (reopen):  118 sec, so reopen() takes  15 sec ==> Speedup: 46.9 X\n   \n\nSecond run: Index size: 3.3M, 24 segments (14x 230.000, 10x 10.000)\n\n   * 1) + TermQuery:    235 sec\n   * 1) + 2) (open):   1162 sec, so open()   takes 927 sec\n   * 1) + 2) (reopen):  321 sec, so reopen() takes  86 sec ==> Speedup: 10.8X",
            "date": "2007-08-01T21:46:21.513+0000",
            "id": 8
        },
        {
            "author": "Yonik Seeley",
            "body": "> I think closing the old reader is fine. What do others think? Is keeping the old\n> reader after a reopen() a useful usecase?\n\nIn a multi-threaded environment, one wants to open a new reader, but needs to wait until all requests finish before closing the old reader.  Seems like reference counting is the only way to handle that case.",
            "date": "2007-08-06T22:07:38.315+0000",
            "id": 9
        },
        {
            "author": "Hoss Man",
            "body": "\n(note: i haven't looked at the latest patch in detail, just commenting on the comments)\n\nOne key problem i see with automatically closing things in reopen is MultiReader: it's perfectly legal to do something like this psuedocode...\n\n   IndexReader a, b, c = ...\n   MultiReader ab = new MultiReader({a, b})\n   MultiReader bc = new MultiReader({b, c})\n   ...b changes on disk...\n   ab.reopen(); // this shouldn't affect bc;\n\none possibility would be for the semantics of reopen to close old readers only if it completely owns them; ie: MultiReader should never close anything in reopen, MultiSegmentReader should close all of the subreaders since it opened them in the first place ... things get into a grey area with SegementReader though.\n\nIn general i think the safest thing to do is for reopen to never close.  Yonik's comment showcases one of the most compelling reasons why it can be important for clients to be able to keep using an old IndexReader instance, and it's easy enough for clients that want the old one closed to do something like...\n\n   IndexReader r = ...\n   ...\n   IndexReader tmp = r.reopen();\n   if (tmp != r) r.close(); \n   r = tmp;\n   ...\n\n\n(one question that did jump out at me while greping the patch for the where old readers were being closed: why is the meat of reopen still in \"IndexReader\" with a \"if (reader instanceof SegmentReader)\" style logic in it?  can't the different reopen mechanisms be refactored down into SegmentReader and MultiSegmentReader respectively?  shouldn't the default impl of IndexReader throw an UnsuppportedOperationException?)",
            "date": "2007-08-13T06:15:45.938+0000",
            "id": 10
        },
        {
            "author": "Michael Busch",
            "body": ">   IndexReader a, b, c = ...\n>   MultiReader ab = new MultiReader({a, b})\n>   MultiReader bc = new MultiReader({b, c})\n>   ...b changes on disk...\n>   ab.reopen(); // this shouldn't affect bc;\n>\n> one possibility would be for the semantics of reopen to close old readers only \n> if it completely owns them; ie: MultiReader should never close anything in \n> reopen, MultiSegmentReader should close all of the subreaders since it opened \n> them in the first place\n\nSo if 'b' in your example is a MultiSegmentReader, then the reopen() call \ntriggered from MultiReader.reopen() would close old readers, because it owns them, \nthus 'bc' wouldn't work anymore. So it depends on the caller of \nMultiSegmentReader.reopen() whether or not to close the subreaders. I think this \nis kind of messy. Well instead of reopen() we could add \nreopen(boolean closeOldReaders), but then...\n\n>   IndexReader r = ...\n>   ...\n>   IndexReader tmp = r.reopen();\n>   if (tmp != r) r.close(); \n>   r = tmp;\n>   ...\n\n... is actually easy enough as you pointed out, so that the extra complexity is not \nreally worth it IMO.\n\n> In general i think the safest thing to do is for reopen to never close.  \n\nSo yes, I agree.\n\n> why is the meat of reopen still in \"IndexReader\" with a \"if (reader instanceof \n> SegmentReader)\" style logic in it?  can't the different reopen mechanisms be \n> refactored down into SegmentReader and MultiSegmentReader respectively? \n\nI'm not sure if the code would become cleaner if we did that. Sometimes a \nSegmentReader would then have to return a MultiSegmentReader instance and vice\nversa. So we'd probably have to duplicate some of the code in these two classes.\n",
            "date": "2007-08-17T07:10:56.813+0000",
            "id": 11
        },
        {
            "author": "Hoss Man",
            "body": "\n\n> I'm not sure if the code would become cleaner if we did that. Sometimes a SegmentReader would then have to \n> return a MultiSegmentReader instance and vice versa. So we'd probably have to duplicate some of the code in\n> these two classes.\n\ni don't hink there would be anything wrong with SegmentReader.reopen returning a MultiSegmentReader in some cases (or vice versa) but it definitely seems wrong to me for a parent class to be explicitly casing \"this\" to one of two know subclasses ... making reopen abstract in the base class (or throw UnsupportOp if for API back compatibility) seems like the only safe way to ensure any future IndexReader subclasses work properly.",
            "date": "2007-08-20T20:40:32.463+0000",
            "id": 12
        },
        {
            "author": "Michael Busch",
            "body": "We should first refactor segmentInfos into IndexReader's subclasses.",
            "date": "2007-08-22T23:21:49.793+0000",
            "id": 13
        },
        {
            "author": "Testo Nakada",
            "body": "Please also consider making an option where the reopen can be automated (i.e. when the index is updated) instead of having to call it explicitly. Thread safety should be taken into account as well.",
            "date": "2007-09-04T11:42:38.805+0000",
            "id": 14
        },
        {
            "author": "Michael Busch",
            "body": "I'm attaching a new version of the patch that has a lot of changes compared to the last patch:\n\n- I factored most of the reopen logic into the subclasses of IndexReader. Now that we're having the DirectoryIndexReader layer this was possible in a more elegant way.\n\n- IndexReader.reopen() now does not close the old readers by default. This was somewhat tricky, because now the IndexReaders must be cloneable. I changed IndexReader to implement the Cloneable interface and implemented clone() for all Lucene built-in IndexReaders. However, there are probably custom IndexReader implementations out there that do not implement clone() and reopen() should throw an exception when an attempt is made to reopen such a reader. But I don't want to throw an exception in IndexReader.clone() itself, because then it would not be possible anymore for subclasses to recursively call the native Object.clone() via super.clone(). To solve this conflict I added the method \n{code:java}\n  /**\n   * Returns true, if this IndexReader instance supports the clone() operation.\n   */\n  protected boolean isCloneSupported();\n{code}\n  \nto IndexReader which returns false by default. IndexReader.clone() checks if the actual implementation supports clone() (i. e. the above method returns true). If not, it throws an UnsupportedOperationException, if yes, it returns super.clone().\n\nI was not sure about whether to throw an (unchecked) UnsupportedOperationException or a CloneNotSupportedException in this case. I decided to throw UnsupportedOperationException even though it's not really following the clone() guidelines, because it avoids the necessity to catch the CloneNotSupportedException every time clone() is called (in the reopen() methods of all IndexReader implementations).\n\nAs an example for how the clone() method is used let me describe how MultiReader.reopen() works: it tries to reopen every of its subreaders. If at least one subreader could be reopened successfully, then a new MultiReader instance is created and the reopened subreaders are added to it. Every of the old MultiReader's subreaders, that was not reopened (because of no index changes) is now cloned() and added to the new MultiReader.\n\n- I also added the new method \n{code:java}\n  /**\n   * In addition to {@link #reopen()} this methods offers the ability to close\n   * the old IndexReader instance. This speeds up the reopening process for\n   * certain IndexReader implementations and reduces memory consumption, because\n   * resources of the old instance can be reused for the reopened IndexReader\n   * as it avoids the need of copying the resources.\n   * <p>\n   * The reopen performance especially benefits if IndexReader instances returned \n   * by one of the <code>open()</code> methods are reopened with \n   * <code>closeOldReader==true</code>.\n   * <p>\n   * Certain IndexReader implementations ({@link MultiReader}, {@link ParallelReader})\n   * require that the subreaders support the clone() operation (see {@link #isCloneSupported()}\n   * in order to perform reopen with <code>closeOldReader==false</code>.  \n   */\n  public synchronized IndexReader reopen(boolean closeOldReader);\n{code}\n\nAs the javadoc says it has two benefits: 1) it speeds up reopening and reduces ressources, and 2) it allows to reopen readers, that use non-cloneable subreaders.\n\n\nPlease let me know what you think about these changes, especially about the clone() implementation.",
            "date": "2007-10-02T06:24:21.825+0000",
            "id": 15
        },
        {
            "author": "Michael Busch",
            "body": "I ran new performance tests with the latest patch similar to the tests I explained in an earlier comment on this issue.\n\nI'm using again a 4.5M index. In each round I delete one document and (re)open the IndexReader thereafter. Here are the numbers for 5000 rounds:\n\n|| || Time || Speedup ||\n| open |  703s | |\n| reopen(closeOldReader==false) | 62s | 11x |\n| reopen(closeOldReader==true) |16s | 44x |\n\nNow in each round I delete on document and also set the norm for one random document. Numbers for 1000 rounds:\n\n|| || Time || Speedup ||\n| open |  166s | |\n| reopen(closeOldReader==false) | 33s | 5.0x |\n| reopen(closeOldReader==true) | 29s | 5.7x |\n\nI think these numbers look pretty good. We get a quite decent speedup even if the old readers are not closed.\n\nI would like to commit this in a couple of days to get ready for Lucene 2.3. It would be nice if someone could review the latest patch! Hoss? Others?",
            "date": "2007-10-05T07:41:49.693+0000",
            "id": 16
        },
        {
            "author": "Yonik Seeley",
            "body": "I think this looks pretty good Michael!\nToo bad so much needs to be cloned in the case that closeOldReader==false... maybe someday in the future we can have read-only readers.",
            "date": "2007-10-06T00:58:19.301+0000",
            "id": 17
        },
        {
            "author": "Michael Busch",
            "body": "> Too bad so much needs to be cloned in the case that closeOldReader==false... maybe someday in the future we can have read-only readers.\n\nYeah, the cloning part was kind of tedious. Read-only readers would indeed make our life much easier here. I'm wondering how many people are using the IndexReader to alter the norms anyway?\n\nWell, thanks for reviewing the patch, Yonik!",
            "date": "2007-10-06T03:43:56.219+0000",
            "id": 18
        },
        {
            "author": "robert engels",
            "body": "Nice to see all the good work on this. We are still on a 1.9 derivative.\n\nHopefully we'll be able to move to stock 2.X release in the future.\n\n",
            "date": "2007-10-06T04:24:47.816+0000",
            "id": 19
        },
        {
            "author": "Hoss Man",
            "body": "I haven't looked at the patch yet (i really really plan to this weekend, baring catastrophe) but i'm confused as to why you went the cloning route (along with the complexity of the api changes to indicate when it is/isn't supported) ... based on the comments, it seems to boil down to...\n\n> As an example for how the clone() method is used let me describe how MultiReader.reopen()\n> works: it tries to reopen every of its subreaders. If at least one subreader could be reopened\n> successfully, then a new MultiReader instance is created and the reopened subreaders are\n> added to it. Every of the old MultiReader's subreaders, that was not reopened (because of no\n> index changes) is now cloned() and added to the new MultiReader.\n\nthat seems like circular logic: the clone method is used so that the sub readers can be cloned (?)\n\nwhy use clones at all? why not just use the original reader (if the \"index\" that reader represents hasn't changed, why clone it?\n\nAnd if (for reasons that aren't clear to me) it is important for MultiReader to use a clone of it's subreaders when their reopen method returns \"this\" then shouldn't clients do the same thing? ... why not make reopen always return this.clone() if the index hasn't changed (which now that i think about it, would also help by punting on the isCloneSupported issue -- each class would already know if it was clonable.\n\nmaybe this will make more sense once i read the patch ... i just wanted to through it out there in case someone had a chance to reply before i get a chance.\n\n",
            "date": "2007-10-06T05:37:46.239+0000",
            "id": 20
        },
        {
            "author": "Michael Busch",
            "body": "> why use clones at all? why not just use the original reader (if the \"index\" that reader represents hasn't changed, why clone it?\n\nLet's say you have a MultiReader with two subreaders:\n{code:java}\nIndexReader ir1 = IndexReader.open(index1);\nIndexReader ir2 = IndexReader.open(index2);\nIndexReader mr = new MultiReader(new IndexReader[] {ir1, ir2});\n{code}\n\nNow index1 changes and you reopen the MultiReader and keep the old one open:\n\n{code:java}\nIndexReader mr2 = mr.reopen();\n{code}\n\nir1 would now be reopened and let's assume we wouldn't clone ir2. If you use mr2 now to e.g. delete a doc and that doc happens to be in index2, then mr1 would also see the changes because both MultiReaders share the same subreader ir2 and are thus not independent from each other.\n\n> why not make reopen always return this.clone()\n\nclone() might be an expensive operation. We only need to clone if at least one of the subreaders has changed.\n",
            "date": "2007-10-06T06:56:42.064+0000",
            "id": 21
        },
        {
            "author": "Michael McCandless",
            "body": "> > Too bad so much needs to be cloned in the case that\n> > closeOldReader==false... maybe someday in the future we can have\n> > read-only readers.\n>\n> Yeah, the cloning part was kind of tedious. Read-only readers would\n> indeed make our life much easier here. I'm wondering how many people\n> are using the IndexReader to alter the norms anyway?\n\nI think the closeOldReader=false case is actually quite important.\n\nBecause in production, I think you'd have to use that, so that your\nold reader stays alive and is used to service incoming queries, up\nuntil the point where the re-opened reader is \"fully warmed\".\n\nSince fully warming could take a long time (minutes?) you need that\nold reader to stay open.\n\nCan we take a copy-on-write approach?  EG, this is how OS's handle the\nvirtual memory pages when forking a process.  This would mean whenever\na clone has been made of a SegmentReader, they cross-reference one\nanother. Then whenever either needs to alter deleted docs, one of them\nmakes a copy then.  Likewise for the norms.\n\nThis would mean that \"read-only\" uses of the cloned reader never\npay the cost of copying the deleted docs bit vector nor norms.",
            "date": "2007-10-06T13:26:50.463+0000",
            "id": 22
        },
        {
            "author": "Michael McCandless",
            "body": "\nActually if we went back to the sharing (not cloning) approach, could\nwe insert a check for any writing operation against the re-opened\nreader that throws an exception if the original reader is not yet\nclosed?\n\nIn Michael's example above, on calling mr2.deleteDoc, you would hit an\nexception because mr2 would check and see that it's \"original\" reader\nmr is not yet closed.  But once you've closed mr, then the call\nsucceeds.\n\nI think this would let us have our cake and eat it too: re-opening\nwould be very low cost for unchanged readers (no clones created), and,\nyou can still do deletes, etc, after you have closed your prior\nreader.  You control when your prior reader gets closed, to allow for\nwarming time and for queries to finish on the old reader.\n\nWould this work?",
            "date": "2007-10-06T14:16:18.384+0000",
            "id": 23
        },
        {
            "author": "Michael McCandless",
            "body": "\nA couple other questions/points:\n\n  * Just to verify: if you have a DirectoryIndexReader that is holding\n    the write lock (because it has made changes to deletes/norms) then\n    calling reopen on this reader should always return 'this', right?\n    Because it has the write lock, it must be (better be!) current.\n\n    This might be a good place to add an assert: if you are not\n    current, assert that you don't have the write lock, and if you\n    have the write lock, assert that you are current.\n\n  * I think you should add \"ensureOpen()\" at the top of\n    MultiReader.reopen(...)?\n\n  * If an Exception is hit during reopen, what is the resulting state\n    of your original reader?  I think, ideally, it is unaffected by\n    the attempt to re-open?  EG if you're on the hairy edge of file\n    descriptor limits, and the attempt to re-open failed because you\n    hit the limit, ideally your original reader is unaffected (even if\n    you specified closeOldReader=true).\n",
            "date": "2007-10-06T14:29:08.438+0000",
            "id": 24
        },
        {
            "author": "Hoss Man",
            "body": "Okay, read the patch.  I'm on board with the need for Clonable now ... it's all about isolation.  if \"r.reopen(false) == r\" then the client is responsible for recognizing that it's got the same instance and can make the judgement call about reusing the instance or cloning depending on it's needs ... internally in things like MultiReader we have to assume we need a clone for isolation.\n\nQuestions and comments...\n\n1. CompoundFileReader, FieldsReader, IndexReader, and BitVector all have clone methods where they silently catch and ignore CloneNotSupportedExceptions from super.clone()... if we don't expect the exception to ever happen, we should just let the exception propogate up the stack (there is no down side to declaring that clone() throws CloneNotSupportedException).  If we think the exception might happen, but it's not a big deal if it does and we can ignore it, then we should put a comment in the catch block to that effect.  i'm not clear which are the cases here.\n\n2. i don't remember if the old patches had this issue as well, but having \"return new FilterIndexReader(reopened);\" in FilterIndexReader doesn't really help anyone using FilterIndexReader -- they're going to want an instance of their own subclass.  to meet the contract of FilterIndexReader, we should implement all \"abstract\" methods and delegate to the inner reader - so in theory do don't need a new instance of FIlterIndexReader, we could just return in.reopen(closeold) ... my gut says it would be better to leave the method out entirely so that the default impl which throws UnSupOpEx is used --- that way subclasses who want to use reopen *must* define their own (instead of getting confused when their filtering logic stops working after they reopen for the first time)\n\n3. instead of having an isClonable() method, why don't we just remove the \"implements Clonable\" declaration from IndexReader and put it on the concrete subclasses -- then use \"instanceof Cloneable\" to determine if something is clonable?  ... for that matter, the only place isCloneSupported is really used is in IndexReader.clone where an exception is thrown if Clone is not  supported ... subclasses which know they are Clonable don't need this from the base class, subclasses which don't implement Clonable but are used in combination with core classes whose reopen method requires it could be skiped by the caller (since they don't implement Clonable) .. \n\n4. javadocs frequently refer to \"reopened successfully\" and \"refreshed successfully\" when what it really means is \"reopen() returned a newer/fresher reader\" ... this may confuse people who are use to thinking of \"successfully\" a \"without error\"\n\n5. random thought: are their any synchronization issues we're missing here?  I'm wondering about the case where once thread calls reopen while another thread is updating norms or deleting docs.  is there any chance for inconsistent state?\n\n",
            "date": "2007-10-07T18:22:45.836+0000",
            "id": 25
        },
        {
            "author": "Hoss Man",
            "body": "a rough variation on Michael's latest patch that makes the changes along two of the lines i was suggesting before reagrding FilterIndexReader and ising \"instanceof Cloneable\" instead of \"isCloneSupported()\" two important things to note:\n\n1) i didn't change any of the documentation, i was trying to change as little aspossibel so the two patches could be compared side-by-side\n\n2) this patch is currently broken.  TestIndexReaderReopen gets an exception i can't understand ... but i have to stop now, and i wanted to post what i had in case people had comments.\n\n...now that i've done this exercise, i'm not convinced that it's a better way to go, but it does seem like isCloneSupported isn't neccessary, that's the whole point of the Cloneable interface.\n\n",
            "date": "2007-10-07T19:57:08.722+0000",
            "id": 26
        },
        {
            "author": "Yonik Seeley",
            "body": "> I'm wondering about the case where once thread calls reopen while another thread is updating norms or deleting docs.\n\nHmmm  there is cause for concern (and I should have had my mt-safe hat on :-)\nReopen is synchronized on the reader, and so are norms access and docs, but from a quick look:\n- reopen() may be synchronized, but clone() called on sub-readers isn't in a synchronized context that the sub-reader cares about.  For example, MultiReader.reopen has the lock on the multireader, but calles subreader.clone() which iterates over the norms in a non thread-safe way.\n- IndexInput objects that are in use should never be cloned... (like what is done in FieldsReader.clone())",
            "date": "2007-10-07T20:09:29.924+0000",
            "id": 27
        },
        {
            "author": "Michael Busch",
            "body": "Thanks all for the reviews and comments!\n\nThere seem to be some issues/open questions concerning the cloning. \nBefore I comment on them I think it would make sense to decide whether\nwe want to stick with the cloning approach or not. Mike suggests this \napproach:\n\n> Actually if we went back to the sharing (not cloning) approach, could\n> we insert a check for any writing operation against the re-opened\n> reader that throws an exception if the original reader is not yet\n> closed?\n\nInteresting, yes that should work in case we have two readers (the \noriginal one and the re-opened one). But what happens if the user calls \nreopen twice to get two re-opened instances back? Then there would be \nthree instances, and without cloning the two re-opened ones would also \nshare the same resources. Is this a desirable use case or would it be \nokay to restrict reopen() so that it can only create one new instance?",
            "date": "2007-10-08T17:56:11.549+0000",
            "id": 28
        },
        {
            "author": "Michael McCandless",
            "body": "> > Actually if we went back to the sharing (not cloning) approach,\n> > could we insert a check for any writing operation against the\n> > re-opened reader that throws an exception if the original reader\n> > is not yet closed?\n>\n> Interesting, yes that should work in case we have two readers (the\n> original one and the re-opened one). But what happens if the user\n> calls reopen twice to get two re-opened instances back? Then there\n> would be three instances, and without cloning the two re-opened ones\n> would also share the same resources. Is this a desirable use case or\n> would it be okay to restrict reopen() so that it can only create one\n> new instance?\n\nHmmm good point.\n\nActually, we could allow more then one re-open call if we take the\nfollowing approach: every time a cloned Reader \"borrows\" a reference\nto a sub-reader, it increments a counter (call it the \"referrer\ncount\").  When the Reader is closed, it decrements the count (by 1)\nfor each of the sub-readers.\n\nThen, any reader should refuse to do a writing operation if its\n\"referrer\" count is greater than 1, because it's being shared across\nmore than one referrer.\n\nThis way if you have a reader X and you did reopen to get Y and did\nreopen again to get Z then the shared sub-readers between X, Y and Z\nwould not allow any write operations until 2 of the three had been\nclosed.  I think that would work?\n\nBTW this would also allow for very efficient \"snapshots\" during\nsearching: keeping multiple readers \"alive\", each searching a\ndifferent point-in-time commit of the index, because they would all\nshare the underlying segment readers that they have in common.  Vs\ncloning which would have to make many copies of each segment reader.\n",
            "date": "2007-10-08T18:45:12.523+0000",
            "id": 29
        },
        {
            "author": "Michael Busch",
            "body": "> This way if you have a reader X and you did reopen to get Y and did\n> reopen again to get Z then the shared sub-readers between X, Y and Z\n> would not allow any write operations until 2 of the three had been\n> closed.  I think that would work?\n\nYes I think it would work. However, this approach has two downside IMO:\n- reopen() becomes more complicated and restricted for the user. With \nthe cloning approach the user doesn't have to care about when index \nmodifications are not allowed. IndexReader instances returned by open()\nor reopen() can be used exactly the same without any restrictions.\n\n- We have to be very careful about cross-referencing multiple readers.\nIf for some reason any references between two or more readers are not\ncleared after one was closed, then that reader might not become GC'd.\nI'm not saying it's not possible or even very hard, we just have to \nmake sure those things can't ever happen.\n\nOf course the cloning approach has disadvantages too. For custom \nreaders clone() has to be implemented in order to make reopen() work\ncorrectly. Also reopen() is more expensive in case of \ncloseOldReader=false. Well we could certainly consider the lazy clone\napproach that you suggested, Mike, but we have to be careful about the\ncross-referencing issue again.\n\nSo I'm really not sure which way the better one is. I think I'm slightly\nin favor for the cloning approach, so that reopen() returns instances \nthat are completely independant from each other, which seems cleaner IMO.\nWhat do others think?",
            "date": "2007-10-08T21:42:29.871+0000",
            "id": 30
        },
        {
            "author": "Michael McCandless",
            "body": "\n> We have to be very careful about cross-referencing multiple readers.\n> If for some reason any references between two or more readers are\n> not cleared after one was closed, then that reader might not become\n> GC'd.  I'm not saying it's not possible or even very hard, we just\n> have to make sure those things can't ever happen.\n\nOne correction: there should be no cross-referencing, right?  The only\nthing that's happening is incrementing & decrementing the \"referrer\ncount\" for a reader?  (But, you're right: the \"copy on write\" approach\nto cloning would have cross-referencing).\n\nI think the downside of this proposed \"shared readers\" (non-cloning)\napproach is that you can't delete/setNorm on the clone until you close\nthe original.  But I think that's fairly minor?  Also if you really\nneed a full deep copy of your reader you could just open a new one\n(ie, not use \"reopen\")?\n\nI think the big upside of \"shared readers\" is reopening becomes quite\na bit more resource efficient: the cost of re-opening a reader would\nbe in proportion to what has actually changed in the index.  EG, if\nyour index has added a few tiny segments since you last opened then\nthe reopen would be extremely fas but with cloning you are forced\nto make a full deep copy of all other [unchanged] segments.\n",
            "date": "2007-10-08T22:15:09.997+0000",
            "id": 31
        },
        {
            "author": "Hoss Man",
            "body": "\nin deciding \"to clone or not clone\" for the purposes of implementing reopen, it may make sense to step back and ask a two broader questions...\n\n1) what was the motivation for approaching reopen using clones in the first place\n2) what does it inherently mean to clone an indexreader.\n\nthe answer to the first question, as i understand it, relates to the issue of indexreaders not being \"read only\" object ... operations can be taken which modify the readers state, and those operations can be flushed to disk when the reader is closed.  so readerB = readerA.reopen(closeOld=false) and then readerA.delete(...) is called, there is ambiguity as to what should happen in readerB.  so the clone route seems pretty straight forward if and only if we have an unambiguous concept of cloning a reader (because then the clone approach to reopen becomes unambiguous as well).  alternately, since reopen is a new method, we can resolve the ambiguity anyway we want, as long as it's documented ... in theory we should pick a solution that seems to serve the most benefit ... perhaps that solution is to document reopen with \"if reopen(closeOld=false) returns a new reader it will share state with the current reader, attempting to do the following operations on this new reader will result in undefined behavior\"\n\nthe answer the the second is only important if we want to go the cloning route ... but it is pretty important in a larger sense then just reopening ... f we start to say that any of the IndexReader classes are Clonable we have to be very clear about what that means in *all* cases where someone might clone it in addition to reopen ... in particular, i worry about what it means to clone a reader which has already had \"write\" operations performed on it (something the clone based version of reopen will never do because a write operation indicates the reader must be current), but some client code might as soon as we add the Clonable interface to a class.\n\n",
            "date": "2007-10-11T18:43:26.895+0000",
            "id": 32
        },
        {
            "author": "Michael Busch",
            "body": "> in deciding \"to clone or not clone\" for the purposes of implementing \n> reopen, it may make sense to step back and ask a two broader questions...\n\nI agree!\n\n> 1) what was the motivation for approaching reopen using clones in the \n> first place\n\nGood summarization! You are right, I started the clone approach because\nIndexReaders are not \"read only\" objects.\n\n> \"if reopen(closeOld=false) returns a new reader it will share state with \n> the current reader, attempting to do the following operations on this \n> new reader will result in undefined behavior\"\n\nThis would mean, that we simply warn the user that performing write \noperations with the re-opened indexreader will result in undefined behavior,\nwhereas with Mike's approach we would prevent such an undefined behavior by \nusing reference counting.\n\nHmm, so what are our long-term plans for indexreaders? If our goal is to \nmake them read-only (we can delete via IndexWriter already), then I think \nadding those warning comments to reopen(), as you suggest Hoss, would be \nsufficient. \n\nIf everybody likes this approach I'll go ahead and submit a new patch.\n\n",
            "date": "2007-10-16T20:34:24.357+0000",
            "id": 33
        },
        {
            "author": "Doug Cutting",
            "body": "{quote}\nHmm, so what are our long-term plans for indexreaders? If our goal is to\nmake them read-only (we can delete via IndexWriter already), then I think\nadding those warning comments to reopen(), as you suggest Hoss, would be\nsufficient.\n{quote}\n\nI think that's a fine direction.  Note however that IndexWriter implements delete by calling IndexReader.delete().  That method could be made package-private, so that users cannot call it, but then this makes it impossible for someone to subclass IndexReader from a different package.  So perhaps delete() needs to move to a subclass of IndexReader?  That gets messy...",
            "date": "2007-10-16T20:51:22.013+0000",
            "id": 34
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nI think that's a fine direction. Note however that IndexWriter implements delete by calling IndexReader.delete(). That method could be made package-private, so that users cannot call it, but then this makes it impossible for someone to subclass IndexReader from a different package. So perhaps delete() needs to move to a subclass of IndexReader? That gets messy...\n{quote}\n\nActually all of the lock/commit logic moved from IndexReader to DirectoryIndexReader already, and the delete logic is in SegmentReader, which subclasses DirectoryIndexReader. So we could remove the deleteDocument() API from IndexReader but leave it in DirectoryIndexReader. Then it would still be possible to extend IndexReader from a different package just as today, and IndexWriter could use DirectoryIndexReader for performing deletes. These changes should be trivial.",
            "date": "2007-10-16T21:24:13.223+0000",
            "id": 35
        },
        {
            "author": "Doug Cutting",
            "body": "Got it.  IndexWriter only works with SegmentReaders anyway, not with an arbitrary IndexReader implementation: IndexReader is extensible, but IndexWriter is not.  I'd (momentarily) forgotten that.  Nevermind.",
            "date": "2007-10-16T21:33:04.911+0000",
            "id": 36
        },
        {
            "author": "Yonik Seeley",
            "body": "Having a read-only IndexReader would (should?) mean being able to remove \"synchronized\" from some things like isDeleted()... a nice performance win for multi-processor systems for things that didn't have access to the deleted-docs bitvec.\n\n> If our goal is to make them read-only (we can delete via IndexWriter already)\n\nBut you can only delete-by-term.\nIt's more powerful to be able to delete by docid, however I manage to come up with it.\nSo I think deleteDocument(int id) should either be moved to a subclass.  same with setNorms?",
            "date": "2007-10-16T21:40:11.350+0000",
            "id": 37
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nSo I think deleteDocument(int id) should either be moved to a subclass. same with setNorms?\n{quote}\n\nOr we could take the approach you suggested in http://www.gossamer-threads.com/lists/lucene/java-dev/52017.\n\nThat would mean to add a callback after flush to get a current IndexReader to get the docids and to use the IndexWriter then to perform deleteDocument(docId) or setNorm(). These methods could also take an IndexReader as argument, e. g. deleteDocument(IndexReader reader, int docId), which would throw an IOException if the passed in reader is stale (i. e. docids have changed since the reader was opened). Just as IndexReader does it today. Does this make sense or am I missing something?",
            "date": "2007-10-16T22:29:00.498+0000",
            "id": 38
        },
        {
            "author": "Michael Busch",
            "body": "I just opened LUCENE-1030 and would like to move discussions related to \"read-only\" IndexReaders to that issue.\n\nAs for reopen() I'd like to go with Hoss' suggestion for now and add warning comments to reopen() saying that using an re-opened IndexReader with closeOldReader==false for write operations will result in an undefined behavior. Any objections?",
            "date": "2007-10-17T18:35:47.354+0000",
            "id": 39
        },
        {
            "author": "Yonik Seeley",
            "body": "{quote}\nAs for reopen() I'd like to go with Hoss' suggestion for now and add warning comments to reopen() saying that using an re-opened IndexReader with closeOldReader==false for write operations will result in an undefined behavior.\n{quote}\n\nHow about just defining the behavior such that any pending changes are flushed.  That would make it more useful because you could then reopen readers you used for deletes.  An alternative would be a method to explicitly flush changes on a reader, giving one the ability to then reopen it, but  I like the former better since it avoids adding another API call.",
            "date": "2007-10-17T21:02:00.041+0000",
            "id": 40
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nHow about just defining the behavior such that any pending changes are flushed. That would make it more useful because you could then reopen readers you used for deletes.\n{quote}\n\nHmm, I'm not sure I understand. A reader which is being used for deletes or setting norms is always current (it owns the write lock), so there should never be the need to re-open such a reader.\n\nHowever, if you re-open an existing reader which was not used for deletes before and use the new instance (b) to perform deletes, it will result in a undefined behavior for the old reader (a):\n\n{code:java}\nIndexReader a = .....\n....\nIndexReader b = a.reopen();\nb.deleteDocument(...);\n{code}",
            "date": "2007-10-17T21:23:30.947+0000",
            "id": 41
        },
        {
            "author": "Yonik Seeley",
            "body": "{quote}\nA reader which is being used for deletes or setting norms is always current (it owns the write lock), so there should never be the need to re-open such a reader.\n{quote}\n\nI was thinking about the \"add some docs\" then \"delete some docs\" scenario:\nOne currently needs to close() the deleting reader to open an IndexWriter.  If IndexReader.commit() was public, then one could simply flush changes, and then call reopen() after the IndexWriter was done adding new documents.  But perhaps longer term, all deletions should be done via the IndexWriter anyway.\n\n{quote}\nif you re-open an existing reader which was not used for deletes before and use the new instance (b) to perform deletes\n{quote}\n\nAh, thanks for that clarification.  I guess that should remain undefined.\n",
            "date": "2007-10-18T16:55:12.767+0000",
            "id": 42
        },
        {
            "author": "Michael Busch",
            "body": "Hmm one other thing: how should IndexReader.close() work? If we re-open a reader (a is the old reader, b is the new one), and then someone calls a.close(), then a should not close any resources that it shares with b. \n\nOne way to make this work would be reference counting. Since we want to avoid that, we could simply restrict reopen() from being called twice for the same reader. Then there would never be more than 2 readers sharing the same ressources. The old reader a would remember that reopen() was called already and would not close the shared ressources on close(). However, the new reader b would close all ressources, meaning that reader a would not work anymore after b.close() was called. \nThoughts?",
            "date": "2007-10-18T19:49:19.819+0000",
            "id": 43
        },
        {
            "author": "Michael McCandless",
            "body": "I think reference counting would solve this issue quite nicely.  How come we want to avoid reference counting?  It seems like the right solution here.\n\nThe implementation seems simple.  When a reader is opened, it starts with RC 1.  When it is closed, it decrefs the RC and marks itself closed (to make sure double-close does not re-decref the RC).  When a MultiReader needs to use the reader, it calls incref.  And when that MultiReader is done with it, it calls decref.  Whenever the RC hits 0 it's safe to free all resources.\n\nWouldn't that work?",
            "date": "2007-10-18T20:03:05.788+0000",
            "id": 44
        },
        {
            "author": "Yonik Seeley",
            "body": "> When it is closed, it decrefs the RC and marks itself closed (to make sure double-close does not re-decref the RC)\n\nBut if a reader is shared, how do you tell two real closes from an erronous double-close?  \nPerhaps have a top level close() that is only invoked once via isClosed, and a projected doClose() that a multi-reader would use that actually does the decref?\n",
            "date": "2007-10-18T20:35:03.971+0000",
            "id": 45
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nThe implementation seems simple. When a reader is opened, it starts with RC 1. When it is closed, it decrefs the RC and marks itself closed (to make sure double-close does not re-decref the RC). When a MultiReader needs to use the reader, it calls incref. And when that MultiReader is done with it, it calls decref. Whenever the RC hits 0 it's safe to free all resources.\n\nWouldn't that work?\n{quote}\n\nYou're right, for a MultiReader and ParallelReader this would work and wouldn't be hard to implement. \n\nIt is quite different when it comes to SegmentReaders. SegmentReader.reopen() checks SegmentInfos if there is a segment with the same name but newer normGen or delGen. If there is one then a new SegmentReader instance is created that reuses resources like e. g. TermInfosReader and loads the new generation of the del or norm file.\n\nNow you can end up having a bunch of SegmentReaders that share the same resources but don't know about each other. The reference counting would have to happen somewhere else, e. g. in the TermInfosReader. Of course this is doable, but it's a special case and more complicated compared to the \"restrict reopen() to only be called once\"-approach.",
            "date": "2007-10-18T20:43:57.397+0000",
            "id": 46
        },
        {
            "author": "Michael McCandless",
            "body": "> But if a reader is shared, how do you tell two real closes from an erronous double-close?\n> Perhaps have a top level close() that is only invoked once via isClosed, and a projected doClose() that a multi-reader would use that actually does the decref?\n\nYes I think that's the right approach.\n\n> It is quite different when it comes to SegmentReaders. SegmentReader.reopen() checks SegmentInfos if there is a segment with the same name but newer normGen or delGen. If there is one then a new SegmentReader instance is created that reuses resources like e. g. TermInfosReader and loads the new generation of the del or norm file.\n>\n> Now you can end up having a bunch of SegmentReaders that share the same resources but don't know about each other. The reference counting would have to happen somewhere else, e. g. in the TermInfosReader. Of course this is doable, but it's a special case and more complicated compared to the \"restrict reopen() to only be called once\"-approach.\n\nFor SegmentReader, I think on reopen(), everything would be shared\nexcept norms and/or deletedDocs right?  In which case couldn't all\ncascaded reopens hold onto the original SegmentReader & call doClose()\non it when they are closed?  (Ie it is the \"owner\" of all the shared\nparts of a SegmentReader).  Then, deletedDocs needs no protection (it\nhas no close()), and for Norms we could push the reference counting\ndown into it as well?\n\nWe wouldn't need to push reference counting into all the readers that\na SegmentReader holds because those are always shared when a\nSegmentReader is reopened?",
            "date": "2007-10-18T21:53:38.263+0000",
            "id": 47
        },
        {
            "author": "Michael Busch",
            "body": "Hi Mike,\n\nI'm not sure if I fully understand your comment. Consider the following (quite constructed) example:\n\n{code:java}\nIndexReader reader1 = IndexReader.open(index1);  // optimized index, reader1 is a SegmentReader\nIndexReader multiReader1 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index2)});\n... // modify index2\nIndexReader multiReader2 = multiReader1.reopen();  \n// only index2 changed, so multiReader2 uses reader1 and has to increment the refcount of reader1\n... // modify index1\nIndexReader reader2 = reader1.reopen();\n// reader2 is a new instance of SegmentReader that shares resources with reader1\n... // modify index1\nIndexReader reader3 = reader2.reopen();\n// reader3 is a new instance of SegmentReader that shares resources with reader1 and reader2\n{code}\n\nNow the user closes the readers in this order:\n# multiReader1.close();\n# multiReader2.close();\n# reader2.close();\n# reader3.close();\n\nreader1 should be marked as closed after 2., right? Because multiReader1.close() and multiReader2.close() have to decrement reader1's refcount. But the underlying files have to remain open until after 4., because reader2 and reader3 use reader1's resources.\n\nSo don't we need 2 refcount values in reader1? One that tells us when the reader itself can be marked as closed, and one that tells when the resources can be closed? Then multiReader1 and multiReader2 would decrement the first refCount, whereas reader2 and reader3 both have to \"know\" reader1, so that they can decrement the second refcount.\n\nI hope I'm just completely confused now and someone tells me that the whole thing is much simpler :-)\n\n",
            "date": "2007-10-19T21:49:45.034+0000",
            "id": 48
        },
        {
            "author": "Michael McCandless",
            "body": "It's not nearly this complex (we don't need two ref counts). If we\nfollow the simple rule that \"every time reader X wants to use reader\nY, it increfs it\" and \"whenver reader X is done using reader Y, it\ndecrefs it\",  all should work correctly.\n\nAlso we should think of \"close()\" as the way that the external user\ndoes the decref of their reader.  We just special-case this call, by\nsetting isOpen=false, to make sure we don't double decref on a double\nclose call.\n\nLet's walk through your example...\n\nI'm assuming in your example you meant for reader2 and reader3 to also\nbe SegmentReaders?  Ie, the changes that are happening to the\nsingle-segment index1 are just changes to norms and/or deletes.  If\nnot, the example is less interesting because reader1 will be closed\nsooner :)\n\nAlso in your example let's insert missing \"reader1.close()\" as the\nvery first close?  (Else it will never be closed because it's RC never\nhits 0).\n\nWhen reader1 is created it has RC 1.\n\nWhen multiReader1 is created, reader1 now has RC 2.\n\nWhen multiReader2 is created, reader1 now has RC 3.\n\nWhen reader2 is created (by reader1.reopen()), it incref's reader1\nbecause it's sharing the sub-readers in reader1.  So reader1 now has\nRC 4.\n\nWhen reader3 was created (by reader2.reopen()), it incref's reader2\nbecause it's sharing the sub-readers reader2 contains.  So reader1 is\nstill at RC 4 and reader2 is now at RC 2.\n\nNow, we close.\n\nAfter reader1.close() is called, reader1 sets isOpen=false (to prevent\ndouble close by the user) and RC drops to 3.\n\nWith multiReader1.close(), multiReader1 is not at RC 0, and so it\ndecrefs all readers it was using, and so reader1 RC is now 2.\n\nWith multiReader2.close(), likewise it is now at RC 0 and so it\ndecrefs all readers it was using, and so reader1 RC is now 1.\n\nWith reader2.close(), it decrefs its own RC, however that brings its\nRC to 1 (reader3 is still referring to it) and so it does not decref\nthe reader1 that it's referring to.\n\nFinally, with reader3.close(), it is now at RC 0 and so it decrefs the\nreader2 it refers to.  This brings reader2's RC to 0, and so reader2\ndecrefs the reader1 that it's referring to.  Which brings reader1's RC\nto 0, and so reader1 finally closes all its internal sub-readers.\n",
            "date": "2007-10-20T09:09:31.761+0000",
            "id": 49
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nI'm assuming in your example you meant for reader2 and reader3 to also\nbe SegmentReaders?\n{quote}\nYes that's what I meant. Sorry, I didn't make that clear.\n\n{quote}\nAlso in your example let's insert missing \"reader1.close()\" as the\nvery first close? (Else it will never be closed because it's RC never\nhits 0).\n{quote}\nDoesn't what you describe change the semantics of MultiReader.close()?\n\nIf you do:\n{code:java}\nIndexReader reader1 = IndexReader.open(index1);  \nIndexReader multiReader1 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index2)});\nmultiReader1.close();\n{code}\n\nthen today multiReader1.close() also closes reader1. That's why I consciously omitted reader1.close().\n\nConsequently, if you do\n{code:java}\nIndexReader reader1 = IndexReader.open(index1);  \nIndexReader multiReader1 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index2)});\nIndexReader multiReader2 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index3)});\nmultiReader1.close();\n{code}\nthen multiReader2 is not usable anymore, because multiReader1.close() closes reader1. But that can be explicitly avoided by the user because it's known that multiReader1 and multiReader2 share the same reader.\n\nNow, with the reopen() code:\n{code:java}\nIndexReader reader1 = IndexReader.open(index1);  // optimized index, reader1 is a SegmentReader\nIndexReader multiReader1 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index2)});\n... // modify index2\nIndexReader multiReader2 = multiReader1.reopen();  \n// only index2 changed, so multiReader2 uses reader1 and has to increment the refcount of reader1\n{code}\nThe user gets a new reader instance from multiReader.reopen(), but can't tell which of the subreaders has been reopened and which are shared. That's why multiReader1.close() should not close reader1 in this case and we need refcounting in order to make this work.\n\nSo do you suggest that a MultiReader should increment the refcounts when it is opened as well (in the constructor)? I believe we can implement it like this, but as I said it changes the semantics of MultiReader.close() (and ParallelReader.close() is, I believe, the same). A user would then have to close subreaders manually.\n\n",
            "date": "2007-10-20T09:46:35.808+0000",
            "id": 50
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nIf you do:\n{code:java}\nIndexReader reader1 = IndexReader.open(index1);  \nIndexReader multiReader1 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index2)});\nmultiReader1.close();\n{code}\n\nthen today multiReader1.close() also closes reader1. That's why I consciously omitted reader1.close().\n{quote}\n\nAhh, I missed that MultiReader is allowed to close all readers that\nwere passed into it, when it is closed.  OK, let's leave\nreader1.close() out of the example.\n\nIt's somewhat \"aggressive\" of MultiReader/ParallelReader to do that?\nIf you go and use those same sub-readers in other MultiReaders then\nthey closing of the first MultiReader will then break the other ones?\n\nI think we are forced to keep this semantics, for backwards\ncompatibility.  But I don't really think MultiReader/ParallelReader\nshould actually be this aggressive.  Maybe in the future we can add\nctors for MultiReader/ParallelReader that accept a \"doClose\" boolean\nto turn this off.\n\nAnyway, it's simple to preserve this semantics with reference\ncounting.  It just means that IndexReader / MultiReader do not incref\nthe readers they receive, and, when they are done with those readers,\nthey must call their close(), not decref.  Ie they \"borrow the\nreference\" that was passed in, rather than incref'ing their own\nreference, to the child readers.\n\nWith that change, plus the change below, your example works fine.\n\n{quote}\nConsequently, if you do\n{code:java}\nIndexReader reader1 = IndexReader.open(index1);  \nIndexReader multiReader1 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index2)});\nIndexReader multiReader2 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index3)});\nmultiReader1.close();\n{code}\nthen multiReader2 is not usable anymore, because multiReader1.close() closes reader1. But that can be explicitly avoided by the user because it's known that multiReader1 and multiReader2 share the same reader.\n{quote}\n\nThis is why I don't like the semantics we have today -- I don't think\nit's right that the multiReader1.close() breaks multiReader2.\n\n{quote}\nNow, with the reopen() code:\n{code:java}\nIndexReader reader1 = IndexReader.open(index1);  // optimized index, reader1 is a SegmentReader\nIndexReader multiReader1 = new MultiReader(new IndexReader[] {reader1, IndexReader.open(index2)});\n... // modify index2\nIndexReader multiReader2 = multiReader1.reopen();  \n// only index2 changed, so multiReader2 uses reader1 and has to increment the refcount of reader1\n{code}\nThe user gets a new reader instance from multiReader.reopen(), but can't tell which of the subreaders has been reopened and which are shared. That's why multiReader1.close() should not close reader1 in this case and we need refcounting in order to make this work.\n{quote}\n\nBoth of these cases are easy to fix with reference counting: we just\nhave to change ensureOpen() to assert that RC > 0 instead of\nclosed==false.  Ie, a reader may still be used as long as its RC is\nstill non-zero.\n",
            "date": "2007-10-20T10:45:29.711+0000",
            "id": 51
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nI think we are forced to keep this semantics, for backwards\ncompatibility.  But I don't really think MultiReader/ParallelReader\nshould actually be this aggressive.  Maybe in the future we can add\nctors for MultiReader/ParallelReader that accept a \"doClose\" boolean\nto turn this off.\n{quote}\n\nActually I retract this: it's no longer necessary as long as we change\nensureOpen to assert that RC > 0 instead of closed==false.\n\nI think this is actually a nice unexpected side-effect of using\nreference counting: it resolves this overly aggressive behavior of\nMultiReader/ParallelReader.\n",
            "date": "2007-10-20T11:05:46.470+0000",
            "id": 52
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nWith that change, plus the change below, your example works fine.\n{quote}\n\nTwo things:\n- MultiReader/ParallelReader must not incref the subreaders on open() \nas you said. But on reopen() it must incref the subreaders that \nhaven't changed and thus are shared with the old MultiReader/\nParallelReader. This further means, that the re-opened MultiReader/\nParallelReader must remember which of the subreaders to decref on\nclose(), right?\n\n- If we change ensureOpen() like you suggest, then the user might\nstill be able to use reader1 (in my example), even after \nreader1.close() was explicitly called. Probably not a big deal?\n",
            "date": "2007-10-22T19:36:00.782+0000",
            "id": 53
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\n    * MultiReader/ParallelReader must not incref the subreaders on open()\n      as you said. But on reopen() it must incref the subreaders that\n      haven't changed and thus are shared with the old MultiReader/\n      ParallelReader. This further means, that the re-opened MultiReader/\n      ParallelReader must remember which of the subreaders to decref on\n      close(), right?\n{quote}\n\nHmm, right.  MultiReader/ParallelReader must keep track of whether it\nshould call decref() or close() on each of its child readers, when it\nitself is closed.\n\n{quote}\n    * If we change ensureOpen() like you suggest, then the user might\n      still be able to use reader1 (in my example), even after\n      reader1.close() was explicitly called. Probably not a big deal?\n{quote}\n\nI think this is OK?\n",
            "date": "2007-10-22T20:36:03.347+0000",
            "id": 54
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nI think this is OK?\n{quote}\n\nThis was essentially the reason why I suggested to use two refcount values:\none to control when to close a reader, and one to control when to close\nit's (shared) resources in case of SegmentReader. That approach would not\nalter the behaviour of IndexReader.close(). \nBut I agree that your approach is simpler and I also think it is okay to \nchange ensureOpen() and accept the slight API change.\n\nSo I'll go ahead and implement the refcount approach unless anybody objects.\n\nOh and Mike, thanks for bearing with me :-)",
            "date": "2007-10-22T21:35:46.849+0000",
            "id": 55
        },
        {
            "author": "Yonik Seeley",
            "body": "What about a new constructor for MultiReader/ParallelReader that implements more sensible semantics (increment refcount on readers passed to it, and decrement on close())?",
            "date": "2007-10-22T21:54:41.503+0000",
            "id": 56
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nWhat about a new constructor for MultiReader/ParallelReader that implements more sensible semantics (increment refcount on readers passed to it, and decrement on close())?\n{quote}\n\nYeah, when reference counting is implemented then such a constructor should be easy to add.",
            "date": "2007-10-22T23:06:51.433+0000",
            "id": 57
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nOh and Mike, thanks for bearing with me :-)\n{quote}\n\nThank you for bearing with me!\n\n{quote}\nWhat about a new constructor for MultiReader/ParallelReader that implements more sensible semantics (increment refcount on readers passed to it, and decrement on close())?\n{quote}\n\n+1",
            "date": "2007-10-22T23:31:02.678+0000",
            "id": 58
        },
        {
            "author": "Michael Busch",
            "body": "Ok here is the next one :-)...\n\nThis patch implements the refCounting as discussed with Mike and Yonik\nabove.\n\nOther changes/improvements/comments:\n- ensureOpen() is now also called in MultiReader.reopen() and \nParallelReader.reopen(). (thanks, Mike)\n- in case an exception occurs during reopen() it is taken care of \nclosing or decreasing the refCount of already created readers.\nAlso old readers should not be affected in case an exception occurs.\n- I improved how norms are re-opened in a MultiSegmentReader (MSR). \nIt now checks which parts of the normsCache haven't changed and \ncopies those to the new normsCache. Because I'm imagining Yonik with \nhis thread-safety hat on now ;), another comment about this: In case \na MSR is refreshed, then the synchronized MSR.reopen() method has the \nlock on the old MSR. This method creates the new MSR and the values\nfrom the old cache are copied to the new cache in the constructor, so\nwhile the lock on the old MSR is still being held.\n- added new constructors to MultiReader and ParallelReader that \nincrease the refCount on the subReaders and thus prevent closing the\nsubReaders on close(). (thanks, Yonik)\n\nI also made the changes suggested by Hoss (thanks!):\n- changed the \"successfully reopened\" comments int the javadocs \n- added comments to the javadocs saying that write operations on the\nre-opened reader will result in undefined behavior unless the old \nreader is closed\n- FilterIndexReader.reopen() not implemented, i. e. will throw an\nUnsupportedOperationException.\n\nAll unit tests pass.",
            "date": "2007-10-29T20:53:24.354+0000",
            "id": 59
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks great!  I'm still working through it but found a few small\nissues...\n\nIt might be good to put a \"assert refCount > 0\" at various places like\ndecRef(), incRef(), ensureOpen()?  That would require changing the\nconstructors to init refCount=1 rather than incRef() it to 1.\n\nI'm seeing a failure in contrib/memory testcase:\n\n{code}\n    [junit] *********** FILE=./NOTICE.txt\n    [junit] Fatal error at query=Apache, file=./NOTICE.txt, anal=org.apache.lucene.analysis.SimpleAnalyzer@341960\n    [junit] ------------- ---------------- ---------------\n    [junit] Testcase: testMany(org.apache.lucene.index.memory.MemoryIndexTest):\tCaused an ERROR\n    [junit] this IndexReader is closed\n    [junit] org.apache.lucene.store.AlreadyClosedException: this IndexReader is closed\n    [junit] \tat org.apache.lucene.index.IndexReader.ensureOpen(IndexReader.java:158)\n    [junit] \tat org.apache.lucene.index.IndexReader.termDocs(IndexReader.java:632)\n    [junit] \tat org.apache.lucene.search.TermQuery$TermWeight.scorer(TermQuery.java:64)\n    [junit] \tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:143)\n    [junit] \tat org.apache.lucene.search.Searcher.search(Searcher.java:118)\n    [junit] \tat org.apache.lucene.search.Searcher.search(Searcher.java:97)\n    [junit] \tat org.apache.lucene.index.memory.MemoryIndexTest.query(MemoryIndexTest.java:412)\n    [junit] \tat org.apache.lucene.index.memory.MemoryIndexTest.run(MemoryIndexTest.java:313)\n    [junit] \tat org.apache.lucene.index.memory.MemoryIndexTest.testMany(MemoryIndexTest.java:234)\n{code}\n\nI think it's because MemoryIndexReader (private class in\nMemoryIndex.java) calls super(null) =\nIndexReader.IndexReader(Directory) in its constructor, which does not\ninitialize the refCount to 1?  If I insert incRef() into\nIndexReader.IndexReader(Directory) constructor, the test passes, but\nwho else is using that constructor (ie will this double-incref in\nthose cases?).\n",
            "date": "2007-10-30T08:55:11.128+0000",
            "id": 60
        },
        {
            "author": "Michael McCandless",
            "body": "OK I think this patch is very close!  I finished reviewing it --\nhere's some more feedback:\n\n  - In multiple places you catch an IOException and undo the attempted\n    re-open, but shouldn't this be a try/finally instead so you also\n    clean up on hitting any unchecked exceptions?\n\n  - I think you need an explicit refCount for the Norm class in\n    SegmentReader.\n    .\n    Say I've done a chain of 10 re-opens for SegmentReader and each\n    time only the segment's norms has changed.  I've closed all but\n    the last SegmentReader.  At this point all 10 SegmentReaders are\n    still alive (RC > 0) and holding open all file handles for their\n    copies of the norms.  So this will leak file handles/RAM with each\n    reopen?\n   .\n    To fix this, I think you just need to add refCount into Norm class\n    & set refCount to 1 in the constructor.  Then, each each\n    SegmentReader calls Norm.decRef(), not Norm.close(), when it's\n    done.  When refCount hits 0 then the Norm closes itself.  Finally,\n    during re-open you should share a Norm instance (rather than open\n    a new one) if it had not changed from the previous SegmentReader.\n  .\n    For singleNormStream, I think each reopened SegmentReader should\n    always re-open this descriptor and then we can forcefully close\n    this stream when the SegmentReader is closed (what you are doing\n    now).  Ie the SegmentReader fully owns singleNormStream.\n\n  - If you have a long series of reopens, then, all SegmentReaders in\n    the chain will remain alive.  So this is a [small] memory leak\n    with time.  I think if you changed referencedSegmentReader to\n    always be the *starting* SegmentReader then this chain is broken\n    and after 10 reopens only the original SegmentReader and the most\n    recent one will remain alive (assuming I closed all SegmentReaders\n    but the most recent one).\n",
            "date": "2007-10-30T11:41:25.752+0000",
            "id": 61
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nPatch looks great!  I'm still working through it but found a few small\nissues...\n{quote}\nThanks Mike! Very good review and feedback!\n\n{quote}\nIt might be good to put a \"assert refCount > 0\" at various places like...\n{quote}\nAgreed. I added those asserts to incRef() and decRef(). I didn't add it\nto ensureOpen(), because it throws an AlreadyClosedException anyway, and\nsome testcases check if this exception is thrown.\n\n{quote}\nI'm seeing a failure in contrib/memory testcase:\n{quote}\nOups, I fixed this already. I changed the (deprecated) ctr \nIndexReader.IndexReader(Directory) to call this() which sets the refCount \nto 1. The test passes then. I made this fix yesterday, I think I just \nforgot to update the patch file before I submitted it, sorry about this.\n\n{quote}\n  - In multiple places you catch an IOException and undo the attempted\n    re-open, but shouldn't this be a try/finally instead so you also\n    clean up on hitting any unchecked exceptions?\n{quote}\nYes of course! Changed it.\n\n{quote}\n  - I think you need an explicit refCount for the Norm class in\n    SegmentReader.\n{quote}\nOK I see. I made this change as well. I also made the change that\nthere is no chain, but one starting SegmentReader which all re-opened \nones reference (see below). Now this starting SegmentReader won't close \nits norms until all other readers that reference it are closed (RC=0),\nbecause only then doClose() is called, which calls closeNorms().\nDo you see an easy way how to improve this?\nHmm, probably I have to definalize IndexReader.incRef() and decRef()\nand overwrite them in SegmentReader. Then SegmentReader.incRef() would\nalso incRef the norms, SegmentReader.decref() would decref the norms,\nand somehow a clone that shares references the reader but not the norms\n(because they changed) would only incref the reader itself, but not\nthe norms... Or do you see an easier way?\n\n{quote}\n  - If you have a long series of reopens, then, all SegmentReaders in\n    the chain will remain alive.  So this is a [small] memory leak\n    with time.  I think if you changed referencedSegmentReader to\n    always be the *starting* SegmentReader then this chain is broken\n{quote}\nGood point. Ok I changed this and also the test cases that check the refCount\nvalues.",
            "date": "2007-10-31T07:02:46.586+0000",
            "id": 62
        },
        {
            "author": "Michael McCandless",
            "body": "Looks great!  All tests pass for me.\n\n{quote}\nOK I see. I made this change as well. I also made the change that\nthere is no chain, but one starting SegmentReader which all re-opened\nones reference (see below). Now this starting SegmentReader won't close\nits norms until all other readers that reference it are closed (RC=0),\nbecause only then doClose() is called, which calls closeNorms().\nDo you see an easy way how to improve this?\n{quote}\n\nHow about if SegmentReader.close() always calls Norm.decRef(),\nimmediately, for each Norm is has open?  EG you could implement\ndoCloseUnsharedResources in SegmentReader and do it there).  This way,\nif the SegmentReader has been closed but it shares resources (and not\nthe Norms) with reopened SegmentReaders then its Norms would all\ndecRef to 0 & be closed.\n\nAlso make sure that if a SegmentReader is decRef'd to 0 and close was\nnever called, that also in this case you remember to call Norm.decRef\nfor all open norms.\n\nOne more comment: I think you can partially share Norm instances?  Eg\nif I have 2 fields that have norms, but only one of them changed since\nI opened this SegmentReader, then the reopened SegmentReader could\nshare the Norm instance of the field that didn't change with the old\nSegmentReader?  But right now you're re-loading all the Norms.\n\nOtherwise no more comments!",
            "date": "2007-10-31T18:04:28.583+0000",
            "id": 63
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nHow about if SegmentReader.close() always calls Norm.decRef(),\nimmediately, for each Norm is has open?  EG you could implement\ndoCloseUnsharedResources in SegmentReader and do it there).  This way,\n{quote}\n\nHmm I was thinking about this before (that's actually why I put that\nmethod in there). But I don't think this is gonna work. For example,\nlet's say we use a MultiReader that has two SegmentReader SR1 and SR2.\nNow only SR2 changed, we reopen the MR which increases the refCount on\nSR1, because it shares that SR. Now we close the old MultiReader, which\ncalls close() on SR1. If now SegmentReader.close() calls Norm.decRef(), \nthen it will close the norms even though they are still used by the new\nMultiReader.\n",
            "date": "2007-10-31T22:56:20.108+0000",
            "id": 64
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nOne more comment: I think you can partially share Norm instances? Eg\n{quote}\nGood idea! Will make the change.",
            "date": "2007-10-31T22:56:54.409+0000",
            "id": 65
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nHmm I was thinking about this before (that's actually why I put that\nmethod in there). But I don't think this is gonna work. For example,\nlet's say we use a MultiReader that has two SegmentReader SR1 and SR2.\nNow only SR2 changed, we reopen the MR which increases the refCount on\nSR1, because it shares that SR. Now we close the old MultiReader, which\ncalls close() on SR1. If now SegmentReader.close() calls Norm.decRef(), \nthen it will close the norms even though they are still used by the new\nMultiReader.\n{quote}\n\nUgh, you're right.  The challenge is sometimes a reference to SR means\n\"I will use norms\" (this is when MultiReader incRefs) but other times\nit means \"I will not use norms\" (this is when SR incRefs due to\nreopen).\n\nOK, I like your original proposal: SR overrides incRef() and incrs its\nRC as well as the RC for each Norm it's using.  Then, in SR's\nreopenSegment, you carefully incRef the \"original\" SR without\nincRef'ing its Norms (except for those Norms you will keep).\n\nLikewise, SR overrides decRef() to decr its RC and RC for each Norm.\nBut, when a reopened SR1.doClose() is called, you must carefully\ndecRef the RD of the original SR but not decRef each of its Norms\n(except for those you had actually shared).\n\nThis way when MR calls SR.incRef/decRef then all Norms and the SR's RC\nare incr'd/decr'd.  But when SR1 shares resources with an original SR\nit only incr's/decr's the refCount of the SR.\n",
            "date": "2007-11-01T13:12:16.984+0000",
            "id": 66
        },
        {
            "author": "Michael Busch",
            "body": "OK, I think it's finally working now! :-)\n\nSegmentReader now overwrites incRef() and increments the readers RC,\nas well as the RCs of all norms. I further added the private method\nincRefReaderNotNorms() to SegmentReader, which is called in \nreopenSegment(), because it takes care of incrementing the RCs of\nall shared norms.\n\nI also added the method doCloseUnsharedResources() to IndexReader,\nwhich is a NOOP by default. It is called when a reader is closed,\neven if its RC > 0. SegmentReader overwrites this method and \ncloses (=decRef) the norms in it. The SegmentReader then remembers\nthat it closed the norms already and won't close them again in\ndoClose(), which is called when its RC finally drops to 0.\n\nI also made the change you suggested, Mike, to only reload the \nfield norms that actually changed. SegmentReader.openNorms() now\nchecks if there is already a norm for a field in the HashTable,\nand only loads it if it's not there. reopenSegment() puts all\nnorms in the new SegmentReader that haven't changed.\n\nI added some new tests to verify the norms ref counting. All unit\ntests pass now. So I think this is ready to commit, but I'd feel \nmore comfortable if you could review it again before I commit it.",
            "date": "2007-11-02T09:53:07.072+0000",
            "id": 67
        },
        {
            "author": "Yonik Seeley",
            "body": "I just did a quick partial review of SegmentReader for thread safety only and ran across some potential issues\n\n- It looks like fieldsReader is shared between clones(), and that isn't thread-safe (synchronization is done at the SegmentReader level, and now there is more than one)\n- maybe the same issue with deletedDocs?  mutual exclusion is no longer enforced.\n- it looks like the norms Hashtable could be shared... looping over the individual norms and calling incRef doesn't seem safe for a number of reasons (for example, you might miss some just being added)\n- reading new norms isn't safe...\n  synchronized norms(String field, byte[] bytes, int offset) uses the \"norm' IndexInput that is shared.  synchronization on a single reader no longer guarantees mutual exclusion.\n\nThere's probably other stuff, but I stopped looking.  Since we are sharing things now, every method that was synchronized is now potentially unsafe.  Synchronizing on the object being shared is probably a much better strategy now.\n\nThis is complex enough that in addition to review, I think we need a good multi-threaded test - 100 or 1000 threads over a ram directory, all changing, querying, retrieving docs, reopening, closing, etc.",
            "date": "2007-11-02T14:09:40.496+0000",
            "id": 68
        },
        {
            "author": "Yonik Seeley",
            "body": "It also looks like Norm.incRef is used in an unsafe manner (unsynchronized, or synchronized on the reader), and also Norm.decRef() is called inside a synchronized(norms) block, but an individual Norm may be shared across multiple Hashtables, right?\n\nI don't think that norms even needs to be a synchronized Hashtable... it could be changed to a HashMap since it's contents never change, right?",
            "date": "2007-11-02T14:37:34.709+0000",
            "id": 69
        },
        {
            "author": "Michael McCandless",
            "body": "\nOK, reviewed the latest patch:\n\n* In this code:\n  {code}\n// singleNormFile means multiple norms share this file\nif (fileName.endsWith(\".\" + IndexFileNames.NORMS_EXTENSION)) {\n  clone.singleNormStream = d.openInput(fileName, readBufferSize);            \n}\n  {code}\n  I think the comment should be removed (it doens't apply) and also\n  won't this incorrectly open the singleNormStream more than once if\n  more than one field does not have separate norms?  I think you should\n  init that to null and then only reopen it, once, if it's still null?\n\n* In MultiSegmentReader, the logic that copies over unchanged norms\n  from the old norms cache can be simplified.  I think you can just\n  look up the old Norm instance & the new Norm instance and if they\n  are == then you can copy bytes over?  This would also let you remove\n  \"sharedNorms\" entirely which is good because it's not a just a\n  boolean thing anymore since some Norm instances are shared and some\n  aren't.\n\n* I think you also need to override decRef (and add\n  decRefReaderNotNorms) to SegmentReader?  Because now there is a\n  mismatch: incRef incr's the Norm RC's, but, decRef does not.  So I\n  think norms are not getting closed?  I think we should modify the\n  \"assertReaderClosed()\" in the unit test to verify (when appropriate)\n  that also the RC of all Norm instances is also 0 (ie\n  assertTrue(SR.normsClosed())).  Then, make sure SR calls\n  referencedSegmentReader.decRefReaderNotNorms instead of decRef.  I\n  think you then don't need to track \"closedNorms\" boolean, at all.\n  You simply always decRef the norms whenever SR.decRef is called.\n  The doCloseUnsharedResources is still needed to close the\n  singleNormStream.\n",
            "date": "2007-11-02T14:43:14.649+0000",
            "id": 70
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nThis is complex enough that in addition to review, I think we need a\ngood multi-threaded test - 100 or 1000 threads over a ram directory,\nall changing, querying, retrieving docs, reopening, closing, etc.\n{quote}\n\n+1\n\nWe should fix all the synchronization issues you've found, create this\nunit test, and then iterate from there.\n",
            "date": "2007-11-02T14:47:05.243+0000",
            "id": 71
        },
        {
            "author": "Yonik Seeley",
            "body": "{quote}We should fix all the synchronization issues you've found, create this\nunit test, and then iterate from there.\n{quote}\n\nOr reverse it... write the test first so we have confidence that it can at least uncover some of these issues.\nThe test should do as little synchronization as possible of it's own so it doesn't mask a lack of synchronization in the core.\nIt should be possible to uncover the unsynchronized concurrent use of IndexInput at least, and hopefully some of the refcounting issues too.",
            "date": "2007-11-02T14:57:34.515+0000",
            "id": 72
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nOr reverse it... write the test first so we have confidence that it can at least uncover some of these issues.\nThe test should do as little synchronization as possible of it's own so it doesn't mask a lack of synchronization in the core.\nIt should be possible to uncover the unsynchronized concurrent use of IndexInput at least, and hopefully some of the refcounting issues too.\n{quote}\n\nExcellent, I agree!\n",
            "date": "2007-11-02T15:08:29.251+0000",
            "id": 73
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nI just did a quick partial review of SegmentReader for thread safety only and ran across some potential issues\n{quote}\n\nOK, let's scratch my \"ready to commit\" comment ;)\n\nA question about thread-safety here. I agree that we must\nfix all possible problems concerning two or more \nIndexReaders in *read-mode*, like the FieldsReader issue.\n\nOn the other hand: We're saying that performing write\noperations on a re-opened reader results in undefined\nbehavior. Some of the issues you mentioned, Yonik, should \nonly apply in case one of the shared readers is used to\nperform index modifications, right? Then the question is: \nhow much sense does it make to make reopen() thread-safe \nin the write case then?\n\nSo I think the multi-threaded testcase should not\nperform index modifications using readers involved in a\nreopen()?\n\n",
            "date": "2007-11-02T16:32:18.043+0000",
            "id": 74
        },
        {
            "author": "Yonik Seeley",
            "body": "Sorry, I hadn't kept up with this issue wrt what was going to be legal (and we should definitely only test what will be legal in the MT test).   So that removes the deletedDocs issue I guess.\n",
            "date": "2007-11-02T16:58:53.873+0000",
            "id": 75
        },
        {
            "author": "Thomas Peuss",
            "body": "To find concurrency issues with an unit test is hard to do, because your potential problems lie in the time domain and not in the code domain. ;-)\n\nFrom my experience following things can have impact on the results of such a test:\n* Running on SP or SMP machines. SMP machines (the more cores the better) reveal concurrency issues much earlier.\n* The Java implementation you are using. IBM's and Sun's thread implementations behave slightly different for example.\n* The OS you are running. This may seem odd in the first run but remember that modern Java implementations rely heavily on the threading implementations of the OS.\n* The processor platform you are running. NUMA vs. UMA (which is AMD vs. intel). The timing of threads can differ because of this.\n\nAnd be prepared that one time your tests runs through without a problem and on the next run it breaks...\n\nJust my \u20ac 0.02",
            "date": "2007-11-05T07:34:11.550+0000",
            "id": 76
        },
        {
            "author": "Michael Busch",
            "body": "Changes in this patch:\n\n- Fixed ParallelReader and MultiReader so that they don't incRef the subreaders anymore in case reopen() is a NOOP (i. e. reopen() doesn't return a new instance)\n- In the new ctr in MultiSegmentReader it was possible to hit a NullPointerException during filling the norms cache, because I didn't check for null after retrieving the old reader from the HashMap. I fixed this.\n- SegmentReader now also overwrites decRef() and implements decRefReaderNotNorms(). \n- As Mike suggested I removed \"boolean sharedNorms\" from SegmentReader. Now in MultiSegmentReader I compare the norm instances from the old and the new subReaders and copy the bytes to the new cache in case they are ==.\n- In SegmentReader I changed norms to be a HashMap instead of HashTable.\n- Norm.decRef() and Norm.incRef() are synchronized now.\n- SegmentReader#norms(String field, byte[] bytes, int offset) now synchronizes on the norm object that is to be read.\n- SegmentReader#reopen() now opens a new FieldsReader because it is not thread-safe.\n- SegmentReader.Norm has a new boolean variable \"useSingleNormStream\". SegmentReader#norms(String field, byte[] bytes, int offset) checks if it is true. If yes, then the readers' singleNormStream is used, otherwise norm.in. This is necessary so that a reopened SegmentReader always uses its own singleNormStream and to avoid synchronization on the singleNormStream.\n- I added a bunch of code to TestIndexReaderReopen to test the thread-safety of reopen(). It starts 150 threads: some modify the index (some delete docs, some add docs and some set norms), some reopen readers and check if the re-opened ones deliver the same results as fresh ones.\n- assertReaderClosed now checks if the norms are closed and also checks recursively if all subReaders are closed.\n\nStill outstanding:\n- On the IBM JVM all tests pass. On Sun, the thread-safety test *sometimes* fails. When it fails, then in assertReaderClosed, because the refCounts of either the norms or some subReaders aren't 0 at the end of the test. At this point I'm not sure why and I'm still debugging. I just wanted to submit the patch to give others the chance to review the patch or possibly (hopefully) find the problem before me.",
            "date": "2007-11-10T06:47:42.236+0000",
            "id": 77
        },
        {
            "author": "Michael Busch",
            "body": "Changes:\n\n- Updated patch to current trunk (I just realized that the \n  latest didn't apply cleanly anymore)\n- MultiSegmentReader now decRefs the subReaders correctly\n  in case an exception is thrown during reopen()\n- Small changes in TestIndexReaderReopen.java\n\nThe thread-safety test still sometimes fails. The weird\nthing is that the test verifies that the re-opened \nreaders always return correct results. The only problem\nis that the refCount value is not always 0 at the end\nof the test. I'm starting to think that the testcase\nitself has a problem? Maybe someone else can take a look\n- it's probably something really obvious but I'm already \nstarting to feel dizzy while pondering about \nthread-safety.",
            "date": "2007-11-12T10:28:08.716+0000",
            "id": 78
        },
        {
            "author": "Michael McCandless",
            "body": "I think the cause of the intermittant failure in the test is a missing\ntry/finally in doReopen to properly close/decRef everything on\nexception.\n\nBecause of lockless commits, a commit could be in-process while you\nare re-opening, in which case you could hit an IOexception and you\nmust therefore decRef those norms you had incRef'd (and, close eg the\nnewly opened FieldsReader).",
            "date": "2007-11-12T21:34:33.887+0000",
            "id": 79
        },
        {
            "author": "Michael Busch",
            "body": "> I think the cause of the intermittant failure in the test is a missing\n> try/finally in doReopen to properly close/decRef everything on\n> exception.\n\nAwesome! Thanks so much for pointing me there, Mike! I was getting a \nlittle suicidal here already ... ;)\n\nI should have read the comment in SegmentReader#initialize more \ncarefully:\n{code:java}\n    } finally {\n\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above.  In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        doClose();\n      }\n    }\n{code}\n\nWhile debugging, it's easy to miss such an exception, because \nSegmentInfos.FindSegmentsFile#run() ignores it. But it's good that it\nlogs such an exception, I just have to remember to print out the \ninfoStream next time.\n\nSo it seems that this was indeed the cause for the failing test case.\nI made the change and so far the tests didn't fail anymore (ran it \nabout 10 times so far). I'll run it another few times on a different \nJVM and submit an updated patch in a short while if it doesn't fail \nagain.\n",
            "date": "2007-11-13T00:14:45.932+0000",
            "id": 80
        },
        {
            "author": "Michael Busch",
            "body": "OK, all tests pass now, including the thread-safety test.\nI ran it several times on different JVMs.\n\nChanges:\n- As Mike suggested I added a try ... finally block to \nSegmentReader#reopenSegment() which cleans up after an\nexception was hit.\n- Added some additional comments.\n- Minor improvements to TestIndexReaderReopen",
            "date": "2007-11-13T01:26:32.663+0000",
            "id": 81
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nAwesome! Thanks so much for pointing me there, Mike! I was getting a\nlittle suicidal here already ... \n{quote}\n\nNo problem, I lost some hairs tracking that one down too!!\n\nOK, latest patch looks good!  I love the new threaded unit test.\n\nOnly two smallish comments:\n\n  * You should also close fieldsReader when referencedSegmentReader !=\n    null, right?  (in SegmentReader.doClose)\n\n  * In the new try/finally in reopenSegment: if you first setup\n    referencedSegmentReader, then can't that finally clause just be\n    clone.decRef() instead of duplicating code for decRef'ing norms,\n    closeNorms(), etc.?\n",
            "date": "2007-11-13T19:18:11.229+0000",
            "id": 82
        },
        {
            "author": "Yonik Seeley",
            "body": "So how about a public IndexReader.flush() method so that one could also reopen readers that  were used for changes?\n\nUsecase:\n\nreader.deleteDocument()\nreader.flush()\nwriter = new IndexWriter()\nwriter.addDocument()\nwriter.close()\nreader.reopen()\nreader.deleteDocument()\n",
            "date": "2007-11-13T19:54:01.042+0000",
            "id": 83
        },
        {
            "author": "Michael Busch",
            "body": "{quote}  \n  * You should also close fieldsReader when referencedSegmentReader !=\n    null, right?  (in SegmentReader.doClose)\n{quote}\n\nYes, will do!\n\t\n{quote}\n  * In the new try/finally in reopenSegment: if you first setup\n    referencedSegmentReader, then can't that finally clause just be\n    clone.decRef() instead of duplicating code for decRef'ing norms,\n    closeNorms(), etc.?\n{quote}\n\nHmm, what if then in clone.close() an exception is thrown from\nFieldsReader.close() or singleNormStream.close(). In that case it \nwould not decRef the referenced reader. \n\nHmm but actually we could change the order in close() so that \nreferencedSegmentReader.decRefReaderNotNorms() is done first even\nif the following close() operations don't succeed?",
            "date": "2007-11-14T06:02:14.289+0000",
            "id": 84
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nSo how about a public IndexReader.flush() method \n{quote}\n\nSince our goal is it to make IndexReader read-only in the future\n(LUCENE-1030), do you really think we need to add this?",
            "date": "2007-11-14T06:05:00.112+0000",
            "id": 85
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nHmm but actually we could change the order in close() so that\nreferencedSegmentReader.decRefReaderNotNorms() is done first even\nif the following close() operations don't succeed?\n{quote}\n\n+1",
            "date": "2007-11-14T10:10:11.972+0000",
            "id": 86
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nSo how about a public IndexReader.flush() method\n{quote}\nI think also if we do decide to do this we should open a new issue for it?",
            "date": "2007-11-14T10:59:55.528+0000",
            "id": 87
        },
        {
            "author": "Yonik Seeley",
            "body": "> Since our goal is it to make IndexReader read-only in the future\n> (LUCENE-1030), do you really think we need to add this?\n\nflush() would make reopen() useful in more cases, and LUCENE-1030 is further off (not Lucene 2.3, right?)\nAnyway, flush() would be considered a write operation like setNorm() & deleteDocument() and could be deprecated along with them in the future if that's how we decide to go.\n\n> I think also if we do decide to do this we should open a new issue for it?\n\nYes, that's fine.",
            "date": "2007-11-14T13:50:36.201+0000",
            "id": 88
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nI think also if we do decide to do this we should open a new issue for it?\n{quote}\n\n+1\n\nI'll open a new issue.",
            "date": "2007-11-14T15:57:30.745+0000",
            "id": 89
        },
        {
            "author": "Michael Busch",
            "body": "Changes:\n\n- Close FieldsReader in SegmentReader#doClose() even if \nreferencedReader!=null\n- Call clone.decRef() in the finally clause of \nSegmentReader#reopenSegment()\n- decRef referencedReader before closing other resources\nin SegmentReader#doClose()\n- Removed IndexReader#doCloseUnsharedResources().",
            "date": "2007-11-14T20:59:59.689+0000",
            "id": 90
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks good.  Only thing I found was this leftover\nSystem.out.println, in SegmentReader.java:\n\n{code}\n  System.out.println(\"refCount \" + getRefCount());\n{code}\n",
            "date": "2007-11-15T14:22:53.064+0000",
            "id": 91
        },
        {
            "author": "Michael Busch",
            "body": "Thanks for the review, Mike! I'll remove the println.\n\nOk, I think this patch has been reviewed a bunch of times and\nshould be ready to commit now. I'll wait another day and commit\nit then if nobody objects.",
            "date": "2007-11-15T15:02:15.701+0000",
            "id": 92
        },
        {
            "author": "Michael Busch",
            "body": "Changes:\n\n- Updated to current trunk.\n- Removed println in SegmentReader.\n\nI'm going to commit this soon!",
            "date": "2007-11-17T20:44:04.813+0000",
            "id": 93
        },
        {
            "author": "Michael Busch",
            "body": "Committed! Phew!!! ",
            "date": "2007-11-17T21:38:16.384+0000",
            "id": 94
        }
    ],
    "component": "core/index",
    "description": "This is Robert Engels' implementation of IndexReader.reopen() functionality, as a set of 3 new classes (this was easier for him to implement, but should probably be folded into the core, if this looks good).\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-743",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "IndexReader.reopen()",
    "systemSpecification": true,
    "version": ""
}