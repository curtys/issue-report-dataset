{
    "comments": [
        {
            "author": "Shai Erera",
            "body": "Way outdated code and it's not really clear what needs to be done. If this is still a problem, I suggest reopening and post a proper patch.",
            "date": "2011-01-26T09:13:41.701+0000",
            "id": 0
        },
        {
            "author": "David Herrera",
            "body": "Hi.\n\nIs there some way to re-open and fix this behavior/bug in AnalyzingQueryParser?\nI have discover this opened (and closed 4 years later) bug. We are working with Lucene 3.2 and we use AnalyzingQueryParser because we need to parse with analyzer every query, even wildcard queries. \n\nThis works great with most queries, and with the ones that don't work (for example in cases analyzer add/remove words and query have wildcards) we use QueryParser although it doesn't analyze wildcard queries.\n\nIn our application there are some cases when we need to allow leading wildcard queries, and AnalyzingQueryParser fails although I set to true 'AllowLeadingWildcard' flag. Strings like '*ucene' is converted into WildcardQuery like this 'ucene*'. This is another strange behavior, the ending wildcard.\n\nI know QueryParser doesn't have this leading wildcard bug, but I need to parse query (I am Spanish and we have special characters (\u00f1, \u00fc, vocals with accent on them) and we parse indexed data, and to search we need to parse query too.\n\n\n\nThanks in advance. Regards!\n\n",
            "date": "2011-09-20T07:18:04.084+0000",
            "id": 1
        },
        {
            "author": "David Herrera",
            "body": "Sorry, is my first post here and I didn't know special characters like {noformat}*{noformat} is bold. For that mistake, in my previous comment there one bold line that I didn't want to be bold. This is what I want to put:\n\n{noformat}'*ucene' is converted into WildcardQuery like this 'ucene*'{noformat}",
            "date": "2011-09-20T07:22:04.285+0000",
            "id": 2
        },
        {
            "author": "David Smiley",
            "body": "Reopening at the request of [~tallison@mitre.org] who intends to attach a patch.  Regular users can't re-open JIRA issues, apparently.",
            "date": "2013-04-02T17:36:16.263+0000",
            "id": 3
        },
        {
            "author": "Tim Allison",
            "body": "This allows for leading wildcards in the AnalyzingQueryParser if setAllowLeadingWildcard is set to true.  ",
            "date": "2013-04-02T17:40:15.142+0000",
            "id": 4
        },
        {
            "author": "Robert Muir",
            "body": "Hello Timothy, can you turn these changes into a patch?\n\nSee http://wiki.apache.org/lucene-java/HowToContribute#Creating_a_patch\n\nThanks!",
            "date": "2013-04-09T13:33:00.003+0000",
            "id": 5
        },
        {
            "author": "Tim Allison",
            "body": "First patch.  Let me know if this actually works.",
            "date": "2013-04-11T20:42:43.228+0000",
            "id": 6
        },
        {
            "author": "Robert Muir",
            "body": "Thank you Timothy. the patch looks very good to me, thanks also for adding tests!\n\nA few questions:\n* The regex simplification looks good to me, but I'm not a regex expert. Maybe someone that is better with regex like [~steve_rowe] can have a look. If nobody objects after a few days I'm inclined to move forward though.\n* What about the case where someone has escaped wildcards? I'm not sure whats even happening today in this case... perhaps it already has surprising behavior and should really be a separate bug, or maybe its working and I just dont see it. I doubt its tested though... but it seems the regex would need to accomodate that?\n* The String.format() invocations should probably pass getLocale() from the superclass as the first argument, rather than depending on the default locale. Since they are locale sensitive I think its best to use the one that someone configured on the queryparser (e.g. via setLocale)",
            "date": "2013-04-12T16:03:17.841+0000",
            "id": 7
        },
        {
            "author": "Steve Rowe",
            "body": "Hi Timothy, I agree with Robert, the patch reduces line count while improving clarity and adding functionality - sweet!\n\nA few nitpicks (+1 otherwise):\n\n- You don't handle escaped metachars ? and * in the query, though the original doesn't either, so this shouldn't stop the patch from being committed.\n- The {{(?s)}} has no effect in {{\"(?s)([^\\\\?\\\\*]+)\"}}, since it only affects the expansion of the dot metachar, which isn't present (see [http://docs.oracle.com/javase/6/docs/api/java/util/regex/Pattern.html#DOTALL]): an inverted charset will always include newlines unless the charset to be inverted explicitly includes them.  Of course, this is all moot, since the query parser will already have split on whitespace before sending {{termStr}} to {{getWildcardQuery()}} :) \n- You can drop the following line in {{normalizeMustBeSingleTerm()}}: {{nonWildcardMatcher.reset(termStr);}}, since nonWildcardMatcher is never reused.\n- The presence of term breaking chars is not the only condition under which analysis of a single term can produce multiple terms (e.g. synonyms, multiple readings), so the following exception message should be generalized: \"There is a term breaking character between %s and %s\".\n- In your new test, the following assertion message seems to have too many words? \"Testing wildcard with wildcard with initial wildcard not allowed\"",
            "date": "2013-04-12T17:15:52.511+0000",
            "id": 8
        },
        {
            "author": "Steve Rowe",
            "body": "One more minor thing: the javadoc on {{getWildcardQuery()}} needs fixing - probably previously should have been \"{{but not for <code>user*</code>}}\" to illustrate not being called for prefix queries, but with your patch it's just plain wrong:\n\n{noformat}\n* Example: will be called for <code>H?user</code> or for <code>H*user</code> \n* but not for <code>*user</code>.\n{noformat}",
            "date": "2013-04-12T17:25:42.283+0000",
            "id": 9
        },
        {
            "author": "Tim Allison",
            "body": "Thank you very much for the feedback. I refactored a bit and added escaped wildcard handling.  Let me know how this looks.",
            "date": "2013-04-18T17:49:40.100+0000",
            "id": 10
        },
        {
            "author": "Steve Rowe",
            "body": "Tim, thanks, I'll take a look at your new patch later today.\n\nFYI, you shouldn't remove old patches - when you upload a file with the same name, the older versions still appear, but their names appear in grey, and you can see the date/time each was uploaded.  See e.g. SOLR-3251, where I've uploaded the same-named patch multiple times.\n",
            "date": "2013-04-18T17:54:29.822+0000",
            "id": 11
        },
        {
            "author": "Tim Allison",
            "body": "Refactored a bit and added a few more tests.",
            "date": "2013-04-26T00:59:37.981+0000",
            "id": 12
        },
        {
            "author": "Steve Rowe",
            "body": "Hi [~tallison@mitre.org],\n\nSorry it took so long, I've attached a patch based on your patch with some fixes:\n\n* Removed tabs.\n* Restored license header and class javadoc to {{AnalyzingQueryParser.java}} (your patch removed them for some reason?).\n* Converted all code indentation to 2 spaces per level (you had a lot of 3 space per level indentation).\n* Converted the {{wildcardPattern}} to allow anything to be escaped, not just backslashes and wildcard chars '?' and '*'.  Also removed the optional backslashes from group 2 (the actual wildcards) - when iterating over wildcardPattern matches, your patch would throw away any number of real wildcards following an escaped wildcard.  I added a test for this.\n* When multiple output tokens are produced (and there should only be one), now reporting all of them in the exception message instead of just the first two.\n* Removed all references to \"chunklet\" in favor of \"output token\" - this non-standard terminology made the code harder to read.\n* Changed descriptions of multiple output tokens to not necessarily be as the result of splitting (e.g. synonyms).\n* In {{analyzeSingleChunk()}}, moved exception throwing to the source of problems.\n\nI also added a {{CHANGES.txt}} entry.  \n\nTim, let me know if you think my changes are okay - if so, I think it's ready to commit.",
            "date": "2013-05-06T07:11:39.145+0000",
            "id": 13
        },
        {
            "author": "Steve Rowe",
            "body": "One other change I forgot to mention, Tim: I substituted MockAnalyzer where you used StandardAnalyzer in the test code - this allowed me to remove the analyzers-common dependency you introduced (and also the memory dependency, which didn't seem to be used for anything in your patch).",
            "date": "2013-05-06T07:20:08.643+0000",
            "id": 14
        },
        {
            "author": "Tim Allison",
            "body": "Steve, no problem on the delay.  Thank you for your help!  Changes sound great.  Thank you.\n\n",
            "date": "2013-05-06T11:40:14.100+0000",
            "id": 15
        },
        {
            "author": "Steve Rowe",
            "body": "Committed to trunk and branch_4x.\n\nThanks Tim!",
            "date": "2013-05-06T23:03:19.582+0000",
            "id": 16
        },
        {
            "author": "Steve Rowe",
            "body": "Although this is labelled as a Major Bug, it feels more like a new feature to me, so I'm not motivated to backport this to 4.3.1.",
            "date": "2013-05-10T22:57:23.687+0000",
            "id": 17
        },
        {
            "author": "Steve Rowe",
            "body": "Bulk close resolved 4.4 issues",
            "date": "2013-07-23T18:36:59.035+0000",
            "id": 18
        }
    ],
    "component": "core/queryparser",
    "description": "The getWildcardQuery mehtod in AnalyzingQueryParser.java need the following changes to accept leading wildcards:\n\n\tprotected Query getWildcardQuery(String field, String termStr) throws ParseException\n\t{\n\t\tString useTermStr = termStr;\n\t\tString leadingWildcard = null;\n\t\tif (\"*\".equals(field))\n\t\t{\n\t\t\tif (\"*\".equals(useTermStr))\n\t\t\t\treturn new MatchAllDocsQuery();\n\t\t}\n\t\tboolean hasLeadingWildcard = (useTermStr.startsWith(\"*\") || useTermStr.startsWith(\"?\")) ? true : false;\n\n\t\tif (!getAllowLeadingWildcard() && hasLeadingWildcard)\n\t\t\tthrow new ParseException(\"'*' or '?' not allowed as first character in WildcardQuery\");\n\n\t\tif (getLowercaseExpandedTerms())\n\t\t{\n\t\t\tuseTermStr = useTermStr.toLowerCase();\n\t\t}\n\n\t\tif (hasLeadingWildcard)\n\t\t{\n\t\t\tleadingWildcard = useTermStr.substring(0, 1);\n\t\t\tuseTermStr = useTermStr.substring(1);\n\t\t}\n\n\t\tList tlist = new ArrayList();\n\t\tList wlist = new ArrayList();\n\t\t/*\n\t\t * somewhat a hack: find/store wildcard chars in order to put them back\n\t\t * after analyzing\n\t\t */\n\t\tboolean isWithinToken = (!useTermStr.startsWith(\"?\") && !useTermStr.startsWith(\"*\"));\n\t\tisWithinToken = true;\n\t\tStringBuffer tmpBuffer = new StringBuffer();\n\t\tchar[] chars = useTermStr.toCharArray();\n\t\tfor (int i = 0; i < useTermStr.length(); i++)\n\t\t{\n\t\t\tif (chars[i] == '?' || chars[i] == '*')\n\t\t\t{\n\t\t\t\tif (isWithinToken)\n\t\t\t\t{\n\t\t\t\t\ttlist.add(tmpBuffer.toString());\n\t\t\t\t\ttmpBuffer.setLength(0);\n\t\t\t\t}\n\t\t\t\tisWithinToken = false;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (!isWithinToken)\n\t\t\t\t{\n\t\t\t\t\twlist.add(tmpBuffer.toString());\n\t\t\t\t\ttmpBuffer.setLength(0);\n\t\t\t\t}\n\t\t\t\tisWithinToken = true;\n\t\t\t}\n\t\t\ttmpBuffer.append(chars[i]);\n\t\t}\n\t\tif (isWithinToken)\n\t\t{\n\t\t\ttlist.add(tmpBuffer.toString());\n\t\t}\n\t\telse\n\t\t{\n\t\t\twlist.add(tmpBuffer.toString());\n\t\t}\n\n\t\t// get Analyzer from superclass and tokenize the term\n\t\tTokenStream source = getAnalyzer().tokenStream(field, new StringReader(useTermStr));\n\t\torg.apache.lucene.analysis.Token t;\n\n\t\tint countTokens = 0;\n\t\twhile (true)\n\t\t{\n\t\t\ttry\n\t\t\t{\n\t\t\t\tt = source.next();\n\t\t\t}\n\t\t\tcatch (IOException e)\n\t\t\t{\n\t\t\t\tt = null;\n\t\t\t}\n\t\t\tif (t == null)\n\t\t\t{\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!\"\".equals(t.termText()))\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttlist.set(countTokens++, t.termText());\n\t\t\t\t}\n\t\t\t\tcatch (IndexOutOfBoundsException ioobe)\n\t\t\t\t{\n\t\t\t\t\tcountTokens = -1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\ttry\n\t\t{\n\t\t\tsource.close();\n\t\t}\n\t\tcatch (IOException e)\n\t\t{\n\t\t\t// ignore\n\t\t}\n\n\t\tif (countTokens != tlist.size())\n\t\t{\n\t\t\t/*\n\t\t\t * this means that the analyzer used either added or consumed\n\t\t\t * (common for a stemmer) tokens, and we can't build a WildcardQuery\n\t\t\t */\n\t\t\tthrow new ParseException(\"Cannot build WildcardQuery with analyzer \" + getAnalyzer().getClass()\n\t\t\t\t\t+ \" - tokens added or lost\");\n\t\t}\n\n\t\tif (tlist.size() == 0)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t\telse if (tlist.size() == 1)\n\t\t{\n\t\t\tif (wlist.size() == 1)\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * if wlist contains one wildcard, it must be at the end,\n\t\t\t\t * because: 1) wildcards at 1st position of a term by\n\t\t\t\t * QueryParser where truncated 2) if wildcard was *not* in end,\n\t\t\t\t * there would be *two* or more tokens\n\t\t\t\t */\n\t\t\t\tStringBuffer sb = new StringBuffer();\n\t\t\t\tif (hasLeadingWildcard)\n\t\t\t\t{\n\t\t\t\t\t// adding leadingWildcard\n\t\t\t\t\tsb.append(leadingWildcard);\n\t\t\t\t}\n\t\t\t\tsb.append((String) tlist.get(0));\n\t\t\t\tsb.append(wlist.get(0).toString());\n\t\t\t\treturn super.getWildcardQuery(field, sb.toString());\n\t\t\t}\n\t\t\telse if (wlist.size() == 0 && hasLeadingWildcard)\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * if wlist contains no wildcard, it must be at 1st position\n\t\t\t\t */\n\t\t\t\tStringBuffer sb = new StringBuffer();\n\t\t\t\tif (hasLeadingWildcard)\n\t\t\t\t{\n\t\t\t\t\t// adding leadingWildcard\n\t\t\t\t\tsb.append(leadingWildcard);\n\t\t\t\t}\n\t\t\t\tsb.append((String) tlist.get(0));\n\t\t\t\tsb.append(wlist.get(0).toString());\n\t\t\t\treturn super.getWildcardQuery(field, sb.toString());\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * we should never get here! if so, this method was called with\n\t\t\t\t * a termStr containing no wildcard ...\n\t\t\t\t */\n\t\t\t\tthrow new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\t/*\n\t\t\t * the term was tokenized, let's rebuild to one token with wildcards\n\t\t\t * put back in postion\n\t\t\t */\n\t\t\tStringBuffer sb = new StringBuffer();\n\t\t\tif (hasLeadingWildcard)\n\t\t\t{\n\t\t\t\t// adding leadingWildcard\n\t\t\t\tsb.append(leadingWildcard);\n\t\t\t}\n\t\t\tfor (int i = 0; i < tlist.size(); i++)\n\t\t\t{\n\t\t\t\tsb.append((String) tlist.get(i));\n\t\t\t\tif (wlist != null && wlist.size() > i)\n\t\t\t\t{\n\t\t\t\t\tsb.append((String) wlist.get(i));\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn super.getWildcardQuery(field, sb.toString());\n\t\t}\n\t}\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-949",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "AnalyzingQueryParser can't work with leading wildcards.",
    "systemSpecification": true,
    "version": "2.2"
}