{
    "comments": [
        {
            "author": "Tim Smith",
            "body": "since Weight.explain() is passed the \"sub reader\", it also should be passed the offset in order to calculate the \"real\" docid",
            "date": "2009-08-18T21:06:54.328+0000",
            "id": 0
        },
        {
            "author": "Mark Miller",
            "body": "I think we would prefer that you didn't cache by multi-reader. We want to encourage cache by segment.\n\nIn my mind, I don't think we should try and squeeze this into 2.9. We can see if anyone disagrees.",
            "date": "2009-08-18T21:07:57.215+0000",
            "id": 1
        },
        {
            "author": "Tim Smith",
            "body": "For the explain case, if Searcher had the following method, the base offset would not have to be passed in (could be inferred):\n{code}\npublic int getIndexReaderBase(IndexReader reader);\n{code}",
            "date": "2009-08-18T21:09:17.130+0000",
            "id": 2
        },
        {
            "author": "Tim Smith",
            "body": "I have a really crazy cache that for performance and memory reasons has to be based on the Multi-Reader (and this is very important in my application)\n\nlooking closer at the per segment searching, i cannot upgrade to 2.9 (which i really want to do) because of this",
            "date": "2009-08-18T21:11:14.289+0000",
            "id": 3
        },
        {
            "author": "Mark Miller",
            "body": "Can you give a use example? What are you caching in the Scorer index wide? It really seems you should be doing it per segment ...",
            "date": "2009-08-18T21:11:17.023+0000",
            "id": 4
        },
        {
            "author": "Tim Smith",
            "body": "I'm caching an \"index\" into the terms for the document (Think of the \"StringIndex\" without the String[])\nall i care about is that integer index value\n\nbreaking this out into a per segment cache would then require me to also store along with the int[] index array a String[] \nthis then gets really slow and nasty when trying to run through the required algorithms to use the cache for my application",
            "date": "2009-08-18T21:16:06.083+0000",
            "id": 5
        },
        {
            "author": "Tim Smith",
            "body": "I think i found a workaround (to allow me to upgrade)\n\nI already subclass IndexSearcher, so i could just add the following method (and use this instead of regular search())\n{code}\n  public void mySearch(Weight weight, Collector collector) throws IOException {\n    collector.setNextReader(reader, 0);\n    Scorer scorer = weight.scorer(reader, !collector.acceptsDocsOutOfOrder(), true);\n    if (scorer != null) {\n      scorer.score(collector);\n    }\n  }\n{code}\n\nhowever, this prevents me from being able to take full advantage of per segment caching (which i really want to use for all my other caches)\n",
            "date": "2009-08-18T21:25:07.806+0000",
            "id": 6
        },
        {
            "author": "Mark Miller",
            "body": "{quote}breaking this out into a per segment cache would then require me to also store along with the int[] index array a String[] \nthis then gets really slow and nasty when trying to run through the required algorithms to use the cache for my application {quote}\n\nWhy is this? You must be keying this to the multi reader now right? Why cannot you not do the same thing keyed to the sub reader?",
            "date": "2009-08-18T21:53:24.674+0000",
            "id": 7
        },
        {
            "author": "Tim Smith",
            "body": "Thought about it a bit more\n\nall i really need is the following method added to Searcher\n{code}\n public int getIndexReaderBase(IndexReader);\n{code}\n\nif this doesn't go into 2.9, i should be able to add this method to my subclass of IndexSearcher (so i wouldn't put this as blocker status for me anymore)\n\nas long as Searcher has getIndexReaderBase(), i can have my Weight hold onto the Searcher it was created with and when the scorer is created off it, i can lookup the base offset based on the IndexReader passed in\n\ni can work up a patch for this in the morning if desired\n\nalso, there should be a big old warning in the change log about MultiReader based cache used in a Weight/Scorer being broken (not sure if there's a warning specifically about this in there)",
            "date": "2009-08-18T21:58:43.394+0000",
            "id": 8
        },
        {
            "author": "Tim Smith",
            "body": "the int[] index array is used as a \"perfect\" hash function in order to be able to map all documents sharing the same value, so the int[] index from each sub reader can have different hash values for the same term (Thats why the string sorting in 2.9 is real nasty, because it can't just compare the ord values any more (unless you're lucky and you're comparing docs from the same reader)",
            "date": "2009-08-18T22:01:58.057+0000",
            "id": 9
        },
        {
            "author": "Mark Miller",
            "body": "I'd go with your solution then - I'd hate to expose doc base stuff on Searcher or in Scorer (I'm not a big fan of gatherSubReaders being protected either).\n\nAlso, *we* can't put Searcher on a Weight - it needs to be serializable (though you can if you don't need to count on that).\n\nWhere do you suggest we should place a warning that we havn't? I don't think we ever intended to support the use of external ids.\n\nI think your use case is fairly special, and I'm not sure we should expose per segment stuff where we don't have to.\n\nIt is an interesting use case though - maybe someone else will chime in.",
            "date": "2009-08-18T22:23:41.785+0000",
            "id": 10
        },
        {
            "author": "Tim Smith",
            "body": "I'll prepare a patch in the morning (unless someone beats me to it) and look over the changelog then to suggest some more disclaimers (if what's there isn't sufficient)\n\nI don't hold the contract that Weight be serializable (so i'm safe there)\n\ni agree that per-segment is the way to go in general and should be as tight as possible (as long as i can get my mits on the \"sub readers\")\n\nbut there are use cases that still require looking at the index as a whole as well\nespecially if you need to know the number of unique terms for a field, or otherwise need documents in one segment to be aware of documents in other segments (i could probably come up a bunch more use cases there)\n",
            "date": "2009-08-18T22:35:33.070+0000",
            "id": 11
        },
        {
            "author": "Mark Miller",
            "body": "You should pull that info from a top level reader and somehow pass it to your scorer through your query impl or something than.\n\nWe are working very hard to make search per segment and discourage non per segment use - it doesn't seem like you want to be consulting the entire index on every call to scorer. Passing the base around does not help you with looking at the whole index either - just in terms of doc ids - which we don't support externally - and you are essentially caching them externally. The document ids should be purely internal - I don't think we want to support documents in one segment being aware of docs in another segment either.\n\ncreateWeight on Query gives you the opportunity to grab stuff your Scorer may need top level (off the Searcher).\n\nYou could also make a new Query each time that takes a top level IndexReader and uses it.\n\nYou can also override IndexSearcher (as you have) and work around things there.\n\n",
            "date": "2009-08-18T23:01:52.844+0000",
            "id": 12
        },
        {
            "author": "Tim Smith",
            "body": "My current plan of attack for this use case will be to:\n* pull the cache using the MultiReader at createWeight() time (index into cache will be MultiReader docid)\n* pull the base offset for the IndexReader at scorer() creation time (will need to add the getIndexReaderBase() method to my searcher to do so)\n* when the scorer needs to hit the cache, it'll add the base to the scorer's docid to get the key for the cache lookup\n\nI should be able to do this easily enough with a customized IndexSearcher (subclass)\n\nthere are use cases where documents from one segment need to be aware of documents from other segments\nsorting is such a use case (this is just done at the Collector level, so there are more hooks to do the needed base offset stuff)\nduplicate removal is another such use case (only return the first document for docs sharing a field value)\n\nboth these use cases can be done at the Collector level, however Duplicate Removal could potentially be done at the Query level in order to perform duplicate removal at any location in the query matching\nalso, efficient duplicate removal for a String field would require the int[] ord index in order to reduce overall memory requirements\nUsing the int[] ord index allows using a BitSet for the hash set required to mark if a document for a specified value has been encountered (would need a HashSet<String> otherwise (ugh))\n\nmy particular use case must be done at the query level in order to have full boolean query support, and the ability to layer multiple queries with all combinations of AND/OR/NOT, and any other query operators, and sadly i have yet to come up with any way to create a cache on a per segment level (without creating the cache at the MultiReader level)\n",
            "date": "2009-08-19T00:11:16.365+0000",
            "id": 13
        },
        {
            "author": "Mark Miller",
            "body": "Sorting is internal. To allow this switch to per segment we implemented a new HitCollector that can collect from multiple readers - sorting across multiple segments still needed to be supported, and custom comparators still needed to be supported. All of the ids are manged internally though - when I say internally, I mean within Lucene. If you implement a custom FieldComparator, you are still respecting Lucene's internal id usage. We map priority queue values so that they can be compared with the values in a different Reader, but again, all of the ids are managed internally. All caching and everything is still done per segment. All FieldCaches are per Reader and per segment.\n\nThe goal is to move all caches to the segment level in Lucene - we don't want to encourage users to cache per multi-reader by providing API help to do so.\n\nIf you need index wide stats, you use the Weight.\n\nYou are trying to use the internal ids externally - you are caching from external id to ord - its really not something I think we intend to support. The fact that we don't support it is why we were able to make this change. The FieldCache is the caching mechanism that Lucene supports with internal ids - and it supports it per segment.",
            "date": "2009-08-19T00:54:19.757+0000",
            "id": 14
        },
        {
            "author": "Hoss Man",
            "body": "bq. you are caching from external id to ord - its really not something I think we intend to support. The fact that we don't support it is why we were able to make this change. The FieldCache is the caching mechanism that Lucene supports with internal ids - and it supports it per segment.\n\nI think Tim's got a valid point though about wanting an ordinal value across the entire index ... he's not using external ids, he's using the internal lucene docIds, and wants to know the ordinal value of a field for each doc across the entire index -- as he said, he's essentially using a FieldCache.StringIndex he just doesn't care about the String[] part.\n\nSolr had/has the same problem with some of the function queries that wanted ordinal values (or the min/max field value for the whole index) that i think yonik just punted on and fetched the outermost field cache anyway ... we just weren't using it inside the Weight class, so we didn't encounter the specified problem Tim did.\n",
            "date": "2009-08-19T01:10:07.848+0000",
            "id": 15
        },
        {
            "author": "Mark Miller",
            "body": "bq. I think Tim's got a valid point though about wanting an ordinal value across the entire index ...\n\nI don't disagree about wanting them at all. Hes using them for a neat purpose. \n\nbq. he's not using external ids, he's using the internal lucene docIds\n\nIf he were respecting the internal ids, you wouldn't need to calculate the multi-reader id. Hes essentially caching the multi-reader ids - thats the same as using a filter that always allows doc 0 to pass - its using the internal ids externally. To use the ids correctly, you get a reader and an id space that starts at 0 for that reader. If you want to use the whole reader, you should work with the multi-reader. You can use the multi-reader without breaking it apart here as well if you need to.\n\nI think its a slippery slope - we start having to support both the segment ids, plus the multi-reader ids. And as we work on real-time, we will have to count on users caching that way - I think its better to try and work all of our support towards per segment.\n\nI'll leave it for smarter people to discuss for now - but I don't think its the right path. He can essentially do what he needs without built in support, and personally I think thats the way to go. I think its great that right now, other than the sorting/hitcollector, things don't know about the sub reader breakout.",
            "date": "2009-08-19T01:29:11.080+0000",
            "id": 16
        },
        {
            "author": "Tim Smith",
            "body": "bq. The goal is to move all caches to the segment level in Lucene - we don't want to encourage users to cache per multi-reader by providing API help to do so.\nI agree that this is the goal, and that using per segment caches should be the encouraged route for field caching needs. \nI plan to update the vast majority of the caches i use to be loaded on a per segment basis once i switch to 2.9 to take advantage of this.\nBut it should still be possible for advanced users to do caching on the multireader level. This may require porting upon subsequent versions of lucene (as i'm seeing i will have to for 2.9), however this should remain possible\n\nbq. If you need index wide stats, you use the Weight.\nI'm currently using weight to get this cache on the multireader level, however with 2.9 i will have to jump through some more hoops in order to be able to use this cache on each sub reader's scorer\n\nbq. You are trying to use the internal ids externally\nAll my usage of \"internal\" docids occurs inside Weight, Scorer, and HitCollector implementations. I don't see how this is really \"external\" as it is using published interfaces. Its just that the interpretation of these interfaces changed for 2.9 (i have no problem with this as long as i can port from 2.4 with minimal to moderate effort). The reason they were able to change was only because no implementations provided by vanilla lucene or in contrib required the \"whollistic\" view of the index\n\nbq. The FieldCache is the caching mechanism that Lucene supports with internal ids - and it supports it per segment.\nThe FieldCache mechanism did not meet all my needs with regards to schema/retention policy/etc, so i have been doing caching in my own code base for quite some time. While the FieldCache usage should be encouraged, it should not be required of advanced users. It should be acceptable for advanced users to feel some pain on upgrading, but there should be a rather clear path for doing so (without a loss of functionality, and ideally without requiring custom patches on top of a released version of lucene)\n\nbq. Sorting is internal.\nWhile sorting is provided by lucene APIs, there is nothing (and should be nothing) stopping someone from performing sorting on their own terms via the Collector interface and their own priority queues/API\n\n",
            "date": "2009-08-19T01:46:00.509+0000",
            "id": 17
        },
        {
            "author": "Mark Miller",
            "body": "The \"internal\" vs \"external\" is kind of confusing made up terms - my fault really.\n\nWhen I think of using the ids 'internally' I'm thinking that you are taking the index reader and making no assumptions. You just use the single reader and its id space. You can use those ids to get values, and you can map from those ids to values.\n\nThe assumption being made here is that you can load up ords for every doc and that these ords will be comparable in a way that every document id across the whole index maps to the same ord if it has the same value for a field. Nothing in the API promised that to my knowledge - it just happened to be a happy side effect. \n\nbq. While sorting is provided by lucene APIs, there is nothing (and should be nothing) stopping someone from performing sorting on their own terms via the Collector interface and their own priority queues/API\n \nIndeed - just like there is nothing stopping you from continuing to use a MultiReader for this functionality.\n\nWhat I mean by sorting is internal is that we specifically support comparing ords/values across readers. I think we would prefer that you don't count on ids coming from the top reader or a sub reader in other cases. We don't promise one way or another. We just give a reader and say work with this reader.\n\nExperts can generally jump around that if they need to - Solr does a bit of this - or you can choose to continue using Multi-Readers.\n\nI'm not saying we should make it impossible for you to do this - but I don't think we should open a path for scorers to reconstruct multi-reader virtual ids. I don't think a Scorer should know or care why type of IndexReader it is working with.",
            "date": "2009-08-19T02:25:51.091+0000",
            "id": 18
        },
        {
            "author": "Mark Miller",
            "body": "bq. he's not using external ids, he's using the internal lucene docIds\n\nLet me try a response to this one once more:\n\nIf you try and make a filter that always matches docs 0-10, you could have made a filter that just sets bits 0-10. You are technically using 'internal' lucene doc ids. \n\nWith the new per segment search though, you will find that you match the first 10 docs in every segment, not just the first 10 docs in the multi-reader virtual id space. This is what I call using the internal doc ids externally. You are counting on a single id space covering the whole index for the reader. This was never promised though. So just like this type of filter was not *really* supported and no longer works - this method of relying on the IndexReader to support one id space across the whole index no longer works as well. The Searcher supports the whole index, but a given IndexReader was never promised to do so. We could have passed base doc ids to the filters so that they could reconstruct the multi-reader virtual ids, and then just actually match docs 0-10 - but thats exactly the opposite of what we are trying to achieve. We switched to per segment to get away from that.",
            "date": "2009-08-19T03:08:56.154+0000",
            "id": 19
        },
        {
            "author": "Tim Smith",
            "body": "bq. I'm not saying we should make it impossible for you to do this - but I don't think we should open a path for scorers to reconstruct multi-reader virtual ids. I don't think a Scorer should know or care why type of IndexReader it is working with.\n\ni disagree with that, i think the APIs should make it clear whether you are working with a sub reader or a top level reader\nif a Scorer is given an IndexReader, it should have the same ability to reconstruct the \"client facing\" docid in the same manner as the Collector interface provides in order to provide a consistent interface between Collectors and Scorers\nThis reconstruction should be documented as \"advanced\", however it should still be available\n\nWhereever an IndexReader is exposed in API calls, it should be possible to walk the IndexReader's parent IndexReaders until you get the top level reader in order to have the full context of that IndexReader. This walking should only be done at \"init\" time (Scorer construction/Collector setScorer(), and so on depending on need of the application, but it should be possible (ideally without doing nasty things))\n",
            "date": "2009-08-19T03:11:08.245+0000",
            "id": 20
        },
        {
            "author": "Tim Smith",
            "body": "on \"internal lucene ids\"\n\nright now (2.4) i always know what docids map to what IndexReader (always the top level)\ni don't have a problem breaking that assumption, as long as i have the context to map docids between spaces (sub reader to top level and back (mabye even a couple more levels in between))  \n\nI opened this ticket soley because in the Scorer API there is no presented way to actually do this mapping between spaces (short of the \"hacks\" i discussed way above)\nI have no problem whatsoever in the changing of what \"space\" docids exist in, as long as i can get to and from the top level to this space\nI also have no problem if how to do this mapping changes between releases (as long as its documented)",
            "date": "2009-08-19T03:17:17.726+0000",
            "id": 21
        },
        {
            "author": "Mark Miller",
            "body": "You may get furthers with others than me Tim, so don't get too, too caught up with me. McCandless is still on vacation for one, and he may have ideas other than mine (and certainly better ideas even if they are not other) - others may still jump in too. The two of us did the majority of the per segment work though. Yonik has also fought through a lot of this type of stuff with Solr - I'm sure he has some stance on this stuff.\n\nbq. Whereever an IndexReader is exposed in API calls, it should be possible to walk the IndexReader's parent IndexReaders until you get the top level reader in order to have the full context of that IndexReader\n\nSolr now works this way to get around some of the per segment issues. I'm not sure if it makes sense to support that fully in Lucene or not. Perhaps so. Too late for me to properly think though - time for bed.\n\nAny downsides I wonder ...\n\nI think my main issue is that it will encourage people to work per top level reader and it will force us to take that into account ...\n\n",
            "date": "2009-08-19T03:30:05.010+0000",
            "id": 22
        },
        {
            "author": "Michael McCandless",
            "body": "\nBTW contrib/spatial has exactly this same problem.  It currently\nbuilds up a cache, keyed on the \"top\" (MultiReader's) docID, of the\nprecise distance computed by its precise distance filters, to then be\nused during sorting.  Right now it simply computes its own docBase and\nincrements it every time getDocIdSet() is called (which is messy).\nThough I think it could (and should) switch to a per-segment cache.\n\nI am torn.  On the one hand we don't want to encourage apps to be\nusing \"top docIDs\" anywhere \"down low\" (eg Weight/Scorer).  We'd like\nall such per-segment swtiching to happen \"up high\".\n\nBut on the other hand, this is quite a sudden change, and most\nadvanced apps will be using the top docIDs by definition (since\nper-segment docIDs only becomes an [easy] option in 2.9), so it'd be\nmore friendly to offer up a cleaner migration path for such apps where\nWeight/Scorer is told its docBase.\n\nAnd, having to migrate an ord index from \"top\" to \"sub\" docIDs is\ntruly a nightmare, having gone through that with Mark in getting\nString sorting to work per segment!\n",
            "date": "2009-08-19T09:45:24.577+0000",
            "id": 23
        },
        {
            "author": "Tim Smith",
            "body": "Concerning the changelog, i feel the below should be added to the \"Changes in runtime behavior\" section (it's kinda specified in \"New features\", however\nit is also a rather substantial change in the runtime behavior and should be called out explicitly there)\n\n{code}\n 13. LUCENE-1483: When searching over multiple segments, a new Scorer is created for each segment. \n        The Weight is created only once for the top level searcher. Each Scorer is passed the per-segment IndexReader.\n        This will result in docids in the Scorer being internal to the per-segment IndexReader and there is currently no way\n         to rebase these docids to the top level IndexReader. This results in any caches/filters that use docids over the top \n         IndexReader to be broken.\n{code}\n",
            "date": "2009-08-19T12:46:32.792+0000",
            "id": 24
        },
        {
            "author": "Mark Miller",
            "body": "I think thats a good idea. I think that last sentence needs a bit of work. Here is another attempt that I am still not quite happy with:\n\n{code}13. LUCENE-1483: When searching over multiple segments, a new Scorer is created for each segment. \n        The Weight is created only once for the top level searcher. Each Scorer is passed the per-segment IndexReader.\n        This will result in docids in the Scorer being internal to the per-segment IndexReader and there is currently no way\n         to rebase these docids to the top level IndexReader. This will likely break any caches/filters in Scorers that rely on docids from the top \n         level IndexReader eg if you rely on the IndexReader to contain every doc id in the index.{code}",
            "date": "2009-08-19T12:55:37.286+0000",
            "id": 25
        },
        {
            "author": "Tim Smith",
            "body": "One more pass\n\n{code}\n13. LUCENE-1483: When searching over multiple segments, a new Scorer is created for each segment. \n        The Weight is created only once for the top level searcher. Each Scorer is passed the per-segment IndexReader.\n        This will result in docids in the Scorer being internal to the per-segment IndexReader. If a custom Scorer implementation \n         uses any caches/filters based on the top level IndexReader/Searcher, it will need to be updated to use caches/filters on a \n         per segment basis. There is currently no way provided to rebase the docids in the Scorer to the top level IndexReader.\n         See LUCENE-1821 for discussion on workarounds for this.\n{code}",
            "date": "2009-08-19T13:03:37.422+0000",
            "id": 26
        },
        {
            "author": "Tim Smith",
            "body": "Here's a patch that adds getIndexReaderBase(IndexReader reader) to IndexSearcher\n\nsadly, this cannot be easily added to MultiSearcher as well as it uses \"Searchables\", which would require adding this method to the Searchable interface\nI could work up another patch that adds this method to the Searchable interface, however that has some back-compat concerns\n",
            "date": "2009-08-19T13:07:40.428+0000",
            "id": 27
        },
        {
            "author": "Mark Miller",
            "body": "Looks great!\n\nI still almost want to say rely on though:\n\nbq. uses any caches/filters based on the top level IndexReader/Searcher\n\nbq. uses any caches/filters that rely on being based on the top level IndexReader/Searcher\n\nNo? It seems like you could be based on a top level reader before, but not rely on the fact that it was a top level ...",
            "date": "2009-08-19T13:08:32.833+0000",
            "id": 28
        },
        {
            "author": "Tim Smith",
            "body": "\"rely on\" it is",
            "date": "2009-08-19T13:10:38.967+0000",
            "id": 29
        },
        {
            "author": "Michael McCandless",
            "body": "I think we should in fact add this API to 2.9?  It can ease the transition for users doing expert stuff w/ Lucene today.  The current patch looks reasonable, but we should mark it as expert and note that one should switch one's app logic to be per-segment whenever possible, instead of operating in the composite reader's docID space.  We should also note that it's O(N) CPU cost, ie, you should not call it for every hit (for example), but rather once per-segment and then hold onto that base.",
            "date": "2009-08-20T09:57:40.595+0000",
            "id": 30
        },
        {
            "author": "Tim Smith",
            "body": "It would also be nice if the top level Searcher were pased in to Weight.scorer() (like in Weight.explain())\nthat way custom Weight implementations won't need to hold onto the Searcher at Weight creation time (thats a bigger patch though)",
            "date": "2009-08-20T12:05:17.561+0000",
            "id": 31
        },
        {
            "author": "Mark Miller",
            "body": "bq. It can ease the transition for users doing expert stuff w/ Lucene today\n\nI think it only helps if you counted on the reader having every doc id in it?\n\nIt needs more than the current patch I think - we can't rely on people being able to plant a Searcher on the Weight ...",
            "date": "2009-08-20T12:08:29.982+0000",
            "id": 32
        },
        {
            "author": "Tim Smith",
            "body": "I can work up another patch where the Searcher is passed into Weight.scorer() as well if that is an acceptable approach (this method was already changed alot in 2.9 anyway)",
            "date": "2009-08-20T12:27:15.176+0000",
            "id": 33
        },
        {
            "author": "Mark Miller",
            "body": "I'm still not sold on this - these use cases don't work with MultiSearcher either right? I think thats part of this not being officially supported before either ...\n\nAnd passing the Searcher doesn't quite work right either - thats already kind of a bug with explain - you get the searcher with the doc - not a searcher that covers the whole multisearcher space.",
            "date": "2009-08-20T12:52:54.697+0000",
            "id": 34
        },
        {
            "author": "Tim Smith",
            "body": "true, MultiSearcher does kink things up some (and the Searcher abstract class in general)\n\npersonally, this is not a problem for me (don't use MultiSearcher (not yet at least)), and i'm happy with being passed the IndexSearcher instance that directly contains the IndexReader i'm being passed\n\nThe contract could be marked that the Searcher provided is the direct container of the IndexReader also passed\nat which point, both explain() and scorer() would be \"accurate\" in terms of this\n\nI would almost like to see something different passed in instead of a Searcher/IndexReader pair\n\ni would actually like to see a \"SearchContext\" sort of object passed in\nthis would represent the whole \"tree\" of Searchers/IndexReaders\nthis would allow access to the MultiSearcher, the direct IndexSearcher, and the sub IndexReader (which should actually be used for the scoring) (as well as any other Searcher's in the call stack) \nthis SearchContext could also pass in the \"topScorer/allowDocsInOrder\" flags (but that would be more difficult as scorers have subscorers that need to sometimes be created with different flags for these), but this SearchContext could be used to pass more information throughout the Scorer API in general from the top level (like - always use constant score queries where possible, use scoring algorithm X, Y, or Z, and so on)\n\nobviously this would impact the API of Searcher a good deal as it would have to maintain this stack as sub Searcher's search() methods are called)",
            "date": "2009-08-20T13:06:03.014+0000",
            "id": 35
        },
        {
            "author": "Tim Smith",
            "body": "Marking as fix for 2.9 so this gets looked over real good prior to 2.9 going out (even if it is punted)\n\ni believe i can workaround this (still integrating 2.9 into my app, and i haven't got to per-field caching stuff yet)\n\nIn order to get my app to work with 2.9 (without any major mods), i had to add the following to my IndexSearcher subclass:\nNOTE: i never use Filter (thats why this skips it over)\n{code}\n  @Override\n  public void search(Weight weight, Filter filter, Collector collector) throws IOException {\n    // Need to work on the top level reader for now\n    collector.setNextReader(reader, 0);\n    final Scorer scorer = weight.scorer(reader, !collector.acceptsDocsOutOfOrder(), true);\n    if (scorer != null) {\n      scorer.score(collector);\n    }\n  }\n{code}",
            "date": "2009-08-20T21:56:52.942+0000",
            "id": 36
        },
        {
            "author": "Mark Miller",
            "body": "I'm still not a fan of giving access to the upper readers.\n\nI think I could go for having the offset available with the appropriate warnings.\n\nI tried this out, and after adjusting all scorer, explains to carry the offset as well, I ended up with one spot left:\n\n{code}\n  public DocIdSet getDocIdSet(final IndexReader reader) throws IOException {\n    final Weight weight = query.weight(new IndexSearcher(reader));\n    return new DocIdSet() {\n      public DocIdSetIterator iterator() throws IOException {\n        return weight.scorer(reader, docBase?, true, false);\n      }\n    };\n  }\n{code}\n\nTrouble - in these cases, how do you pass the doc base? Its too much breakage to pass it with the reader *everywhere*. You almost want a class that holds the reader ref and the docBase, but you still break apis all over. You could deprecate everything, but then you can't count on getting a good offset (would have to guess 0? ).",
            "date": "2009-08-21T00:13:15.930+0000",
            "id": 37
        },
        {
            "author": "Tim Smith",
            "body": "in the case of the getDocIdSet() method, i would say you should pass \"0\" for the docBase\nThis is because in this case, you are asking for DocIdSet in the context of *reader*\n\nhowevever, this method is actually also a bit broken now with per segment searching\nwhat if *reader* is a MultiReader\nThis could now incur the \"double ram usage\" penalty refered to in that \"explain()\" ticket i recall seeing last week\nIf  *query* has any ValueSource based queries, it'll result in getting the ValueSource in the context of the MultiReader (if i'm not mistaken)\nSo, this method in particular should probably be rewritten to return a DocIdSetIterator that will step through each segment in \"reader\" in turn",
            "date": "2009-08-21T00:55:12.714+0000",
            "id": 38
        },
        {
            "author": "Mark Miller",
            "body": "{quote}\nhowevever, this method is actually also a bit broken now with per segment searching\nwhat if reader is a MultiReader\n{quote}\n\nRight - there are many places where this could be the case - your still free to use multi-readers, though we encourage you to switch. We provide a cool cache sanity checker to help you find these cases, and evaluate whether or not you can make the switch. *edit* I know this doesn't help with filters - there was an issue that helped address that I think though - worked on by Hoss and Mike McCandless - not sure if that helps here or if this was overlooked or what though - I'll have to go skim that issue again. *edit*\n\nIf you just pass 0, many times it will be wrong. Why shouldn't this have access to a doc id cache as well? We always ask for everything in the context of the Reader given. I think thats the issue. Lucene just never officially supported this use case - we can't with MultiSearcher, Searchable, Remote - the API doesn't work with the idea that you can count on all the doc ids from a Reader. You were taking advantage of the implementation and your limited use of the full API - but its never been part of the API IMHO.\n\nPerhaps we could one day change things - RMI hasn't really worked out in comparison to other methods large scale (supposedly very chatty - though I have been told very large installations have been built with it ) - we have already factored it into contrib. But this still doesn't fit the current model/API, and if we address it, it will take longer than 2.9 to do right IMO.",
            "date": "2009-08-21T01:03:43.764+0000",
            "id": 39
        },
        {
            "author": "Michael McCandless",
            "body": "OK... pondering this some more, and on seeing just how much change\nwould be required, I'm now nervous about making deep changes to\nLucene's scoring/filtering APIS (Weight.scorer, Filter.getDocIdSet) to\nenable access to top readers and/or a sub-readers doc base.\n\nAll of Lucene's core & contrib now operates \"context free\"\n(per-segment), where each reader need not know its \"context\" in the\nfull searcher tree, and I think we should strongly encourage external\nusage of these APIs to switch to context free as well.  Since there\nare workarounds possible (accessing sub-readers via IndexSearcher),\nexternal apps that have problems making the switch can use these\nworkarounds?\n",
            "date": "2009-08-21T11:41:40.430+0000",
            "id": 40
        },
        {
            "author": "Tim Smith",
            "body": "I'm OK with having to jump through some hoops in order to get back to the \"full index\" context\n\nIt would be nice if this was more facilitated by lucene's API (IMO, this would be best handled by adding a Searcher as the first arg to Weight.scorer(), as then a Weight will not need to hold on to this (breaking serializable))\n\nThere are definitely plenty of use cases that take advantage of the \"whole\" index (one created by IndexWriter), so this ability should not be removed\nI have at least 3 in my application alone (and they are all very important)\n\nYou get tradeoffs working \"Per-Segment\" vs \"Per-MultiReader\" when it comes to caching in general\ngoing per-segment means caches load faster, and load less frequently, however this causes algorithms working with the caches to be slower (depending on algorithm and cache type)\n\nfor static boosting from a field value (ValueSource), it makes no difference\nfor numeric sorting, it makes no difference \n\nfor string sorting, it makes a big difference - you now have to do a bunch of String.equals() calls, where you didn't have to in 2.4 (just used the ord index)\nGiven this reason, you should really be able to do string sorting 2 ways\n* using per segment field cache (commit time/first query faster, sort time slower)\n* using multi-reader field cache (commit time/first query slower, sort time faster)\n\nThis same argument also goes for features like faceting (not provided by lucene, but is provided by applications like solr, and my application). Using a per-segment cache will cause some significant performance loss when performing faceting, as it requires creating the facets for each segment, and then merging them (this results in a good deal of extra object overhead/memory overhead/more work where faceting on the multi-reader does not see this)\n\nIn the end, it should be up to the application developer to choose what strategy works best for them, and their application (fast commits/fast cache loading may take a back seat to fast query execution)\n\nIn general, i find there is a tradeoff between commit time and query time. The more you speed up commit time, the slower query time gets, and vice versa\nI just want/need the ability to choose\n\n\n\n\n",
            "date": "2009-08-21T12:35:38.152+0000",
            "id": 41
        },
        {
            "author": "Mark Miller",
            "body": "bq. I'm OK with having to jump through some hoops in order to get back to the \"full index\" context\n\nYou never officially had the full index context - only because you jettison a large part of the API did you have it.\n\nbq.  this would be best handled by adding a Searcher as the first arg to Weight.scorer()\n\nThe current API would not support this without back compat breaks up the wazoo - the MultiSearcher can be on the client - its not available on the server. Passing just the local Searcher does not jive with the API.\n\n\n{quote}for string sorting, it makes a big difference - you now have to do a bunch of String.equals() calls, where you didn't have to in 2.4 (just used the ord index)\nGiven this reason, you should really be able to do string sorting 2 ways{quote}\n\nThis is only valid for those short circuiting the API and ignoring MultiSearcher and its affects on the API. As a project, we can't and shouldn't support this type of thing unless we can make it work with MultiSearcher or eventually pull MultiSearcher.\n\nbq. In the end, it should be up to the application developer to choose what strategy works best for them, and their application (fast commits/fast cache loading may take a back seat to fast query execution)\n\nYou can pick, but we have to be true to the API or change it (not easy with our back compat policies)",
            "date": "2009-08-21T12:48:08.225+0000",
            "id": 42
        },
        {
            "author": "Mark Miller",
            "body": "The Searcher being passed to explain is also really a break - I almost think we should pull it.\n\nWe put it in because a break was already introduced when someone tried to add stats for the whole context in TermWeight - that wasn't legal though.\n\nTo prevent further spread, I actually think we need to pull that searcher and that extra explain info in TermWeight.",
            "date": "2009-08-21T12:55:55.305+0000",
            "id": 43
        },
        {
            "author": "Tim Smith",
            "body": "bq. You never officially had the full index context\nOfficially, i didn't \"not\" have the full index context either (it was undefined at best, but was clear from both lucene code and my use of the API that i did have the full index context)\n\nWhenever i do a search, i always explicitly know what context i'm searching in (its always an IndexSearcher context)\nfurther, whenever i pass an IndexReader to any method (to create a cache/etc), i explicitly know what context i'm dealing with in order to know what the docids used mean\nas the application developer, i have full control over what i pass into the lucene API and where, and know the context of passing that in (javadoc should just be fully clear on how what goes in is used (if not already) (i always have the option to not use a utility class/method provided by lucene if it does not have the proper context semantics i need (and can write my own that does)\n\nbq. The current API would not support this without back compat breaks up the wazoo\ni kinda see what you mean here, but then how is it ok to pass an IndexReader to this method by the same right\nit seems like it should be ok to pass the IndexSearcher (the direct context for the IndexReader) for the IndexReader in question to Weight.scorer() if its ok to pass the IndexReader (the scorer() method's interface was already changed between 2.4 and 2.9 (adding allowDocsInOrder and topScorer))\n\nbq. You can pick, but we have to be true to the API or change it (not easy with our back compat policies)\nbe fair, 2.9 has a lot of back compat breaks, both in API and runtime behavior (i had tons of compile errors when i dropped 2.9 in, as well as some other hacks i had to add in (at least temporarily) in order to get 2.9 to work due to run time changes (primarily this per segment search stuff))\n\nI have no problem with back compat breaks in general (only took me about a day to absorb 2.9 initially (still working on fully taking advantage of new features and getting rid of deprecated class use)) The only requirement i would put on a back compat break is that it have a workaround to get back the the previous versions behavior (in this case have it possible to remap the docids to the \"IndexSearcher\" context inside the scorer)\n\n",
            "date": "2009-08-21T13:15:32.807+0000",
            "id": 44
        },
        {
            "author": "Mark Miller",
            "body": "bq. (it was undefined at best, but was clear from both lucene code and my use of the API that i did have the full index context)\n\nIt was an implementation detail. If you look at MultiSearcher, Searchable, Searcher and how the API is put together, you can see we don't support that type of thing. I think its fairly clear after a little thought.\n\nYou can limit your API's to handle just IndexSearchers, but as a project, we cannot.\n\nbq. it seems like it should be ok to pass the IndexSearcher (the direct context for the IndexReader) \n\nMultiSearcher and Searchable make this impossible IMO. We would be playing to those that don't fully use the API, and thats a mistake in my opinion. At best, we would have to shift the whole API.\n\nIts okay to pass the Reader because its a contextless Reader. There is no value in also passing a contextless Searcher IMO - especially when its an arbitrary different context. We have to live up to the current API - your throwing MultiSearcher, Searchable, Remote out the window.\n\nbq. be fair, 2.9 has a lot of back compat breaks,\n\nOh I'm fair, I know that for sure - though I do like to argue way to much for my own good. All of these back compat breaks were painful to stomach ;) But we reached each one under special circumstances - usually our own early incompetence :) We technically are not allowed to just break things though. We break to fix what we already accidentally broke, or we break when we screwed up earlier and we are in between a rock and a hard place now - or we break when something else is broke anyway, so lets do more :) This was the release of the break for sure. We don't necessarily want this to happen every release though, and its our responsibility to strive towards our back compat policy (listed on the wiki).\n\nI'm not talking about a break in adding a Searcher - that would be fine - back compat is already broken there - but unless we can pass a MultiSearcher there over a remove RMI call, its a break of the whole API IMO.",
            "date": "2009-08-21T13:26:39.531+0000",
            "id": 45
        },
        {
            "author": "Tim Smith",
            "body": "{quote}\nIt was an implementation detail. If you look at MultiSearcher, Searchable, Searcher and how the API is put together, you can see we don't support that type of thing. I think its fairly clear after a little thought.\n\nYou can limit your API's to handle just IndexSearchers, but as a project, we cannot.\n{quote}\nI totally understand your resistance here.  I get that i'm really utilizing advanced lucene concepts at very low levels (and these are subject to some changes that i will have to absorb with new versions)\n\nbq. Its okay to pass the Reader because its a contextless Reader. There is no value in also passing a contextless Searcher\nwell, when you pass the Searcher that contains Reader, the Reader is no longer contextless.\nalso, the context of the Searcher can be fairly well defined (its a \"leaf\" Searcher. the one that actually called Weight.scorer())\n\nAlso, looking a bit more at MultiSearcher semantics, sorting requires this \"leaf\" Searcher context in order to work already\nMultiSearcher just takes the top docs from each underlaying Searchable, adjusts the docids to the MultiSearcher Context, and sends them through another priority queue\nSo, this \"leaf\" Searcher context concept is required by sorting already. \nI just want my Scorer to be given this \"leaf\" context as well\n\nAlso, since it is a \"leaf\" context, the Weight.scorer() method could have the following interface:\n{code}\n/**\n * @param searcher The IndexSearcher that contains reader.\n */\npublic Scorer scorer(IndexSearcher searcher, IndexReader reader, boolean allowDocsInOrder, boolean topScorer);\n{code}\n\nthen, with the patch i posted, i could call:\nsearcher.getIndexReaderBase(reader) \nand i'm all set\n\n",
            "date": "2009-08-21T13:58:19.354+0000",
            "id": 46
        },
        {
            "author": "Tim Smith",
            "body": "NOTE: if the leaf IndexSearcher were to be passed to scorer(), it would also have to be passed to explain()",
            "date": "2009-08-21T14:00:04.581+0000",
            "id": 47
        },
        {
            "author": "Mark Miller",
            "body": "I certainly think IndexSearcher makes a lot more sense than Searchable or Searcher there - it somewhat handles the whole API break thing - your clearly limiting to an IndexSearcher, so its compatible with the current API and can be clearly explained with javadoc - I still worry about pushing the API towards things that leave MultiSearcher/Remote out in the cold on features. They are technically first class citizens. I think some expert warnings could sell me anyway though.\n\nI still have a problem with this though:\n\n{code}\npublic DocIdSet getDocIdSet(final IndexReader reader) throws IOException {\n    final Weight weight = query.weight(new IndexSearcher(reader));\n    return new DocIdSet() {\n      public DocIdSetIterator iterator() throws IOException {\n        return weight.scorer(reader, docBase?, true, false);\n      }\n    };\n  }\n\n{code}\n\nThat scorer call should get the right IndexSearcher and I don't see how it can without breaking back compat on this method and passing an IndexSearcher too.\n\n* edit *\n\nAnd even if we fix this here, what about outside code doing the same thing? They won't get the right IndexSearcher.",
            "date": "2009-08-21T14:09:49.697+0000",
            "id": 48
        },
        {
            "author": "Mark Miller",
            "body": "bq. clearly explained with javadoc\n\nWe need something along the lines of - you cannot count on this IndexSearcher to cover the whole index unless you control the use of your application to ensure that - its possible that this IndexSearcher will only correspond to one sub-index of multiple being used in the context of one large index.",
            "date": "2009-08-21T14:13:00.148+0000",
            "id": 49
        },
        {
            "author": "Tim Smith",
            "body": "here's what you can do:\n\n{code}\n  /** @deprecated use {@link getDocIdSet(IndexSearcher, IndexReader)} */\n  public DocIdSet getDocIdSet(final IndexReader reader) throws IOException {\n    return getDocIdSet(new IndexSearcher(reader), reader);\n  }\n\n  public DocIdSet getDocIdSet(final IndexSearcher searcher, final IndexReader reader) {\n    final Weight weight = query.weight(searcher);\n    return new DocIdSet() {\n      public DocIdSetIterator iterator() throws IOException {\n        return weight.scorer(searcher, reader, true, false);\n      }\n    };\n  }\n{code}\n\nand yeah, i'm all for tons warnings in javadoc explicitly defining the contracts\n",
            "date": "2009-08-21T14:15:22.785+0000",
            "id": 50
        },
        {
            "author": "Mark Miller",
            "body": "I don't think thats fully back compat - though it covers a lot of ground.",
            "date": "2009-08-21T14:20:03.838+0000",
            "id": 51
        },
        {
            "author": "Tim Smith",
            "body": "what class is this getDocIdSet method on (lacking the context of where its used)",
            "date": "2009-08-21T14:28:44.874+0000",
            "id": 52
        },
        {
            "author": "Mark Miller",
            "body": "Its org.apache.lucene.search.QueryWrapperFilter. And technically we have to account for subclasses and combinations and anything possible.\n\nThis being the release of the break, who knows though. I can't reasonably see releasing without notes indicating that you *must* recompile. And while we want to limit how much work must be done (we also consider the likely impact), this would be the time to skirt through.\n\nPretty much depends on what McCandless weighs in with I guess - unless a new spectator pops up.\n{code}\ngetDocIdSet(IndexReader) : DocIdSet - org.apache.lucene.search.QueryWrapperFilter\n\tbits(IndexReader) : BitSet - org.apache.lucene.search.BooleanFilterTest.getOldBitSetFilter(...).new Filter() {...}\n\tConstantScorer(Similarity, IndexReader, Weight) - org.apache.lucene.search.ConstantScoreQuery.ConstantScorer\n\texplain(Searcher, IndexReader, int) : Explanation - org.apache.lucene.search.FilteredQuery.createWeight(...).new Weight() {...}\n\tgetDISI(ArrayList, int, IndexReader) : DocIdSetIterator - org.apache.lucene.search.BooleanFilter\n\tgetDocIdSet(IndexReader) : DocIdSet - org.apache.lucene.search.BooleanFilter (3 matches)\n\tgetDocIdSet(IndexReader) : DocIdSet - org.apache.lucene.search.CachingWrapperFilter\n\tgetDocIdSet(IndexReader) : DocIdSet - org.apache.lucene.search.CachingWrapperFilterHelper\n\tgetDocIdSet(IndexReader) : DocIdSet - org.apache.lucene.search.RemoteCachingWrapperFilter\n\tgetDocIdSet(IndexReader) : DocIdSet - org.apache.lucene.search.RemoteCachingWrapperFilterHelper\n\tscorer(IndexReader, boolean, boolean) : Scorer - org.apache.lucene.search.FilteredQuery.createWeight(...).new Weight() {...}\n\tsearchWithFilter(IndexReader, Weight, Filter, Collector) : void - org.apache.lucene.search.IndexSearcher\n\ttstFilterCard(String, int, Filter) : void - org.apache.lucene.search.BooleanFilterTest\n{code}",
            "date": "2009-08-21T14:46:22.251+0000",
            "id": 53
        },
        {
            "author": "Tim Smith",
            "body": "Looks like Filter should have another method added getDocIdSet(IndexSearcher searcher, IndexReader reader) (deprecating getDocIdSet(IndexReader))\n\nnew method would call old method by default (with little harm done in general)\nIndexSearcher would call the new getDocIdSet() variant\nQueryWrapperFilter would be updated to implement getDocIdSet(IndexSearcher, IndexReader) (with old method wrapping IndexReader with an IndexSearcher)\nThis would actually be cleaner for QueryWrapperFilter, as it wouldn't have to create a new IndexSearcher on every call\n\ni definitely see that this is potentially more painful than the changes to the scorer() method (question is how many people implement custom Filters?)\n\nPersonally, i don't use Filter, so any changes here don't impact me, but to the best of my knowledge, i'm not the only one using lucene :)",
            "date": "2009-08-21T15:02:25.776+0000",
            "id": 54
        },
        {
            "author": "Tim Smith",
            "body": "I started integrating the per-segment searching (removed my hack that was doing searching on MultiReader)\n\nIn order to get my query implementations to work, i had to hold onto my Searcher in the Weight constructor and add getIndexReaderBase() method to my IndexSearcher implementation, and this seems to be working well\n\nI had 3 query implementations that were affected:\none used a cache that will be easy to create per segment (will have this use a per segment cache as soon as i can)\none used an int[] ord index (the underlaying cache cannot be made per segment)\none used a cached DocIdSet created over the top level MultiReader (should be able to have a DocIdSet per Segment reader here, but this will take some more thinking (source of the matching docids is from a separate index), will also need to know which sub docidset to use based on which IndexReader is passed to scorer() - shouldn't be any big deal)\n\ni'm a bit concerned that i may not be testing \"multi-segment\" searching quite properly right now though since i think most of my indexes being tested only have one segment.\nOn that topic, if i create a subclass of LogByteSizeMergePolicy and return null from findMerges() and findMergesToExpungeDeletes() will this guarantee that segments will only be merged if i explicitly optimize? In which case, i can just pepper in some commits as i add documents to guarantee that i have more than 1 segment.\n\nOverall, i am really liking the per-segment stuff, and the Collector API in general \nits already made it possible to optimize a good deal of things away (like calling Scorer.score() for docs that end up getting filtered away), however i hit some deoptimization due to some of the crazy stuff i had to do to make those 3 query implementations work, but this should only really be isolated to one of the implementations (and i can hopefully reoptimize those cases anyway)\n\nI would still like to see IndexSearcher passed to Weight.scorer(), and the getIndexReaderBase() method added to IndexSearcher\nThis will clean up my current \"hacks\" to map docids \n\n\n",
            "date": "2009-08-21T21:59:13.832+0000",
            "id": 55
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. i'm a bit concerned that i may not be testing \"multi-segment\" searching quite properly right now though since i think most of my indexes being tested only have one segment.\n\nYup - went through this in Solr.  I ended up changing the test config to use LogByteSizeMergePolicy  and maxBufferedDocs=10.",
            "date": "2009-08-21T22:07:26.855+0000",
            "id": 56
        },
        {
            "author": "Mark Miller",
            "body": "Lucene also use maxBufferedDocs to make sure there are multiple segments in some tests -\n\nTim's idea here is nice too though - you still see some merging that way - with a mergepolicy that just returns null you can easily pick the exact number of segments by issuing commits mod whatever. (*edit you just have to set maxBufferedDocs to Integer.max)\n\nThe mergepolicy impl is easy enough - anon class generated by eclipse will work out of the box.",
            "date": "2009-08-21T22:18:33.040+0000",
            "id": 57
        },
        {
            "author": "Mark Miller",
            "body": "{quote}Looks like Filter should have another method added getDocIdSet(IndexSearcher searcher, IndexReader reader) (deprecating getDocIdSet(IndexReader))\nnew method would call old method by default (with little harm done in general) {quote}\n\nIts the corner cases. Someone's class calls the deprecated method directly - someone is using that, plus a new class that overrides the none deprecated method - which never gets called, cause the other code is calling the dep method directly. Technically, everything has to be covered (Depending on how consensus goes anyway ... always depending ...). Its a pain in the butt just thinking about it. \n\n*edit*\n\nIn your example deprecation this is actually the opposite - someone calls the new code directly, but other code you are using overrides the deprecated code. The override is now not called.",
            "date": "2009-08-22T21:42:06.358+0000",
            "id": 58
        },
        {
            "author": "Tim Smith",
            "body": "well, you could go the route similar to the 2.4 TokenStream api (next() vs next(Token))\n\nhave Filter.getDocIdSet(IndexSearcher, IndexReader) call Filter.getDocIdSet(IndexReader), and vice versa by default\none method or the other would be required to be overridden\n\ngetDocIdSet(IndexReader) would be deprecated (and removed in 3.0)\n\nSince the deprecated method would be removed in 3.0, and since noone would probably be depending on these new semantics right away this should work\n\nAlso, in general, QueryWrapperFilter performs a bit worse now in 2.9\nthis is because it creates an IndexSearcher for every query it wraps (which results in doing \"gatherSubReaders\" and creating the offsets anew each time getDocIdSet(IndexReader) is called\nso, the new method with the IndexSearcher also passed in is much better for evaluating these Filters\n",
            "date": "2009-08-23T13:17:35.728+0000",
            "id": 59
        },
        {
            "author": "Mark Miller",
            "body": "You want to weigh in again Mike ? You still have the same stance as your last comment?",
            "date": "2009-08-23T14:31:04.012+0000",
            "id": 60
        },
        {
            "author": "Mark Miller",
            "body": "bq. well, you could go the route similar to the 2.4 TokenStream api (next() vs next(Token))\n\nthats a tough bunch of code to decide to spread ...",
            "date": "2009-08-23T14:34:30.051+0000",
            "id": 61
        },
        {
            "author": "Tim Smith",
            "body": "bq. thats a tough bunch of code to decide to spread ...\nat least it'll be able to go away real soon with 3.0",
            "date": "2009-08-23T15:00:30.923+0000",
            "id": 62
        },
        {
            "author": "Michael McCandless",
            "body": "bq. You want to weigh in again Mike ? \n\nI do!  I'm trying desperately to catch up over here :)",
            "date": "2009-08-23T15:19:00.839+0000",
            "id": 63
        },
        {
            "author": "Michael McCandless",
            "body": "Tim, one option might be to subclass DirectoryReader (though, it's package protected now, and, you'd need to make your own \"open\" to return your subclass), and override getSequentialSubReaders to return null?  Then Lucene would treat it as an atomic reader.  Could that work?",
            "date": "2009-08-23T15:55:21.010+0000",
            "id": 64
        },
        {
            "author": "Michael McCandless",
            "body": "bq. for string sorting, it makes a big difference - you now have to do a bunch of String.equals() calls, where you didn't have to in 2.4 (just used the ord index)\n\nWe actually went through a number of iterations on this, on the first cutover to per-segment collection, and eventually arrived at a decent comparator (StringOrdValComparator) that operates per segment.  Have you tested performance of this comparator?\n",
            "date": "2009-08-23T16:02:44.347+0000",
            "id": 65
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. Filter.getDocIdSet(IndexSearcher, IndexReader).\n\nThis suggests that one needs an IndexSearcher to get the ids matching a filter.",
            "date": "2009-08-23T16:27:47.028+0000",
            "id": 66
        },
        {
            "author": "Michael McCandless",
            "body": "bq. one used an int[] ord index (the underlaying cache cannot be made per segment)\n\nCould you compute the top-level ords, but then break it up\nper-segment?  Ie, create your own map of IndexReader -> offset into\nthat large ord array?  This would make it \"virtually\" per-segment, but\nallow you to continue computing at the top level.\n\nBTW another option is to simply accumulate your own docBase, by adding\nup the maxDoc() every time an IndexReader is passed to your\nWeight.scorer().  EG this is what contrib/spatial is now doing.\n\nThis isn't a long-term solution, since the order in which Lucene\nvisits the readers isn't in general guaranteed, but it will work for\n2.9 and buy time to figure out how to switch scoring to per-segment.\n",
            "date": "2009-08-23T16:48:08.355+0000",
            "id": 67
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Using a per-segment cache will cause some significant performance loss when performing faceting, as it requires creating the facets for each segment, and then merging them (this results in a good deal of extra object overhead/memory overhead/more work where faceting on the multi-reader does not see this)\n\nThis is a good point... Yonik, how [in general!] is Solr handling the cutover to per-segment, for faceting?",
            "date": "2009-08-23T16:52:14.274+0000",
            "id": 68
        },
        {
            "author": "Michael McCandless",
            "body": "bq. one used a cached DocIdSet created over the top level MultiReader (should be able to have a DocIdSet per Segment reader here, but this will take some more thinking (source of the matching docids is from a separate index), will also need to know which sub docidset to use based on which IndexReader is passed to scorer() - shouldn't be any big deal)\n\nI think, similarly, you could continue to create the top-level\nDocIdSet, but then make a new DocIdSet that presents one segment's\n\"slice\" out of this top-level DocIdSet.  Then, pre-build the mapping\nof IndexReader -> docBase like above, then when scorer() is called in\nyour custom query, just return the \"virtual\" per-segment DocIdSet.\nWould this work?",
            "date": "2009-08-23T16:57:18.615+0000",
            "id": 69
        },
        {
            "author": "Michael McCandless",
            "body": "Net/net, I'm still nervous about pushing down \"full context\" plus\n\"context free\" searcher/reader deep into Lucene's general searching\n(scorer/filter) APIs.  I think these APIs should remain fully\ncontext-free (even IndexSearcher still makes me nervous).\n\nIn some sense, Multi/RemoteSearcher keep us honest, in that they force\nus to clearly separate out \"stuff that has the luxury of full context\"\n(to be done on construction of Weight) from \"the heavy lifting that\nmust be context free since it may not have access to the top searcher\"\n(scorer(), getDocIdSet()).\n",
            "date": "2009-08-23T16:58:58.660+0000",
            "id": 70
        },
        {
            "author": "Mark Miller",
            "body": "Cool - I don't like it much either.\n\nI say we push this issue from 2.9 for now.",
            "date": "2009-08-23T17:05:34.766+0000",
            "id": 71
        },
        {
            "author": "Tim Smith",
            "body": "Lot of new comments to respond to :)\nwill try to cover them all\n\nbq. decent comparator (StringOrdValComparator) that operates per segment.\n\nStill, the StringOrdValComparator will have to break down and call String.equals() whenever it compars docs in different IndexReaders\nIt also has to do more maintenance in general than would be needed for just a StringOrd comparator that would have a cache across all IndexReaders\nWhile the StringOrdValComparator may be faster in 2.9 than string sorting in 2.4, its not as fast as it could be if the cache was created on the IndexSearcher level\nI looked at the new string sorting stuff last week, and it looks pretty smart to reduce the number of String.equals() calls needed, but this adds extra complexity and will still be reduced to String.equals() calls, which will translate to slower sorting than could be possible\n\nbq. one option might be to subclass DirectoryReader \n\nThe idea of this is to disable per segment searching?\nI don't actually want to do that. I want to use per segment searching functionality to take advantage of caches on per segment basis where possible, and map docs to the IndexSearcher context when i can't do per segment caching.\n\nbq. Could you compute the top-level ords, but then break it up per-segment?\n\nI think i see what your getting at here, and i've already thought of this as a potential solution. The cache will always need to be created at the top most level, but it will be pre-broken out into a per-segment cache whose context is the top level IndexSearcher/MultiReader. The biggest problem here is the complexity of actually creating such a cache, which i'm sure will translate to this cache loading slower (hard to say how much slower without implementing)\nI do plan to try this approach, but i expect this will be at least a week or two out from now.\n\nI've currently updated my code for this to work per-segment by adding the docBase when performing the lookup into this cache (which is per-IndexSearcher)\nI did this using my getIndexReaderBase() funciton i added to my subclass of IndexSearcher during Scorer construction time (I can live with this, however i would like to see getIndexReaderBase() added to IndexSearcher, and the IndexSearcher passed to Weight.scorer() so i don't need to hold onto my IndexSearcher subclass in my Weight implementation)\n\nbq. just return the \"virtual\" per-segment DocIdSet.\n\nThats what i'm doing now. I use the docid base for the IndexReader, along with its maxDoc to have the Scorer represent a virtual slice for just the segment in question\nThe only real problem here is that during Scorer initialization for this i have to call fullDocIdSetIter.advance(docBase) in the Scorer constructor. If advance(int) for the DocIdSet in question is O(N), this adds an extra penalty per segment that did not exist before\n\nbq. his isn't a long-term solution, since the order in which Lucene visits the readers isn't in general guaranteed,\n\nthat's where IndexSearcher.getIndexReaderBase(IndexReader) comes into play. If you call this in your scorer to get the docBase, it doesn't matter what order the segments are searched in (as it'll always return the proper base (in the context of the IndexSearcher that is))\n\n\nHere's another potential thought (very rough, haven't consulted code to see how feasible this is):\nwhat if Similarity had a method called getDocIdBase(IndexReader)\nthen, the searcher implementation could wrap the provided Similarity to provide the proper calculation\nSimilarity is always already passed through this chain of Weight creation and is passed into the Scorer\nObviously, a Query Implementation can completely drop the passing of the Searcher's similarity and drop in its own (but this would mean it doesn't care about getting these docid bases)\nI think this approach would potentially resolve all MultiSearcher difficulties\n\n\n\n\n\n",
            "date": "2009-08-23T17:37:42.928+0000",
            "id": 72
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. This is a good point... Yonik, how [in general!] is Solr handling the cutover to per-segment, for faceting?\n\nIt doesn't.  Faceting is not connected to searching in Solr, and is only done at the top level IndexReader.\nWe obviously want to enable per-segment faceting for more NRT in the future - with the expected disadvantage that it will be somewhat slower for some types of facets.  I imagine we will keep the top-level faceting as an option because there will be tradeoffs.",
            "date": "2009-08-23T17:44:44.605+0000",
            "id": 73
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. I say we push this issue from 2.9 for now.\n\n+1 \n",
            "date": "2009-08-23T17:45:17.883+0000",
            "id": 74
        },
        {
            "author": "Mark Miller",
            "body": "I'm going to push it out for now. Of course, feel free to argue for its re inclusion.",
            "date": "2009-08-23T19:10:07.396+0000",
            "id": 75
        },
        {
            "author": "Tim Smith",
            "body": "can i at least argue for it being tagged for 3.0 or 3.1 (just so it gets looked at again prior to the next releases)\n\nI have workarounds for 2.9, so i'm ok with it not getting in then (just want to make sure my use cases won't be made impossible in future releases)",
            "date": "2009-08-23T19:29:19.718+0000",
            "id": 76
        },
        {
            "author": "Mark Miller",
            "body": "Yeah, no problem - tag whatever you'd like - I only went to nothing because it was the easiest default move.\n\nWith the current plan (subject to change), the earliest it could be considered again is 3.1, so I'll move there.",
            "date": "2009-08-23T19:51:26.085+0000",
            "id": 77
        },
        {
            "author": "Mark Miller",
            "body": "whoops - try the right thing this time",
            "date": "2009-08-23T19:58:54.400+0000",
            "id": 78
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nbq. decent comparator (StringOrdValComparator) that operates per segment.\n\nStill, the StringOrdValComparator will have to break down and call String.equals() whenever it compars docs in different IndexReaders\n{quote}\n\nAgreed, it will be slower than a top-level ords cache, but I'm\nwondering in practice, in your case, what impact that turns out to be.\nAlso, since Lucene has already done this, maybe you could use its\nStringOrdValComparator instead of having to cutover yours to\nsegment-based.\n\nOr, better, work up a patch for a \"forced\" top-level StringComparator\nfor apps that don't mind the slow commit time and possible risk of\nburning memory, in exchange for faster sorting.\n\nActually sorting (during collection) already gives you the docBase so\nshouldn't your app already have the context needed for this?\n\n{quote}\nThe idea of this is to disable per segment searching?\nI don't actually want to do that. I want to use per segment searching functionality to take advantage of caches on per segment basis where possible, and map docs to the IndexSearcher context when i can't do per segment caching.\n{quote}\n\nOK\n\n{quote}\nbq. Could you compute the top-level ords, but then break it up per-segment?\n\nI think i see what your getting at here, and i've already thought of this as a potential solution. The cache will always need to be created at the top most level, but it will be pre-broken out into a per-segment cache whose context is the top level IndexSearcher/MultiReader. The biggest problem here is the complexity of actually creating such a cache, which i'm sure will translate to this cache loading slower (hard to say how much slower without implementing)\nI do plan to try this approach, but i expect this will be at least a week or two out from now.\n\nI've currently updated my code for this to work per-segment by adding the docBase when performing the lookup into this cache (which is per-IndexSearcher)\nI did this using my getIndexReaderBase() funciton i added to my subclass of IndexSearcher during Scorer construction time (I can live with this, however i would like to see getIndexReaderBase() added to IndexSearcher, and the IndexSearcher passed to Weight.scorer() so i don't need to hold onto my IndexSearcher subclass in my Weight implementation)\n{quote}\n\nOK sounds like an at least workable solution.\n\n{quote}\nbq. just return the \"virtual\" per-segment DocIdSet.\n\nThats what i'm doing now. I use the docid base for the IndexReader, along with its maxDoc to have the Scorer represent a virtual slice for just the segment in question\nThe only real problem here is that during Scorer initialization for this i have to call fullDocIdSetIter.advance(docBase) in the Scorer constructor. If advance(int) for the DocIdSet in question is O(N), this adds an extra penalty per segment that did not exist before\n{quote}\n\nHmm... is advance in fact costly for your DocIdSets?\n\n{quote}\nbq. This isn't a long-term solution, since the order in which Lucene visits the readers isn't in general guaranteed,\n\nthat's where IndexSearcher.getIndexReaderBase(IndexReader) comes into play. If you call this in your scorer to get the docBase, it doesn't matter what order the segments are searched in (as it'll always return the proper base (in the context of the IndexSearcher that is))\n{quote}\n\nI think adding that one method for 2.9 would make sense?  (Marking it\nexpert, subject to change).  Because... assuming your app is OK w/\nsomehow (privately, external to Lucene) having access to the top\nIndexSearcher via it's custom Weight, this one method would allow you\nto not have to subclass IndexSearcher.\n",
            "date": "2009-08-24T10:03:27.006+0000",
            "id": 79
        },
        {
            "author": "Tim Smith",
            "body": "bq. Actually sorting (during collection) already gives you the docBase so shouldn't your app already have the context needed for this?\n\nYes, i get the docbase and all during collection, so doing sorting with a top level cache will be no problem.\nI was mainly using sorting as an example of some of the pain caused by per-segment searching/caches (the Collector API makes it easy enough to do sorting\non the top level or per segment, so i'm not concerned about integration here)\n\nFor my app, i plan to allow sorting to be either \"per-segment\" or \"top-level\" in order to allow people to choose thier poison: faster commit/less memory vs faster sorting\nI also plan to do faceting likewise\ncertain features will always require a top-level cache (but those are advanced features anyway and should be expected to have impacts on commit time/first search time)\n\nbq. Hmm... is advance in fact costly for your DocIdSets?\n\nThink how costly it would be to do advance for the SortedVInt DocIdSet (linear search over compressed values)\nfor a bitset, this is instantaneous, but to conserve memory, its better to use a sorted int[] (or the SortedVInt stuff 2.9 provides)\n\nin the end, i plan to bucketize the collected docs per segment, so in the end this should hopefully be less of an issue\nnice thing about that approach is that i can have a bitset for one segment (lost of matches in this segment) and a very small int[] for a different segment based on the matches per segment. Biggest difficulty is doing the mapping to the per-segment \"DocIdSet\" (which will probably have to be slower)\n\nbq. this one method would allow you to not have to subclass IndexSearcher.\n\nI already have to subclass index searcher (i do a lot of extra stuff)\nhowever, the IndexSearcher doesn't provide any protected access to its sub readers and doc starts, so i have to do this myself in my subclass's constructor (in the same way IndexSearcher is doing this\n\nI would really like to see getIndexReaderBase() added to 2.9's IndexSearcher\nI would also like to see the subreaders and docstarts either made protected or given protected accessor methods (so i don't have to recreate the same set of sub readers (and make sure i do this the same way for future versions of lucene)\nWould also be nice to see a protected constructor on IndexSearcher like so:\n{code}\n  protected IndexSearcher(IndexReader reader, IndexReader[] subReaders, int[] docStarts) {\n   ...\n  }\n{code}\n\nThis would allow creating \"temporary\" IndexSearchers much faster (don't need to gather sub readers)\nThis would allow:\n* easily creating IndexSearcher that is \"top-level\" (subReaders[] would be length 1 and just contain reader)\n* create a \"temporary\" IndexSearcher off another IndexSearcher that contains some \"short lived\" context (i have this use case)\n\n\n",
            "date": "2009-08-24T10:44:02.289+0000",
            "id": 80
        },
        {
            "author": "Mark Miller",
            "body": "bq.  faster commit/less memory vs faster sorting\n\nHave you done any benching here? I think we actually found that even most sorting cases were faster than in 2.4.1.\n\nIts a lot of poison to swallow top level - loading a field cache off a multi-segment index was dog slow. *edit* (I can never remember if Yonik fix that or not - he fixed something related, or at least made it better)",
            "date": "2009-08-24T12:16:43.987+0000",
            "id": 81
        },
        {
            "author": "Tim Smith",
            "body": "bq. Have you done any benching here? I think we actually found that even most sorting cases were faster than in 2.4.1.\n\nI haven't done any benchmarking. \nI'm not arguing that 2.9 string sorting is slower than 2.4 string sorting, it may well be faster for every case.\nper segment searching and other improvements potentially added more gains in performance than the new string sorting added losses in performance.\n\nBut, i can say rather confidently, that a large index with a bunch of segments will result in string sorting being slower when using a per segment string sort cache instead of a full index sort cache (think worst case using \\*:\\* query)\n\nbq. loading a field cache off a multi-segment index was dog slow\nthis is a trade off.\nslower cache loading in order to get faster sorting\ni plan to provide the ability to do both, and allow specific use cases to decide what is best for them",
            "date": "2009-08-24T12:25:31.061+0000",
            "id": 82
        },
        {
            "author": "Mark Miller",
            "body": "{quote}\nthis is a trade off.\nslower cache loading in order to get faster sorting\ni plan to provide the ability to do both, and allow specific use cases to decide what is best for them{quote}\n\nYes a trade off :) I meant it was bug slow though - as in it may take 80 seconds to load it when it should have taken 5. Unless the index was optimized. Could be fixed though - dropped off my radar now that we don't do it internally anymore.",
            "date": "2009-08-24T12:29:05.241+0000",
            "id": 83
        },
        {
            "author": "Tim Smith",
            "body": "I allow caches to be loaded at commit time (if configured), and recommend that frequently used caches be configured to be loaded at this time\nthis can result in slower commit times, but responsive queries as soon as the commit is finished\n\nonce i also add the option for per-segment caching for sorting and faceting (i'll probably put this on by default for sorting, faceting maybe not), this will allow full tunability for the end-user",
            "date": "2009-08-24T12:35:09.316+0000",
            "id": 84
        },
        {
            "author": "Tim Smith",
            "body": "I've been playing with per-segment caches for the last couple of weeks and have got everything working pretty well\n\nHowever, i have to end up doing a lot of mapping between an IndexReader instance, and the \"index into the IndexReader[]\" array of the IndexSearcher\nthis then allows me to easily get the proper document offset where needed, and/or get a handle on the proper per-segment cache/evaluation object/etc\n\nFor my use cases, it would be much easier if the following methods were available:\n\non Weight:\n{code}\n// readerId is the \"i\" in the for (int i = 0; i < readers.length; ++i) in IndexSearcher\n// NOTE: that readerId is at the IndexSearcher level, not the MultiSearcher level\npublic Scorer scorer(IndexReader reader, int readerId, boolean inOrder, boolean topLevel);\n{code}\n\non Collector:\n{code}\npublic void setNextReader(IndexReader reader, int docBase, int readerId);\n// NOTE: this isn't extremely needed, as its easier to get the readerId from docBase (using a cached int[] of docbases for the searcher)\n{code}\n\nI suppose i could use the fact that these methods will always be called in order, keeping and incrementing counter, however the javadoc explicitly says that these methods may be called out of \"segment order\" to be more efficient in the future. It would therefore be very useful if these indexes were passed into these methods.\n\nTo work around this, my searcher currently has a getReaderIdForReader() method very similar to my earlier proposed getIndexReaderBase() method\n\n\n",
            "date": "2009-09-18T15:19:09.434+0000",
            "id": 85
        },
        {
            "author": "Tim Smith",
            "body": "This would actually be solved by LUCENE-2345 for me as i would then be able to tag SegmentReaders with any additional accounting information i would need",
            "date": "2010-03-24T19:01:42.691+0000",
            "id": 86
        },
        {
            "author": "Uwe Schindler",
            "body": "This is resolved by adding AtomicReaderContext in 4.0 (LUCENE-2831).",
            "date": "2011-01-14T18:12:53.060+0000",
            "id": 87
        }
    ],
    "component": "core/search",
    "description": "Now that searching is done on a per segment basis, there is no way for a Scorer to know the \"actual\" doc id for the document's it matches (only the relative doc offset into the segment)\n\nIf using caches in your scorer that are based on the \"entire\" index (all segments), there is now no way to index into them properly from inside a Scorer because the scorer is not passed the needed offset to calculate the \"real\" docid\n\nsuggest having Weight.scorer() method also take a integer for the doc offset\n\nAbstract Weight class should have a constructor that takes this offset as well as a method to get the offset\nAll Weights that have \"sub\" weights must pass this offset down to created \"sub\" weights\n\n\nDetails on workaround:\nIn order to work around this, you must do the following:\n* Subclass IndexSearcher\n* Add \"int getIndexReaderBase(IndexReader)\" method to your subclass\n* during Weight creation, the Weight must hold onto a reference to the passed in Searcher (casted to your sub class)\n* during Scorer creation, the Scorer must be passed the result of YourSearcher.getIndexReaderBase(reader)\n* Scorer can now rebase any collected docids using this offset\n\nExample implementation of getIndexReaderBase():\n{code}\n// NOTE: more efficient implementation can be done if you cache the result if gatherSubReaders in your constructor\npublic int getIndexReaderBase(IndexReader reader) {\n  if (reader == getReader()) {\n    return 0;\n  } else {\n    List readers = new ArrayList();\n    gatherSubReaders(readers);\n    Iterator iter = readers.iterator();\n    int maxDoc = 0;\n    while (iter.hasNext()) {\n      IndexReader r = (IndexReader)iter.next();\n      if (r == reader) {\n        return maxDoc;\n      } \n      maxDoc += r.maxDoc();\n    } \n  }\n  return -1; // reader not in searcher\n}\n{code}\n\nNotes:\n* This workaround makes it so you cannot serialize your custom Weight implementation\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1821",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Weight.scorer() not passed doc offset for \"sub reader\"",
    "systemSpecification": true,
    "version": "2.9"
}