{
    "comments": [
        {
            "author": "Yonik Seeley",
            "body": "Attached simple test case demonstrating the issue.",
            "date": "2010-05-18T00:58:12.223+0000",
            "id": 0
        },
        {
            "author": "Earwin Burrfoot",
            "body": "Or, you do it so various caches are preserved across clone()",
            "date": "2010-05-18T09:33:04.056+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "Indeed, right now the newly returned NRT reader will always provide a\nshallow clone for any segments that have not changed vs the previous\nNRT reader.\n\nFieldCache is unaffected by this (it always keys on the \"core\"\nreaders, getFieldCacheKey, which is the same for shallow clones) --\nsuch shallow clones will share the same field cache entry.\n\nBut other caches (CachingWrapperFilter, CachingSpanFilter) don't use\nthis key, and so they'll now get multiple entries for the shallow\nclones.  So we need to fix that.\n\nHowever, when new deletions have arrived, a new shallow clone must be\ncreated.  In this case the FieldCache entries are shared.\n\nSo, should these other caches share an entry for that clone, or not?\nIt's tempting to do so -- all that's changed is new docs got deleted,\nand any time these filters are applied for searching, they are AND'd\nwith \"not deleted\".\n\nBut, this is technically shaky ground, since the new deletions will in\nfact mean some docs that previously passed the filter (bit was set)\nwill now have the bit un-set.\n\nI would lean towards letting the caches share the filter in these\ncases, and advertising in these classes javadocs that this will\nhappen.  Thoughts?\n",
            "date": "2010-05-18T09:55:23.563+0000",
            "id": 2
        },
        {
            "author": "Earwin Burrfoot",
            "body": "Reusing fieldCacheKey is probably a good temporary solution? (possibly renaming it in the process to just cacheKey)\nNRT.reopen() is not the only case when we're getting shallow clones, IR.clone() explicitly does that, so with cacheKey we're getting all the bases covered.",
            "date": "2010-05-18T10:59:38.462+0000",
            "id": 3
        },
        {
            "author": "Shay Banon",
            "body": "Sounds like a good solution for me. I just noticed in trunk that there is also explicit purge from FieldCache when possible. I think it would be great to enable to do this for other caches that are based on it (like the CachingWrapperFilter, but externally written ones as well).\n\nI was thinking of an expert API to allow to add a \"CacheEvictionListener\" or something similar, which will be called when this happens. What do you think?",
            "date": "2010-05-18T12:17:00.559+0000",
            "id": 4
        },
        {
            "author": "Yonik Seeley",
            "body": "bq, I would lean towards letting the caches share the filter in these cases, and advertising in these classes javadocs that this will happen. Thoughts?\n\nI think that's prob OK - users won't notice when using filters to search, but may get different behavior if they use it for other purposes.\n\nShay, as far as CachingWrapperFilter and CacheEvictionListener, it seems more powerful to just let apps create a new query type themselves?  That's the nice part of lucene's openness to user query types - start with the code for CachingWrapperFilter and hook up your own caching logic.",
            "date": "2010-05-18T12:48:31.997+0000",
            "id": 5
        },
        {
            "author": "Shay Banon",
            "body": "bq. Shay, as far as CachingWrapperFilter and CacheEvictionListener, it seems more powerful to just let apps create a new query type themselves? That's the nice part of lucene's openness to user query types - start with the code for CachingWrapperFilter and hook up your own caching logic.\n\nYea, but it would be great to know when an IndexReader has decided to actually close, so caches can be eagerly cleaned. Even if one will write a custom implementation, it would benefit it.",
            "date": "2010-05-18T13:47:24.034+0000",
            "id": 6
        },
        {
            "author": "Shay Banon",
            "body": "I think that the solution suggested, to use the FieldCacheKey is not good enough, sadly. I am attaching a simpel test that shows that this does not work for cases when a query is passed to a searcher, without a filter, but that query, is, for example, a ConstantScoreQuery. I have simply taken the CachingWrapperFiler and changed it to use the getFieldCacheKey instead of using the IndexReader.\n\nThis is problematic, since a filter can be used somewhere in the query tree, and wrapped for caching. I am running against 3.0.1.",
            "date": "2010-05-18T14:31:33.849+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "Renaming to cacheKey makes me a bit nervous.... since... this key is the same even when deletions change.  How about coreCacheKey?  The javadocs should make it clear that new deletions can show up yet have the identical (==) coreCacheKey.\n\nOK I'll take this approach.\n",
            "date": "2010-05-18T14:33:37.984+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "bq. This is problematic, since a filter can be used somewhere in the query tree, and wrapped for caching\n\nRight so the issue here is that ConstantScoreQuery's scorer does not check deleted docs when it runs -- it just relies entirely on what the filter said was set.\n\nBut I expect this is the exception not the rule.\n\nIe most uses of a filter will see to it that deleted docs are already removed.\n\nIt's as if, somehow, when a caller wants the scorer or DocIdSet, it should express whether it's OK that deleted docs are not removed... I think this'd be another boolean arg (mustContainDeletions or some such) to scorer and getDocIdSet.\n\nOr, for a less invasive change, we could that you tell ConstantScoreQuery that it must fully enforce deletions (if your app runs a query tree that has a path involving ConstantScoreQuery not AND'd with some other query that'd enforce deletions).",
            "date": "2010-05-18T15:03:08.425+0000",
            "id": 9
        },
        {
            "author": "Shay Banon",
            "body": "Agreed, seems like ConstantScoreQuery is the only problematic one... .",
            "date": "2010-05-18T15:25:55.914+0000",
            "id": 10
        },
        {
            "author": "Michael McCandless",
            "body": "Attached patch -- renames IR.getFieldCacheKey -> IR.getCoreCacheKey, fixes CachingWrapperFilter and CachingSpanFilter to, by default, disregard deletions when checking the cache.  But I added expert ctors to each to force deletions to be \"respected\" at a perf hit.",
            "date": "2010-05-18T19:30:42.129+0000",
            "id": 11
        },
        {
            "author": "Shay Banon",
            "body": "Thanks for the work Michael!. Is this issue going to include the ConstantSoreQuery, or should I open a different issue for this?",
            "date": "2010-05-18T20:25:54.111+0000",
            "id": 12
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Is this issue going to include the ConstantSoreQuery, or should I open a different issue for this?\n\nSorry -- what change is needed to ConstantScoreQuery?\n",
            "date": "2010-05-18T21:59:47.854+0000",
            "id": 13
        },
        {
            "author": "Shay Banon",
            "body": "Check two comments above :), we discussed it. Basically, it does not work with your change and it using a cached filter.",
            "date": "2010-05-18T22:17:46.649+0000",
            "id": 14
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Basically, it does not work with your change and it using a cached filter.\n\nI'm still confused :)  My patch has your test case (which uses ConstantScoreQuery).  I tweaked the test case a bit, eg to not rely on TermsFilter (which is in contrib).\n\nThe test failed when I first made the change (as expected).\n\nThen I modified CachingWrapperFilter to take the optional boolean \"enforceDeletions\".\n\nThen I changed the test to pass \"true\" for enforceDeletions, and the test now passes.\n\nI don't think any change is needed to ConstantScoreQuery?  (Ie, I took the \"less invasive\" option in my comment above).",
            "date": "2010-05-18T23:46:50.216+0000",
            "id": 15
        },
        {
            "author": "Shay Banon",
            "body": "Ahh, now I see that, sorry I missed it. But, basically, enforcing deletions means that we are back to the original problem... . I think it would be quite confusing for users, to be honest. Out of the filters, the problematic ones are the ones that can be converted to queries. From what I can see, the FilteredQuery is ok, so, maybe the ConstantScore can be changed (if possible) to do that... .",
            "date": "2010-05-19T00:10:47.539+0000",
            "id": 16
        },
        {
            "author": "Shay Banon",
            "body": "Here is a go at making ConstantScoreQuery deletion aware. I named it differently, but it can replace ConstantScoreQuery with a flag making it deletion aware. What do you think?",
            "date": "2010-05-19T00:52:19.053+0000",
            "id": 17
        },
        {
            "author": "Shay Banon",
            "body": "Another quick question Mike, what do you think about the ability to know when a \"cache key\" is actually closed so it can be removed from a cache? Similar in concept to the eviction done from the field cache in trunk by readers, but open so other Reader#cacheKey based caches (which is the simplest way to do caching in Lucene) can use.",
            "date": "2010-05-19T02:07:52.186+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Here is a go at making ConstantScoreQuery deletion aware. I named it differently, but it can replace ConstantScoreQuery with a flag making it deletion aware. What do you think?\n\nI don't think we need to fix ConstantScoreQuery to be deletions\naware?\n\nWith the perf fix we are doing here, the problem (not correctly\n\"seeing\" deletes on a reopened reader) is isolated to\nCachingWrapperFilter/CachingSpanFilter, right?\n\nWhy fix ConstantScoreQuery, when so many other Filter impls will\nproperly apply deletions?\n",
            "date": "2010-05-19T18:04:17.696+0000",
            "id": 19
        },
        {
            "author": "Michael McCandless",
            "body": "bq.Another quick question Mike, what do you think about the ability to know when a \"cache key\" is actually closed so it can be removed from a cache? Similar in concept to the eviction done from the field cache in trunk by readers, but open so other Reader#cacheKey based caches (which is the simplest way to do caching in Lucene) can use.\n\nI think this would be a good change -- it would make eviction immediate instead of just when GC gets around to pruning the WeakHashMap.  Can you open a separate issue and maybe work out a patch?\n\nOr, the other alternative would be to have IR hold such caches, as a service, to \"things\" that need caching.",
            "date": "2010-05-19T18:07:22.006+0000",
            "id": 20
        },
        {
            "author": "Shay Banon",
            "body": "bq. With the perf fix we are doing here, the problem (not correctly\n\"seeing\" deletes on a reopened reader) is isolated to\nCachingWrapperFilter/CachingSpanFilter, right?\n\nYes, but, this means that ConstantScoreQuery should basically not be cached when using NRT (even with using IndexReader as key...), because of the excessive readers created. With the one that is deletion aware, you can cache it based on the cache key.\n\nbq. I think this would be a good change - it would make eviction immediate instead of just when GC gets around to pruning the WeakHashMap. Can you open a separate issue and maybe work out a patch?\n\nSure, I will do it.",
            "date": "2010-05-19T18:31:41.419+0000",
            "id": 21
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Yes, but, this means that ConstantScoreQuery should basically not be cached when using NRT (even with using IndexReader as key...), because of the excessive readers created. With the one that is deletion aware, you can cache it based on the cache key.\n\nOK, now (finally) I understand the problem!\n\nYou want to be able to cache the original filter and reuse it even when deletions have changed, but then dynamically apply the deletions so they are properly enforced (rather than discarding the cache entry).\n\nSo... why not do this in CachingWrapper/SpanFilter, but, instead of discarding the cache entry when deletions must be enforced, we dynamically apply the deletions?  (I think we could use FilteredDocIdSet).\n\nReally... we need a more generic solution here (but, it's a much bigger change), where somehow in creating the scorer per-segment we dynamically determine who/where the deletions are enforced.  A Filter need not care about deletions if it's AND'd w/ a query that already enforces the deletions.",
            "date": "2010-05-19T19:19:52.683+0000",
            "id": 22
        },
        {
            "author": "Shay Banon",
            "body": "bq. So... why not do this in CachingWrapper/SpanFilter, but, instead of discarding the cache entry when deletions must be enforced, we dynamically apply the deletions? (I think we could use FilteredDocIdSet).\n\nYea, that would work well. You will need to somehow still know when to enable or disable this based on the filter you use (it should basically only be enabled ones that are passed to constant score... .\n\nbq. Really... we need a more generic solution here (but, it's a much bigger change), where somehow in creating the scorer per-segment we dynamically determine who/where the deletions are enforced. A Filter need not care about deletions if it's AND'd w/ a query that already enforces the deletions.\n\nAgreed. As I see it, caching based on IndexReader is key in Lucene, and with NRT, it should feel the same way as it is without it. NRT should not change the way you build your system.",
            "date": "2010-05-19T21:47:42.561+0000",
            "id": 23
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nbq. So... why not do this in CachingWrapper/SpanFilter, but, instead of discarding the cache entry when deletions must be enforced, we dynamically apply the deletions? (I think we could use FilteredDocIdSet).\n\nYea, that would work well. You will need to somehow still know when to enable or disable this based on the filter you use (it should basically only be enabled ones that are passed to constant score... {quote}\n\nOK I'll take that approach on next iter.\n\nBut: I think this may need to be enabled in other cases where the\nfilter is used (ie not only CSQ).  Sure, CSQ is the one example we\nhave today, where if you pass a Filter that ignores \"recent\" deletions\nyou'll be in trouble... but who knows what other uses of a Filter\nmight trip up on this intentional cache-incoherence we're introducing.\n\nbq. Agreed. As I see it, caching based on IndexReader is key in Lucene, and with NRT, it should feel the same way as it is without it. NRT should not change the way you build your system.\n\nWell... NRT and up-to-date deletions will always present a challenge.\n\nReally, this tradeoff we are making here, where a cached filter can be\nset to either 1) ignore new deletions, 2) discard its cache entry and\nfully regenerate itself, or 3) dynamically intersect the deletions, is\nsimilar to the discussions we've had about just how an NRT segment\nreader should enforce recent deletions.\n\nIe, ignoring option 1 (which of course gives the best perf), option 2,\nwhile making a reopen more costly, gets you the best search\nperformance (since only one bit set is checked during searches).\n\nOption 3 makes reopens much faster, but then search peformance takes a\nhit (since you're checking 2 bit sets).\n\nOption 2 is analogous to how Lucene now handles the per-segment\ndeleted docs bit vector (it's fully recreated on each reopen), while\noption 3 is analogous to how Zoie handles deletions (new deletions are\ndynamically applied to all search hits).\n",
            "date": "2010-05-20T11:05:07.829+0000",
            "id": 24
        },
        {
            "author": "Shay Banon",
            "body": "Hi Mike, \n\nFirst, I opened and attached a patch regarding the Cache eviction listeners to IndexReader: https://issues.apache.org/jira/browse/LUCENE-2474, tell me what you think.\n\nRegarding your last comment, I agree. Though, trying to streamline its usage in terms of having all built in components and possible extensions work well with it make sense. Thats what you suggest in with the filtered doc set, which is cool.",
            "date": "2010-05-20T21:32:01.671+0000",
            "id": 25
        },
        {
            "author": "Michael McCandless",
            "body": "OK, I attached another go at this.\n\nI added a DeletesMode enum to CachingWrapperFilter: IGNORE (default)\nmeans just re-use the cache entry when the reader is reopened w/ new\ndeletions; RECACHE (fully recreate the cache entry); DYNAMIC (re-use\nthe cache entry, but use FilteredDocIdSet to dynamically re-filter it\nagainst the current deletions).\n\nI did the same for CachingSpanFilter, but I don't allow DYNAMIC for\nthat one -- I punted on it because it's kinda hairy (I'd have to copy\nthe List<PositionInfo> and remove entries corresponding to deleted\ndocs).  IGNORE and RECACHE are allowed.\n",
            "date": "2010-05-21T22:37:15.065+0000",
            "id": 26
        },
        {
            "author": "Michael McCandless",
            "body": "backport",
            "date": "2010-05-30T12:32:59.331+0000",
            "id": 27
        }
    ],
    "component": "",
    "description": "A repoen on an NRT reader doesn't seem to share readers for those segments that are unchanged.\nhttp://search.lucidimagination.com/search/document/9f0335d480d2e637/nrt_and_caching_based_on_indexreader",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2468",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "reopen on NRT reader should share readers w/ unchanged segments",
    "systemSpecification": true,
    "version": ""
}