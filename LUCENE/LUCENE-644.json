{
    "comments": [
        {
            "author": "Ronnie Kolehmainen",
            "body": "Test case",
            "date": "2006-08-02T07:54:18.000+0000",
            "id": 0
        },
        {
            "author": "Ronnie Kolehmainen",
            "body": "Patch against current trunk",
            "date": "2006-08-02T07:55:03.000+0000",
            "id": 1
        },
        {
            "author": "Mark Harwood",
            "body": "Hi Ronnie,\nThanks for the contribution but I'm not sure I follow the justification for producing this code. Could it be because you assume the existing highlighter still requires an Analyzer to obtain a list of tokens? For a while now the highlighter has taken a TokenStream (as an alternative argument to Analyzer) in order to allow for faster sources of tokenized data. \nThe TokenSources class from which you took some of the code was specifically introduced to offer the ability to quickly create TokenStreams from TermPositionVectors however I notice that the JUnit tests don't contain an example of using it -  that should be added.\n\nIs there something else in your contribution/thinking here that I have missed?\n\n\n\nCheers,\nMark",
            "date": "2006-08-02T10:51:58.000+0000",
            "id": 2
        },
        {
            "author": "Ronnie Kolehmainen",
            "body": "Speed. Roughly about 3-5 times faster in my tests (when creating a TokenStream with TokenSources). The code was produced because a list of 10 or 20 hits with highlighted snippets often took 3-4 seconds to render. May not sound so much but compared with times below a second it *feels* like a real improvement.\n",
            "date": "2006-08-02T11:11:48.000+0000",
            "id": 3
        },
        {
            "author": "Mark Harwood",
            "body": "I'm all for speed.\n\nI'm just not sure I see why/where the optimization comes in over using existing Highlighter + TokenSources.getTokenStream\n\nCan you post the client code that does the performance comparisons so I can see exactly what it is you are comparing?\n\n\nThanks",
            "date": "2006-08-02T11:55:44.000+0000",
            "id": 4
        },
        {
            "author": "Ronnie Kolehmainen",
            "body": "Mark,\n\nI believe the performance gain is mostly because TokenSources.getTokenStream iterates *all* terms in the field, no?\n\nI've tested against a real index we have with theses and dissertations in fulltext. It's a 1.1GB compound file. I think I will send you the code used for the test and the output instead of posting it here.",
            "date": "2006-08-02T12:09:24.000+0000",
            "id": 5
        },
        {
            "author": "Mark Harwood",
            "body": "Many thanks for the client code Ronnie - I have tried it with my index and have reproduced the speed-up. \nI'm keen to integrate any code that offers a speed-up and ideally in such a way so that we have one highlighter + Junit test rig which can work with indexes with TermPositionVectors and also those without. This I suspect will involve merging bits of our code. There are a lot of test cases with strange analyzers that need to be considered so that's why I'm keen to have one codebase.\n\nI'm disappearing on 2 weeks holiday (vacation) shortly so haven't got a lot of time to look at this right now but I plan to when I get back.\n\nAfter a quick look I haven't yet identified the difference between your approach and mine which offers the speed-up. One factor is likely that your code only considers offset positions of tokens that are actually query terms and that may be something I could retrofit into TokenSources to produce TokenStreams of only the important tokens to the highlighter.\nI suspect there are other benefits to be had from your code too though which I'll have to consider when I have more time.\n\nThanks again for this,\n\nCheers\nMark",
            "date": "2006-08-02T13:33:58.000+0000",
            "id": 6
        },
        {
            "author": "Ronnie Kolehmainen",
            "body": "Many thanks for your feedback Mark.\n\nI have to admit, this was a a rather quick fix for our needs, thus a separate class. Ideally, Highlighter and TokenSources should handle this internally and transparent, when applicable. Maybe some sort of HighlightedTokenStream (just out of my head) with query term tokens plus a few surrounding tokens. Should be doable\n\nI'm heading for Seattle shortly so i'm not sure I will have so much time either, but if I do I will see if the current package can be patched in order to benefit from the speed improvements available. Meanwhile this code can stay here as a reminder/inspiration source, or if someone finds use for it ;)\n\nCheers!\nRonnie\n\n",
            "date": "2006-08-02T13:54:14.000+0000",
            "id": 7
        },
        {
            "author": "Ronnie Kolehmainen",
            "body": "Mark, I played around a bit with the code in TokenSources and added a method which takes an optional Query object. It will return a TokenSources.BestFragmentsTokenStream (which could later be identified by Highlighter if needed) when the query is not null and term positions are available. This token stream only holds the highlighted tokens and their surroundings.\n\nThese changes shave off about 50% of the time but is still two times slower than my first example. Also, the fragments don't look as expected. The terms are highlighted but the surrounding tokens are most often missing. I'm not sure why as I haven't dug deeper in the HighLighter code. The tokens returned by TokenSources look fine though, with positions and in order...\n\nIt would certainly be nice if most changes could be made in TokenSources. This would allow HighLigheter to be flexible as it is today, with Scorers and Formatters.\n\nI won't have time to look at it anymore, at least for a while, but I'm posting my version of TokenSources and a diff against current trunk here in case you want to have a peek at it later.\n",
            "date": "2006-08-03T17:43:41.000+0000",
            "id": 8
        },
        {
            "author": "Ronnie Kolehmainen",
            "body": "Bugfix",
            "date": "2006-08-25T10:59:05.000+0000",
            "id": 9
        },
        {
            "author": "Grant Ingersoll",
            "body": "Is this still an issue?  Does this speedup still apply?",
            "date": "2008-01-10T21:15:35.016+0000",
            "id": 10
        },
        {
            "author": "Mark Miller",
            "body": "Yes it is still an issue.\n\nIts been a while since I look at this, so I may be a little off, but I believe the speed gain comes from the fact that this implementation will only consider the terms from the query, and using info from TermVectors, reconstructs the document in large chunks (chunks between each query term). So a 200 page document with one query term will be put together from the original doc after examining one token.\n\nThe current Highlighter reconstructs by running over every term in the TokenStream. This doesn't scale well. A 200 page document will have every token analyzed and scored as the correct offsets from the original document are slowly built up.\n\nThe result is, Ronnies highlighter is *much* faster with larger documents, but not for smaller documents (getting TermVector info is slow enough that you need large docs to benefit).\n\nI think Mark H could probably incorporate this into the other Highlighter, but it certainly won't fit the framework, so either you have to change the framework quite radically (affecting code out there I suppose) or have two frameworks that can be chosen from.\n\nThe other disadvantage to this approach is that I don't see any way to incorporate position sensitive highlighting.",
            "date": "2008-01-11T18:47:24.206+0000",
            "id": 11
        },
        {
            "author": "Mark Miller",
            "body": "I think its time to close this issue - further work here should probably be applied to the FastVectorHighlighter (which is very similar and now in contrib).",
            "date": "2009-12-06T20:06:13.430+0000",
            "id": 12
        },
        {
            "author": "Uwe Schindler",
            "body": "Closing since FastVectorHighlighter was added in Lucene 2.9.",
            "date": "2011-01-27T10:51:19.054+0000",
            "id": 13
        }
    ],
    "component": "modules/highlighter",
    "description": "Mark Harwoods highlighter package is a great contribution to Lucene, I've used it a lot! However, when you have *large* documents (fields), highlighting can be quite time consuming if you increase the number of bytes to analyze with setMaxDocBytesToAnalyze(int). The default value of 50k is often too low for indexed PDFs etcetera, which results in empty highlight strings.\n\nThis is an alternative approach using term position vectors only to build fragment info objects. Then a StringReader can read the relevant fragments and skip() between them. This is a lot faster. Also, this method uses the *entire* field for finding the best fragments so you're always guaranteed to get a highlight snippet.\n\nBecause this method only works with fields which have term positions stored one can check if this method works for a particular field using following code (taken from TokenSources.java):\n\n        TermFreqVector tfv = (TermFreqVector) reader.getTermFreqVector(docId, field);\n        if (tfv != null && tfv instanceof TermPositionVector)\n        {\n          // use FulltextHighlighter\n        }\n        else\n        {\n          // use standard Highlighter\n        }\n\nSomeone else might find this useful so I'm posting the code here.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-644",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Contrib: another highlighter approach",
    "systemSpecification": true,
    "version": ""
}