{
    "comments": [
        {
            "author": "Shai Erera",
            "body": "Patch adds maxMergeMB handling to optimize as well. If there are no segments exceeding the threshold, then only maxNumSegments constraint is taken into account. Basically I've created two private methods findMergesForOptimizeMaxMergeSize and findMergesForOptimizeMaxNumSegments (the original logic). findMergesForOptimize calls the relevant one.\n\nI've also changed some members to protected and methods as well, for really easy extension of LMP. As a result, I removed two methods from BalancedSegmentsMP that were copied over from LMP.\n\nI took the opportunity to change OneMerge.segments and userCompoundfile to public - they are final so no risk of changing from the outside. But otherwise, if you would like to write a MP which queries the OneMerge objects, you can't. I added totalSize() to return the total size in bytes of that merge.\n\nTest + CHANGES entry as well.",
            "date": "2010-10-14T09:28:36.928+0000",
            "id": 0
        },
        {
            "author": "Shai Erera",
            "body": "Added support for maxMergeDocs as well. Also, I created a test class for size bounded optimize and added several test cases.\n\nI think it's ready to commit, but I'll wait a few days for some reviews.",
            "date": "2010-10-15T10:20:37.098+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks good!\n\nMaybe rename OneMerge.totalSize -> totalSizeInBytes?  Hmm does anyone\nactually call this new method?\n\nMaybe note somewhere that now optimize (when there's a maxMergeDocs/MB\nconstraint) is able to merge fewer than mergeFactor segments at a\ntime?\n\nThis code is a bit confusing:\n\n{noformat}\n       if (last - start - 1 > 1) {\n         // there is more than 1 segment to the right of this one.\n         spec.add(new OneMerge(infos.range(start + 1, last), useCompoundFile));\n       } else if (start != last - 1 && !isOptimized(infos.info(start + 1))) {\n          spec.add(new OneMerge(infos.range(start + 1, last), useCompoundFile));\n       }\n{noformat}\n\nBoth if clauses are doing the same thing right?  (Ie merging the chunk\nof segs to the right). Maybe put a comment explaining the 2nd one?  (I\nthink it's for the case where there's 1 segment to our right but it's\nnot optimized, eg the CFS differs?).  Or maybe consolidate into a single\nif?\n",
            "date": "2010-10-15T12:46:19.609+0000",
            "id": 2
        },
        {
            "author": "Shai Erera",
            "body": "You're right about the code - the 'else if' is in case there is one not optimized segment to the right. Added a comment and combined them into one OR-ed if. Also added a test case.\n\nOneMerge.totalSizeInBytes -- no one calls it now, but I would like to write a MP which will, and remove merges that exceed a specified total size. It's just a service method, instead of you needing to write it on your own. I renamed it to totalBytesSize. And on the way added totalNumDocs, doing the same for the number of docs.\n\nbq. Maybe note somewhere that now optimize (when there's a maxMergeDocs/MB constraint) is able to merge fewer than mergeFactor segments at a time?\n\nWasn't it able to do so even before? E.g. if maxNumSegments < numSegments < mergeFactor?",
            "date": "2010-10-15T13:20:46.768+0000",
            "id": 3
        },
        {
            "author": "Shai Erera",
            "body": "Committed revision 1025544 (3x).\nCommitted revision 1025577 (trunk).",
            "date": "2010-10-20T14:01:56.346+0000",
            "id": 4
        },
        {
            "author": "Simon Willnauer",
            "body": "This change together with LUCENE-2773 caused a change of the IW#optimize() and friends semantics.\nIW#optimize() says:\n{code}\n /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n\n{code}\n\nWhich is not entirely true anymore since default now uses \n\n{code}\n  /** Default maximum segment size.  A segment of this size\n   *  or larger will never be merged.  @see setMaxMergeMB */\n  public static final double DEFAULT_MAX_MERGE_MB = 2048;\n{code}\n\nthis is not what I would expect from optimize() even if it would be documented that way. A plain optimize call should by default result in a single segment IMO. Yet, we could make this set by a flag in LogMergePolicy maybe something like LogMergePolicy#useMasMergeSizeForOptimize = false; as a default?",
            "date": "2011-01-14T12:04:04.302+0000",
            "id": 5
        },
        {
            "author": "Jason Rutherglen",
            "body": "I agree that there should not be a defaults for the max merge segment size for optimize, though it's good to have the option.",
            "date": "2011-01-14T15:51:46.297+0000",
            "id": 6
        },
        {
            "author": "Shai Erera",
            "body": "I don't think we need a useDefaultMaxMergeMb. Instead, we can default the member to Long.MAX_VAL. That way, if no one sets it, all segments will be considered for merge, and if one wants, he can set it.\n\nI expect that if I use IW with a LMP that sets maxMergeMB, then even if I call optimize() this setting will take effect.\n\nBTW, I don't remember introducin this defaul as part of this issue. This issue only changed LMP to take the already existed setting into account. So maybe reverting this default should be handled within the issue I was changed in?",
            "date": "2011-01-14T16:25:22.570+0000",
            "id": 7
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. BTW, I don't remember introducin this defaul as part of this issue. This issue only changed LMP to take the already existed setting into account. So maybe reverting this default should be handled within the issue I was changed in?\nTrue this was done in here:  LUCENE-2773  - but this seemed to be more related?!\nbq. I don't think we need a useDefaultMaxMergeMb. Instead, we can default the member to Long.MAX_VAL. That way, if no one sets it, all segments will be considered for merge, and if one wants, he can set it.\n\nI think mike did that on purpose to prevent large segs from merging during indexing.... so what is wrong with disable that limit during optimize?",
            "date": "2011-01-14T16:38:57.080+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "bq. I think mike did that on purpose to prevent large segs from merging during indexing.\n\nRight -- large merges are really quite nasty -- mess up searches, NRT turnaround, IW.close() suddenly unexpectedly takes like an hour, etc.\n\nBut, really the best fix, which I'd love to do at some point, is to fix our merge policy so that insanely large merges are done w/ fewer segments (eg only 2 segments at once).  I think BalancedMP does this.\n",
            "date": "2011-01-14T17:29:27.995+0000",
            "id": 9
        },
        {
            "author": "Shai Erera",
            "body": "Patch fixes some jdocs + adds a separate setting for maxMergeSizeForOptimize which is applied only during optimize().",
            "date": "2011-01-16T19:24:23.100+0000",
            "id": 10
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Patch fixes some jdocs + adds a separate setting for maxMergeSizeForOptimize which is applied only during optimize().\npatch looks good to me! +1 to commit\n\nthanks shai",
            "date": "2011-01-16T19:39:27.054+0000",
            "id": 11
        },
        {
            "author": "Shai Erera",
            "body": "Thanks Simon !\n\nCommitted revision 1059750 (3x).\nCommitted revision 1059751 (trunk).",
            "date": "2011-01-17T04:47:25.142+0000",
            "id": 12
        },
        {
            "author": "Grant Ingersoll",
            "body": "Bulk close for 3.1",
            "date": "2011-03-30T15:50:16.040+0000",
            "id": 13
        }
    ],
    "component": "core/index",
    "description": "LogMergePolicy allows you to specify a maxMergeSize in MB, which is taken into consideration in regular merges, yet ignored by findMergesForOptimze. I think it'd be good if we take that into consideration even when optimizing. This will allow the caller to specify two constraints: maxNumSegments and maxMergeMB. Obviously both may not be satisfied, and therefore we will guarantee that if there is any segment above the threshold, the threshold constraint takes precedence and therefore you may end up w/ <maxNumSegments (if it's not 1) after optimize. Otherwise, maxNumSegments is taken into consideration.\n\nAs part of this change, I plan to change some methods to protected (from private) and members as well. I realized that if one wishes to implement his own LMP extension, he needs to either put it under o.a.l.index or copy some code over to his impl.\n\nI'll attach a patch shortly.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2701",
    "issuetypeClassified": "REFACTORING",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Factor maxMergeSize into findMergesForOptimize in LogMergePolicy",
    "systemSpecification": true,
    "version": ""
}