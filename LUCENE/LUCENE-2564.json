{
    "comments": [
        {
            "author": "Robert Muir",
            "body": "There are more problems with this loader... it uses FileReader (platform-dependent encoding).\nI think we should break it to default to UTF-8, too.\n",
            "date": "2010-07-26T14:11:20.950+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "as much as i hate the fact this one uses the default encoding in its File method, \nits only used by StopFilter etc.\n\nOur provided analyzers and Solr are treating all this stuff as UTF-8 encoded resources,\nso I think its ok to delay until 3.2 and re-assess the best way.\n\nI made a prototype patch and it was complicated, mainly because i wanted to fix\nthis thing so that its coherent with Solr's resource loeading.\n",
            "date": "2011-01-16T16:31:33.638+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "bulk move 3.2 -> 3.3",
            "date": "2011-06-03T16:40:44.803+0000",
            "id": 2
        },
        {
            "author": "Simon Willnauer",
            "body": "I tried to simplify this a little without going into changing solr (not sure what robert meant by that anyway...)  I basically moved all File / InputStream related stuff out of WordListLoader and made it fixed to CharArraySet/Map - there are still nocommits in there since I wanted to get some feedback what others think before I add javadoc everywhere",
            "date": "2011-11-09T06:32:26.061+0000",
            "id": 3
        },
        {
            "author": "Robert Muir",
            "body": "patch looks good... i was just referring to Solr's resource loading of stopwords and stuff.\n\nbut we don't have to do that here, imo we should fix the issues here first.\n\nMaybe for the javadocs on getReader we should explain that unlike the java default, it creates\na reader that will throw an exception if it detects the charset is wrong \n(so this is good for configuration files-reading like WordListLoader, but not recommended\nfor say documents crawled from the web or something)\n",
            "date": "2011-11-09T17:58:14.600+0000",
            "id": 4
        },
        {
            "author": "Simon Willnauer",
            "body": "next iteration\n* added javadocs & removed all nocommits\n* renamed IOUtils#getReader to IOUtils#getDecodingReader\n* used a CharSet instance instead of a string in all getDecodingReader variants so we can use a cached UTF-8 CharSet instance instead of looking it up for each invocation.\n\n\nI think its ready... where do we add the CHANGES.txt entry for that stuff? I figure since we backport this I should put it under lucene/contrib/CHANGES.txt? ",
            "date": "2011-11-09T23:27:31.768+0000",
            "id": 5
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nI figure since we backport this I should put it under lucene/contrib/CHANGES.txt? \n{quote}\n\n+1",
            "date": "2011-11-09T23:30:50.990+0000",
            "id": 6
        },
        {
            "author": "Simon Willnauer",
            "body": "final patch containing a CHANGES.txt entry - I am going to commit this in a minute",
            "date": "2011-11-10T01:17:32.835+0000",
            "id": 7
        },
        {
            "author": "Simon Willnauer",
            "body": "committed to trunk and backported to 3.x",
            "date": "2011-11-10T04:03:00.760+0000",
            "id": 8
        },
        {
            "author": "Uwe Schindler",
            "body": "Bulk close after release of 3.5",
            "date": "2011-11-27T12:29:22.903+0000",
            "id": 9
        }
    ],
    "component": "modules/analysis",
    "description": "WordListLoader is basically used for loading up stopwords lists, stem dictionaries, etc.\nUnfortunately the api returns Set<String> and sometimes even HashSet<String> or HashMap<String,String>\n\nI think we should break it and return CharArraySets and CharArrayMaps (but leave the return value as generic Set,Map).\n\nIf someone objects to breaking it in 3.1, then we can do this only in 4.0, but i think it would be good to fix it both places.\nThe reason is that if someone does new FooAnalyzer() a lot (probably not uncommon) i think its doing a bunch of useless copying.\n\nI think we should slap @lucene.internal on this API too, since thats mostly how its being used.\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2564",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "BUG",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "wordlistloader is inefficient",
    "systemSpecification": true,
    "version": ""
}