{
    "comments": [
        {
            "author": "Michael Busch",
            "body": "I don't think I will be able anytime soon to work on this.\n\nI still think this is a good idea, maybe someone else would like to take it?",
            "date": "2008-05-22T06:58:05.200+0000",
            "id": 0
        },
        {
            "author": "Uwe Schindler",
            "body": "I assign this to Lucene 4.0, as we may support this with flexible indexing when we enable custom segments files.",
            "date": "2011-01-27T11:00:38.194+0000",
            "id": 1
        },
        {
            "author": "Michael McCandless",
            "body": "Actually I think SimpleText's SegmentInfosFormat does this well?\n",
            "date": "2012-03-20T16:12:09.025+0000",
            "id": 2
        }
    ],
    "component": "core/index",
    "description": "Various index-reading components in Lucene need metadata in addition to data.\nThis metadata is presently stored in arbitrary binary headers and spread out\nover several files.  We should move to concentrate it in a single file, and \nthis file should be encoded using a human-readable, extensible, standardized \ndata serialization language -- either XML or YAML.\n\n* Making metadata human-readable makes debugging easier.  Centralizing it\n  makes debugging easier still.  Developers benefit from being able to scan\n  and locate relevant information quickly and with less debug printing.  Users\n  get a new window through which to peer into the index structure.\n* Since metadata is written to a separate file, there would no longer be a \n  need to seek back to the beginning of any data file to finish a header, \n  solving issue LUCENE-532.\n* Special-case parsing code needed for extracting metadata supplied by \n  different index formats can be pared down.  If a value is no longer \n  necessary, it can just be ignored/discarded.\n* Removing headers from the data files simplifies them and makes the file\n  format easier to implement. \n* With headers removed, all or nearly all data structures can take the\n  form of records stacked end to end, so that once a decoder has been\n  selected, an iterator can read the file from top to tail.  To an extent,\n  this allows us to separate our data-processing algorithms from our\n  serialization algorithms, decoupling Lucene's code base from its file\n  format.  For instance, instead of further subclassing TermDocs to deal with\n  \"flexible indexing\" formats, we might replace it with a PostingList which\n  returns a subclass of Posting.  The deserialization code would be wholly\n  contained within the Posting subclass rather than spread out over several\n  subclasses of TermDocs.\n* YAML and XML are equally well suited for the task of storing metadata, \n  but in either case a complete parser would not be needed -- a small subset \n  of the language will do.  KinoSearch 0.20's custom-coded YAML parser \n  occupies about 600 lines of C -- not too bad, considering how miserable C's \n  string handling capabilities are. ",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-783",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Store all metadata in human-readable segments file",
    "systemSpecification": true,
    "version": ""
}