{
    "comments": [
        {
            "author": "Cheolgoo Kang",
            "body": "This patch adds one line of 0xAC00~0xD7AF, the Korean syllables range to the StandardTokenizer.jj code.",
            "date": "2005-10-04T23:28:34.000+0000",
            "id": 0
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Committed.  Thanks Cheolgoo.",
            "date": "2005-10-05T12:54:26.000+0000",
            "id": 1
        },
        {
            "author": "Erik Hatcher",
            "body": "I'm closing this issue... but some unit tests would be nice to go along with this too, eventually :)",
            "date": "2005-10-05T19:40:50.000+0000",
            "id": 2
        }
    ],
    "component": "modules/analysis",
    "description": "While using StandardAnalyzer, exp. StandardTokenizer with Korean text stream, StandardTokenizer ignores the Korean characters. This is because the definition of CJK token in StandardTokenizer.jj JavaCC file doesn't have enough range covering Korean syllables described in Unicode character map.\nThis patch adds one line of 0xAC00~0xD7AF, the Korean syllables range to the StandardTokenizer.jj code.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-444",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "StandardTokenizer loses Korean characters",
    "systemSpecification": false,
    "version": ""
}