{
    "comments": [
        {
            "author": "Uwe Schindler",
            "body": "Attached is a patch that implements the first variant (without super interface for all FieldParsers). All current tests pass. A special test case for a custum field parser was not implemented.\n\nFor testing, I modified one of my contrib TrieRangeQuery test cases locally to sort using a custom LongParser that decoded the encoded longs in the cache [parseLong(value) returns TrieUtils.trieCodedToLong(value)].\n\nA good test case would be to store some dates in ISO format in a field and then sort it as longs after parsing using SimpleDateFormat. This would be another typical use case (sorting by date, but not using SortField.STRING to minimize memory usage).\n\nIf you like my patch, we could also discuss about using a super-interface for all Parsers. The modifications are rather simple (only the SortField constructor would be affected and some casts, and of course: the superinterface in all declarations inside FieldCache, ExtendedFieldCache)",
            "date": "2008-12-04T21:25:12.965+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "Patch looks good, thanks Uwe!  Back compat looks preserved; while some\nAPIs (FieldSortedHitQueue.getCachedComparator) were changed, they are\npackage private.\n\nBack-compat tests (\"ant test-tag\") pass as well.\n\nbq. For testing, I modified one of my contrib TrieRangeQuery test cases locally to sort using a custom LongParser that decoded the encoded longs in the cache [parseLong(value) returns TrieUtils.trieCodedToLong(value)].\n\nIt looks like this didn't make it into the patch -- could you add it?\n\nActually, adding a core test case would also be good.  It could be\nsomething silly, eg that parses ints but negates them, and then assert\nthat this yields the same result as the default IntParser with\nreverse=true (assuming no ties).\n\nbq. If you like my patch, we could also discuss about using a super-interface for all Parsers. The modifications are rather simple (only the SortField constructor would be affected and some casts, and of course: the superinterface in all declarations inside FieldCache, ExtendedFieldCache)\n\nI agree, I would like to at least get some minimal static typing into\nthe API (Object is not ideal) even if it's simply a \"marker\" interface\nIf you're sure this can be done, such that all changes to\nFieldCache/ExtendedFieldCache remain back compatibitle, then let's do\nit?  And I think I do now agree: this can be done w/o breaking back\ncompat.  The only affected public methods should be your new SortField\nmethods, which is fine (no public methods take \"Object parser\" as far\nas I can tell).\n",
            "date": "2008-12-05T10:55:23.867+0000",
            "id": 1
        },
        {
            "author": "Uwe Schindler",
            "body": "I found a hidden bug in FieldSortedHitQueue that materialized when writing a TestCase for a SortField.BYTE sorting with custom parser (it took me a long time to find out whats happening). The problem is, that the comparator for byte fields returned SortField.INT in sortType() instead of SortField.BYTE. The effect of this was, that my new code crahsed when generating the new SortField in the constructor because of the incorrect Parser/SortField type. The other problem was, that on later calling the cache again, it would return another hit, because the type was different. The problem is, that this does not affect correctness of the previous implementation, but may coud lead to errors, like with my new impl.\n\nI fix this bug (its just one line) in my next patch (I will supply it shortly). Is it OK, or should I open a separate bug report?",
            "date": "2008-12-06T12:08:52.593+0000",
            "id": 2
        },
        {
            "author": "Uwe Schindler",
            "body": "Here is the patch using the superinterface for all field parsers. The patch also provides a test case in \"TestSort\" that uses a custom parser, that maps a simple char value from 'A' to 'J' to a byte, short, int, long, float, double with some crazy algorithm :-) to test sorting.\n\nAlso fixed is the bug with the sortType() in comparator as mentioned before, without this, the test case for bytes would not pass.\n\nAdditionally the new SortField constructor checks the sort type and corresponding parser for consistency and throws IllegalArgumentException, if not correct (e.g. using a LongParser with SortField.BYTE). During inventing this patch I had another idea to fix the issue with not to have a new super-interface: SortField could have separate constructors for each parser type without type parameter (as type is forced by parser instance -- we could also remove the type parameter in the current patch, as the type maybe set by  instanceof operator). Changing this would require some more work in the FieldSortedHitQueue, as copying the SortField would require more work (but could be fixed better as is is currently: a new SortField instance in the constructor is only needed, if SortField.AUTO or CUSTOM was used, in all other cases, the SortField instance can just be directly used).\n\nJust give some comments!",
            "date": "2008-12-06T12:59:06.434+0000",
            "id": 3
        },
        {
            "author": "Uwe Schindler",
            "body": "I forget to mention, this patch also extends contrib's TrieUtils and test cases to support a static trie-tolong/double-parser and a SortField factory to handle trie-encoded fields very simple using the long fieldcache (for sorting, there need to be no difference between long/double, it will work for all 3 trie encodings and long is the simpliest to handle an compare) - for which this patch was mainly invented. The double parser instance is only supplied for other usages of FieldCache from TrieUtils.",
            "date": "2008-12-06T13:03:15.544+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "bq. The problem is, that the comparator for byte fields returned SortField.INT in sortType() instead of SortField.BYTE.\n\nWhoa, nice catch!  I think it's fine to include the fix here (it was not manifesting as a bug w/o your changes).\n\nbq. The patch also provides a test case in \"TestSort\" that uses a custom parser, that maps a simple char value from 'A' to 'J' to a byte, short, int, long, float, double with some crazy algorithm  to test sorting. \n\nAwesome, I like the new test!\n\nbq. Additionally the new SortField constructor checks the sort type and corresponding parser for consistency and throws IllegalArgumentException, if not correct\n\nI like this stronger typing.  Could you change the message thrown exception to detail the type that was given and what parser was provided (better transparency)?\n\nbq. SortField could have separate constructors for each parser type without type parameter\n\nThat is a good idea, I think.  The two args are redundant & therefore a source of confusion/error.  It is annoying how we keep having to \"multiply by N\" so many places in Lucene that want to switch on the different builtin types (LUCENE-831 has this too).\n\nbq. Changing this would require some more work in the FieldSortedHitQueue, as copying the SortField would require more work\n\nCan we just SortField.clone() instead of \"new SortField(lots-of-tricky-args)\" in FieldSortedHitQueue?\n\nbq. this patch also extends contrib's TrieUtils and test cases to support a static trie-tolong/double-parser and a SortField factory to handle trie-encoded fields very simple using the long fieldcache\n\nGreat!",
            "date": "2008-12-06T13:47:23.751+0000",
            "id": 5
        },
        {
            "author": "Uwe Schindler",
            "body": "New patch that integrates Mike's comments. This version still uses a super-interface. If we want to remove it, we can create 6*2 new constructors (for each parser with and without reverse) and use Object for the internal member variable holding the parser. In FieldSortedHitQueue, the parser is stored in the CacheEntry's custom member which is also Object..., so the supertype is only used in SortField.\n\n12 new constructors are (in my eyes) very bad and from the JavaDoc side very heavy. The only advantage of them is:\n- removing the super-interface\n- the if-queue of instanceof tests can be removed because of stronger typing",
            "date": "2008-12-07T14:51:57.694+0000",
            "id": 6
        },
        {
            "author": "Uwe Schindler",
            "body": "As LUCENE-1481 is committed, here the updated patch with SortField.hashCode() and equals()",
            "date": "2008-12-08T15:49:39.948+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "OK I made a few small changes to the patch: added CHANGES entry, touched up javadocs, and added null check for field in the new SortField ctors.  I think it's ready to commit!\n\nUwe can you look over my changes?  Thanks.",
            "date": "2008-12-08T18:21:38.799+0000",
            "id": 8
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Mike,\n\npatch looks good, checked each change of you with TortoiseMerge. All tests pass including Trie ones.\n\nThe only comments: You added this java docs to hashCode() and equals() in the patch of LUCENE-1481. Maybe you should add the parser here, too.\n\n{code}\n  /** Returns a hash code value for this object.  If a\n   *  {@link SortComparatorSource} was provided, it must\n   *  properly implement hashCode. */\n{code}\nBut on the other hand side: If the parser and/or comparator are static singletons (like it is done by the TrieUtils factories) they are not needed to implement equals and hashcode. The default Object equals/hashcode is enough for singletons. And I think most parsers and comparators are singletons. A short not should be enough.\n\nThe additional null check is OK but in my opinion not needed, because field!=null when not one of the special RELEVANCE/DOCORDER sorts. For consistency we may add the check to the other ctors, too.",
            "date": "2008-12-08T19:33:40.192+0000",
            "id": 9
        },
        {
            "author": "Michael McCandless",
            "body": "New patch attached:\n\nbq. Maybe you should add the parser here, too.\n\nOK done.\n\nbq. The default Object equals/hashcode is enough for singletons.\n\nOK I updated javadoc to add \"unless a singleton is always used\".\n\nbq. The additional null check is OK but in my opinion not needed, because field!=null when not one of the special RELEVANCE/DOCORDER sorts. For consistency we may add the check to the other ctors, too.\n\nYeah I added that because the javadoc had previously said field could\nbe null for DOC/SCORE sort type.  OK I added that check for all ctors\n(added initFieldType private utility method).",
            "date": "2008-12-08T20:21:29.032+0000",
            "id": 10
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Mike,\nall is ok. The extra check is better than before! I think its ready for commit.\nThanks for the discussions!",
            "date": "2008-12-08T21:00:59.279+0000",
            "id": 11
        },
        {
            "author": "Michael McCandless",
            "body": "Committed revision 724484.\n\nThanks Uwe!",
            "date": "2008-12-08T21:08:43.451+0000",
            "id": 12
        },
        {
            "author": "Uwe Schindler",
            "body": "Hi Mike,\nsorry, after looking a second time into the new SortField ctors, I chaged two cosmetic things:\n\n- The ctor for parser assigns this.type=type and later calls the init method with the member variable type. The init method assigns so the meber to the member agian. Cleaner is just call the initFieldType() method in the correct instanceof clause hit.\n- Moved the initFieldType() behind all ctors.\n\nBut this is only cosmetic :)",
            "date": "2008-12-08T22:54:30.204+0000",
            "id": 13
        },
        {
            "author": "Michael McCandless",
            "body": "No problem -- Committed revision 724552.  Thanks!",
            "date": "2008-12-08T23:27:53.330+0000",
            "id": 14
        },
        {
            "author": "Uwe Schindler",
            "body": "Just a note:\nFor the FieldCache it is also important, that the parser is a singleton or implements hashCode() and equals(). If not, each call to sort with another SortField using a different parser instance (but from the same class) would create a new FieldCache. This is why I said, that SortComparators and Parsers should generally be made static final members (and so singletons) like I have done it in TrieUtils. With that you can be sure, that all SortFields hit the same cache entry when looking up using FieldCacheImpl.Entry. The implementation of hashCode and equals for parsers is the other variant, but it does not make really sense (as long as parsers and comparators do not have an instance-specific state).",
            "date": "2008-12-09T22:52:33.864+0000",
            "id": 15
        },
        {
            "author": "Yonik Seeley",
            "body": "I tracked down how this patch was causing Solr failures:\n\nExternalFileField in Solr maps from a uniqueKey to a float value from a separate file.\nThere is a cache that is essentially keyed by (IndexReader,field) that gives back a float[].\n\nAny change in the index used to cause all values to be updated  (cache miss because the MultiReader was a different instance).  Now, since it's called segment-at-a-time, only new segments are reloaded from the file, leaving older segments with stale values.\n\nIt's certainly in the very gray area... but perhaps Solr won't be the only one affected by this - maybe apps that implement security filters, etc?",
            "date": "2009-01-30T04:58:43.492+0000",
            "id": 16
        },
        {
            "author": "Uwe Schindler",
            "body": "I am not really sure, how this patch can can change this. Maybe you have more a problem with the new MultiReaderHitCollector patch (LUCENE-1483) - your comment looks like this? The current patch does not change anything, as long as you use the old SortField constructors.\n\nCan you explain a little bit more, maybe a test?",
            "date": "2009-01-30T07:50:29.933+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "After reading your comment several times and looking into ExternalFileField, the problem can maybe fixed using this issue:\n\nYou problem may come from the fact, that you instantated this own FieldCache implementation, keyed it with the parent MultiReader and the new Sort implementation does not use it.\n\nWrite a FloatParser that maps the the uniqueKey to a float value using the external file. If you want to use it with the new MultiReaderHitCollector sorting (LUCENE-1483), create the SortField using the parser interface parameter from this issue. When the field caches for searching are now rebuild (even only for one of them in a Multi(Segment)Reader)), the new Lucene search API will re-read the changed segments and build several new FieldCaches (standard ones) using the suplied parser. There is no longer the need for a extra FieldCache implementation with this issue.\n\nIs this your problem? Maybe this is why you wrote the comment here.",
            "date": "2009-01-30T08:16:46.135+0000",
            "id": 18
        },
        {
            "author": "Michael McCandless",
            "body": "Yonik, why was the failure so intermittent?\n\nSo it sounds like Solr was relying on Lucene loading the entire\nfloat[] for all docs in the MultiSegmentReader, when only some\nsegments were new?  (And so it was LUCENE-1483 that caused the\nfailure).\n\nLucene implicitly assumes that a FieldCache's arrays do not change for\na given segment; this is normally safe since the arrays are derived\nfrom the postings in the field (which are write once).\n\nBut it sounds like Solr changed that assumption, and the values in the\n(Solr-subclass of) FieldCache's arrays are now derived from something\nexternal, which is no longer write once.\n\nHow do you plan to fix it with Solr?  It seems like, since you are\nmaintaining a private cache, you could forcefully evict entries from\nthe cache for all SegmentReaders whenever the external file has\nchanged (or a new MultiSegmentReader had been opened)?\n",
            "date": "2009-01-30T10:11:56.410+0000",
            "id": 19
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Write a FloatParser that maps the the uniqueKey to a float value using the external file.\n\nUwe, would that result in a memory leak?  Ie, a single long-lived segment would accumulate multiple entries for each new XXXParser instance used during sorting?  (Unless there's logic to evict the \"stale\" entries).\n\nIt seems like LUCENE-831, which would expose / allow custom control over FieldCache's caching impl, would help here too.",
            "date": "2009-01-30T10:17:25.477+0000",
            "id": 20
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. Uwe, would that result in a memory leak? Ie, a single long-lived segment would accumulate multiple entries for each new XXXParser instance used during sorting? (Unless there's logic to evict the \"stale\" entries).\n\nAs noted before on Dec 9, 08, the parser should be a singleton for all field caches or have hashCode()/equals(). You create a FloatParser and supply it to SortField. When then sorting against this field, the new sort implementation would create a FieldCache for each segment. When one segment is reloaded, the FieldCache gets unused and a new one for the replacement segment is created (this is the same like with the standard field parser). The FieldCache is using (IndexReader,SortField.type,Parser) as key.\n\nIf the FieldCache is used for CachingFilters, there is also no problem: The new search algorithm executes each filter's getDocIDSet() for each single SegmentReader.\n\nSo the only problem is, that with the new search implementation, you cannot rely anymore on the fact, that for a MultiReader only one FieldCache exists and every filter's getDocIdSet() is executed only one time. So injecting a custom FieldCache into the cache for the whole MultiReader before search (by getting it) is not possible anymore.\n\nI tested the new search impl with trie fields, sorting works perfect using TrieUtils.getSortField()/TrieUtils.LONG_PARSER, no leaks (because FieldParser is singleton). I had to only modify the test case (Revision: 737079), because with an unoptimized index, the statistics for retrieving the number of visited terms did not work anymore (because the Filter was called more than once per search).\n\nThe problem with stale entries, if the external file changes is another problem, that also happend before the new sort impl.\n\nbq. It seems like LUCENE-831, which would expose / allow custom control over FieldCache's caching impl, would help here too.\n\nYes!",
            "date": "2009-01-30T10:51:12.870+0000",
            "id": 21
        },
        {
            "author": "Uwe Schindler",
            "body": "By the way: The Cache of FieldCache instances in FieldCacheImpl is a WeakHashMap, so unused FieldCache instances for no longer used readers/parsers are GC'ed.",
            "date": "2009-01-30T11:02:43.779+0000",
            "id": 22
        },
        {
            "author": "Michael McCandless",
            "body": "\nbq. the parser should be a singleton for all field caches or have hashCode()/equals().\n\nI guess I don't understand your proposed workaround then -- I thought\nyou were explicitly proposing *not* using a singleton, so that you\ncould force re-parsing of all values (even for old segments) when a\nnew external file was being used.\n\n(Also likely my lack of understanding of Solr's ExternalFileField is\nadding to my confusion here -- I haven't yet looked at it.)\n\nbq. The Cache of FieldCache instances in FieldCacheImpl is a WeakHashMap, so unused FieldCache instances for no longer used readers/parsers are GC'ed.\n\nThe WeakHashMap is keyed by the IndexReader, and then there's a normal\nHashMap (innerCache) keyed on field,Parser.  So it's only when the\nIndexReader (SegmentReader) is no longer referenced elsewhere that the\ninnerCache, in entirety, can be GCd.  There's no reclaiming of stale\nentries in the innerCache.\n",
            "date": "2009-01-30T11:20:32.828+0000",
            "id": 23
        },
        {
            "author": "Uwe Schindler",
            "body": "Ah, now I understand (by the way, I do not understand Solrs ExternalFileField in complete, too):\n\nWith my workaround, I did not want to work around the problem of a changed external file. I propsed, not to implement a own FieldCache for the whole thing and just use the new SortField's parser to fill the standard FloatCache during searching/filtering. Just use the external (static) file and convert the the values from the index using the HashMap in ExternalFileField to the floats. This parser is a singleton for each ExternalFileField.\n\nBut I think we should wait, until Yonik explains us the problem more detail.",
            "date": "2009-01-30T11:33:03.119+0000",
            "id": 24
        },
        {
            "author": "Yonik Seeley",
            "body": "Apologies, I meant to post in LUCENE-1483",
            "date": "2009-01-30T14:57:24.064+0000",
            "id": 25
        }
    ],
    "component": "core/search",
    "description": "When implementing the new TrieRangeQuery for contrib (LUCENE-1470), I was confronted by the problem that the special trie-encoded values (which are longs in a special encoding) cannot be sorted by Searcher.search() and SortField. The problem is: If you use SortField.LONG, you get NumberFormatExceptions. The trie encoded values may be sorted using SortField.String (as the encoding is in such a way, that they are sortable as Strings), but this is very memory ineffective.\n\nExtendedFieldCache gives the possibility to specify a custom LongParser when retrieving the cached values. But you cannot use this during searching, because there is no possibility to supply this custom LongParser to the SortField.\n\nI propose a change in the sort classes:\nInclude a pointer to the parser instance to be used in SortField (if not given use the default). My idea is to create a SortField using a new constructor\n{code}SortField(String field, int type, Object parser, boolean reverse){code}\n\nThe parser is \"object\" because all current parsers have no super-interface. The ideal solution would be to have:\n\n{code}SortField(String field, int type, FieldCache.Parser parser, boolean reverse){code}\n\nand FieldCache.Parser is a super-interface (just empty, more like a marker-interface) of all other parsers (like LongParser...). The sort implementation then must be changed to respect the given parser (if not NULL), else use the default FieldCache.getXXXX without parser.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1478",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Missing possibility to supply custom FieldParser when sorting search results",
    "systemSpecification": true,
    "version": "2.4"
}