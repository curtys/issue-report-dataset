{
    "comments": [
        {
            "author": "Michael Busch",
            "body": "First half is done:\nShingleFilter and ShingleFilterTest are converted to the new API.\n\nShingleFilter is much more efficient now, it clones much less often and computes the tokens mostly on the fly now. \n\nWould be good if someone could review my changes.\n\nWe still need to convert ShingleMatrixFilter.",
            "date": "2009-08-02T07:54:15.394+0000",
            "id": 0
        },
        {
            "author": "Michael Busch",
            "body": "Converted TestShingleMatrixFilter. Not the actual filter yet.",
            "date": "2009-08-02T08:16:47.995+0000",
            "id": 1
        },
        {
            "author": "Michael Busch",
            "body": "ShingleMatrixFilter is a very complicated filter. It seems that it is implemented in a very inefficient way, it does lots of cloning. While I was able to fully convert ShingleFilter in a way, so that it is now much more efficient now, I'm not going to do that with the ShingleMatrixFilter.\nI don't know the code well enough to even try and with 1000 LOC it's very complex.\n\nThe drawback of not fully converting it is that if someone uses custom Attributes, i. e. ones that are not in core Lucene, it is undefined what the filter will do with those Attributes. However, I don't even know what the behavior should be. If only core Attributes are used, everything is working fine, as the passing junits show.\n\nI added a corresponding comment to the javadocs of that class.",
            "date": "2009-08-02T08:55:45.084+0000",
            "id": 2
        },
        {
            "author": "Michael Busch",
            "body": "I'll commit this in a couple of days if nobody objects.",
            "date": "2009-08-02T08:57:25.549+0000",
            "id": 3
        },
        {
            "author": "Uwe Schindler",
            "body": "This ShingleMatrixFilter is really a pain!\n\nI think the ShingeMatrix is very \"special\" and only produce tokens with few correlation to the original input stream, so it is not so bad, if the extra attributes get lost.\n\nYou could use a simple AttributeSource instead of EmptyTokenStream and create it with the same AttributeFactory as the filter isself. Because of this, you could copyTo the extra Tokens (currently implemented by the Token instance). This reuseableToken could also be an AttributeSource? For me it is not really clear what all this copying between the attributes and the Token instance does, but it seems that it could be converted to Attributes, too. If you do it that way, would it be not work also with custom attributes? One possibility would be to copyTo the Tokens around (or use States) and then modify the shingle speicfic things.",
            "date": "2009-08-02T09:24:27.059+0000",
            "id": 4
        },
        {
            "author": "Michael Busch",
            "body": "I noticed that a shingle test uses PrefixAndSuffixAwareTokenFilter.\n\nSo I undeprecated it and also PrefixAwareTokenFitler by using the same trick as in ShingleMatrixFilter.\n\nAll tests pass.",
            "date": "2009-08-02T09:34:23.720+0000",
            "id": 5
        },
        {
            "author": "Michael Busch",
            "body": "Hi Uwe,\n\nI just noticed your comment after I attached the latest patch...\n\nThere's probably a better way to do it. Feel free to update the patch ;)\nMy brain is tired and I really need to sleep now...\n\nI used the same trick in the Prefix/Suffix filters - one of the reasons I did it in those filters is it to not change the updateSuffixToken(Token, Token) method, which I assume is there so that users can overwrite it.",
            "date": "2009-08-02T09:38:12.670+0000",
            "id": 6
        },
        {
            "author": "Michael Busch",
            "body": "Committed revision 800195.",
            "date": "2009-08-03T04:33:35.580+0000",
            "id": 7
        },
        {
            "author": "Robert Muir",
            "body": "Michael, I looked at your patch, really glad you were successful here!\n\nOne last question, we didnt do anything with analysis/sinks (DateRecognizerSinkTokenizer, etc). \nThese are deprecated as they extend SinkTokenizer... will they be removed with the old api or do we need to implement alternatives?\n",
            "date": "2009-08-03T12:58:58.550+0000",
            "id": 8
        },
        {
            "author": "Michael Busch",
            "body": "{quote}\nOne last question, we didnt do anything with analysis/sinks (DateRecognizerSinkTokenizer, etc). \n{quote}\n\nYeah I guess we should. Here is the patch.",
            "date": "2009-08-03T18:36:44.099+0000",
            "id": 9
        },
        {
            "author": "Robert Muir",
            "body": "same patch as Michael's, just removed a stray import org.apache.tools.ant.filters.FixCrLfFilter.AddAsisRemove;",
            "date": "2009-08-03T18:56:55.150+0000",
            "id": 10
        },
        {
            "author": "Michael Busch",
            "body": "Thanks, Robert. I'll commit this later today.",
            "date": "2009-08-03T19:57:45.208+0000",
            "id": 11
        },
        {
            "author": "Michael Busch",
            "body": "Committed revision 800606.",
            "date": "2009-08-03T22:45:44.028+0000",
            "id": 12
        }
    ],
    "component": "modules/analysis",
    "description": "All other contrib streams/filters have already been converted with LUCENE-1460.\n\nThe two shingle filters are the last ones we need to convert.",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1775",
    "issuetypeClassified": "REFACTORING",
    "issuetypeTracker": "OTHER",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Change remaining contrib streams/filters to use new TokenStream API",
    "systemSpecification": true,
    "version": ""
}