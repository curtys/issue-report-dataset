{
    "comments": [
        {
            "author": "Simon Willnauer",
            "body": "attached extension based patch",
            "date": "2009-11-06T18:40:49.698+0000",
            "id": 0
        },
        {
            "author": "Uwe Schindler",
            "body": "I do not like this extension.\n\nIn my opinion, we should simply use the new QueryParser framework for it, where it is quite easy to plugin support for RegExQueries even if they live in contrib. ",
            "date": "2009-11-06T18:48:19.889+0000",
            "id": 1
        },
        {
            "author": "Grant Ingersoll",
            "body": "The new QP framework is not proven out and doesn't have very many people using it and is still in contrib.  This extension allows for a pretty simple way for people to add simple extensions to the current QP without having to do a whole lot of programming.",
            "date": "2009-11-07T08:01:07.168+0000",
            "id": 2
        },
        {
            "author": "Luis Alves",
            "body": "I agree with Uwe,\n\nI think we should implement this on the new queryparser using the opaque terms framework described in LUCENE-1823.\n\nThe current implementation of this patch will create backward compatibility syntax problems, for queries using \"/\" characters\nfor example \"file paths\" or \"urls\" would be affected. If we are doing this we should change the syntax to allow for opaque terms.\n\nWhen we have support for opaque terms in the new queryparser, we can implement regex support with it.\n\nOpaque terms, is a framework to extend the queryparser syntax to bypass parts of the query  to a smaller parsing code (not a full parser), or a analyzer, and allow extensions of the query syntax as needed, without requiring changing the lucene code.",
            "date": "2009-11-10T19:17:45.311+0000",
            "id": 3
        },
        {
            "author": "Grant Ingersoll",
            "body": "I have a need for this in the Lucene Query Parser.  It simply isn't practical for me to switch to using the contrib Query Parser as that would involve a fair amount of changes in the application.  As for the back compat issue, I think we can work around that by having a flag set.  I'll look into it a bit more.",
            "date": "2009-11-10T19:45:32.940+0000",
            "id": 4
        },
        {
            "author": "Robert Muir",
            "body": "regardless of which query parser, I think it would be nice to have regex support in some query parser available.\n\ndoesn't query parser now take Version as a required argument? Maybe the back compat issue could be solved with that???",
            "date": "2009-11-10T19:51:51.189+0000",
            "id": 5
        },
        {
            "author": "Simon Willnauer",
            "body": "I totally see you point but on the other hand I really miss the option to extend the old-fashion query parser. I do not see the new parser being THE lucene query parser by now.Many many people are using the javaCC parser and will do so in the future. I possibly have another solution which preserves backwards compatibility and would support the query extension too.\n\nThe alternative idea is to utilize the fact that queries enclosed in double quotes are passed to getFieldQuery() and are not interpreted by the grammar. Extension queries could be embedded in quotes while the content needs to be escaped. (that is already the case though. To identify which extension should be used we could utilize the field name and a pattern so that users could plug in extension mapped to some field name pattern. Something like: re_field:\"^.\\*$\" -> (re_field, RegexExtension) \n\nthat would not change anything in the parser as long as no extension is registered. No new character and no backwards compat issues. \n\nThoughts?",
            "date": "2009-11-10T19:54:14.773+0000",
            "id": 6
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. I think we can work around that by having a flag set. I'll look into it a bit more. \n\nGrant, JavaCC only generates parsers, a flag is a semantic check. You need to do a lot more work to do those checks. First step would be to build a tree using jjtree. Then you need to build the symbol table and then you can traverse the tree to do your checks.\n\nOne solution would be creating a parser from two javacc files one for < 3.0 and one or 3.0 - something like robert suggested. Then we could use the Version to choose the corresponding parser impl. \n\nsimon",
            "date": "2009-11-10T20:14:29.325+0000",
            "id": 7
        },
        {
            "author": "Robert Muir",
            "body": "Simon, personally I would prefer the Version argument used for such things.\n\nI know this isn't popular, but I'd actually be for having say, a 3.0 javacc grammar file that differs from the 2.9 one, with version driving it.\n\nyeah it would be duplicated code, but its mostly auto-generated code anyway, and I think it would be simple to understand what is going on.",
            "date": "2009-11-10T20:14:31.103+0000",
            "id": 8
        },
        {
            "author": "Luis Alves",
            "body": "Hi Simon, \n\nI think one problem lucene has today, is that the queryparser code in very tightly integrated with the javacc code. If we continue to do that it will always be very difficult to create a standard way of making small changes to the current queryparser.\n\nI like the implementation proposed by Simon, is very similar to the opaque term idea, but I would prefer not to overload the fileds names.\n{quote}\nThe alternative idea is to utilize the fact that queries enclosed in double quotes are passed to getFieldQuery() and are not interpreted by the grammar. Extension queries could be embedded in quotes while the content needs to be escaped. (that is already the case though. To identify which extension should be used we could utilize the field name and a pattern so that users could plug in extension mapped to some field name pattern. Something like: re_field:\"^.*$\" -> (re_field, RegexExtension)\n{quote}\n\nWe should decouple the user extensions from the JAVACC generated code. Just like in the new queryparser framework does, the queryparser should allow for the user to register these extensions at run time, and have Interface that extensions should implement.\n\nFor example, something like this:\n{code}\nQueryParser  qp = QueryParserFactory.getInstance(\"3.0\");\nqp.registerOpaqueTerm(\"regexp\", new QueryParserRegExpParser());\nqp.registerOpaqueTerm(\"complex_phrases\", new QueryParserComplexPhraseParser());\n...\nqp.parser(\" regexp:\\\"/blah*/\\\" complex_phrase:\\\"(sun OR sunny) sky\\\" \",...);\n{code}\nOf course this is not possible with the lucene queryparser code today :(,\nbut this is the idea I think we should try to implement.\n\nFor the problem of field overload:\nIn your proposal we lose the field name information for the extensions, so we need to another solution that would allow the fieldname to be available for the extensions.\n\nHere is another idea, that would allow for fieldnames not to be overloaded,\nand allow regular term or phrase syntax for extensions.\n{code}\nsyntax:\nextension:fieldname:\"syntax\"\n\nexamples:\nregexp:title:\"/blah[a-z]+[0-9]+/\"  <- regexp extension, title index field\ncomplex_phrase:title:\"(sun OR sunny) sky\" <- complex_phrase extension, title index field\n\nregexp_phrase::\"/blah[a-z]+[0-9]+/\"  <- regexp extension, default field\ncomplex_phrase::\"(sun OR sunny) sky\" <- complex_phrase extension, default field\n\ntitle:\"blah\" <- regular field query\n\n{code}\n\n",
            "date": "2009-11-10T22:30:44.519+0000",
            "id": 9
        },
        {
            "author": "Luis Alves",
            "body": "{quote}\nGrant, JavaCC only generates parsers, a flag is a semantic check. You need to do a lot more work to do those checks. \nFirst step would be to build a tree using jjtree. \nThen you need to build the symbol table and then you can traverse the tree to do your checks.\n{quote}\n\nIn the new queryparser we don't use jjtree, but the same concept is implemented in the new queryparser, \nthe ouput from the SyntaxParser interface is a syntax tree, this tree is not related with any lucene objects just like jjtree.\nBut I think this is a ugly solution.\n\nI think if we use the new queryparser, it allows for multiple SyntaxParsers to use the same Processors and the Builders.\nAnd with a small implementation of a SyntaxParser(javacc, jflex, antlr, java tokenizer, etc), you can use the same Processors and Builders to create a lucene query.\nThis will avoid duplicate code and allow for multiple syntaxes.\n\nI don't want to be preacher here, but some of these problems are already solved in the new queryparser framework, we just need to keep improving it, by adding more syntaxes, extensions and features to it.\n\nI know the new queryparser is not in main, but that can be fixed in 3.1.\nIf the community thinks it is stable, we should move it to main.\n",
            "date": "2009-11-10T23:00:20.176+0000",
            "id": 10
        },
        {
            "author": "Yonik Seeley",
            "body": "bq. I think one problem lucene has today, is that the queryparser code in very tightly integrated with the javacc code.\n\nThis almost seems more of an issue for core lucene developers - it's an annoyance that one needs to recompile the javacc grammar when just tweaking what one of the methods does.  Seems like this could easily be solved by just separating into two files... the javacc grammar would have a base class that left things like getFieldQuery() unimplemented, and then the standard QueryParser (in a different java file) would override and implement those methods.\n\nbq. We should decouple the user extensions from the JAVACC generated code.\n\nIt already is today via subclassing QueryParser and overriding methods like getFieldQuery... that's very simple for users to understand and to leverage.\n\nbq. Just like in the new queryparser framework does, the queryparser should allow for the user to register these extensions at run time, and have Interface that extensions should implement.\n\nI don't understand the motivation for this - it's complex and harder for a user to understand.  Java's own extension mechanism (overriding) has worked perfectly fine in the past.\n",
            "date": "2009-11-11T16:32:44.936+0000",
            "id": 11
        },
        {
            "author": "Luis Alves",
            "body": "Hi Yonik,\n\n{quote}\nThis almost seems more of an issue for core lucene developers - it's an annoyance that one needs to recompile the javacc grammar when just tweaking what one of the methods does. Seems like this could easily be solved by just separating into two files... the javacc grammar would have a base class that left things like getFieldQuery() unimplemented, and then the standard QueryParser (in a different java file) would override and implement those methods.\n{quote}\n\nThis solution does not fix the problem of having multiple syntaxes sharing the same lucene processing code. For example if you have one javacc grammar and one in antlr, you can't use lucene QueryParser, to process the output of both. You will need to re-implement the QueryParser recursive logic in a diff class to be able to use antlr.\n\n{quote}\nIt already is today via subclassing QueryParser and overriding methods like getFieldQuery... that's very simple for users to understand and to leverage.\n{quote}\n\nTrue. This is simple, but is not customizable.\n- You can't change the syntax.\n- You can't reuse the QueryParser logic with other parsers\n- If you do have to change syntax, you can't reuse QueryParser class anymore, you need to maintain your own copy of the class.\n\nYou can read LUCENE-1567 to understand the reasons for the new queryparser.\nBut the focus of the new queryparser is extensibility and customization,\nwithout changing lucene code, but reusing lucene logic as much as possible.\n\nIf you look at TestSpanQueryParserSimpleSample in queryparser contrib, or LUCENE-1938 Precedence query parser.\nIt illustrates two cases that would be very difficult to do in the current QueryParser in lucene by overriding methods.\n\nActually the a implementation  PrecedenceQueryParser exists today in contrib/misc. That contains a seperated javacc grammar and does not share any code with the main lucene Queryparser, and it illustrates the problem I described above (code duplication, impossible to reuse if grammar is different, easily gets outdated when the core queryparser changes)\n\nI'm not trying to say the QueryParser in main is worst than the one in contrib,\n\nWhat I'm trying to describe is that the one in contrib is more modular and if we build the modules\nfor the lucene users. The users will be able to build smarter and more sophisticated solutions using Lucene in less time.\nUsers can decide what modules to use in the queryparser and build their query pipelines with less work.\n\nUsers can also use the pre-built ones like StandardQueryParser or PrecedenceQueryParser, these should be as easy to use as the old queryparser in main.\n\n",
            "date": "2009-11-11T21:27:21.633+0000",
            "id": 12
        },
        {
            "author": "Adriano Crestani",
            "body": "This is a new feature already suggested by Luis and Shai (maybe others too) before, the ability to delegate to another parser the syntax processing of certain piece of the query string. This feature is a new feature to both: core QP and contrib QP.\n\nSo, I think we should focus more on how/when a query substring will be delegated to another parser and not discuss about how/when any logic will be applied to it. I think in both QPs, this part is already defined.\n\nFirst, to identify this substring we would need a open and close token. It could be either double-quote, slash or whatever. The ideal solution would allow the user to specify these two tokens. Unfortunately, I think JavaCC is not so flexible to allow defining these tokens programatically (after parser generation by JavaCC). So we need to stick with some specific open/close token, that's one decision we need to take. Maybe we could provide a property file, where the user could specify the open/close token and regenerate Lucene QP using 'ant javacc' (which is pretty easy today). Anyway, by default, we could use any new token. I don't agree with double-quotes (as I think someone suggested), it's already used by phrases, so, slash is fine for me, as already defined in Simon's patch.\n\nNow, about any semantic(logic) processing performed on any query substring, it will be up to the QP implementation. In the core QP, its own extension would be responsible to do this processing. In the contrib QP, the extension parser would only parse the substring and return a QueryNode, which will be later processed, after the syntax parsing is complete, by the query node processors. As I said before, this part is defined and I don't think we should discuss it on this topic.\n\nI like Simon's patch, I think the same approach can be applied to the contrib QP. The only part I disagree is when you pass the fieldname to the extension parser, I wouldn't implement that on the contrib parser, because it assumes the syntax always has field names. Anyway, for the core QP, I see the reason why you pass the fieldname, and it's completely related to the way the core QP implements the semantic (logic) processing. So, in future, if the main core QP needs to pass a new info to its extension parser, the extension parser interface would have to be changed :S...here I go again starting a new discussion about how semantic (logic) processing should be handled :P",
            "date": "2009-11-12T07:32:09.544+0000",
            "id": 13
        },
        {
            "author": "Luis Alves",
            "body": "Simon and Adriano,\nCan you comment on the example below.\n\n{quote}\nsyntax:\nextension:fieldname:\"syntax\"\n\nexamples:\nregexp:title:\"/blah[a-z]+[0-9]+/\"  <- regexp extension, title index field\ncomplex_phrase:title:\"(sun OR sunny) sky\" <- complex_phrase extension, title index field\n\nregexp_phrase::\"/blah[a-z]+[0-9]+/\"  <- regexp extension, default field\ncomplex_phrase::\"(sun OR sunny) sky\" <- complex_phrase extension, default field\n\ntitle:\"blah\" <- regular field query\n{quote}\n\nThis would allow the filedname and phrases or terms to be passed to a extension, and still be very compatible with the old syntax.\n(only double quotes and backslash need to be escaped in a phrase, so it should cover a big number of future extensions)\n\nSomething like this would work for base64, but it would be target at programmatic layer, since users will not be able to generate that base64 strings, and it is supported by the syntax described above.\n{quote}\n\nbinary:image:\"base64:TWFuIGlzIGRpc3Rpbmd1aXNoZWQsIG5vdCBvbmx5IGJ5IGhpcyByZWFzb24sIGJ1dCBieSB0aGlz\"\n\n{quote}\n\nFor extensions that won't work well with escaping double quotes and back-slash, we probably need some other delimiter, probably more than a single character\nsome sugestions below:\n{quote}\nxml style:\n1) xpath:xmlfield:<[[ //title[@lang=\"c:\\windowspath\\folder\" ]]>\n2) xpath:xmlfield:<![CDATA[ //title[@lang=\"c:\\windowspath\\folder\" ]]>\n\nanother one\n3) xpath:xmlfield:\\![CDATA[ //title[@lang=\"c:\\windowspath\\folder\" ]]!\n\n{quote}\n\nAny of the sequences above is good OK with me. \nThis should not affect old queries very much since the new syntax tokens would be \n\":<[[ \"  and \"]]>\" and these shouldn't be common on any lucene queries.\nStill not very user friendly, but better than the base64 approach.\n\n\n\n",
            "date": "2009-11-12T20:19:16.741+0000",
            "id": 14
        },
        {
            "author": "Simon Willnauer",
            "body": "Luis,\n{quote}\n    syntax:\n    extension:fieldname:\"syntax\"\n\n    examples:\n    regexp:title:\"/blah[a-z]+[0-9]+/\" <- regexp extension, title index field\n    complex_phrase:title:\"(sun OR sunny) sky\" <- complex_phrase extension, title index field\n\n    regexp_phrase::\"/blah[a-z]+[0-9]+/\" <- regexp extension, default field\n    complex_phrase::\"(sun OR sunny) sky\" <- complex_phrase extension, default field\n\n    title:\"blah\" <- regular field query\n{quote}\n\nThis is pretty much what I suggested above. We can extend the queryparser without breaking the backwards compatibility just by adding some code which is aware of the fieldname scheme. Even this could be extendable. FieldNames are terms and therefore they can not contain unescaped special chars like : { ] ... I would not even hard code the separator into the query parser but have the field name processed by something pluggable. So If somebody wants to have a regex extension they could use re\\:field: or re\\:: or re_field:.... \nEscaping a field is easy, just like you would do it with a term. \nMore interesting is that we do not change any syntax, no special character but we can add a default implementation with a default implementation for extensions. This could be a whole API which takes are of creating and escaping the field name, building the query once it is passed to the extension etc. \nIn a first step we can resolve the extension the second step calls the extension and build the query. If no extension is registered the query parser works like in previous versions so it is all up to the user.\n\n@Adriano:\n{quote}\nThe only part I disagree is when you pass the fieldname to the extension parser, I wouldn't implement that on the contrib parser, because it assumes the syntax always has field names. Anyway, for the core QP, I see the reason why you pass the fieldname\n{quote}\n\nYou need the field to create you query in the extension, the field will always be set to either the default field or the explicitly defined field in the query. No reason why we should not pass it.\nI agree with you that we should wrap the information in a class so that we do not need to change the method signature if something has to be changed in the future. Instead we just add a new member to the wrapper though.\n",
            "date": "2009-11-13T11:36:24.395+0000",
            "id": 15
        },
        {
            "author": "Adriano Crestani",
            "body": "{quote}\nThis is pretty much what I suggested above. We can extend the queryparser without breaking the backwards compatibility just by adding some code which is aware of the fieldname scheme. Even this could be extendable. FieldNames are terms and therefore they can not contain unescaped special chars like : { ] ... I would not even hard code the separator into the query parser but have the field name processed by something pluggable. So If somebody wants to have a regex extension they could use re\\:field: or re\\:: or re_field:....\nEscaping a field is easy, just like you would do it with a term.\nMore interesting is that we do not change any syntax, no special character but we can add a default implementation with a default implementation for extensions. This could be a whole API which takes are of creating and escaping the field name, building the query once it is passed to the extension etc.\nIn a first step we can resolve the extension the second step calls the extension and build the query. If no extension is registered the query parser works like in previous versions so it is all up to the user.\n{quote}\n\n+1 :)\n\n{quote}\nI agree with you that we should wrap the information in a class so that we do not need to change the method signature if something has to be changed in the future. Instead we just add a new member to the wrapper though.\n{quote}\n\nA Map should solve this problem",
            "date": "2009-11-13T21:23:53.015+0000",
            "id": 16
        },
        {
            "author": "Luis Alves",
            "body": "+1 \n\nI'm work on changing the queryparser on Contrib, to implement that syntax for the opaque terms.",
            "date": "2009-11-17T01:45:39.788+0000",
            "id": 17
        },
        {
            "author": "Simon Willnauer",
            "body": "This patch implements the field:ext: approach. I will do some more work on the javadoc - pushing it out for comments!\n\nComments on class naming are welcome too :)",
            "date": "2009-11-18T21:45:03.847+0000",
            "id": 18
        },
        {
            "author": "Luis Alves",
            "body": "Hi Simon,\n\nI also posted a patch in LUCENE-1823, that implements the ext:field approach, and added a junit that implements a new QParser for regex.\n\nIf you have time can you take a look at the classes in the standart2 test folder, RegexQueryParser amd TestOpaqueExtensionQuery and review the testcase\n\n",
            "date": "2009-11-18T22:23:52.801+0000",
            "id": 19
        },
        {
            "author": "David Kaelbling",
            "body": "I apologize if I haven't read the comments carefully enough, but in LUCENE-2039_field_ext.patch why is ExtendableQueryParser final?  That means (for example) that ComplexPhraseQueryParser cannot subclass it.  In the earlier LUCENE-2039.patch the complex phrase parser picked up the changes for free.\n\nAnd would RegexParserExtension maybe be easier to use if it set the RegexCapabilities on the new RegexQuery it is returning?\n",
            "date": "2009-11-19T18:38:18.742+0000",
            "id": 20
        },
        {
            "author": "Robert Muir",
            "body": "Hi, in my opinion RegexParserExtension should not be  tied to RegexQuery/RegexCapabilities.\nThis is only one possible implementation of regex support and has some scalability problems.\n",
            "date": "2009-11-19T20:26:50.526+0000",
            "id": 21
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. That means (for example) that ComplexPhraseQueryParser cannot subclass it\nThis patch was not meant to include ComplexPhraseQueryParser it is rather a proposal for the concept of field \"overloading\". But you are right the parser should not be final at all especially if you wanna override a get*query method it should be expendable. \n\nbq. Hi, in my opinion RegexParserExtension should not be tied to RegexQuery/RegexCapabilities.\nThis is only one possible implementation of regex support and has some scalability problems. \n\nAlso true, but again this is just a POC to show how it would look like. Comments on the concept would be more useful by now. \nI did write that up during a train ride and aimed to get some comments. I already have worked on it and will upload a new patch soon which includes RegexCapabilities + tests. \nThanks again for the pointer with the final class.",
            "date": "2009-11-19T20:38:21.658+0000",
            "id": 22
        },
        {
            "author": "Simon Willnauer",
            "body": "Updated the patch\n - removed final modifier from ExtendableQueryParser\n - added RegexCapabilities ctor to RegexParserExtension\n\nI still need to work on the Extensions JavaDoc - and I'm not too happy with the name. \n\nComments on the concept are very welcome.",
            "date": "2009-11-19T21:09:51.720+0000",
            "id": 23
        },
        {
            "author": "Mark Miller",
            "body": "It looks like the patch puts this in core? Any compelling reason? Offhand I'd think it would go in the misc contrib with the other queryparsers that extend the core queryparser.",
            "date": "2009-11-19T22:42:01.765+0000",
            "id": 24
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Offhand I'd think it would go in the misc contrib with the other queryparsers that extend the core queryparser. \n\nFor sure. I will attach another patch - did not thing about that too much when I moved from the first proposal which modified the core one.\n",
            "date": "2009-11-21T20:15:12.845+0000",
            "id": 25
        },
        {
            "author": "Simon Willnauer",
            "body": "moved ext parser to contrib/misc",
            "date": "2009-11-21T20:17:35.568+0000",
            "id": 26
        },
        {
            "author": "Simon Willnauer",
            "body": "Took over from Grant ",
            "date": "2009-11-24T16:32:36.025+0000",
            "id": 27
        },
        {
            "author": "Simon Willnauer",
            "body": "I finished the JavaDoc, added package.html file.\nI again refactored RegexParserExtension to use a factory method to obtain an instance of RegexCapabilities. RegexCapabilities is stateful and can not be shared so subclassing to change seems to be reasonable. JavaUtil seems to be reasonable anyway after the latest Jakarta Regexp drama :).\n\nI had to introduce a compile time dependency from regex to misc to build the extension - should add misc as a dependency to maven in this case?",
            "date": "2009-11-25T18:07:57.014+0000",
            "id": 28
        },
        {
            "author": "Robert Muir",
            "body": "bq. JavaUtil seems to be reasonable anyway after the latest Jakarta Regexp drama\n\nyeah, we shouldn't mislead anyone into believing the constant prefix with jakarta actually works even now.\nfor example the constant prefix of (ab|ac) is not \"a\" but instead empty string.\n",
            "date": "2009-11-25T18:14:34.510+0000",
            "id": 29
        },
        {
            "author": "Simon Willnauer",
            "body": "The contrib/regex dependency on contrib/misc buggs me a bit though. I have the impression that this regex default extension should not be part of this patch. The extension seems to be so trivial that users could implement it on their own. This would save us the dependency and IMO would not be a problem for users though.\n\n Any thoughts?",
            "date": "2009-11-30T09:51:41.684+0000",
            "id": 30
        },
        {
            "author": "Simon Willnauer",
            "body": "I removed the RegexExtension in this patch as in my opinion this is not worth the dependency. As soon as roberts automation patch is in core we won't have this problem anymore anyway.\nUsers should add trivial extensions like on their own. \nOne other thing I was thinking about is adding another ExtensionParser which subclasses ComplexPhraseQueryParser. This is a benefit from moving it into misc, I think we should do it. \nThoughts?",
            "date": "2009-12-01T15:27:56.736+0000",
            "id": 31
        },
        {
            "author": "Mark Miller",
            "body": "bq. One other thing I was thinking about is adding another ExtensionParser which subclasses ComplexPhraseQueryParser.\n\nWe should be careful here - the thought at one time was to remove ComplexPhraseQueryParser soon and replace it with one written for the new QueryParser. In that case, we might not want to add more that relies on it - the new one might not match the feature/results of the old one. Just an FYI though. In my mind, who knows if that will end up happening, and it shouldn't necessarily block other good work just because it might. Just thought I'd mention it.",
            "date": "2009-12-01T15:42:37.755+0000",
            "id": 32
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. ...was to remove ComplexPhraseQueryParser soon and replace it with one written for the new QueryParser.\nThanks Mark, I do not recall this so good that you mention it again. Either way, this was just a suggestion which came to my mind. Another suggestion for maybe a future development is to move this into the core query parser as it does not change any behavior as long as you do not explicitly specify any extension. \nTo me these ideas are future considerations which could be done in sep. issues once this is in. I plan to commit the current patch until 12/06/09 if nobody objects.",
            "date": "2009-12-02T17:32:14.198+0000",
            "id": 33
        },
        {
            "author": "Simon Willnauer",
            "body": "I will commit this tomorrow if nobody objects.",
            "date": "2009-12-04T23:43:50.976+0000",
            "id": 34
        },
        {
            "author": "Simon Willnauer",
            "body": "Commited in revision 887533",
            "date": "2009-12-05T12:30:16.873+0000",
            "id": 35
        },
        {
            "author": "David Kaelbling",
            "body": "Currently the master parser doesn't pass settings down to the extension parsers (things like setAllowLeadingWildcard, setMultiTermRewriteMethod, etc.)   Should it?\n",
            "date": "2009-12-09T22:05:20.442+0000",
            "id": 36
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Currently the master parser doesn't pass settings down to the extension parsers (things like setAllowLeadingWildcard, setMultiTermRewriteMethod, etc.) Should it? \nDavid, so some sort of parsers this would make sense though. Yet, we either reflect all of the setting from the \"master\" parser or none of it. I would suggest to modify the ExtensionQuery ctor to take a QueryParser instance and add the corresponding getters to it. That way we can maintain a consistent view on the setting even if they are reset on the master parser without overriding all setters though. Would that make sense?\nAnother way of enable this is to pass the query parser instance into ExtensionQuery and simply add a getter so extension parsers can access the parser and its utilities too.\nAnyhow, we should open a new issue for that. I will do so",
            "date": "2009-12-11T12:03:38.804+0000",
            "id": 37
        },
        {
            "author": "David Kaelbling",
            "body": "> I would suggest to modify the ExtensionQuery ctor to take a QueryParser instance and add \n> the corresponding getters to it. That way we can maintain a consistent view on the setting \n> even if they are reset on the master parser without overriding all setters though. Would \n> that make sense?\n\nSimon, it sounds like the right direction! But relying on ExtensionParser implementors to manually copy all the parent settings to the child seems like a maintenance problem.  We add new settings relatively often. Unfortunately there's nothing like the token Attribute stuff for QueryParser...\n\n\n> Another way of enable this is to pass the query parser instance into ExtensionQuery and \n> simply add a getter so extension parsers can access the parser and its utilities too.\n\nUmm, I don't quite follow.  If the extension wraps an existing parser, the extension would have to subclass it, override all the getters/setters to delegate to the parent, and trust that everyone uses them?  That's not currently true -- for example QueryParser.getPrefixQuery() directly accesses allowLeadingWildcard, without using the getter.  There are probably other cases too, that's just the first one I checked.\n",
            "date": "2009-12-11T16:29:54.710+0000",
            "id": 38
        },
        {
            "author": "Simon Willnauer",
            "body": "{quote}\nSimon, it sounds like the right direction! But relying on ExtensionParser implementors to manually copy all the parent settings to the child seems like a maintenance problem. We add new settings relatively often. Unfortunately there's nothing like the token Attribute stuff for QueryParser...\n{quote}\nyeah that is the reason why I suggested passing the top level parser instance itself to the extension and expose it there.\n\n{quote}\nUmm, I don't quite follow. If the extension wraps an existing parser, the extension would have to subclass it, override all the getters/setters to delegate to the parent, and trust that everyone uses them? That's not currently true - for example QueryParser.getPrefixQuery() directly accesses allowLeadingWildcard, without using the getter. There are probably other cases too, that's just the first one I checked.\n{quote}\n\nDavid here is an example of what I mean by wrapping the top level parser. This would give you access to all the settings right away inside your extension.",
            "date": "2009-12-11T16:38:57.978+0000",
            "id": 39
        },
        {
            "author": "David Kaelbling",
            "body": "> David here is an example of what I mean by wrapping the top level parser. This would give \n> you access to all the settings right away inside your extension.\n\nMaybe I'm oversimplifying.  As a lazy implementor I want to write something like this:\n\next.add(\"regex\", new ParserExtension() {\n  public Query parse(ExtensionQuery q) throws ParseException {\n      return new RegexQuery(new Term(q.getField(), q.getRawQueryString()));\n} } );\n\nMy ParserExtension can query any top level parser settings it likes, but how do I get those\nvalues down into RegexQuery?  Or whatever full parser I'm invoking?\n",
            "date": "2009-12-14T16:12:36.806+0000",
            "id": 40
        },
        {
            "author": "Simon Willnauer",
            "body": "Am I missing something? Why not using the getTopLevelParser() method?\nlike that:\n{code}\n extensions.add(\"regex\", new ParserExtension() {\n\t\t\n\t\t@Override\n\t\tpublic Query parse(ExtensionQuery query) throws ParseException {\n\t\t\tboolean enableWildcards = query.getTopLevelParser().getAllowLeadingWildcard();\n\t\t\treturn new RegexQuery(new Term(query.getField(), query.getRawQueryString()));\n\t\t}\n\t});\n\n{code}\nI mean enableWildcards doesn't do anything here but you can take whatever settings you like as shown above.\nsimon",
            "date": "2009-12-14T16:49:12.025+0000",
            "id": 41
        },
        {
            "author": "David Kaelbling",
            "body": "Hi Simon -- sorry, an example using a full query parser rather than just RegexQuery would have been clearer.  What I'm worried about is that I don't in general know all the parent settings that need to be mirrored in the nested parser.  Writing nestedParser.setFoo(topLevelParser.getFoo()) calls for all possible Foo, past, present, and future, is going to bite me eventually.\n",
            "date": "2009-12-14T18:17:21.158+0000",
            "id": 42
        },
        {
            "author": "Simon Willnauer",
            "body": "David, I assume you use a subclass of QueryParser inside your ParserExtension and your are worried about reflecting all properties of the top level parser into your sub parser?! I understand what your issues are but I do not see another way than pulling the properties from the top level parser once you need it. If you rely on an already existing parser that does not allow you to call the getters in place you probably have to set them each time if you really need all of those. I don't see another way to do it, do you?\n\nsimon",
            "date": "2009-12-14T20:05:01.119+0000",
            "id": 43
        },
        {
            "author": "David Kaelbling",
            "body": "bq. I do not see another way than pulling the properties from the top level parser once you need it.\n\nExactly! :-)  I don't see another way either, hence my original lament that QueryParser didn't have anything like Token attributes where all the state was extracted into a separate sharable entity.\n\nI can live with hard-coding knowledge of both the top level- and embedded-parser settings in the ParserExtension implementation.  I was just hoping for a better way.\n",
            "date": "2009-12-14T21:15:55.074+0000",
            "id": 44
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Exactly! I don't see another way either, hence my original lament that QueryParser didn't have anything like Token attributes where all the state was extracted into a separate sharable entity.\nDavid, FYI  I created  a new issue for that (LUCENE-2162)",
            "date": "2009-12-15T11:11:35.354+0000",
            "id": 45
        },
        {
            "author": "Yonik Seeley",
            "body": "Reopening, as I believe the grammar as implemented is a bit flawed.\n\nA simple query of foo/bar will now fail since the slash in the middle of the term is seen as the start of a regex.",
            "date": "2012-09-06T13:49:34.417+0000",
            "id": 46
        },
        {
            "author": "Hoss Man",
            "body": "Yonik: strongly suggest you open a new issue to address this, since LUCENE-2039 is already listed as a feature added in 4.0-ALPHA.\n\nif you \"fix\" this mid string slash issue, you're going to want a unique jira id to refer to when citing the bug fix as a CHANGES.txt for 4.0-final, or no one will have any clear idea what works where.",
            "date": "2012-09-06T17:15:38.443+0000",
            "id": 47
        },
        {
            "author": "Alexandre Rafalovitch",
            "body": "This can be re-closed as it was fixed in beta by SOLR-3467 .",
            "date": "2012-09-07T13:11:26.735+0000",
            "id": 48
        },
        {
            "author": "Uwe Schindler",
            "body": "Closed after release.",
            "date": "2013-05-10T10:34:20.719+0000",
            "id": 49
        }
    ],
    "component": "core/queryparser",
    "description": "Since the early days the standard query parser was limited to the queries living in core, adding other queries or extending the parser in any way always forced people to change the grammar file and regenerate. Even if you change the grammar you have to be extremely careful how you modify the parser so that other parts of the standard parser are affected by customisation changes. Eventually you had to live with all the limitation the current parser has like tokenizing on whitespaces before a tokenizer / analyzer has the chance to look at the tokens. \nI was thinking about how to overcome the limitation and add regex support to the query parser without introducing any dependency to core. I added a new special character that basically prevents the parser from interpreting any of the characters enclosed in the new special characters. I choose the forward slash  '/' as the delimiter so that everything in between two forward slashes is basically escaped and ignored by the parser. All chars embedded within forward slashes are treated as one token even if it contains other special chars like * []?{} or whitespaces. This token is subsequently passed to a pluggable \"parser extension\" with builds a query from the embedded string. I do not interpret the embedded string in any way but leave all the subsequent work to the parser extension. Such an extension could be another full featured query parser itself or simply a ctor call for regex query. The interface remains quiet simple but makes the parser extendible in an easy way compared to modifying the javaCC sources.\n\nThe downsides of this patch is clearly that I introduce a new special char into the syntax but I guess that would not be that much of a deal as it is reflected in the escape method though. It would truly be nice to have more than once extension an have this even more flexible so treat this patch as a kickoff though.\n\nAnother way of solving the problem with RegexQuery would be to move the JDK version of regex into the core and simply have another method like:\n{code}\nprotected Query newRegexQuery(Term t) {\n  ... \n}\n{code}\n\nwhich I would like better as it would be more consistent with the idea of the query parser to be a very strict and defined parser.\n\nI will upload a patch in a second which implements the extension based approach I guess I will add a second patch with regex in core soon too.\n\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2039",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Critical",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Regex support and beyond in JavaCC QueryParser",
    "systemSpecification": true,
    "version": ""
}