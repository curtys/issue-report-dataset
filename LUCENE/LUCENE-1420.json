{
    "comments": [
        {
            "author": "Andrzej Bialecki ",
            "body": "This patch adds Similarity,length(fieldName, numTokens, numOverlapTokens), and provides backward-compatible implementation in Similarity.java.",
            "date": "2008-10-13T13:50:24.920+0000",
            "id": 0
        },
        {
            "author": "Michael McCandless",
            "body": "Looks good, thanks Andrzej.  I plan to commit in a day or two.",
            "date": "2008-10-13T17:06:43.461+0000",
            "id": 1
        },
        {
            "author": "Hoss Man",
            "body": "1) i only skimmed this quickly, but i don't think the changes to SweetSpotSimilarity are back compatible ... setLengthNormFactors has a new arg list.\n\n2) ditto for the public \"Info\" constructor in MemoryIndex.java\n\n3) as long as we are adding a new lengthNorm method that has access to new data about the stream, would it also make sense to pass in fieldState.position?  and/or a new count of hte number of times getPositionIncrementGap(fieldInfo.name) is called?  Those also seem like they could be useful, and should be just as cheap to keep track of as numOverlap and length.  (this occured to me because of recent threads on solr-user asking about lengthNorm and multivalued fields ... there may only be one fieldNorm per field name, but with stats like that we could at least do some interesting things based on the average length of each field value.\n\n4) independent of #3, we may want to consider making FieldInvertState a public class and passing it directly to lengthNorm ... that way lengthNorm can utilize whatever data it wants, and we can add more available data later without changing the API again.  We could even deprecate lengthNorm entirely and add a new FieldInvertState.norm property that a new Similarity.computeNorm(FieldInvertState) could set directly so it could choose to ignore the doc & field boosts altogether if it wanted to.",
            "date": "2008-10-15T00:27:21.677+0000",
            "id": 2
        },
        {
            "author": "Michael McCandless",
            "body": "Re 1 & 2: I agree.  Even though the back compat is \"looser\" for contribs, we still should not break it unless we have to.  In this case we definitely don't have to.\n\nRe 3 & 4: I like this in principle, but I'm nervous about making FieldInvertState public since it's such a new API.  I guess if we put the \"this API is new & subject to change\" caveat on there, to reserve the right to change it, that's OK.  I also like having Similiarity.computeNorm factor in the boost, and extending FieldInverState to track the number of field occurrences that had been processed.\n\nAndrzej, can you update the patch to address these issues?",
            "date": "2008-10-16T09:28:47.743+0000",
            "id": 3
        },
        {
            "author": "Michael McCandless",
            "body": "Andrzej are you [going to] work out a new patch here?  I'd like to bring closure.",
            "date": "2008-10-25T10:39:00.647+0000",
            "id": 4
        },
        {
            "author": "Andrzej Bialecki ",
            "body": "Patch that uses FieldInvertState, as suggested. Changes in other classes are limited to minimum in this patch - users of Similarity other than o.a.l.index.* still use lengthNorm(String, int).",
            "date": "2008-10-25T22:56:22.640+0000",
            "id": 5
        },
        {
            "author": "Michael McCandless",
            "body": "Thanks Andrzej.\n\nI made some further changes (attached new patch):\n\n  * Changed the new Similarity.computeNorm(String, FieldInvertState)\n    method to return the float norm instead of setting it on the\n    FieldInvertState.  I also removed FieldInvertState.{get,set}Norm.\n\n  * I put back the changes to SweetSpotSimilarity & MemoryIndex, but\n    kept the old APIs (deprecated) for back compat.\n\n  * I added {set/get}DiscountOverlaps to DefaultSimilarity, and also\n    overrode computeNorm to use discountOverlaps to compute the number\n    of tokens to pass to lengthNorm.\n\n  * The Info class is private inside MemoryIndex, even though its ctor\n    is public, so, I just added boolean to its ctor (ie, there's no\n    back-compat issue).\n\n  * Tweaked javadocs\n\nSo now, both DefaultSimilarity and SweetSpotSimilarity have the option\nto discount overlaps, but do not do so by default.",
            "date": "2008-10-28T14:04:59.612+0000",
            "id": 6
        },
        {
            "author": "Andrzej Bialecki ",
            "body": "Thanks for a thorough review. I'm fine with these changes, and the idea to gently introduce discountOverlaps in the Similarity API is great. Please go ahead if there are no further objections.",
            "date": "2008-10-28T15:16:12.353+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "OK thanks Andrzej.  I plan to commit in a day or two.",
            "date": "2008-10-29T19:15:51.095+0000",
            "id": 8
        },
        {
            "author": "Michael McCandless",
            "body": "Committed revision 710117.  Thanks Andrzej!",
            "date": "2008-11-03T18:05:08.248+0000",
            "id": 9
        }
    ],
    "component": "core/index",
    "description": "Calculation of lengthNorm factor should in some cases take into account the number of tokens with positionIncrement=0. This should be made optional, to support two different scenarios:\n\n* when analyzers insert artificially constructed tokens into TokenStream (e.g. ASCII-fied versions of accented terms, stemmed terms), and it's unlikely that users submit queries containing both versions of tokens: in this case lengthNorm calculation should ignore the tokens with positionIncrement=0.\n\n* when analyzers insert synonyms, and it's likely that users may submit queries that contain multiple synonymous terms: in this case the lengthNorm should be calculated as it is now, i.e. it should take into account all terms no matter what is their positionIncrement.\n\nThe default should be backward-compatible, i.e. it should count all tokens.\n\n(See also the discussion here: http://markmail.org/message/vfvmzrzhr6pya22h )",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-1420",
    "issuetypeClassified": "IMPROVEMENT",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Major",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Similarity.lengthNorm and positionIncrement=0",
    "systemSpecification": true,
    "version": "2.9"
}