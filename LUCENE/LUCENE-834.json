{
    "comments": [
        {
            "author": "Grant Ingersoll",
            "body": "First draft at a BoostingTermQuery, which is based on the SpanTermQuery and can be used for boosting the score of a term based on what is in the payload (for things like weighting terms higher according to their font size or part of speech).  \n\nA couple of classes that were previously package level are now public and have been marked as Public and for derivational purposes only.\n\n\nSee the CHANGES.xml for some more details.\n\nI believe all tests still pass.",
            "date": "2007-03-17T21:41:23.215+0000",
            "id": 0
        },
        {
            "author": "Grant Ingersoll",
            "body": "I should add, one open question is how big the array in the BoostingSpanScorer should be preallocated to.  I set it to 256, but I would imagine it could be smaller???? but I'm not sure.  Probably should be configurable, but I didn't go that route.  I would think, for practical purposes, that payloads should be kept small for the most part, otherwise performance will most likely suffer.  What do others think?  Have you seen papers/applications where the engine is storing large amounts of data on a per term basis?\n\nI could see where it might be useful to write VInts, etc. to the payload.  Perhaps a refactoring of some of the writing/reading methods to allow for usage of them may be useful.  Just thinking out loud...",
            "date": "2007-03-17T23:01:56.590+0000",
            "id": 1
        },
        {
            "author": "Grant Ingersoll",
            "body": "I committed this patch, plus added in some more documentation.  Everything is still marked experimental.\n\nSVN revision: 523302.",
            "date": "2007-03-28T12:59:04.681+0000",
            "id": 2
        },
        {
            "author": "Michael Busch",
            "body": "Hi Grant,\n\ncool that you started implementing queries that use of payloads! I have a question about this one: BoostingTermQuery only takes the payload of the first term position into account for scoring. Could you explain why you implemented it this way? Shouldn't we rather compute the average of the payload values of all positions?",
            "date": "2007-04-17T19:31:44.478+0000",
            "id": 3
        },
        {
            "author": "Grant Ingersoll",
            "body": "Uh, because I always forget about multiple terms per position?  :-)  Mea culpa.\n\nAverage sounds good, or, would it be better to deliver all the payloads at a given term and let the implementation decide?",
            "date": "2007-04-17T19:47:39.397+0000",
            "id": 4
        },
        {
            "author": "Michael Busch",
            "body": "I think averaging should be the default, but you are right, it would be nice if it was possible to alter this, maybe via subclassing?. I wouldn't recommend to gather all payloads and send them to Similarity. Memory consumption would be proportional to posting list size then.",
            "date": "2007-04-17T20:20:10.382+0000",
            "id": 5
        },
        {
            "author": "Marvin Humphrey",
            "body": "Would it be so bad if memory consumption was proportional to posting list size?  True, special consideration might be necessary for large documents if payloads were large, and if you have any Query subclasses that rewrite themselves to a zillion subqueries, each of which maintains its own TermPositions subclass instance, that could pose difficulties. What are some other problematic scenarios?",
            "date": "2007-04-17T21:06:54.618+0000",
            "id": 6
        },
        {
            "author": "Michael Busch",
            "body": "Yes, I was mainly thinking about large documents. I think in general memory consumption during search should depend on query complexity, not on the actual index.\nBesides, I don't see much benefits in gathering all payloads up front and processing them thereafter (maybe I overlook some?). What about having a method in BoostingTermScorer like:\n\nprotected float calculateTermBoost(TermPostions tp);\n\nwhich implements averaging per default but can be overwritten by subclasses? An optimized implementation might e. g. consider just to read the first x% position payloads for large docs and estimate the boost for performance reasons.",
            "date": "2007-04-17T22:12:29.498+0000",
            "id": 7
        },
        {
            "author": "Marvin Humphrey",
            "body": "Averaging is how I've got this implemented by default in KS.  However, all positions and boosts get read in at once.  TermDocs/TermPositions has been replaced by PostingList, which goes doc by doc.  The type of Posting assigned to each field (MatchPosting, ScorePosting, RichPosting, eventually PayloadPosting) determines how much gets read in. (KS doesn't have any queries that rewrite(), so it's only large docs that are an issue.)\n\nI haven't yet worked out the mechanics of per-position boosts and phrase queries.",
            "date": "2007-04-17T22:48:29.800+0000",
            "id": 8
        },
        {
            "author": "Grant Ingersoll",
            "body": "Fixed the issue with only loading one payload per term and added unit test for it.  The unit test uses the multiField field that contains a repeat of each set of terms per document. \n\nUpdated the docs on the Similarity to indicate what offset and length are used for.  ",
            "date": "2007-04-21T16:54:58.112+0000",
            "id": 9
        },
        {
            "author": "Grant Ingersoll",
            "body": "I applied and committed this patch",
            "date": "2007-04-24T18:13:11.200+0000",
            "id": 10
        }
    ],
    "component": "core/search",
    "description": "Now that payloads have been implemented, it will be good to make them searchable via one or more Query mechanisms.  See http://wiki.apache.org/lucene-java/Payload_Planning for some background information and https://issues.apache.org/jira/browse/LUCENE-755 for the issue that started it all.  ",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-834",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Payload Queries",
    "systemSpecification": true,
    "version": ""
}