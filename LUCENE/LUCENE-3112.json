{
    "comments": [
        {
            "author": "Michael McCandless",
            "body": "Initial patch.\n\nIt's not done yet (needs tests, and the nocommit needs to be addressed).",
            "date": "2011-05-17T10:51:12.154+0000",
            "id": 0
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Initial patch.\n\nnice simple idea! I like the refactorings into pre/postUpdate - looks much cleaner. Yet, I think you should push the document iteration etc into DWPT to actually apply the delterm only once to make it really atomic. I also wonder if we should allow multiple delTerm e.g. Tuple<DelTerm, Document> otherwise you would be bound to one delterm pre \"collection\" but what if you want to remove only one of the \"sub-documents\"? So if we would have those tuples you really want to push the iteration into DWPT to make a final finishDocument(Term[] terms) call pushing the terms into a single DeleteItem.\n\n",
            "date": "2011-05-17T11:09:48.853+0000",
            "id": 1
        },
        {
            "author": "Robert Muir",
            "body": "We should really think through the consequences of this though.\n\nIf core features of lucene become implemented in a way that they rely upon these sequential docids, we then lock ourselves out of future optimizations such as reordering docids for optimal index compression.\n",
            "date": "2011-05-17T11:42:36.478+0000",
            "id": 2
        },
        {
            "author": "Jason Rutherglen",
            "body": "I think perhaps like a Hadoop input format split, we can define meta-data at the segment level as to where the documents live so that if one is 'splitting' the index, as is being implemented with HBase, the 'splitter' can be 'smart'.",
            "date": "2011-05-17T12:13:41.952+0000",
            "id": 3
        },
        {
            "author": "Michael McCandless",
            "body": "bq. Yet, I think you should push the document iteration etc into DWPT to actually apply the delterm only once to make it really atomic.\n\nAhh good point -- it's wrong just passing that delTerm down N times, too.  I'll fix.\n\nbq. I also wonder if we should allow multiple delTerm e.g. Tuple<DelTerm, Document> otherwise you would be bound to one delterm pre \"collection\" but what if you want to remove only one of the \"sub-documents\"?\n\nSo, this won't work today w/ nested querying, if I understand it right.  Ie, if you only update one of the subs, now your subdocs are no longer sequential (nor in one segment).  So I think \"design for today\" here...?\n\nSomeday, when we implement incremental field updates correctly, so that updates are written as stacked segments against the original segment containing the document, at that point I think we can add an API that lets you update multiple docs atomically?\n{quote}",
            "date": "2011-05-17T13:14:24.478+0000",
            "id": 4
        },
        {
            "author": "Michael McCandless",
            "body": "{quote}\nWe should really think through the consequences of this though.\n\nIf core features of lucene become implemented in a way that they rely upon these sequential docids, we then lock ourselves out of future optimizations such as reordering docids for optimal index compression.\n{quote}\n\nI agree it's somewhat dangerous we are making an (experimental)\nguarantee that these docIDs will remain adjacent \"forever\".  We\nnormally are very protective about letting apps rely on docID\nassignment/order.\n\nBut, I think this will not be \"core\" functionality that relies on\nsub-docs (adjacent docs), but rather modules -- grouping, faceting,\nnestedqueries/queries.  And, even if you use these modules, it's\noptional whether the app did sub-docs.  Ie we would still have the\n'generic\" grouping collector, but then also an optimized one that\ntakes advantage of sub-docs.\n\nFinally, I think doing this today would not preclude doing docID\nreording in the future because the sub docs would be recomputable\nbased on the \"identifier\" field which grouped them in the first\nplace.\n\nIe the worst case future scenario (an app uses this new sub-docs\nfeature, but then has a big index they don't want to reindex and wants\nto take advantage of a future docid reording compression we add) would\nstill be solvable because we could use this identifier field to find\nblocks of sub-docs.\n\nI suppose we could consider changing the index format today to record\nwhich docs are subs... but I think we don't need to.  Maybe I should\nstrengthen the @experimental to explain the risk that a future\nreindexing could be required?\n",
            "date": "2011-05-17T16:20:54.702+0000",
            "id": 5
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nI suppose we could consider changing the index format today to record\nwhich docs are subs... but I think we don't need to. Maybe I should\nstrengthen the @experimental to explain the risk that a future\nreindexing could be required?\n{quote}\n\nI think this would be perfect. I certainly don't want to hold up this \nimprovement, yet, in the future I just didnt want us to be in a \nsituation where we say 'well if only we had recorded this information,\nnow its not possible to do XYZ because someone COULD have used \nadd/updateDocuments() for some arbitrary reason and we will 'split' \ntheir grouped ids'.\n\nWe could also include in the note that various existing \nIndexSorters/Splitters are unaware about this, so use with caution :)\n",
            "date": "2011-05-17T16:26:23.271+0000",
            "id": 6
        },
        {
            "author": "Michael McCandless",
            "body": "New patch, I think it's ready to commit but it could use some healthy reviewing...\n\nI fang'd up TestNRThreads to add/update doc blocks and verify the docs in each block remain adjacent, and also added a couple other test cases to make sure we test non-aborting exceptions when adding a doc block.\n\nAnd I put warning in the jdocs about possible future full re-indexing.",
            "date": "2011-05-19T13:24:53.082+0000",
            "id": 7
        },
        {
            "author": "Michael McCandless",
            "body": "Fixed.\n\nOnly hitch was in 3.x the APIs take Collection<Document> (vs trunk's Iterable<Document>).  If we backport DWPT we can put it back to Iterable<Document>...",
            "date": "2011-05-23T21:01:50.417+0000",
            "id": 8
        },
        {
            "author": "Steve Rowe",
            "body": "Mike, when you put the branch_3x port back, contrib/misc's IndexSplitter.java has javadocs references to IndexWriter#addDocuments(Iterable), instead of IW#aDs(Collection) - this triggers javadocs warnings which fail the build.",
            "date": "2011-05-24T13:08:39.706+0000",
            "id": 9
        },
        {
            "author": "Michael McCandless",
            "body": "Argh!  Thanks Steven -- I will fix those jdocs 2nd time around.",
            "date": "2011-05-24T14:27:01.527+0000",
            "id": 10
        },
        {
            "author": "Steve Rowe",
            "body": "bq. IndexSplitter.java has javadocs references\n\nOops, I got the trunk javadocs problem mixed up with the branch_3x javadocs problem...\n\nThe incorrect references are actually in IndexWriter.java itself, on updateDocuments() methods.",
            "date": "2011-05-24T15:58:38.389+0000",
            "id": 11
        },
        {
            "author": "Robert Muir",
            "body": "Bulk closing for 3.2",
            "date": "2011-06-03T16:37:18.090+0000",
            "id": 12
        }
    ],
    "component": "",
    "description": "I think nested documents (LUCENE-2454) is a very compelling addition\nto Lucene.  It's also a popular (many votes) issue.\n\nBeyond supporting nested document querying, which is already an\nincredible addition since it preserves the relational model on\nindexing normalized content (eg, DB tables, XML docs), LUCENE-2454\nshould also enable speedups in grouping implementation when you group\nby a nested field.\n\nFor the same reason, it can also enable very fast post-group facet\ncounting impl (LUCENE-3097) when you what to\ncount(distinct(nestedField)), instead of unique documents, as your\n\"identifier\".  I expect many apps that use faceting need this ability\n(to count(distinct(nestedField)) not distinct(docID)).\n\nTo support these use cases, I believe the only core change needed is\nthe ability to atomically add or update multiple documents, which you\ncannot do today since in between add/updateDocument calls a flush (eg\ndue to commit or getReader()) could occur.\n\nThis new API (addDocuments(Iterable<Document>), updateDocuments(Term\ndelTerm, Iterable<Document>) would also further guarantee that the\ndocuments are assigned sequential docIDs in the order the iterator\nprovided them, and that the docIDs all reside in one segment.\n\nSegment merging never splits segments apart, so this invariant would\nhold even as merges/optimizes take place.\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3112",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Add IW.add/updateDocuments to support nested documents",
    "systemSpecification": true,
    "version": ""
}