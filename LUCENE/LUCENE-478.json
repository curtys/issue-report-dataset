{
    "comments": [
        {
            "author": "Daniel Naber",
            "body": "This is how the code looks currently:\n\n| < CJ:                                          // Chinese, Japanese\n      [\n       \"\\u3040\"-\"\\u318f\",\n       \"\\u3300\"-\"\\u337f\",\n       \"\\u3400\"-\"\\u3d2d\",\n       \"\\u4e00\"-\"\\u9fff\",\n       \"\\uf900\"-\"\\ufaff\"\n      ]\n  >\n| < KOREAN:                                          // Korean\n      [\n       \"\\uac00\"-\"\\ud7af\"\n      ]\n  >\n\nAre your suggested changes still needed and if so, where should which range be added (Chinese/Japanese or Korean)?\n",
            "date": "2006-01-02T06:22:07.000+0000",
            "id": 0
        },
        {
            "author": "John Wang",
            "body": "Yes I am.\n\nOur i18n team has provided a more up-to-date list and I thought I'd contribute it back.\n\n-John",
            "date": "2006-01-02T10:00:30.000+0000",
            "id": 1
        },
        {
            "author": "Daniel Naber",
            "body": "John, I'm not sure I understand: do you think that this issue can be closed now? If not, could you ask your i18n experts how your changes could be integrated into the current code (the one where K/Korean and CJ are separate things)?\n\n",
            "date": "2006-01-04T06:41:20.000+0000",
            "id": 2
        },
        {
            "author": "Steve Rowe",
            "body": "There are six classes of issues:\n\n1. A character range in StandardTokenizer.jj that is missing in\nJohn's list, and should be left as-is in StandardTokenizer.jj\n(in the <CJ> section):\n\n   1.a. [ U+3100 - U+312F ]\n        BoPoMoFo (a.k.a. ZhuYin): Phonetic transcription symbols\n        used in Taiwan; not used on mainland China.\n\n2. A character range in StandardTokenizer.jj that is also in\nJohn's list, but in the <LETTER> section rather than in the <CJ>\nsection, and should be left as-is:\n\n   2.a. [ U+1100 - U+11FF ]\n        Korean Jamo (phonetic symbols)\n\n3. A character range in StandardTokenizer.jj that is not present in\nJohn's list, and that should be removed from the <KOREAN> section\nin StandardTokenizer.jj:\n\n   3.a. [ U+D7A4 - U+D7AF ]\n        Non-character range at the end of the pre-composed Hangul \n        (Korean) block\n\n4. A character range in John's list that is missing in\nStandardTokenizer.jj, but which was not present in Unicode 3.0, and\nso strictly should not be included when running on Java 1.4; since\nthis is a non-character range in Unicode 3.0, however, I think it\nshould be included in StandardTokenizer.jj (in the <CJ> section)\nfor future compatibility with Java 1.5 and Unicode 4.0:\n\n   4.a. [ U+31F0 - U+31FF ]\n        Japanese Katakana phonetic extensions; these were introduced\n        in Unicode version 3.2 (see\n        http://www.unicode.org/reports/tr28/tr28-3.html#10_3_katakana )\n\n5. Character ranges in John's list that are missing in\nStandardTokenizer.jj, and that should be added to the newly\nre-labeled <CJ> section:\n\n   5.a. [ U+FF65 - U+FF9F ]\n        Half-width Japanese Katakana (phonetic symbols)\n   \n   5.b. [ U+3d2e - U+4DB5 ] (non-chars [ U+4DB6 - U+4DBF ] excluded)\n        CJK Ideograph Extension A.  \n        This range was introduced in Unicode 3.0.\n\n6. A character range in John's list that is missing in\nStandardTokenizer.jj, and that should be added to the <LETTER>\nsection, since it, like the [ U+1100 - U+11FF ] range already\nincluded there, is a range of Korean Jamo (phonetic symbols):\n\n   6.a. [ U+FFA0 - U+FFDC ]\n        Half-width Korean Jamo (phonetic symbols)\n",
            "date": "2006-01-05T09:56:45.000+0000",
            "id": 3
        },
        {
            "author": "Steve Rowe",
            "body": "Patch addressing the above-described issues",
            "date": "2006-01-05T10:12:33.000+0000",
            "id": 4
        },
        {
            "author": "Steve Rowe",
            "body": "Removed stray comma - obsoletes previous patch",
            "date": "2006-01-07T01:32:35.000+0000",
            "id": 5
        },
        {
            "author": "Otis Gospodnetic",
            "body": "Thanks, I committed Steven Rowe's patch, although it doesn't seem to fully match what he said in comments above (e.g. in his patch, I don't see the range he mentioned in 5.b).",
            "date": "2006-08-13T07:24:18.000+0000",
            "id": 6
        }
    ],
    "component": "modules/analysis",
    "description": "Seems the character list in the CJK section of the StandardTokenizer.jj is not quite complete. Following is a more complete list:\n\n< CJK:                                          // non-alphabets\n      [\n\t   \"\\u1100\"-\"\\u11ff\",\n       \"\\u3040\"-\"\\u30ff\",\n       \"\\u3130\"-\"\\u318f\",\n       \"\\u31f0\"-\"\\u31ff\",\n       \"\\u3300\"-\"\\u337f\",\n       \"\\u3400\"-\"\\u4dbf\",\n       \"\\u4e00\"-\"\\u9fff\",\n       \"\\uac00\"-\"\\ud7a3\",\n       \"\\uf900\"-\"\\ufaff\",\n       \"\\uff65\"-\"\\uffdc\"       \n      ]\n  >\n\n",
    "hasPatch": false,
    "hasScreenshot": false,
    "id": "LUCENE-478",
    "issuetypeClassified": "BUG",
    "issuetypeTracker": "BUG",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "CJK char list",
    "systemSpecification": false,
    "version": "1.4"
}