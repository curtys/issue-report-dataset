{
    "comments": [
        {
            "author": "Simon Willnauer",
            "body": "Attached a patch with a base class that solves the code duplication issue and simplifies stopword loading for contrib analyzers. \nThe patch contains 3 analyzers which use this new base class",
            "date": "2009-11-05T00:10:42.647+0000",
            "id": 0
        },
        {
            "author": "Simon Willnauer",
            "body": "btw. if somebody comes up with a better name for the analyzer speak up!\n@robert: no super, fast or smart please  :)\n\nsimon",
            "date": "2009-11-05T00:15:03.288+0000",
            "id": 1
        },
        {
            "author": "Simon Willnauer",
            "body": "I have removed a sys.out I had accidentally in there.\nThe new patch contains more converted analyzers but I guess we should first get this in before we start converting all analyzers in contrib. \nPretty neat though stuff like ChineseAnalyzer only has one method in it after inheriting BaseAnalyzer",
            "date": "2009-11-05T07:29:04.566+0000",
            "id": 2
        },
        {
            "author": "Simon Willnauer",
            "body": "I changed the name from BaseAnalyzer to AbstractContribAnalyzer that might do a better job than BaseAnalyzer.\n\n",
            "date": "2009-11-05T17:48:10.344+0000",
            "id": 3
        },
        {
            "author": "Uwe Schindler",
            "body": "An then we also have an AbstractCoreAnalyzer? weird...\n\nI want to bring this to core, too.",
            "date": "2009-11-05T18:03:07.054+0000",
            "id": 4
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. An then we also have an AbstractCoreAnalyzer? weird... I want to bring this to core, too.\n\nI understand! Lets get this into contrib with either one name. Once we move this up in core it will be called Analyzer anyway so we can refactor it in contrib easily. The name AbstractContribAnalyzer would than again be ok as it would only contain the stopword convenience.",
            "date": "2009-11-05T18:15:51.130+0000",
            "id": 5
        },
        {
            "author": "Uwe Schindler",
            "body": "Even in core it will be a separate class, because it makes tokenStream() and reusableTokenStream() final, so users want to create an old style Analyzer  cannot do this. So we need a good name even for core.",
            "date": "2009-11-05T18:50:54.305+0000",
            "id": 6
        },
        {
            "author": "Simon Willnauer",
            "body": "I would be happy to get a better name for it - any suggestions - I'm having a hard time to find one.\n\nits your turn uwe :)",
            "date": "2009-11-05T18:57:49.154+0000",
            "id": 7
        },
        {
            "author": "Simon Willnauer",
            "body": "I externalized the stopword related code into another base analyzer and named the analyzer AbstractAnalyzer and StopawareAnalyzer.\n\n",
            "date": "2009-11-06T01:08:34.677+0000",
            "id": 8
        },
        {
            "author": "Robert Muir",
            "body": "Simon, i started looking at this, the testStemExclusionTable( for BrazilianAnalyzer is actually not related to stopwords and should not be changed.\n\nBrazilianAnalyzer has a .setStemExclusionTable() method that allows you to supply a set of words that should not be stemmed. \n\nThis test is to ensure  that if you change the stem exclusion table with this method, that reusableTokenStream will force the creation of a new BrazilianStemFilter with this modified exclusion table so that it will take effect immediately, the way it did with .tokenStream() before this analyzer supported reusableTokenStream()\n\n<edit, addition>\nalso, i think this setStemExclusionTable stuff is really unrelated to your patch, but a reuse challenge in at least this analyzer. one way to solve it would be to:\n* add .setStemExclusionTable to BrazilianStemFilter so it can be changed without creating a new instance.\n* in Brazilian Analyzer's createComponents(), cache the BrazilianStemFilter and change .setStemExclusionTable() to pass along the new value to that.\n",
            "date": "2009-11-08T20:13:39.183+0000",
            "id": 9
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. the testStemExclusionTable( for BrazilianAnalyzer is actually not related to stopwords and should not be changed. \nI agree, I missed to extend the testcase instead I changed it to test the constructor only. I will extend it instead.\nThis testcase is actually a duplicate of testExclusionTableReuse(), it should test tokenStream instead of reusableTokenStream() - will fix this too.\n\nbq. This test is to ensure that if you change the stem exclusion table with this method, that reusableTokenStream will force the creation of a new BrazilianStemFilter with this modified exclusion table so that it will take effect immediately, the way it did with .tokenStream() before this analyzer supported reusableTokenStream()\n\nthat is actually what  testExclusionTableReuse() does.\n\nbq. also, i think this setStemExclusionTable stuff is really unrelated to your patch, but a reuse challenge in at least this analyzer. one way to solve it would be to...\n\nI agree with your first point that this is kind of unrelated. I guess we should to that in a different issue while I think it is not that much of a deal as it does not change any functionality though.\nI disagree with the reuse challenge, in my opinion analyzers should be immutable thats why I deprecated those methods and added the set to the constructor. The problem with those setters is that you have to be in the same thread to change your set as this will only invalidate the cached version of a token stream hold in a ThreadLocal. The implementation is ambiguous and should go away. The analyzer itself can be shared but the behaviour is kind of unpredictable if you reset the set. If there is an instance of this analyzer around and you call the setter you would expect the analyzer to use the set from the very moment on you call the setter which is not always true. \n\n\n\n\n",
            "date": "2009-11-09T11:17:35.582+0000",
            "id": 10
        },
        {
            "author": "Simon Willnauer",
            "body": "Updated patch to current trunk (the massive patch with @Override broke the patch)\n- Moved AbstractAnalyzer to core\n- updated final Analyzers in core to use the AbstractAnalyzer\n- fixed TestBrazilianStemmer.java\n",
            "date": "2009-11-09T11:19:02.203+0000",
            "id": 11
        },
        {
            "author": "Robert Muir",
            "body": "simon, good solution. I agree we should deprecate these analyzer 'setter' methods, which just make things complicated for no good reason.\n\ni wonder if we should consider a different name for this AbstractAnalyzer, since it exists to support/encourage tokenstream reuse. I think when Shai Erera brought the idea up before he proposed ReusableAnalyzer or something like that?\n",
            "date": "2009-11-09T16:12:39.106+0000",
            "id": 12
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. i wonder if we should consider a different name for this AbstractAnalyzer, since it exists to support/encourage tokenstream reuse. I think when Shai Erera brought the idea up before he proposed ReusableAnalyzer or something like that?\n\nI agree that this is not a very good name as we all discussed during apacheCon. With ReusableAnalyzer I would guess people would expect this analyzer to be reusable which isn't the case or rather is not what this is analyzer is doing. What if we call it ComponentAnalyzer or NewStyleAnalyzer or SmartAnalyzer (ok just kidding)\n\nsimon",
            "date": "2009-11-09T16:17:06.449+0000",
            "id": 13
        },
        {
            "author": "Simon Willnauer",
            "body": "Pushed this to 3.1.\nWe might want to change existing analyzers in core to use the new analyzer too and make then final. So we are better off with pushing it to 3.1",
            "date": "2009-11-09T16:34:49.347+0000",
            "id": 14
        },
        {
            "author": "Robert Muir",
            "body": "Simon, here\n{quote}\nsource.reset(reader);\n     if(sink != source)\n       sink.reset(); // only reset if the sink reference is different from source\n{quote}\n\nwe had a discussion on the mailing list about this: http://www.lucidimagination.com/search/document/cd8a94ebc8a4ea99/bug_in_standardanalyzer_stopanalyzer\n\nI think we should consider removing the if, and unconditionally call sink.reset(). \nA bad consumer might not follow the rules, although it says in TokenStream javadoc that consumers should call reset().. \n",
            "date": "2009-11-16T14:48:15.845+0000",
            "id": 15
        },
        {
            "author": "Simon Willnauer",
            "body": "Updated the patch to the current trunk.\nI have not removed all the deprecated methods in contrib/analyzers yet - we should open another issue for that IMO.\nYet this patch still brakes back compatibility as some of the none final contrib analyzers extend StopawareAnalyzer with makes the old tokenstream / reusableTokenstream methods final. IMO this should not block this issues for the following reasons:\n1. its in contrib - different story for core\n2. it is super easy to port them\n3. it make the API cleaner and has less code\n4. those analyzers might have to change anyway due to the deprecated methods\n\n\nsimon",
            "date": "2009-11-24T11:10:08.098+0000",
            "id": 16
        },
        {
            "author": "Simon Willnauer",
            "body": "set svn EOF property to native - missed that in the last patch",
            "date": "2009-11-24T11:14:43.704+0000",
            "id": 17
        },
        {
            "author": "Uwe Schindler",
            "body": "bq. set svn EOF property to native - missed that in the last patch \nYou can cofigure your SVN client to do it automatically and also add the $ID$ props.",
            "date": "2009-11-24T11:19:30.215+0000",
            "id": 18
        },
        {
            "author": "Robert Muir",
            "body": "Simon in my opinion it is ok, about making tokenstream/reusablets final for those non-final contrib analyzers.\n\ni think you should make those non-final analyzers final, too. \n\nthen we can get rid of complexity for sure.\n",
            "date": "2009-11-24T11:45:03.743+0000",
            "id": 19
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. i think you should make those non-final analyzers final, too. \n+1\n\nI think the analyzers should always be final. Maybe there are special cases but for the most of them nobody should subclass.\nSame amount of work  to make your own anyway.\n\nsimon",
            "date": "2009-11-24T11:54:22.754+0000",
            "id": 20
        },
        {
            "author": "Simon Willnauer",
            "body": "bq.  i think you should make those non-final analyzers final, too. \nI would prefer to open a sep. issue for making those final & remove deprecated methods, make public String[] private etc.\n\nOnce this in in we can refactor all other analyzers and fix them case by case.\n\nsimon",
            "date": "2009-11-25T16:00:13.502+0000",
            "id": 21
        },
        {
            "author": "DM Smith",
            "body": "I was trying to lurk, but I'm not able to apply the latest patch against trunk. I'm not sure if its me (using Eclipse) or the patch.",
            "date": "2009-11-30T16:48:41.243+0000",
            "id": 22
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. I was trying to lurk, but I'm not able to apply the latest patch against trunk. I'm not sure if its me (using Eclipse) or the patch. \nits most likely the patch. There is so much going on around the analyzers right now. We try to get LUCENE-2094 in and get this ready once it is in. I will update this patch soon.",
            "date": "2009-11-30T17:00:41.162+0000",
            "id": 23
        },
        {
            "author": "Simon Willnauer",
            "body": "I updated this patch to the latest trunk. The patch doesn't remove any deprecated methods from contrib/analysis neither does it mark the other Analyzers final. I think we should do all that in a different issue. I haven't added a note to contrib/CHANGES.TXT yet while it already breaks bw. compat for all none-final analyzers subclassing AbstractAnalyzer / StopawareAnalyzer. \nOnce we have a consensus on this patch I will add it.",
            "date": "2009-12-01T13:28:06.832+0000",
            "id": 24
        },
        {
            "author": "DM Smith",
            "body": "Patch looks good. I like how this simplifies the classes.\n\nSome comments based on my use case, which allows a user creating an index to decide whether to use Lucene's default stop words or no stop words at all. No stop words is the default. (I'm also allowing stemming to be optional, but on by default.) These two require me to duplicate the each contrib Analyzers but reuse the parts. (If you're interested, each Lucene index is a whole book, where each paragraph is a document. Every word is potentially meaningful so stop words are not used by default.)\n\nRegarding stop words:\n* Some of the analyzers allow for null to be specified for the stop word list. Others require an empty set/file/reader. Those deriving from StopawareAnalyzer allow null. I'd like to see the ability to use null to follow through the rest of the analyzers.\n*Some of the analyzers are cluttered with stopword list processing. Maybe WordListLoader could be extended to handle the other ways that contrib/analyzers store their lists? Specifically, how about moving StopawareAnalyzer.loadStopwordSet(...)? It seems to be a better place.\n* How about splitting out the stop words to their own class? (I'm digging the word lists out of the analyzers and the lack of uniformity is a pain. Having them standalone would be useful.)\n* If not how about adding public static Set<?> getDefaultStopSet() to StopawareAnalyzer?\n* Shouldn't StopawareAnalyzer be in core? and used in StopAnalyzer? Could it be merged into StopAnalyzer? Other than the loadStopwordSet, it really only adds a method to get the current stopword list.\n\nRegarding 3.1:\nThere are some TODOs in the code to make this or that private or final. If this is going to wait for 3.1 shouldn't they change?\n\nOn a separate note:\nIn WordListLoader the return types are not Set or Map, but HashSet and HashMap. What's up with that? Should anyone care what the particular implementation is?\n",
            "date": "2009-12-01T17:40:08.261+0000",
            "id": 25
        },
        {
            "author": "Robert Muir",
            "body": "Hi DM, in response to your comments, I would prefer all stoplists to actually be in the resources/* folder as text files.\n\nThe reasoning is to encourage use of the different parts of the analyzer, i.e. a Solr user can specify to use a russian stopword list embedded in a russian analyzer,\nwithout using the analyzer itself (maybe they want to use the stemmer but after WordDelimiterFilter and things like that).\n\nsomewhat related: I also want to add the stoplists that the snowball project creates to the snowball package in contrib: see LUCENE-2055\nThis would allow us to remove duplicated functionality, analyzers we have coded in java in lucene that are essentially the same as what snowball does already.\n",
            "date": "2009-12-01T17:52:06.036+0000",
            "id": 26
        },
        {
            "author": "DM Smith",
            "body": "Robert, I'd like them to be in files as well. But when it really gets down to it, a uniform interface to the the default stop word list is what really matters to me.\n\nLike your use case, I don't see the provided analyzers as much more than a suggestion and default implementation. Currently and in this patch, I have to use them to get to the stop words.\n\nI'm trying to figure out a way to specify a tokenizer/filter chain. (I've been trying to figure it out for a while, but not with much effort or success). Something like:\n{code}\nTokenStream construct(Version v, String fieldName, Reader r, StreamSpec ...) {\n  source = first StreamSpec.create(v, fieldName, r);\n  result = source;\n  for the remaining StreamSpec {\n     result = streamSpec.create(v, fieldName, result);\n  }\n  return result;\n}\n{code}\n\nThe purpose of the StreamSpec is to allow a late binding of tokenizers/filters into a chain.\n\nThe other part would be to generate a Manifest with version info for Lucene, Java and each component that could be stored in (or with) the index. That way one could compare the manifest to see if the index needs to be rebuilt. This manifest could also be used to reconstruct the TokenStream.\n",
            "date": "2009-12-01T18:34:46.068+0000",
            "id": 27
        },
        {
            "author": "Uwe Schindler",
            "body": "{quote}\nOn a separate note:\nIn WordListLoader the return types are not Set or Map, but HashSet and HashMap. What's up with that? Should anyone care what the particular implementation is?\n{quote}\n\nThat's historical. For 2.9 it was not possible to provide the method covariant with different return type for BW compatibility, so the old ones could not be deprecated. With 3.0 they stayed alive and now there they are.\n\nWith Java 1.5, there should be the possibility to provide an covariant overload and deprecate the specializations. I will try out in a separate issue!\n\nIdeally he new methods should return Set<?> but implement this by a CharArraySet (which would be possible then). At the moment the sets are always copied to CharArraySet in each Analyzer.",
            "date": "2009-12-01T18:35:37.726+0000",
            "id": 28
        },
        {
            "author": "Robert Muir",
            "body": "bq. Robert, I'd like them to be in files as well. But when it really gets down to it, a uniform interface to the the default stop word list is what really matters to me. \n\nDM, I think we can have both? A method to get the default stopword list, but then they also happen to be in text files too?\n",
            "date": "2009-12-01T18:44:55.165+0000",
            "id": 29
        },
        {
            "author": "DM Smith",
            "body": "Robert:\nbq. DM, I think we can have both? A method to get the default stopword list, but then they also happen to be in text files too?\n\nYes.\n\nUwe:\nbq. Ideally he new methods should return Set<?> but implement this by a CharArraySet (which would be possible then). At the moment the sets are always copied to CharArraySet in each Analyzer.\n\nI agree. That could also simplify some of what Simon is doing. However, the one distinctive of CharArraySet is that it can take input that is not lowercase and ignore the casing. This is what Simon's StopawareAnalyzer.loadStopwordSet(...) allows.\n\nBTW, in some of the analyzers sometimes it is a CharArraySet and other times it is not (when it is via this class). This would make the treatment uniform.",
            "date": "2009-12-01T19:02:31.083+0000",
            "id": 30
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Some of the analyzers allow for null to be specified for the stop word list. Others require an empty set/file/reader. Those deriving from StopawareAnalyzer allow null.\nThat is true - Stopawareanalyzer uses an empty set if you pass null. \n\nbq. I'd like to see the ability to use null to follow through the rest of the analyzers.\n*Some of the analyzers are cluttered with stopword list processing.\nThe analyzers in this patch are rather a PoC than a complete list. Eventually we will have all analyzers with stopwords to extend StopawareAnalyzer that is also the reason why we have this class. This and some other issues aim to eventually have a consistent way of processing all this stuff related to stopwords. We will also remove all the setters and have Set<?> only ctors for consistency.\n\nbq. If not how about adding public static Set<?> getDefaultStopSet() to StopawareAnalyzer?\nthe problem is that it is static and it should be static. Thats why we define it in each analyzer that uses stopwords. I would like to have it generalized but this seems to be the ideal solution. We could have something like a getDefaultStopSet(Class<? extends StopawareAnalyzer>) but I like the expressiveness of getDefaultStopSet() way better though.\n\nbq. How about splitting out the stop words to their own class? \nWhat do you mean by that?  can you elaborate?\n\nbq. There are some TODOs in the code to make this or that private or final. If this is going to wait for 3.1 shouldn't they change?\nThe should actually go away but I kept them in there because they are somewhat unrelated to this particular issue. Once this is in we will work on removing the deprecated stuff and make analyzers final (at least in contrib).\n\nbq. In WordListLoader the return types are not Set or Map, but HashSet and HashMap. What's up with that? Should anyone care what the particular implementation is?\nthat is one thing I hate about WordListLoader. +1 towards Uwe working on them!\n\nbq. I'm trying to figure out a way to specify a tokenizer/filter chain. (I've been trying to figure it out for a while, but not with much effort or success).\nThis has been discussed already and we haven't had much of a success though. I can not remember the issue (robert can you remember the factory issue?) but it was basically based on a factory pattern. This would also be my approach to it. That way we could get rid of almost every analyzer. I use such a pattern myself which works quite well.\n\nbq. DM, I think we can have both? A method to get the default stopword list, but then they also happen to be in text files too?\n+1 for having those words in files. Nevertheless we will have a default stopword list though.",
            "date": "2009-12-01T21:11:59.285+0000",
            "id": 31
        },
        {
            "author": "Robert Muir",
            "body": "{quote}\nThis has been discussed already and we haven't had much of a success though. I can not remember the issue (robert can you remember the factory issue?) but it was basically based on a factory pattern. This would also be my approach to it. That way we could get rid of almost every analyzer. I use such a pattern myself which works quite well.\n{quote}\n\nI think the only issue is that if I were to design such a thing, it would look just like how the analysis factories work in Solr... (already a solved problem)... maybe I am missing something?",
            "date": "2009-12-01T21:15:35.862+0000",
            "id": 32
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. I think the only issue is that if I were to design such a thing, it would look just like how the analysis factories work in Solr... (already a solved problem)... maybe I am missing something?\n\nno you don't. I just did that when there where no solr around. works pretty much the same way though. ",
            "date": "2009-12-01T21:25:41.097+0000",
            "id": 33
        },
        {
            "author": "DM Smith",
            "body": "{quote}\nbq.    How about splitting out the stop words to their own class? \n\nWhat do you mean by that? can you elaborate?\n{quote}\n\nThere are several parts of this.\n* The analyzer needs to allow for user supplied stop words, possibly null. This or the default list needs to be supplied to the StopFilter.\n* The stop word list needs to be loaded into a set. Currently it might be a Reader, a File or a String[] array.\n* The WordListLoader is a helper class to construct the set from a File or Reader. StopawareAnalyzer has another helper for reading from file for fa and ar. Otherwise there is duplicated code to stuff the array into a CharArraySet.\n \nMost of the analyzers with stop words allow override with any of these and sometimes throw something else in the mix (such as non-utf8 encoded files).\n\nThe code to handle these cases is somewhat repetitious.\n\nMy thought is for a class, say StopWords, that knows how to read stopwords.txt as a resource loaded by a specified class loader. Something like:\n{code}\npublic class StopWords {\n\n  protected static final String       DEFAULT_STOPFILE = \"stopfile.txt\";\n  protected static final String       DEFAULT_COMMENT  = \"#\";\n  private          final Version      matchVersion;\n  private                CharSetArray defaultStopWords;\n\n  public StopWords(Version matchVersion, String stopFile, String comment, boolean ignoreCase) {\n    this.matchVersion = matchVersion;\n    this.ignoreCase   = ignoreCase;\n    this.stopFile     = stopFile != null ? stopFile : DEFAULT_STOPFILE;\n    this.comment      = comment  != null ? comment  : DEFAULT_STOPFILE;\n  }\n\n  public synchronized Set<?> getDefaultStopWords() {\n    // lazy loading\n    if (defaultStopWords == null) {\n      defaultStopWords = load();\n    }\n\n    return defaultStopWords;\n  }\n\n  protected Set<?> load() {\n    final Reader reader = new BufferedReader(new InputStreamReader(this.class.getResourceAsStream(stopFile), \"UTF-8\"));\n    final CharSetArray result = new CharSetArray(matchVersion, 0, ignoreCase);\n    try {\n      for (String word = reader.readLine(); word != null; word = reader.readLine()) {\n        if (!word.startsWith(comment)) {\n          result.add(word.trim());\n        }\n      }\n      return CharSetArray.unmodifiableSet(result);\n    } finally {\n      reader.close();\n    }\n  }\n\n}\n{code}\nI'm pretty sure that this.class resolves to the class of the actual object and not the class in which it is called (as long as it is not called within the ctor).\n\nThen in o.a.l.analysis.ar have:\n{code}\npublic class ArabicStopWords extends StopWords {\n  public ArabicStopWords(Version matchVersion) {\n      super(matchVersion, null, null, false);\n  }\n}\n{code}\nNote that the arguments to super depend on the nature of the provided stop word list.\n\nAdditional code could be added to StopWords to handle resource as a Reader and as String[], but if we follow Robert's suggestion to externalize the list in a file it is not needed.",
            "date": "2009-12-01T23:02:50.372+0000",
            "id": 34
        },
        {
            "author": "Simon Willnauer",
            "body": "DM, thanks for the extensive example. But I do not see the benefit compared to the current solution. To access a default stopword set you have to create an instance of a specific analyzer which is IMO not a very natural way. If you make it available statically in the analyzer it is simply equivalent to the StopawareAnalyzer solution that provides the loading code. We will always have to add a public static Set<?> getDefaultStopwords() method to each analyzer and this analyzer has to load the stopwords somehow. \n\nI personally prefer the holder pattern as it is guaranteed to be lazy by the JVM. It is a simple declarative solution which requires developers to be consistent but this consistency is already required with the static getDefaultStopwords() method. - not really a win. \nPlease correct me if I miss something. ",
            "date": "2009-12-02T09:33:09.258+0000",
            "id": 35
        },
        {
            "author": "DM Smith",
            "body": "bq. But I do not see the benefit compared to the current solution.\nIn an earlier post we discussed that it'd be possible, like SOLR, to eliminate analyzers for a factory pattern. The benefit of this variation (you are right, it is equivalent) is that it moves in that direction.\n\n.bq  To access a default stopword set you have to create an instance of a specific analyzer which is IMO not a very natural way.\nIt could be made into a singleton (which would have been better in the first place), or static or both. I just tossed together one example, though extensive, to answer. Also, the matchVersion is not needed in the derived classes. So here is an alternate:\n{code}\npublic class ArabicStopWords extends StopWords {\n  private static final StopWords instance = new ArabicStopWords();\n  private ArabicStopWords() {\n    super(Version.LUCENE_30, null, null, false);\n  }\n  public static Set<?> getDefaultStopWords() {\n    return instance.getDefaultStopWords();\n  }\n}\n{code}\n\nbq. I personally prefer the holder pattern as it is guaranteed to be lazy by the JVM.\nI'm not sure about this. I think this is a partially true statement. I know I could look it up to be sure. I thought that the JLS required *all* static initializers to be run at first access to the class. So if one does not want the list of default stopwords, but wants something else in the class or is supplying an alternate set of stopwords, the default stopwords are initialized anyway.\n\nSo the other benefit is that it is fully lazy. Though this is a small benefit.\n\nOn another note, still regarding code placement:\nStopFilter has a bunch of makeStopSet methods. WordListLoader has a few more. StopawareAnalyzer has another. My example has yet another. I think this creates confusion for end users and casual contributors as it is not clear how to proceed without looking at the code for examples. I'd like to see some kind of clarity/consolidation.\n\n\n\n",
            "date": "2009-12-02T13:21:49.192+0000",
            "id": 36
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. Im not sure about this. I think this is a partially true statement. I know I could look it up to be sure. I thought that the JLS required all static initializers to be run at first access to the class. So if one does not want the list of default stopwords, but wants something else in the class or is supplying an alternate set of stopwords, the default stopwords are initialized anyway.\n\nDM, What you say its true but the holder is a static inner class and its static initializers run on the first access. That is right when it needs to be as it is only accessed once you the default stopwords. It does not require any synchronization as this is guaranteed by the JVM. What I like about it is that you can't introduce any synch. problems - simple and declarative.\n\nbq. So the other benefit is that it is fully lazy. Though this is a small benefit.\nsee above\n\nbq. It could be made into a singleton (which would have been better in the first place), or static or both. I just tossed together one example, though extensive, to answer. Also, the matchVersion is not needed in the derived classes.\nIt already is a singleton. the holder makes it a lazy loaded static final singleton. MatchVersion will only be needed in derived classes if the tokenStreamComponents \n\n\nI personally don't like the various different ways you can load stopwords either, my approach is a different one. Stopwords are mainly used in analyzers / filters, we have a standard way to load them in StopawareAnalyzer if you implement your analyzer. If you use the analyzer you should use WordlistLoader. If we fix WordlistLoader to return Set<?> we are good to go with a single way for the user and a standard way for makeing a stopaware analyzer. If you wrap this up in a Class StopWords then people do not know what to do with it once they wanna load a Stem-Exclusion Table.\nMaybe I miss one important thing but I do not see the benefit of wrapping a Set<?> into another class. - If so please explain. :)\n\nThanks",
            "date": "2009-12-04T13:37:29.278+0000",
            "id": 37
        },
        {
            "author": "Simon Willnauer",
            "body": "Updated the patch to the latest trunk.",
            "date": "2009-12-11T17:32:11.169+0000",
            "id": 38
        },
        {
            "author": "Simon Willnauer",
            "body": "I renamed AbstractAnalyzer to ReusableAnalyzerBase which reflects pretty much what it does. Yet the Base postfix is pretty common throughout the JDK similarly to the Abstract prefix.\nI added little more JavaDoc which brings some clarification when to subclass ReusableAnalyzerBase instead of Analyzer.\n\nI guess this is ready to go in though.",
            "date": "2009-12-16T01:02:40.454+0000",
            "id": 39
        },
        {
            "author": "Robert Muir",
            "body": "Simon, the patch looks good to me.\n\nI added a few things:\n* removed the duplication in analyzers/bg\n* fixed some javadoc buglets\n* added CHANGES\n\nIf no one objects, I will commit in a few days.\n",
            "date": "2009-12-16T13:06:24.243+0000",
            "id": 40
        },
        {
            "author": "Simon Willnauer",
            "body": "robert, should we hold on one more time and move StopawareAnalyzer into core? As you suggested, StopwordAnalyzerBase would be a better name for it and way more consistent. That way we could implement StopAnalyzer with it too.\n",
            "date": "2009-12-17T00:42:57.838+0000",
            "id": 41
        },
        {
            "author": "Robert Muir",
            "body": "ok, lets wait and discuss this issue instead.\n\ni don't like how i can't use it for smartcn, etc. but is this just because of our build system/analyzers organization? or can we refactor things out of stopanalyzer, too?",
            "date": "2009-12-17T03:36:20.164+0000",
            "id": 42
        },
        {
            "author": "Simon Willnauer",
            "body": "robert, I updated your patch and moved stopawareAnalzyer to StopwordAnalyzerBase in to core.\nI also updated the CHANGES.TXT. THis will enable use to use it in smartcn too. StopAnalzyer now directly subclasses StopwordAnalyzerBase too.\nSeems to be way more consistent though.",
            "date": "2009-12-17T12:19:58.687+0000",
            "id": 43
        },
        {
            "author": "Robert Muir",
            "body": "Simon, thanks for the update, I like it.\n\nI am going on vacation in a few weeks... so I can say, I will commit next year if no one objects :)",
            "date": "2009-12-18T18:00:22.070+0000",
            "id": 44
        },
        {
            "author": "Simon Willnauer",
            "body": "With LUCENE-2169 this patch becomes even more valuable. The creation of Analyzers extending StopwordAnalyzerBase will be way faster than in previous versions, with this in mind we should add a pointer to StopwordAnalyzerBase that recommends using charArraySet for stopwords and in the next step we should get WordlistLoader refactored and deprecate all public HashSet * methods in favour of Set<?> with CharArraySet as an internal implementation. Unifiying the way to create / load stopwords outside of a StopwordAnalyzerBase subclass goes the same way I would guess. We need one way to do it though. I will create correspondent issues within the next days.",
            "date": "2009-12-24T11:58:44.566+0000",
            "id": 45
        },
        {
            "author": "Robert Muir",
            "body": "I am back on a real computer and (as mentioned december 18th) I would like to commit this soon.\n\nSimon, I only have one question: do you think it would be possible in the future to add an additional feature (under another issue) whereas:\n* analyzers extending the StopwordAnalyzerBase can have multiple stoplists depending upon Version\n* the StopwordAnalyzerBase.getStopwordSet requires a Version argument to match this behavior.\n\nMy reasoning is that we would then be able to improve stopword lists without breaking backwards compatibility.\nI am aware many people feel stopword lists are not that important but for quite a few non-english languages they are very important, no matter how advanced the scoring mechanism is (see persian for a great example of this). \nI also think in the future perhaps we would consider merging in the commongrams functionality that is currently duplicated in nutch and solr so that these stoplists can be ab(used) with that method as well, so I think this kind of thing might become more important in the future.\n\nI realize this is a new feature so it shouldnt be under this issue, but if it means this design isn't viable let me know that. otherwise i would like to commit this one first to make progress. i broke the backwards compat fixing the arabic stopwords before and I would like to not do this sort of thing again.\n",
            "date": "2010-01-02T13:08:25.326+0000",
            "id": 46
        },
        {
            "author": "Simon Willnauer",
            "body": "Robert, I see what you are alluding to. Yet, I agree this is a new issue and should be handled separately. The issues would require some changes in the api I guess or rather additions. Yet, we should commit this regardless! I would be happy to make additions to StopwordAnalyzerBase on another issue as long as we haven't released this code we can still change the API while I don't think we have to. #getStopwordSet will always return the set in use while setting the stopwordset depending on the version is internal to the class. \n\n",
            "date": "2010-01-02T18:20:49.693+0000",
            "id": 47
        },
        {
            "author": "Robert Muir",
            "body": "Ah I see, you are right. This getStopWordSet() is not static, so it is correct with the current way we are doing things in lucene. in the future if this stopwordset was created depending upon version, this will still work.\n\nYeah this is something completely new I just wanted to verify with you that its potentially doable...\n",
            "date": "2010-01-02T18:26:13.861+0000",
            "id": 48
        },
        {
            "author": "Robert Muir",
            "body": "I am going to look at this one last time and commit shortly (finally), unless anyone speaks up.\n",
            "date": "2010-01-02T20:48:31.239+0000",
            "id": 49
        },
        {
            "author": "Robert Muir",
            "body": "Committed revision 895339.\n\nThanks for all your hard work cleaning this up Simon.",
            "date": "2010-01-03T08:50:42.249+0000",
            "id": 50
        }
    ],
    "component": "modules/analysis",
    "description": "Due to the variouse tokenStream APIs we had in lucene analyzer subclasses need to implement at least one of the methodes returning a tokenStream. When you look at the code it appears to be almost identical if both are implemented in the same analyzer.  Each analyzer defnes the same inner class (SavedStreams) which is unnecessary.\nIn contrib almost every analyzer uses stopwords and each of them creates his own way of loading them or defines a large number of ctors to load stopwords from a file, set, arrays etc.. those ctors should be removed / deprecated and eventually removed.\n\n\n",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-2034",
    "issuetypeClassified": "REFACTORING",
    "issuetypeTracker": "IMPROVEMENT",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "Massive Code Duplication in Contrib Analyzers - unifly the analyzer ctors",
    "systemSpecification": true,
    "version": "2.9"
}