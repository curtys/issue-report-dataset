{
    "comments": [
        {
            "author": "Olivier Favre",
            "body": "Proposed patch attached.\n\nWorking against Lucene 3.1 (remove the {{path.length()}} last parameter to assert call).\nBut I am having difficulties making the tests work against trunk ({{ant}} and {{ant test}} fail, at global scope).",
            "date": "2011-05-05T15:20:27.422+0000",
            "id": 0
        },
        {
            "author": "Robert Muir",
            "body": "bq. But I am having difficulties making the tests work against trunk (ant and ant test fail, at global scope).\n\nCan you provide more details about this?\n\nIf possible stuff like ant version, whether you are using an svn checkout (and what the full path is), logs of what error messages, etc would be great.\n\nFeel free to open a new jira issue for these problems!",
            "date": "2011-05-05T15:23:40.257+0000",
            "id": 1
        },
        {
            "author": "Olivier Favre",
            "body": "I'm using Ubuntu 10.04.2 LTS.\nant -version\nApache Ant version 1.7.1 compiled on September 8 2010\nI followed the wiki: http://wiki.apache.org/lucene-java/HowToContribute\nI used svn checkout http://svn.eu.apache.org/repos/asf/lucene/dev/trunk/ lucene-trunk.\nI'm working under revision 1099843 (yours).\nSee ant log attached.",
            "date": "2011-05-05T15:48:37.323+0000",
            "id": 2
        },
        {
            "author": "Robert Muir",
            "body": "Hi Olivier, thanks for uploading the log. \n\nThis test fails for me sometimes too, somehow we should get to the bottom of it. \nI opened an issue: SOLR-2500\n\nAs a workaround, perhaps using 'ant clean test' will help... I fought with this\ntest a little bit the other day and somehow 'clean' seemed to temporarily get the\ntest passing...",
            "date": "2011-05-05T15:54:35.782+0000",
            "id": 3
        },
        {
            "author": "Olivier Favre",
            "body": "{{ant clean test}} did it for me, thanks!\n\nAs for the failing tests, it is because of the {{finalOffset}} that I set to {{path.length()}}.\nI'm not sure whether I should use {{path.length()}}, as my tokens don't go up to there when using the reverse mode.\nWhen I take a look at the the end() function, I think that I \"should\" set it to the end of the string. But I can't see it on the javadoc.\nIf the purpose of the {{finalOffset}} parameter in {{assertTokenStreamContents()}} it to make sure of the {{endOffset}} of the last term, then I should not use {{path.length()}} blindly when using reverse and skip.\n\nCan you help me with the purpose of {{finalOffset}}? Or can I simply skip it in my tests (they are working if I skip it)?\n\nThanks",
            "date": "2011-05-05T16:23:29.397+0000",
            "id": 4
        },
        {
            "author": "Robert Muir",
            "body": "bq. Can you help me with the purpose of finalOffset? Or can I simply skip it in my tests (they are working if I skip it)?\n\nThe finalOffset is supposed to be the offset of the entire document, this is useful so that offsets are correct on multivalued fields.\n\nExample multivalued field \"foo\" with two values:\n\"bar \" <-- this one ends with a space\n\"baz\"\n\nWith a whitespace tokenizer, value 1 will have a single token \"bar\" with startOffset=0, endOffset=3. But, finalOffset needs to be 4 (essentially however many chars you read in from the Reader)\n\nThis way, the offsets will then accumulate correctly for \"baz\".\n",
            "date": "2011-05-05T16:28:55.272+0000",
            "id": 5
        },
        {
            "author": "Olivier Favre",
            "body": "Fixed patch attached.\n\nTests run fine now.\n\nReady to ship?",
            "date": "2011-05-05T17:18:19.425+0000",
            "id": 6
        },
        {
            "author": "Robert Muir",
            "body": "Hi Olivier, at a glance the patch looks really great to me, thanks!\n\nI took a quick look (not in enough detail) but had these thoughts, neither of which I think are really mandatory for this feature, just ideas:\n* do you think it would be cleaner if we made it a separate tokenizer? (e.g. ReversePath....). The main logic of the tokenizer seems to be completely split, depending on whether you are reversing or not.\n* i think its possible in the future we could simplify the way finalOffset is being tracked, such that we just accumulate it on every read(), and then correctOffset a single time in end(). (i don't think this has much to do with your patch, just looking at the code in general).\n",
            "date": "2011-05-05T18:07:59.275+0000",
            "id": 7
        },
        {
            "author": "Ryan McKinley",
            "body": "i'll take a look",
            "date": "2011-05-05T19:00:12.402+0000",
            "id": 8
        },
        {
            "author": "Ryan McKinley",
            "body": "bq. do you think it would be cleaner if we made it a separate tokenizer?\n\nI think its a tossup -- having keeping them together makes one less factory in solr (not much of an argument) and the other three parameters (delimiter,replacement,skip) are nice to keep consistent.\n",
            "date": "2011-05-05T19:43:10.059+0000",
            "id": 9
        },
        {
            "author": "Ryan McKinley",
            "body": "updated patch that includes solr factory.\n\nRobert if this looks ok to you, i will go ahead and commit",
            "date": "2011-05-05T19:44:34.839+0000",
            "id": 10
        },
        {
            "author": "Robert Muir",
            "body": "bq. having keeping them together makes one less factory in solr (not much of an argument) \n\nI don't understand this?\n\nYou can still have one solr factory, if reverse=true it creates ReverseXXX...\n",
            "date": "2011-05-05T19:54:21.102+0000",
            "id": 11
        },
        {
            "author": "Hoss Man",
            "body": "bq. You can still have one solr factory, if reverse=true it creates ReverseXXX...\n\nright ... if it makes the code cleaner to have two distinct Tokenizer impls, they can still share one factory.",
            "date": "2011-05-05T22:00:54.630+0000",
            "id": 12
        },
        {
            "author": "Ryan McKinley",
            "body": "split into two classes... and two test classes",
            "date": "2011-05-05T22:26:22.167+0000",
            "id": 13
        },
        {
            "author": "Robert Muir",
            "body": "this looks great!",
            "date": "2011-05-05T23:11:30.788+0000",
            "id": 14
        },
        {
            "author": "Ryan McKinley",
            "body": "I had some trouble merging from trunk to 3.x, and needed to just copy a few files -- i hope that does not muck stuff up.\n\nThanks Olivier!",
            "date": "2011-05-06T03:11:11.891+0000",
            "id": 15
        },
        {
            "author": "Simon Willnauer",
            "body": "we got failures due to a missing file on 3.x - reopen ",
            "date": "2011-05-06T08:43:19.812+0000",
            "id": 16
        },
        {
            "author": "Simon Willnauer",
            "body": "bq. I had some trouble merging from trunk to 3.x, and needed to just copy a few files \u2013 i hope that does not muck stuff up.\nthat change didn't seem to be hard to merge what did you do instead or merging? Maybe next time you should ask how to do it before copying stuff from trunk to branch?\n\nwe also have a \"how to merge\" wiki here http://wiki.apache.org/lucene-java/SvnMerge\n\nI merged the missing file in and committed I will close once hudson is building correctly.",
            "date": "2011-05-06T08:51:59.288+0000",
            "id": 17
        },
        {
            "author": "Ryan McKinley",
            "body": "thanks simon -- sorry about that, i will check for merge help next time.",
            "date": "2011-05-06T14:03:27.480+0000",
            "id": 18
        },
        {
            "author": "Olivier Favre",
            "body": "It seems you forgot to commit lucene/contrib/CHANGES.txt to describe the new feature.\n\nRegards",
            "date": "2011-05-06T14:12:06.758+0000",
            "id": 19
        },
        {
            "author": "Ryan McKinley",
            "body": "check:\nhttp://svn.apache.org/viewvc/lucene/dev/branches/branch_3x/lucene/CHANGES.txt?p2=%2Flucene%2Fdev%2Fbranches%2Fbranch_3x%2Flucene%2FCHANGES.txt&p1=%2Flucene%2Fdev%2Fbranches%2Fbranch_3x%2Flucene%2FCHANGES.txt&r1=1100033&r2=1100032&view=diff&pathrev=1100033\n\nIt is on the 3.x branch -- my understanding is that will get merged with the trunk changes when 4.x is valid.   \n\nI *think* this was the resolution of how we will handle changes, but now that you ask, i am not sure...  anyone know what the current CHANGES policy is?",
            "date": "2011-05-06T14:20:00.183+0000",
            "id": 20
        },
        {
            "author": "Robert Muir",
            "body": "bulk move 3.2 -> 3.3",
            "date": "2011-06-03T16:40:41.366+0000",
            "id": 21
        },
        {
            "author": "Simon Willnauer",
            "body": "Ryan, are you working on this? This seems to have a working patch (at the time being) any reason why this didn't make it? if you are not working on this can you move it to unassigned?",
            "date": "2011-11-11T23:42:20.136+0000",
            "id": 22
        },
        {
            "author": "Ryan McKinley",
            "body": "Looks like this was actually resolved long ago... the only thing pending was that I did not understand how to manage the CHANGES.txt from 3.x and /trunk",
            "date": "2011-11-12T21:14:54.390+0000",
            "id": 23
        },
        {
            "author": "Uwe Schindler",
            "body": "Bulk close after release of 3.5",
            "date": "2011-11-27T12:29:24.531+0000",
            "id": 24
        }
    ],
    "component": "modules/analysis",
    "description": "{{PathHierarchyTokenizer}} should be usable to split urls the a \"reversed\" way (useful for faceted search against urls):\n{{www.site.com}} -> {{www.site.com, site.com, com}}\n\nMoreover, it should be able to skip a given number of first (or last, if reversed) tokens:\n{{/usr/share/doc/somesoftware/INTERESTING/PART}}\nShould give with 4 tokens skipped:\n{{INTERESTING}}\n{{INTERESTING/PART}}",
    "hasPatch": true,
    "hasScreenshot": false,
    "id": "LUCENE-3071",
    "issuetypeClassified": "RFE",
    "issuetypeTracker": "RFE",
    "priority": "Minor",
    "product": "LUCENE",
    "project": "LUCENE",
    "summary": "PathHierarchyTokenizer adaptation for urls: splits reversed",
    "systemSpecification": true,
    "version": ""
}